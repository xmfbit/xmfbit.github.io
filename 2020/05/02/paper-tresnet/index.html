<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="paper,">





  <link rel="alternate" href="/atom.xml" title="来呀，快活呀~" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="作者在摘要中所想的我们在工作中也观察到，尽管最近两年关于CNN网络的设计仍然有各式各样论文出现，比如Mobilenet / ShuffleNet，又或者是NAS搜索的网络结构如EfficientNet等，实际在GPU上使用起来并没有设想的那么high performance（latency / throughput），反而是ResNet系列历久弥新，真正经受住了工业界的考验，仍然是最常用的模型（可">
<meta name="keywords" content="paper">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读 - TResNet High Performance GPU-Dedicated Architecture">
<meta property="og:url" content="https://xmfbit.github.io/2020/05/02/paper-tresnet/index.html">
<meta property="og:site_name" content="来呀，快活呀~">
<meta property="og:description" content="作者在摘要中所想的我们在工作中也观察到，尽管最近两年关于CNN网络的设计仍然有各式各样论文出现，比如Mobilenet / ShuffleNet，又或者是NAS搜索的网络结构如EfficientNet等，实际在GPU上使用起来并没有设想的那么high performance（latency / throughput），反而是ResNet系列历久弥新，真正经受住了工业界的考验，仍然是最常用的模型（可">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_sota_benchmark.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_our_result.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_stem_design.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_aa.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_arch_overall.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_se_layer.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_single_block.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_comparison_with_resnet.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_ablation_study.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_tresnet_main_work.png">
<meta property="og:updated_time" content="2020-05-04T14:38:02.776Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文阅读 - TResNet High Performance GPU-Dedicated Architecture">
<meta name="twitter:description" content="作者在摘要中所想的我们在工作中也观察到，尽管最近两年关于CNN网络的设计仍然有各式各样论文出现，比如Mobilenet / ShuffleNet，又或者是NAS搜索的网络结构如EfficientNet等，实际在GPU上使用起来并没有设想的那么high performance（latency / throughput），反而是ResNet系列历久弥新，真正经受住了工业界的考验，仍然是最常用的模型（可">
<meta name="twitter:image" content="https://xmfbit.github.io/img/paper_tresnet_sota_benchmark.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://xmfbit.github.io/2020/05/02/paper-tresnet/">





  <title> 论文阅读 - TResNet High Performance GPU-Dedicated Architecture | 来呀，快活呀~ </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89140122-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">来呀，快活呀~</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://xmfbit.github.io/2020/05/02/paper-tresnet/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="一个脱离了高级趣味的人">
    <meta itemprop="description" content>
    <meta itemprop="image" content="/avatar/liumengli.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="来呀，快活呀~">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="来呀，快活呀~" src>
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                论文阅读 - TResNet High Performance GPU-Dedicated Architecture
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-02T15:35:49+00:00">
                2020-05-02
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>作者在摘要中所想的我们在工作中也观察到，尽管最近两年关于CNN网络的设计仍然有各式各样论文出现，比如Mobilenet / ShuffleNet，又或者是NAS搜索的网络结构如EfficientNet等，实际在GPU上使用起来并没有设想的那么high performance（latency / throughput），反而是ResNet系列历久弥新，真正经受住了工业界的考验，仍然是最常用的模型（可以很肯定没有之一），尤其是50，在速度和精度上达到了很好的trade off。</p>
<blockquote>
<p>vanilla ResNet50 is usually significantly faster than its recent competitors, of- fering better throughput-accuracy trade-off.</p>
</blockquote>
<p>深度学习技术现在早已经走出了学术象牙塔，在工业界广泛铺开。在精度已经没有太多提升空间的现在，网络的计算资源消耗 / latency / QPS等越来越成为大家关注的热点。这篇文章就试图在维持网络high performance的前提，提升网络的精度。这在现实问题中很有意义。</p>
<p><img src="/img/paper_tresnet_sota_benchmark.png" alt="SOTA模型的benchmark"></p>
<a id="more"></a>
<h1 id="你们呐，还是Too-young-too-simple"><a href="#你们呐，还是Too-young-too-simple" class="headerlink" title="你们呐，还是Too young, too simple"></a>你们呐，还是Too young, too simple</h1><p>见题图，作者比较了几种SOTA模型和ResNet-50在train和inference的速度（其实体现的是大批量时候的吞吐），可以看到最过分的是EfficientNet和MixNet，FLOPS比ResNet低了这么多，吞吐反而不如（如果没有Google的TPU加持，还是不要挑战EfficientNet了，我们的实测也是发现很坑）。</p>
<p>GPU的计算力越来越强，很多时候其实并不是FLOPS限制了网络的能力，而是访存。</p>
<ul>
<li>EfficientNet / ResNext / MixNet：使用分离卷积降低了FLOPS，但是实际考虑GPU吞吐量时，更重要的是访存，而不是节省的那一点FLOPS。就像这个帖子里面所讨论的那样<a href="https://github.com/pytorch/pytorch/issues/18631" target="_blank" rel="noopener">FP32 depthwise convolution is slow in GPU #18631</a></li>
</ul>
<blockquote>
<p>PS: Depthwise and group convolution is slower due to lower arithmetic intensity i.e. reduced data reuse (both leads to fragmented memory-accesses). Its a feature not a bug. Only specialized implementation can make it fast.</p>
</blockquote>
<ul>
<li>multi-path的使用。在训练的时候，需要为这些路径上的激活都储存相应的grad，造成显存占用上升，不利于大batch size，导致吞吐下降。</li>
</ul>
<p>这里作者对访存的diss之前也看过其他人的分析，我并不是做体系结构的。不过据我所知，很多神经网络加速器也是在解决这个问题。随着芯片的计算能力越来越强，XXTFLOPS的能力，却会被mem访问速度限制。IC设计和半导体产业就这样，不断地在实际中发现问题解决问题，让我们从五十年前（现在看来）孱弱的计算力，一步步发展到今天便捷的手机和强大的GPU。而计算能力的提升，又不断地催生新的技术应用。提出新的问题。电气革命依靠的是对化石能源的利用，而信息革命离不开计算能力的不断发掘。摩尔定律万岁~</p>
<p><img src="/img/paper_tresnet_our_result.png" alt="结果"></p>
<h1 id="TResNet的设计"><a href="#TResNet的设计" class="headerlink" title="TResNet的设计"></a>TResNet的设计</h1><p>怎么说呢，这里的设计好像并没有什么太深入的东西。也是读到这里，让我对这篇文章的价值觉得没这么大了。</p>
<h2 id="Stem设计"><a href="#Stem设计" class="headerlink" title="Stem设计"></a>Stem设计</h2><p>Stem指的是data输入到ResNet连读堆叠block之间的那个部分，起到的作用是迅速downsample输入。例如ResNet使用$7\times 7$，stride为2的conv和max pooling串联，将输入从224缩小到56。其他网络也都有类似的设计。在<a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="noopener">Bag of tricks</a>这篇文章中，ResNet-D是将$7\times 7$的conv分解为两个$3\times 3$的conv，</p>
<p>这里TResNet使用了一个“Space-To-Depth” layer，将spatial转到depth维度上去，达到缩小尺寸的目的，再接一个$1\times 1$的conv，得到想要的channel数量。</p>
<p><img src="/img/paper_tresnet_stem_design.png" alt="stem design"></p>
<p>代码中有这个layer的具体实现方式。类似ShuffleNet，以H为例，会将其分为若干组，即<code>bs</code>，然后重组。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpaceToDepth</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block_size=<span class="number">4</span>)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="keyword">assert</span> block_size == <span class="number">4</span></span><br><span class="line">        self.bs = block_size</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        N, C, H, W = x.size()</span><br><span class="line">        <span class="comment"># reshape NCHW -&gt; NCH'BW'B</span></span><br><span class="line">        x = x.view(N, C, H // self.bs, self.bs, W // self.bs, self.bs)  <span class="comment"># (N, C, H//bs, bs, W//bs, bs)</span></span><br><span class="line">        <span class="comment"># transpose: NBBCH'W'</span></span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>).contiguous()  <span class="comment"># (N, bs, bs, C, H//bs, W//bs)</span></span><br><span class="line">        <span class="comment"># reshape -&gt; NC'H'W'</span></span><br><span class="line">        x = x.view(N, C * (self.bs ** <span class="number">2</span>), H // self.bs, W // self.bs)  <span class="comment"># (N, C*bs^2, H//bs, W//bs)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>这个操作来自于这篇文章<a href="https://arxiv.org/abs/1909.03205" target="_blank" rel="noopener">Non-discriminative data or weak model? On the relative importance of data and model resolution</a>。核心观点是“是网络内部的feature map的resolution影响网络acc，而不是输入”</p>
<blockquote>
<p>In this paper, we show that up to a point, the input resolution alone plays little role in the network performance, and it is the internal resolution that is the critical driver of model quality. We then build on these insights to develop novel neural network architectures that we call \emph{Isometric Neural Networks}. These models maintain a fixed internal resolution throughout their entire depth. </p>
</blockquote>
<h2 id="抗混叠（anti-alias）下采样-AA"><a href="#抗混叠（anti-alias）下采样-AA" class="headerlink" title="抗混叠（anti-alias）下采样 - AA"></a>抗混叠（anti-alias）下采样 - AA</h2><p>将ResNet中的下采样换成一种比较经济的AA：stride为2的conv被替换为stride为1的conv，再接上stride为2的blur $3\times 3$的conv kernel</p>
<p><img src="/img/paper_tresnet_aa.png" alt="AA"></p>
<p>具体实现代码（只展示了blur的$3\times 3$conv）如下。可以看到这里直接使用了$3\times 3$的<a href="https://en.wikipedia.org/wiki/Gaussian_blur" target="_blank" rel="noopener">高斯模糊kernel</a>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Downsample</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, filt_size=<span class="number">3</span>, stride=<span class="number">2</span>, channels=None)</span>:</span></span><br><span class="line">        super(Downsample, self).__init__()</span><br><span class="line">        self.filt_size = filt_size</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.channels = channels</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> self.filt_size == <span class="number">3</span></span><br><span class="line">        a = torch.tensor([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">1.</span>])</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">In [2]: a = torch.tensor([1., 2., 1.])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [3]: filt = (a[:, None] * a[None, :])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [4]: filt</span></span><br><span class="line"><span class="string">Out[4]:</span></span><br><span class="line"><span class="string">tensor([[1., 2., 1.],</span></span><br><span class="line"><span class="string">        [2., 4., 2.],</span></span><br><span class="line"><span class="string">        [1., 2., 1.]])</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        filt = (a[:, <span class="literal">None</span>] * a[<span class="literal">None</span>, :])</span><br><span class="line">        filt = filt / torch.sum(filt)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.filt = filt[None, None, :, :].repeat((self.channels, 1, 1, 1))</span></span><br><span class="line">        self.register_buffer(<span class="string">'filt'</span>, filt[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat((self.channels, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        input_pad = F.pad(input, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="string">'reflect'</span>)</span><br><span class="line">        <span class="keyword">return</span> F.conv2d(input_pad, self.filt, stride=self.stride, padding=<span class="number">0</span>, groups=input.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h2 id="Inplace-Activated-BN-Inplace-ABN"><a href="#Inplace-Activated-BN-Inplace-ABN" class="headerlink" title="Inplace Activated BN (Inplace ABN)"></a>Inplace Activated BN (Inplace ABN)</h2><p>把所有的BN+ReLU结构换成了Inplace Activated BN，节省训练时候的显存消耗，并使用Leaky ReLU替换了plain ReLU。使用Inplace ABN增大了少许计算量，不过大大增加了batch size，从而增大了网络的吞吐。</p>
<h2 id="Block-选择"><a href="#Block-选择" class="headerlink" title="Block 选择"></a>Block 选择</h2><p>ResNet论文中，对于不同深度的网络，采取了两种不同的Block构造方法，plain是指bypass直接堆叠$3\times 3$的两个conv。bottleneck指bypass首尾使用$1\times 1$来reduce depth，中间使用单个$3\times 3$的conv。对于18和34层网络，使用plain；对于50及以上使用bottleneck。</p>
<p>这里作者认为plain结构有更大的感受野，所以放在网络浅层（前两个stage）；bottleneck放在网络深层（后两个stage）。具体网络结构见下图：</p>
<p><img src="/img/paper_tresnet_arch_overall.png" alt="arch overall"></p>
<h2 id="SE-op"><a href="#SE-op" class="headerlink" title="SE op"></a>SE op</h2><p>SENet提出的SE改进用的比较多了。这里作者加进来主要是为了提高网络的acc。具体见下吧，没什么好说的：</p>
<p><img src="/img/paper_tresnet_se_layer.png" alt="SE使用"></p>
<p>最后，TResNet的单个block进化成了这个样子：</p>
<p><img src="/img/paper_tresnet_single_block.png" alt="Block in TResNet"></p>
<h2 id="Code-optimization"><a href="#Code-optimization" class="headerlink" title="Code optimization"></a>Code optimization</h2><p>作者这里花了不少的篇幅讲如何使用jit等trick在PyTorch中加速TResNet。据我们的使用经验，jit是有用，但是会被TRT落下一大截。所以用PyTorch native模型去部署并没有什么意思。TResNet中的操作也都是可以TensorRT化的，然而我对它TensorRT的速度持怀疑态度。</p>
<p>所以这里其实我并没有看。有兴趣的话可以对照代码学习下，包括jit的使用。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验结果这里贴一下。作者构造了M / L / XL三个系列（大杯，超大杯？），其实M是用来和ResNet-50打擂台的。</p>
<p><img src="/img/paper_tresnet_comparison_with_resnet.png" alt="比较"></p>
<p>下面的消融实验我觉得还是有一定意义的。</p>
<p><img src="/img/paper_tresnet_ablation_study.png" alt="消融实验"></p>
<p>此外，增大input的分辨率一般也能提升网络acc，当然也会拖慢网络。这里作者进行了测试。发现TResNet-M在输入size为448情况下，也能有很大的提升。具体数据这里不贴了。</p>
<p>后面和EfficientNet的比较不多说了。不用TPU，EfficientNet并没有多实用。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这篇文章读下来，并没有标题和摘要那般有意义。又是ResNet-50被拉出来打，最后其实速度也没提升多少。训练速度其实我们并不太care；inference速度的话和ResNet-50不相上下，而acc其实也高了一点而已。据我们实际工作观察，有TRT加持的ResNet-50的速度更是起飞（nv对ResNet做了很多对应的trick加速，甚至有block级别的plugin加速支持。。见<a href="https://github.com/mlperf/inference_results_v0.5/tree/master/closed/NVIDIA/code/resnet/tensorrt" target="_blank" rel="noopener">ResNet50 Benchmark</a>）。所以其实如果用TRT部署，目测这篇文章的模型结构是拼不过ResNet的。</p>
<p>TResNet把前人的工作做了一个杂烩。又想快又想acc高怎么办？增大吞吐。然而对于GPU这种已经定型的硬件，其实就是增大batch size。。。简单总结下：</p>
<ul>
<li>提升acc：auti-alias downsampling，leaky-relu，se</li>
<li>提升吞吐：spatial-to-depth，inplace-ABN，se不全用，plain / bottleneck 混用</li>
</ul>
<p>当然，上面两个具体内容是有交叉的。</p>
<p><img src="/img/paper_tresnet_main_work.png" alt="main work"></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/paper/" rel="tag"># paper</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/04/15/paper-tf-training-aweare-quantization/" rel="next" title="论文 - Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference">
                <i class="fa fa-chevron-left"></i> 论文 - Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
        <div id="lv-container" data-id="city" data-uid="MTAyMC8yODMwOS80ODgx"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/avatar/liumengli.jpg" alt="一个脱离了高级趣味的人">
          <p class="site-author-name" itemprop="name">一个脱离了高级趣味的人</p>
          <p class="site-description motion-element" itemprop="description">相与枕藉乎舟中，不知东方之既白</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">89</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/xmfbit" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2629935075/" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#你们呐，还是Too-young-too-simple"><span class="nav-number">1.</span> <span class="nav-text">你们呐，还是Too young, too simple</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TResNet的设计"><span class="nav-number">2.</span> <span class="nav-text">TResNet的设计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Stem设计"><span class="nav-number">2.1.</span> <span class="nav-text">Stem设计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#抗混叠（anti-alias）下采样-AA"><span class="nav-number">2.2.</span> <span class="nav-text">抗混叠（anti-alias）下采样 - AA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inplace-Activated-BN-Inplace-ABN"><span class="nav-number">2.3.</span> <span class="nav-text">Inplace Activated BN (Inplace ABN)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Block-选择"><span class="nav-number">2.4.</span> <span class="nav-text">Block 选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SE-op"><span class="nav-number">2.5.</span> <span class="nav-text">SE op</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Code-optimization"><span class="nav-number">2.6.</span> <span class="nav-text">Code optimization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验"><span class="nav-number">3.</span> <span class="nav-text">实验</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">一个脱离了高级趣味的人</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



    
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  





  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
