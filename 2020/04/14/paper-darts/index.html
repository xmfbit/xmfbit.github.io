<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="paper,nas,">





  <link rel="alternate" href="/atom.xml" title="来呀，快活呀~" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="NAS的文章很多了，这篇介绍DARTS：DARTS: DIFFERENTIABLE ARCHITECTURE SEARCH">
<meta name="keywords" content="paper,nas">
<meta property="og:type" content="article">
<meta property="og:title" content="论文 - DARTS">
<meta property="og:url" content="https://xmfbit.github.io/2020/04/14/paper-darts/index.html">
<meta property="og:site_name" content="来呀，快活呀~">
<meta property="og:description" content="NAS的文章很多了，这篇介绍DARTS：DARTS: DIFFERENTIABLE ARCHITECTURE SEARCH">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_basic_idea.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_optimization_goal.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_approximate_gd.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_alg_precedure.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_apply_chain_rule.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_diff_as_gradient.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_hyper_param_exp_value.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_convergence_discussion.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_net_arch_on_cifar10.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_sota_comparision_cnn.png">
<meta property="og:image" content="https://xmfbit.github.io/img/paper_darts_result_imagenet.png">
<meta property="og:updated_time" content="2021-11-17T13:18:53.902Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文 - DARTS">
<meta name="twitter:description" content="NAS的文章很多了，这篇介绍DARTS：DARTS: DIFFERENTIABLE ARCHITECTURE SEARCH">
<meta name="twitter:image" content="https://xmfbit.github.io/img/paper_darts_basic_idea.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://xmfbit.github.io/2020/04/14/paper-darts/">





  <title> 论文 - DARTS | 来呀，快活呀~ </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89140122-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">来呀，快活呀~</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://xmfbit.github.io/2020/04/14/paper-darts/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="一个脱离了高级趣味的人">
    <meta itemprop="description" content>
    <meta itemprop="image" content="/avatar/liumengli.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="来呀，快活呀~">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="来呀，快活呀~" src>
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                论文 - DARTS
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-14T21:12:52+00:00">
                2020-04-14
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>NAS的文章很多了，这篇介绍DARTS：<a href="https://arxiv.org/abs/1806.09055" target="_blank" rel="noopener">DARTS: DIFFERENTIABLE ARCHITECTURE SEARCH</a></p>
<p><img src="/img/paper_darts_basic_idea.png" alt="darts的基本思路"></p>
<a id="more"></a>
<h1 id="搜索空间"><a href="#搜索空间" class="headerlink" title="搜索空间"></a>搜索空间</h1><p>基本沿用前人工作的基本设定：</p>
<ul>
<li>每个cell是由$N$个有序的节点组成的DAG。其中，每个节点$x^{(i)}$表示一个feature map，节点之间的有向弧$E(i,j)$表示由$x^{(i)}$到$x^{(j)}$的某种操作（operation）$o^{(i,j)}$</li>
<li>每个cell有两个输入，一个输出。两个输入分别是第$i-1$个和$i-2$个cell的输出（假设当前cell是第$i$个）。输出是cell内所有节点应用某种Reduction操作（如concat）得到的</li>
<li>每个节点的值是由它前面的所有节点决定的：</li>
</ul>
<script type="math/tex; mode=display">x^{(j)} = \sum_{i<j}o^{(i,j)}x^{(i)}</script><ul>
<li>特殊op“Zero”，表示两个节点之间其实没有连接。</li>
</ul>
<p>遵循上面的设定，网络结构的搜索，就转换为了搜索节点之间operation的问题。下面，我们就对这个问题建模，将它转换为一个可微分用梯度下降搜索的优化问题。</p>
<h1 id="松弛"><a href="#松弛" class="headerlink" title="松弛"></a>松弛</h1><p>“松弛”是一种优化中常用的技巧。</p>
<p>设搜索空间内的所有可能op的集合为$\mathcal{O}$。本来$x^{(i)}$到$x^{(j)}$的op是在这个集合中离散地取值，但是现在我们把它松弛为一个连续问题：</p>
<script type="math/tex; mode=display">\bar{o} = \sum_{o\in\mathcal{O}}\frac{\exp(\alpha_o)}{\sum_{o^{\prime}\in\mathcal{O}}\exp(\alpha_{o^{\prime}})}o</script><p>其中，$\alpha$是一个长度为$|\mathcal{O}|$的向量，$\alpha_o$是里面对应于操作$o$的权重。</p>
<p>当搜索过程结束后，选取$\mathcal{O}$中能够使得$\alpha$中分量最大的那个元素$o^\ast$就是最终两个节点的连接op：</p>
<script type="math/tex; mode=display">o^{\ast} =\underset{o\in\mathcal{O}}{\operatorname{argmax}} \alpha_o</script><p>当然，除了网络结构，我们还需要去学习网络的权重参数$w$。所以整个问题是一个<a href="https://en.wikipedia.org/wiki/Bilevel_optimization" target="_blank" rel="noopener">bi-level</a>的优化问题，$\alpha$是upper-level变量，$w$是lower-level变量。PS：超参数搜索也有相关工作将其建模为bi-level的优化问题求解。</p>
<p>也就是说，给定某个$\alpha$（也就是某个确定的网络结构），在训练集上得到最优的$w$，并将当前的网络结构和权重在验证集上做评估。那个在验证集上得到最好的结果对应的网络结构，就是我们要找的$\alpha$，而网络的权重$w$也对应得出。</p>
<p><img src="/img/paper_darts_optimization_goal.png" alt="优化目标"></p>
<p>也就是说，我们需要最小化模型在验证集上的损失函数；其中，$w$是$\alpha$的某个函数（在这里，$\alpha$是和某个网络结构一一对应的），需要满足训练集上的损失函数最小。</p>
<h1 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h1><p>我们已经把DARTS抽象成了一个优化问题，下面考虑如何高效求解。</p>
<p>显然，按照上面的想法，给定网络结构后，在训练集上得到最优的$w$，再去验证集上跑评估，是不现实的。一是搜索空间巨大，耗时太长；二是仍然无法根据当前的$\alpha$，得到下一步该向哪里走，难道仍然要用启发式或诸如进化算法等方法？如果是求导，那这个链路也太长了，根本不现实。这里作者指出，可以用如下的方式近似梯度：</p>
<p><img src="/img/paper_darts_approximate_gd.png" alt="论文中使用的approximate gradient descent"></p>
<p>看起来括号里面的内容是把求解$w^\ast$的$N$步迭代只取了一步。</p>
<script type="math/tex; mode=display">w^\ast = w - \sum_{N}\xi\frac{\partial\mathcal{L}_{\text{train}}(w,\alpha)}{\partial w}|_{w_i}</script><p>为什么能这样近似？似乎没有什么严密的理论支撑，作者对这个“瑕疵”的处理方法是：</p>
<ul>
<li>拿出CIFAR10和ImageNet以及PTB等数据集上的结果，证明算法在实际上是可以work的，而且效果很好</li>
<li>后面给出了一个在简单优化问题上的讨论</li>
<li>给出了关于超参数设置的经验技巧，最重要的还放出了源码</li>
</ul>
<p>这无疑让整个文章的可信度大大增强。</p>
<p>算法迭代步骤可以描述如下：</p>
<p><img src="/img/paper_darts_alg_precedure.png" alt="迭代"></p>
<p>不过上面的算法描述在实际中并不好用，因为$\alpha$的那一坨梯度一看就很不好求。我们可以通过链式求导法则将其展开。</p>
<p>考虑函数$f(x, g(x))$对$x$的导数$\frac{df}{dx}$。首先令$y = g(x)$，有全微分：</p>
<script type="math/tex; mode=display">df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy</script><p>而且，有$dy = \frac{dg}{dx} dx$。所以，</p>
<script type="math/tex; mode=display">\frac{df}{dx} = \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} \frac{dg}{dx}</script><p>回归我们的问题，令$x = \alpha$，$w^\prime = g(\alpha) = w - \xi\nabla_w\mathcal{L}_{train}(w, \alpha)$。</p>
<p>有</p>
<script type="math/tex; mode=display">\frac{dw^\prime}{d\alpha} = -\xi \nabla^2_{w,\alpha}\mathcal{L}_{train}(w,\alpha)</script><p>将它代回上面$\frac{df}{dx}$，就得到了论文里面的形式：</p>
<p><img src="/img/paper_darts_apply_chain_rule.png" alt="论文给出的形式"></p>
<p>化简还没有结束。考虑到$\nabla_w\mathcal{L}_{train}$已经是一个$\mathbb{R}^n$的向量，再对$\alpha$求导，就是一个雅克比矩阵。再和后面那个梯度向量相乘，导致计算量很大。这里作者采用了差分近似微分的方法：</p>
<p><img src="/img/paper_darts_diff_as_gradient.png" alt="差分近似微分"></p>
<p>下面是作者的具体计算代码：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新 \alpha</span></span><br><span class="line">architect.step(input, target, input_search, target_search, lr, optimizer, unrolled=args.unrolled)</span><br><span class="line"><span class="comment"># 更新w</span></span><br><span class="line">optimizer.zero_grad()</span><br></pre></td></tr></table></figure>
<p>下面进入<code>Architect</code>类的内部看下<code>step</code>的实现。当令$\xi=0$时，$w$不用前进一步，<code>architect.step</code>比较简单（对应于<code>unrolled=False</code>）:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_backward_step</span><span class="params">(self, input_valid, target_valid)</span>:</span></span><br><span class="line">  <span class="comment"># loss = L_val(w, alpha)</span></span><br><span class="line">  loss = self.model._loss(input_valid, target_valid)</span><br><span class="line">  loss.backward()</span><br></pre></td></tr></table></figure>
<p>当$\xi\neq 0$时，$w$要在train集合上前进一步，对应于<code>unrolled=True</code>：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_backward_step_unrolled</span><span class="params">(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer)</span>:</span></span><br><span class="line">  <span class="comment"># 在train上更新w = w - \xi * dL_train(w, alpha) / dw</span></span><br><span class="line">  unrolled_model = self._compute_unrolled_model(input_train, target_train, eta, network_optimizer)</span><br><span class="line">  <span class="comment"># 在target上计算loss，然后对alpha求导</span></span><br><span class="line">  unrolled_loss = unrolled_model._loss(input_valid, target_valid)</span><br><span class="line"></span><br><span class="line">  unrolled_loss.backward()</span><br><span class="line">  dalpha = [v.grad <span class="keyword">for</span> v <span class="keyword">in</span> unrolled_model.arch_parameters()]</span><br><span class="line">  vector = [v.grad.data <span class="keyword">for</span> v <span class="keyword">in</span> unrolled_model.parameters()]</span><br><span class="line">  <span class="comment"># 就是那个差分替代微分的式子</span></span><br><span class="line">  implicit_grads = self._hessian_vector_product(vector, input_train, target_train)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> g, ig <span class="keyword">in</span> zip(dalpha, implicit_grads):</span><br><span class="line">    g.data.sub_(eta, ig.data)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 更新alpha</span></span><br><span class="line">  <span class="keyword">for</span> v, g <span class="keyword">in</span> zip(self.model.arch_parameters(), dalpha):</span><br><span class="line">    <span class="keyword">if</span> v.grad <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      v.grad = Variable(g.data)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      v.grad.data.copy_(g.data)</span><br></pre></td></tr></table></figure>
<p>差分的计算具体是这里。注意到作者提到了两个超参数的经验值：</p>
<p><img src="/img/paper_darts_hyper_param_exp_value.png" alt="经验值设置"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_hessian_vector_product</span><span class="params">(self, vector, input, target, r=<span class="number">1e-2</span>)</span>:</span></span><br><span class="line">  <span class="comment"># R = \epsilon，按照上面的经验值公式求取</span></span><br><span class="line">  R = r / _concat(vector).norm()</span><br><span class="line">  <span class="comment"># 这是前面那一项</span></span><br><span class="line">  <span class="keyword">for</span> p, v <span class="keyword">in</span> zip(self.model.parameters(), vector):</span><br><span class="line">    p.data.add_(R, v)</span><br><span class="line">  loss = self.model._loss(input, target)</span><br><span class="line">  grads_p = torch.autograd.grad(loss, self.model.arch_parameters())</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 这是后面那一项</span></span><br><span class="line">  <span class="keyword">for</span> p, v <span class="keyword">in</span> zip(self.model.parameters(), vector):</span><br><span class="line">    p.data.sub_(<span class="number">2</span>*R, v)</span><br><span class="line">  loss = self.model._loss(input, target)</span><br><span class="line">  grads_n = torch.autograd.grad(loss, self.model.arch_parameters())</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 别忘把w复原</span></span><br><span class="line">  <span class="keyword">for</span> p, v <span class="keyword">in</span> zip(self.model.parameters(), vector):</span><br><span class="line">    p.data.add_(R, v)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 最后的近似结果</span></span><br><span class="line">  <span class="keyword">return</span> [(x-y).div_(<span class="number">2</span>*R) <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(grads_p, grads_n)]</span><br></pre></td></tr></table></figure>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><h2 id="算法收敛的讨论"><a href="#算法收敛的讨论" class="headerlink" title="算法收敛的讨论"></a>算法收敛的讨论</h2><p>这里并没有数学上的证明保证方法的收敛性。作者也没有回避这一点，并指出，\xi 的选取对于是否收敛很重要。总之，实验效果很好，说明这个近似是可以work的。</p>
<blockquote>
<p>While we are not currently aware of the convergence guarantees for our optimization algorithm, in practice it is able to reach a fixed point with a suitable choice of ξ</p>
</blockquote>
<p>作者对其做在简单问题下的收敛做了讨论。</p>
<p><img src="/img/paper_darts_convergence_discussion.png" alt="简单问题上的讨论"></p>
<h2 id="CNN-CIFAR10"><a href="#CNN-CIFAR10" class="headerlink" title="CNN @ CIFAR10"></a>CNN @ CIFAR10</h2><h3 id="operation-set"><a href="#operation-set" class="headerlink" title="operation set"></a>operation set</h3><p>选择$3\times 3$，$5\times 5$的kernel size大小的分离卷积和pooling等，再加上identity和zero。具体可以参考代码：<a href="https://github.com/quark0/darts/blob/master/cnn/operations.py" target="_blank" rel="noopener">darts/cnn/operations.py</a>。例如，$3\times 3$的分离卷积如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 给定input channel和stride，生成3x3分离卷积</span></span><br><span class="line"><span class="comment"># 'sep_conv_3x3' : lambda C, stride, affine: SepConv(C, C, 3, stride, 1, affine=affine),</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看到是如下更小op的串联：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># relu -&gt; 3x3 seperable conv -&gt; bn -&gt; relu -&gt; 3x3 seperable conv(stride=1) -&gt; bn</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SepConv</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, C_in, C_out, kernel_size, stride, padding, affine=True)</span>:</span></span><br><span class="line">    super(SepConv, self).__init__()</span><br><span class="line">    self.op = nn.Sequential(</span><br><span class="line">      nn.ReLU(inplace=<span class="literal">False</span>),</span><br><span class="line">      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in, bias=<span class="literal">False</span>),</span><br><span class="line">      nn.Conv2d(C_in, C_in, kernel_size=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">      nn.BatchNorm2d(C_in, affine=affine),</span><br><span class="line">      nn.ReLU(inplace=<span class="literal">False</span>),</span><br><span class="line">      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=<span class="number">1</span>, padding=padding, groups=C_in, bias=<span class="literal">False</span>),</span><br><span class="line">      nn.Conv2d(C_in, C_out, kernel_size=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">      nn.BatchNorm2d(C_out, affine=affine),</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.op(x)</span><br></pre></td></tr></table></figure>
<p>主要特点是：</p>
<ul>
<li>顺序为relu -&gt; conv -&gt; bn</li>
<li>可分离卷积重复两次</li>
</ul>
<p>这也是前面NAS文章的惯常操作。</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>在Cell尺度上，每个cell由$N=7$个node组成。输入节点如前所述（有时候可能需要$1\times 1$节点），输出节点是该cell的所有中间节点（不包括input节点）在channel上的concat。</p>
<p>在网络宏观尺度上，cell堆叠形成最后的网络。Cell也被分为<code>normal</code>和<code>reduce</code>两种。后者会对输入节点取stride为$2$，从而downsampling。在网络的$1/3$和$2/3$深度处为reduce cell，其他为normal cell。normal和reduce cell分别有一套共享的$\alpha$参数。从而，整个网络的结构可以被两组$\alpha_{\text{normal}}$和$\alpha_{\text{reduce}}$完全描述。</p>
<p>下图直观地展示了在CIFAR10上搜索出来的cell结构：</p>
<ul>
<li>两个输入，一个输出，四个中间节点，它们通过concat操作成了输出</li>
<li>每个中间节点入度都是2，也就是我们选取的是$\alpha$中top $K=2$的op</li>
</ul>
<p><img src="/img/paper_darts_net_arch_on_cifar10.png" alt="DARTS在CIFAR10上搜出的cell"></p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>在CIFAR10上，搜出的网络性能和之前基于RL或进化算法的SOTA方法是可比的，而且GPU小时数明显缩短。DARTS方法和ENAS是少数能够在&lt;10 GPU*days的计算资源下做出比较好结果的方法。其中DARTS又比ENAS有较好的TestError。作者对此也做了说明：</p>
<blockquote>
<p>DARTS outperformed ENAS (Pham et al., 2018b) by discovering cells with comparable error rates but lessparameters. The longer search time is due to the fact that we have repeated the search process fourtimes for cell selection. This practice is less important for convolutional cells however, because theperformance of discovered architectures does not strongly depend on initialization</p>
</blockquote>
<p><img src="/img/paper_darts_sota_comparision_cnn.png" alt="CNN搜索与SOTA比较"></p>
<h2 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h2><p><img src="/img/paper_darts_result_imagenet.png" alt="在ImageNet上的结果"></p>
<h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><p>文章的主要工作：</p>
<ul>
<li>将NAS问题通过松弛建模为一个关于模型结构的优化问题</li>
<li>提出了一个不错的解决该优化问题的梯度下降解法</li>
<li>在相关任务上证明了方法的有效性</li>
<li>给大家在堆GPU资源用强化学习 / 进化算法之外，指出了一条可行的NAS求解之路</li>
</ul>
<p>文章的作者应该是有比较多的数学优化方面的知识。引入权重向量并softmax求取top K op应该是还算让人容易想到，但后面的优化求解就很容易出错劝退。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li>PyTorch实现的DARTS：<a href="https://github.com/quark0/darts" target="_blank" rel="noopener">quark0/darts</a></li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/paper/" rel="tag"># paper</a>
          
            <a href="/tags/nas/" rel="tag"># nas</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/04/06/mit-missing-semester-05-commandline-env/" rel="next" title="MIT Missing Semester - Command-line Environment">
                <i class="fa fa-chevron-left"></i> MIT Missing Semester - Command-line Environment
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/15/paper-tf-training-aweare-quantization/" rel="prev" title="论文 - Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference">
                论文 - Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
        <div id="lv-container" data-id="city" data-uid="MTAyMC8yODMwOS80ODgx"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/avatar/liumengli.jpg" alt="一个脱离了高级趣味的人">
          <p class="site-author-name" itemprop="name">一个脱离了高级趣味的人</p>
          <p class="site-description motion-element" itemprop="description">相与枕藉乎舟中，不知东方之既白</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">91</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/xmfbit" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2629935075/" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#搜索空间"><span class="nav-number">1.</span> <span class="nav-text">搜索空间</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#松弛"><span class="nav-number">2.</span> <span class="nav-text">松弛</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#求解"><span class="nav-number">3.</span> <span class="nav-text">求解</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiment"><span class="nav-number">4.</span> <span class="nav-text">Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#算法收敛的讨论"><span class="nav-number">4.1.</span> <span class="nav-text">算法收敛的讨论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN-CIFAR10"><span class="nav-number">4.2.</span> <span class="nav-text">CNN @ CIFAR10</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#operation-set"><span class="nav-number">4.2.1.</span> <span class="nav-text">operation set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构"><span class="nav-number">4.2.2.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实验结果"><span class="nav-number">4.2.3.</span> <span class="nav-text">实验结果</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ImageNet"><span class="nav-number">4.3.</span> <span class="nav-text">ImageNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#讨论"><span class="nav-number">4.4.</span> <span class="nav-text">讨论</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考资料"><span class="nav-number">5.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">一个脱离了高级趣味的人</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



    
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  





  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
