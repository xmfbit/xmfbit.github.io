<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="来呀，快活呀~" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="这是Bag of Tricks for Image Classification with Convolutional Neural Networks的笔记。这篇文章躺在阅读列表里面很久了，里面的技术之前也用了一些。最近趁着做SOTA模型的训练，把论文整体读了一下，记录在这里。这篇文章总结的仍然是在通用学术数据集上的tricks。对于实际工作中遇到的训练任务，仍然是要结合问题本身来改进模型和训练">
<meta property="og:type" content="article">
<meta property="og:title" content="论文 - Bag of Tricks for Image Classification with Convolutional Neural Networks">
<meta property="og:url" content="https://xmfbit.github.io/2019/07/06/bag-of-tricks-for-image-cls/index.html">
<meta property="og:site_name" content="来呀，快活呀~">
<meta property="og:description" content="这是Bag of Tricks for Image Classification with Convolutional Neural Networks的笔记。这篇文章躺在阅读列表里面很久了，里面的技术之前也用了一些。最近趁着做SOTA模型的训练，把论文整体读了一下，记录在这里。这篇文章总结的仍然是在通用学术数据集上的tricks。对于实际工作中遇到的训练任务，仍然是要结合问题本身来改进模型和训练">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://xmfbit.github.io/img/bag_of_tricks_no_silver_bullet.jpeg">
<meta property="og:image" content="https://xmfbit.github.io/img/bag_of_tricks_resnet50_overperform_others.jpg">
<meta property="og:image" content="https://xmfbit.github.io/img/bag_of_tricks_fp16_range_dismatch.jpg">
<meta property="og:image" content="https://xmfbit.github.io/img/bag_of_tricks_accelarate_training.jpg">
<meta property="og:image" content="https://xmfbit.github.io/img/bag_of_tricks_ablation_of_accelarate_train.jpg">
<meta property="og:updated_time" content="2020-03-21T02:02:44.778Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文 - Bag of Tricks for Image Classification with Convolutional Neural Networks">
<meta name="twitter:description" content="这是Bag of Tricks for Image Classification with Convolutional Neural Networks的笔记。这篇文章躺在阅读列表里面很久了，里面的技术之前也用了一些。最近趁着做SOTA模型的训练，把论文整体读了一下，记录在这里。这篇文章总结的仍然是在通用学术数据集上的tricks。对于实际工作中遇到的训练任务，仍然是要结合问题本身来改进模型和训练">
<meta name="twitter:image" content="https://xmfbit.github.io/img/bag_of_tricks_no_silver_bullet.jpeg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://xmfbit.github.io/2019/07/06/bag-of-tricks-for-image-cls/">





  <title> 论文 - Bag of Tricks for Image Classification with Convolutional Neural Networks | 来呀，快活呀~ </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-89140122-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">来呀，快活呀~</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://xmfbit.github.io/2019/07/06/bag-of-tricks-for-image-cls/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="一个脱离了高级趣味的人">
    <meta itemprop="description" content>
    <meta itemprop="image" content="/avatar/liumengli.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="来呀，快活呀~">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="来呀，快活呀~" src>
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                论文 - Bag of Tricks for Image Classification with Convolutional Neural Networks
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-06T05:52:45+00:00">
                2019-07-06
              </time>
            

            

            
          </span>

          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这是<a href="https://arxiv.org/abs/1812.01187" target="_blank" rel="external">Bag of Tricks for Image Classification with Convolutional Neural Networks</a>的笔记。这篇文章躺在阅读列表里面很久了，里面的技术之前也用了一些。最近趁着做SOTA模型的训练，把论文整体读了一下，记录在这里。这篇文章总结的仍然是在通用学术数据集上的tricks。对于实际工作中遇到的训练任务，仍然是要结合问题本身来改进模型和训练算法。毕竟，没有银弹。</p>
<p><img src="/img/bag_of_tricks_no_silver_bullet.jpeg" alt="软工里面没有银弹，数据科学同样这样"></p>
<a id="more"></a>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>这篇文章主要讨论了训练图片分类模型的tricks，包括data augmentation，（lr，batch size等）超参设置，模型架构微调和模型蒸馏等技术。可以在增加少许计算量的情况下，把ResNet-50的top 1 acc提升4个点，从而打败许多后起之秀。Talk is cheap, show me the code. 论文讨论的方法对应代码，都已经在GluonCV中开源，所以建议在阅读论文的时候，对照<a href="https://github.com/dmlc/gluon-cv/blob/master/scripts/classification/imagenet/train_imagenet.py" target="_blank" rel="external">代码</a>进行学习。</p>
<p><img src="/img/bag_of_tricks_resnet50_overperform_others.jpg" alt="ResNet-50的效果提升"></p>
<h2 id="Baseline-Training"><a href="#Baseline-Training" class="headerlink" title="Baseline Training"></a>Baseline Training</h2><p>这里介绍了一些（已经不算trick的）训练ResNet-50可以注意的地方。使用这些方法，应该可以复现论文中给出的结果。</p>
<h3 id="Data-Argumentation"><a href="#Data-Argumentation" class="headerlink" title="Data Argumentation"></a>Data Argumentation</h3><p>这里都是老生常谈了，可以直接参看代码<a href="https://github.com/dmlc/gluon-cv/blob/master/scripts/classification/imagenet/train_imagenet.py#L203" target="_blank" rel="external">gluon cv/image classification</a>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">jitter_param = <span class="number">0.4</span></div><div class="line">lighting_param = <span class="number">0.1</span></div><div class="line">mean_rgb = [<span class="number">123.68</span>, <span class="number">116.779</span>, <span class="number">103.939</span>]</div><div class="line">std_rgb = [<span class="number">58.393</span>, <span class="number">57.12</span>, <span class="number">57.375</span>]</div><div class="line">train_data = mx.io.ImageRecordIter(</div><div class="line">    path_imgrec         = rec_train,</div><div class="line">    path_imgidx         = rec_train_idx,</div><div class="line">    preprocess_threads  = num_workers,</div><div class="line">    shuffle             = <span class="keyword">True</span>,</div><div class="line">    batch_size          = batch_size,</div><div class="line">    data_shape          = (<span class="number">3</span>, input_size, input_size),</div><div class="line">    mean_r              = mean_rgb[<span class="number">0</span>],</div><div class="line">    mean_g              = mean_rgb[<span class="number">1</span>],</div><div class="line">    mean_b              = mean_rgb[<span class="number">2</span>],</div><div class="line">    std_r               = std_rgb[<span class="number">0</span>],</div><div class="line">    std_g               = std_rgb[<span class="number">1</span>],</div><div class="line">    std_b               = std_rgb[<span class="number">2</span>],</div><div class="line">    rand_mirror         = <span class="keyword">True</span>,</div><div class="line">    random_resized_crop = <span class="keyword">True</span>,</div><div class="line">    max_aspect_ratio    = <span class="number">4.</span> / <span class="number">3.</span>,</div><div class="line">    min_aspect_ratio    = <span class="number">3.</span> / <span class="number">4.</span>,</div><div class="line">    max_random_area     = <span class="number">1</span>,</div><div class="line">    min_random_area     = <span class="number">0.08</span>,</div><div class="line">    brightness          = jitter_param,</div><div class="line">    saturation          = jitter_param,</div><div class="line">    contrast            = jitter_param,</div><div class="line">    pca_noise           = lighting_param,</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><ul>
<li>使用Xavier初始化卷积层和全连接层的权重，也就是$w\sim \mathcal{U}(-a, a)$，其中$a = \sqrt{6/(d_{in} + d_{out})}$，$d$是输入和输出的channel size。偏置项初始化为$0$。</li>
<li>BatchNorm的$\gamma$初始化为$1$，偏置项为$0$。</li>
</ul>
<h3 id="训练参数"><a href="#训练参数" class="headerlink" title="训练参数"></a>训练参数</h3><p>8卡V100，batch size = 256，使用NAG梯度下降，lr从0.1，在30，60，90epoch处除以10。</p>
<p>使用上述设置，得到的ResNet-50模型比原始论文更好，不过Inception-V3（输入为$229\times 229$大小）和MobileNet稍差于原始论文。</p>
<h2 id="更快地训练"><a href="#更快地训练" class="headerlink" title="更快地训练"></a>更快地训练</h2><p>主要讨论使用低精度（FP16）和大batch size对训练的影响。</p>
<h3 id="大batch-size"><a href="#大batch-size" class="headerlink" title="大batch size"></a>大batch size</h3><p>大的batch size经常会导致模型的val acc降低（一个简单的解释是，大batch size造成iteration次数减少，导致模型效果变差。当然，实际训练中，大batch size常常搭配较大的lr，所以问题并不是这么简单），可以考虑使用下面的方法解决这个问题。</p>
<h4 id="（成比例）提高lr"><a href="#（成比例）提高lr" class="headerlink" title="（成比例）提高lr"></a>（成比例）提高lr</h4><p>上面说的iteration次数减少是一个方面。另一个考虑是大的batch size会造成对梯度的估计方差变小，我们可以乘上一个较大的lr，让方差的不确定性增大一些。一个经验之谈是，lr随着batch size成比例扩大。比如在训练ResNet-50的时候，He给出的在$B = 256$时，lr取为$0.1$。那么如果$B = 512$，那么lr也相应扩大为$0.2$。</p>
<h4 id="lr-warm-up"><a href="#lr-warm-up" class="headerlink" title="lr warm up"></a>lr warm up</h4><p>如果lr初始设置的很大，可能会带来数值不稳定。因为刚开始的时候权重是随机初始化的，gradient也比较大。可以给lr做warm up，也就是开始若干个迭代用较小的lr，等训练稳定了再用回那个大的lr。一种方法是线性warm up，也就是在warm up阶段，lr是线性地从0涨到给定的那个大lr。</p>
<h4 id="设置-gamma-0"><a href="#设置-gamma-0" class="headerlink" title="设置$\gamma = 0$"></a>设置$\gamma = 0$</h4><p>这个操作比较新奇，在初始阶段，BN的$\beta$参数是设置为$0$的。如果我们再设置$\gamma = 0$，说明BN的输出就是$0$了。这是什么操作？！</p>
<p>作者指出，可以在ResNet这种有by-pass的结构中使用这个trick。在ResNet block的最后一层，我们经常做$y = x + res(x)$，可以考虑将res这一路的最后一个BN层的$\gamma$参数设置为0。这时候，相当于只有输入$x$传到后面，相当于减少了网络的层深。之后的训练中，$\gamma$会逐渐变大，也就逐渐恢复了res通路。</p>
<p>这种方法也是试图解决网络训练初始阶段不稳定的问题。不过这个操作还是挺骚的。。。类似的方法（利用BN层的$\gamma$参数）也见到过被用在模型剪枝上，如Net Sliming等方法。可以参见博客中的相关文章讨论。</p>
<h4 id="weight-decay"><a href="#weight-decay" class="headerlink" title="weight decay"></a>weight decay</h4><p>给weight加上L2 norm来做weight decay，是缓解网络过拟合的标准解决办法之一。不过，最好只对conv和fc的kernel做，而不要对它们的bias，BN的$\gamma$和$\beta$做。</p>
<p>上面的方法，在batch size不大于2K的时候，应该是够用了的。</p>
<h3 id="低精度"><a href="#低精度" class="headerlink" title="低精度"></a>低精度</h3><p>很多新GPU都加入了FP16的硬件支持，例如V100上使用FP16比FP32，训练能够加速$2$到$3$倍。FP16的问题是表示范围变小了，同时分辨率变小。对应地会造成两个问题，溢出和无法更新（梯度过小，不到FP16的最小表示）。一种解决办法是使用FP16来做forward和backward，但是在FP32上更新梯度（防止梯度过小）。同时给loss乘上一个系数，让它更好地契合FP16能表示的数据范围。</p>
<p>这里简要介绍下FP16精度的相关内容。关于Nvidia GPU FP16的更多信息，可以参考<a href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" target="_blank" rel="external">Nvidia文档混合精度训练</a>。</p>
<h4 id="FP16数据表示"><a href="#FP16数据表示" class="headerlink" title="FP16数据表示"></a>FP16数据表示</h4><p>FP16，顾名思义，就是使用16个bit表示浮点数。具体编码方式上，和FP32基本一致，只不过位数有了缩水。</p>
<blockquote>
<p>IEEE 754 standard defines the following 16-bit half-precision floating point format: 1 sign bit, 5 exponent bits, and 10 fractional bits.</p>
</blockquote>
<p>TODO: FP32和FP16的比较</p>
<h4 id="FP16-in-MXNet"><a href="#FP16-in-MXNet" class="headerlink" title="FP16 in MXNet"></a>FP16 in MXNet</h4><p>在MXNet中，使用混合精度训练还是挺简单的。具体可以参考<a href="https://mxnet.incubator.apache.org/versions/master/faq/float16.html" target="_blank" rel="external">Mixed precision training using float16</a></p>
<p>下面是使用gluon训练时候要注意的几个地方：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## optimizer 开启混合精度选项</span></div><div class="line"><span class="comment">## 这会使optimizer为参数保存一份FP32拷贝，在上面进行梯度的更新，</span></div><div class="line"><span class="comment">## 防止梯度过小无法更新FP16</span></div><div class="line"><span class="keyword">if</span> opt.dtype != <span class="string">'float32'</span>:</div><div class="line">    optimizer_params[<span class="string">'multi_precision'</span>] = <span class="keyword">True</span></div><div class="line"><span class="comment">## net cast到给定的数值精度</span></div><div class="line">net = get_model(model_name, **kwargs)</div><div class="line">net.cast(opt.dtype)</div><div class="line"><span class="comment">## 训练过程中，将输入也cast到指定精度</span></div><div class="line"><span class="keyword">while</span> in_training:</div><div class="line">    <span class="comment">## blablabla</span></div><div class="line">    outputs = [net(X.astype(opt.dtype, copy=<span class="keyword">False</span>)) <span class="keyword">for</span> X <span class="keyword">in</span> data]</div><div class="line">    <span class="comment">## 计算loss也把label cast到指定精度</span></div></pre></td></tr></table></figure>
<p>使用MXNet老的symbolic接口时候，因为静态图一旦写好就固定了，所以我们需要在建图的时候，考虑FP16精度。</p>
<ul>
<li>在原始输入node后面接一个<code>cast</code> op，将FP32转成FP16。</li>
<li>最好在<code>SoftmaxOutput</code>之前，插入一个<code>cast</code> op，将FP16转回FP32，以便有更高的精度。</li>
<li><code>optimizer</code>打开<code>multi_precision</code>开关，这里和上面gluon是一致的。</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 建图</span></div><div class="line">data = mx.sym.Variable(name=<span class="string">"data"</span>)</div><div class="line"><span class="keyword">if</span> dtype == <span class="string">'float16'</span>:</div><div class="line">    data = mx.sym.Cast(data=data, dtype=np.float16)</div><div class="line"><span class="comment"># ... the rest of the network</span></div><div class="line">net_out = net(data)</div><div class="line"><span class="keyword">if</span> dtype == <span class="string">'float16'</span>:</div><div class="line">    net_out = mx.sym.Cast(data=net_out, dtype=np.float32)</div><div class="line">output = mx.sym.SoftmaxOutput(data=net_out, name=<span class="string">'softmax'</span>)</div><div class="line"><span class="comment">## 优化器设置</span></div><div class="line">optimizer = mx.optimizer.create(<span class="string">'sgd'</span>, multi_precision=<span class="keyword">True</span>, lr=<span class="number">0.01</span>)</div></pre></td></tr></table></figure>
<p>下面有几条额外的建议：</p>
<ul>
<li>FP16加速主要来源于新GPU上的Tensor Core计算$D = A * B + C$这种运算，且它们的维度是$8$的倍数。所以如果不满足$8$倍数这个条件，FP16的计算速度可能不会很快，或者说和FP32相比没多少优势。尤其是当你在CIFAR10这种输入图片size比较小的数据集上训练的时候。</li>
<li>针对上面这种情况，你可以使用<code>nvprof</code>工具来check是否Tensor Core被使用了，那些名字里面带有<code>s884cudnn</code>的操作就是了。</li>
<li>确保data io和preprocessing不要成为瓶颈，不然面对这些扯后腿的地方，FP16男默女泪。</li>
<li>batch size最好设置为8的倍数，2的幂次是坠吼的。</li>
<li>如果GPU memory还算充足，可以设置<code>MXNET_CUDNN_AUTOTUNE_DEFAULT = 2</code>，来让MXNet有更多的测试来选用最快的卷积算法，代价就是更多的显存占用。</li>
<li>最好为BatchNorm和SoftmaxOutput使用FP32精度。Gluon里面这些都是自动的，MXNet中BN层是自动的，但是SoftmaxOutput需要自己设置一下，见上。</li>
</ul>
<h4 id="loss-scaling"><a href="#loss-scaling" class="headerlink" title="loss scaling"></a>loss scaling</h4><p>再说一下上面提到的loss scaling。</p>
<p>为啥要做loss scaling呢？主要是由于FP16的精度比较差，而能够表示的较大的数对于CNN网络来说又基本用不到（虽然说FP16的表示范围相比FP32已经缩水不少了），所以可能出现这样一种情形，loss对FP16 weight或activation求梯度，梯度太小，以至于FP16无法表示。那其实我们可以给loss乘上一个系数，放大gradient，以便FP16能够表示。在梯度更新之前，再把这个梯度scale回去，就可以了。如下图所示。</p>
<p><img src="/img/bag_of_tricks_fp16_range_dismatch.jpg" alt="FP16和FP32的range不匹配"></p>
<p>使用gluon或MXNet设置loss scaling的方法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## gluon</span></div><div class="line">loss = gluon.loss.SoftmaxCrossEntropyLoss(weight=<span class="number">128</span>)</div><div class="line">optimizer = mx.optimizer.create(<span class="string">'sgd'</span>,</div><div class="line">                                multi_precision=<span class="keyword">True</span>,</div><div class="line">                                rescale_grad=<span class="number">1.0</span>/<span class="number">128</span>)</div><div class="line"><span class="comment">## mxnet</span></div><div class="line">mxnet.sym.SoftmaxOutput(other_args, grad_scale=<span class="number">128.0</span>)</div><div class="line">optimizer = mx.optimizer.create(<span class="string">'sgd'</span>,</div><div class="line">                                multi_precision=<span class="keyword">True</span>,</div><div class="line">                                rescale_grad=<span class="number">1.0</span>/<span class="number">128</span>)</div></pre></td></tr></table></figure>
<p>经验来看，对于Multibox SSD, R-CNN, bigLSTM and Seq2seq这些任务，loss scaling是比较有必要的。这里有个疑问，loss scaling应该是在训练过程中不断变化的，但上面的使用都是直接把loss scaling写死了（gluon还好，再手动给loss乘上一个因子），那如何修改loss scaling呢？后面指出可以使用constant的loss scaling（一般取2的幂次64，128等），但是不知道实际训练会不会有问题。<a href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" target="_blank" rel="external">Nvidia guide</a>中给出的建议是：</p>
<blockquote>
<p>If you encounter precision problems, it is beneficial to scale the loss up by 128, and scale the application of the gradients down by 128.</p>
</blockquote>
<p>当然，最好的办法是自己看一下FP32 gradient的分布。</p>
<p>当当当。。。说了这么多，那么具体加速效果如何呢？使用batch size = $1024$，和batch size = $256$的baseline相比，从下表可知，三种不同的网络结构，分别加速了$1.6X$到$3X$，而且acc还涨了一些。</p>
<p><img src="/img/bag_of_tricks_accelarate_training.jpg" alt="加速效果"></p>
<p>具体的acc影响的ablation实验如下。可以看到，只是使用lr线性增大的情况下，大（batch size的）网络稍逊于小（batch size的）网络。不过当使用上面几个技术综合来看的时候，大小网络的性能差异已经抹去了，而且大网络的训练速度更快。</p>
<p><img src="/img/bag_of_tricks_ablation_of_accelarate_train.jpg" alt="ablation实验结果"></p>
<h2 id="更好的网络"><a href="#更好的网络" class="headerlink" title="更好的网络"></a>更好的网络</h2><p>TODO: 未完待续</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/29/tvm-helloworld/" rel="next" title="Hello TVM">
                <i class="fa fa-chevron-left"></i> Hello TVM
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/25/paper-meta-pruning/" rel="prev" title="论文 - MetaPruning：Meta Learning for Automatic Neural Network Channel Pruning">
                论文 - MetaPruning：Meta Learning for Automatic Neural Network Channel Pruning <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
        <div id="lv-container" data-id="city" data-uid="MTAyMC8yODMwOS80ODgx"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/avatar/liumengli.jpg" alt="一个脱离了高级趣味的人">
          <p class="site-author-name" itemprop="name">一个脱离了高级趣味的人</p>
          <p class="site-description motion-element" itemprop="description">相与枕藉乎舟中，不知东方之既白</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">82</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/xmfbit" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2629935075/" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Baseline-Training"><span class="nav-number">2.</span> <span class="nav-text">Baseline Training</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Argumentation"><span class="nav-number">2.1.</span> <span class="nav-text">Data Argumentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参数初始化"><span class="nav-number">2.2.</span> <span class="nav-text">参数初始化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练参数"><span class="nav-number">2.3.</span> <span class="nav-text">训练参数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更快地训练"><span class="nav-number">3.</span> <span class="nav-text">更快地训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#大batch-size"><span class="nav-number">3.1.</span> <span class="nav-text">大batch size</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（成比例）提高lr"><span class="nav-number">3.1.1.</span> <span class="nav-text">（成比例）提高lr</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lr-warm-up"><span class="nav-number">3.1.2.</span> <span class="nav-text">lr warm up</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#设置-gamma-0"><span class="nav-number">3.1.3.</span> <span class="nav-text">设置$\gamma = 0$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#weight-decay"><span class="nav-number">3.1.4.</span> <span class="nav-text">weight decay</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#低精度"><span class="nav-number">3.2.</span> <span class="nav-text">低精度</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#FP16数据表示"><span class="nav-number">3.2.1.</span> <span class="nav-text">FP16数据表示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FP16-in-MXNet"><span class="nav-number">3.2.2.</span> <span class="nav-text">FP16 in MXNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#loss-scaling"><span class="nav-number">3.2.3.</span> <span class="nav-text">loss scaling</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更好的网络"><span class="nav-number">4.</span> <span class="nav-text">更好的网络</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">一个脱离了高级趣味的人</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



    
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  





  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
