{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/caffe-hack-pycaffe-python-cpp-binding.jpg","path":"img/caffe-hack-pycaffe-python-cpp-binding.jpg","modified":0,"renderable":0},{"_id":"source/img/caffe_mathfunctions_gpuisnuclearweapon.jpg","path":"img/caffe_mathfunctions_gpuisnuclearweapon.jpg","modified":0,"renderable":0},{"_id":"source/img/camera_skew.png","path":"img/camera_skew.png","modified":0,"renderable":0},{"_id":"source/img/captcha_test_accuracy.png","path":"img/captcha_test_accuracy.png","modified":0,"renderable":0},{"_id":"source/img/captcha_train_loss.png","path":"img/captcha_train_loss.png","modified":0,"renderable":0},{"_id":"source/img/case_1_m.png","path":"img/case_1_m.png","modified":0,"renderable":0},{"_id":"source/img/case_4_m.png","path":"img/case_4_m.png","modified":0,"renderable":0},{"_id":"source/img/case_3_m.png","path":"img/case_3_m.png","modified":0,"renderable":0},{"_id":"source/img/case_2_m.png","path":"img/case_2_m.png","modified":0,"renderable":0},{"_id":"source/img/conv-in-caffe-im2col-1.png","path":"img/conv-in-caffe-im2col-1.png","modified":0,"renderable":0},{"_id":"source/img/case_m_5.png","path":"img/case_m_5.png","modified":0,"renderable":0},{"_id":"source/img/conv-in-caffe-im2col-3.png","path":"img/conv-in-caffe-im2col-3.png","modified":0,"renderable":0},{"_id":"source/img/convex_opt_intro_title_pic.png","path":"img/convex_opt_intro_title_pic.png","modified":0,"renderable":0},{"_id":"source/img/corner_type_1.png","path":"img/corner_type_1.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_brightnessconstancy_assumption.png","path":"img/cs131_opticalflow_brightnessconstancy_assumption.png","modified":0,"renderable":0},{"_id":"source/img/cs229-supervised-learning-least-square-normal-equation.png","path":"img/cs229-supervised-learning-least-square-normal-equation.png","modified":0,"renderable":0},{"_id":"source/img/cs229-supervised-learning-sigmoid.png","path":"img/cs229-supervised-learning-sigmoid.png","modified":0,"renderable":0},{"_id":"source/img/cs229-supervised-learning-some-useful-matrix-derivatives.png","path":"img/cs229-supervised-learning-some-useful-matrix-derivatives.png","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_02_pointers.png","path":"img/effectivecpp_02_pointers.png","modified":0,"renderable":0},{"_id":"source/img/effective_cpp_07_joke.jpg","path":"img/effective_cpp_07_joke.jpg","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_01_cpp_rely_on_renpin.jpg","path":"img/effectivecpp_01_cpp_rely_on_renpin.jpg","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_04_cwithclass.jpg","path":"img/effectivecpp_04_cwithclass.jpg","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_08_memory_leak_everywherre.jpg","path":"img/effectivecpp_08_memory_leak_everywherre.jpg","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_diamond.png","path":"img/effectivecpp_diamond.png","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_strategy_pattern.png","path":"img/effectivecpp_strategy_pattern.png","modified":0,"renderable":0},{"_id":"source/img/gsl_picture.jpg","path":"img/gsl_picture.jpg","modified":0,"renderable":0},{"_id":"source/img/helloworld_hexo.png","path":"img/helloworld_hexo.png","modified":0,"renderable":0},{"_id":"source/img/hack-pycaffe-code-organization.png","path":"img/hack-pycaffe-code-organization.png","modified":0,"renderable":0},{"_id":"source/img/hinton_01_neuron_commucation.png","path":"img/hinton_01_neuron_commucation.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_margin.png","path":"img/hinton_02_margin.png","modified":0,"renderable":0},{"_id":"source/img/hinton_01_neuron_structure.png","path":"img/hinton_01_neuron_structure.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_perceptron_gragh.png","path":"img/hinton_02_perceptron_gragh.png","modified":0,"renderable":0},{"_id":"source/img/hinton_06_maanmian.jpg","path":"img/hinton_06_maanmian.jpg","modified":0,"renderable":0},{"_id":"source/img/hinton_brainsimulator.jpg","path":"img/hinton_brainsimulator.jpg","modified":0,"renderable":0},{"_id":"source/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg","path":"img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg","modified":0,"renderable":0},{"_id":"source/img/install_ubuntu_in_dell_weixiaojiuhao.jpg","path":"img/install_ubuntu_in_dell_weixiaojiuhao.jpg","modified":0,"renderable":0},{"_id":"source/img/jupyternotebook_logo.png","path":"img/jupyternotebook_logo.png","modified":0,"renderable":0},{"_id":"source/img/install_ubuntu_in_dell_kaiyuandafahao.jpg","path":"img/install_ubuntu_in_dell_kaiyuandafahao.jpg","modified":0,"renderable":0},{"_id":"source/img/kmeans_data_demo.png","path":"img/kmeans_data_demo.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_success.png","path":"img/kmeans_success.png","modified":0,"renderable":0},{"_id":"source/img/line_fit_demo.png","path":"img/line_fit_demo.png","modified":0,"renderable":0},{"_id":"source/img/meanshift_simple_demo.png","path":"img/meanshift_simple_demo.png","modified":0,"renderable":0},{"_id":"source/img/meanshift_basics.jpg","path":"img/meanshift_basics.jpg","modified":0,"renderable":0},{"_id":"source/img/mnist_example.png","path":"img/mnist_example.png","modified":0,"renderable":0},{"_id":"source/img/newton-method-demo.gif","path":"img/newton-method-demo.gif","modified":0,"renderable":0},{"_id":"source/img/paper-fpn-lateral-connection.png","path":"img/paper-fpn-lateral-connection.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-alpha-compact.png","path":"img/paper-mobilenet-alpha-compact.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-comparision-with-other-model.png","path":"img/paper-mobilenet-comparision-with-other-model.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-alpha-rho-effect.png","path":"img/paper-mobilenet-alpha-rho-effect.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-conv-unit.png","path":"img/paper-mobilenet-conv-unit.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-depthwise-separable-conv.png","path":"img/paper-mobilenet-depthwise-separable-conv.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-depthwise-vs-full-conv.png","path":"img/paper-mobilenet-depthwise-vs-full-conv.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-narrow-vs-shallow-net.png","path":"img/paper-mobilenet-narrow-vs-shallow-net.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-rho-compact.png","path":"img/paper-mobilenet-rho-compact.png","modified":0,"renderable":0},{"_id":"source/img/paper-model-pruning-why-so-baixue.jpg","path":"img/paper-model-pruning-why-so-baixue.jpg","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-demo.png","path":"img/paper-pruning-network-demo.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-layer-sensitivity.png","path":"img/paper-pruning-network-layer-sensitivity.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-iterative-pruning.png","path":"img/paper-pruning-network-iterative-pruning.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-energy-for-different-memory-hieracy.png","path":"img/paper-pruning-network-energy-for-different-memory-hieracy.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeeze-sr-impact.png","path":"img/paper-squeeze-sr-impact.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeezenet-bypass.png","path":"img/paper-squeezenet-bypass.png","modified":0,"renderable":0},{"_id":"source/img/paper-ssldnn-experiment-on-lenet.png","path":"img/paper-ssldnn-experiment-on-lenet.png","modified":0,"renderable":0},{"_id":"source/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png","path":"img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png","modified":0,"renderable":0},{"_id":"source/img/paper-xception-equivalent-inception-module.png","path":"img/paper-xception-equivalent-inception-module.png","modified":0,"renderable":0},{"_id":"source/img/paper-summary-model-pruning-joke.jpg","path":"img/paper-summary-model-pruning-joke.jpg","modified":0,"renderable":0},{"_id":"source/img/paper-xception-extreme-version.png","path":"img/paper-xception-extreme-version.png","modified":0,"renderable":0},{"_id":"source/img/paper-xception-inception-module.png","path":"img/paper-xception-inception-module.png","modified":0,"renderable":0},{"_id":"source/img/paper-xception-simplified-inception-module.png","path":"img/paper-xception-simplified-inception-module.png","modified":0,"renderable":0},{"_id":"source/img/paper=yolov3-bbox-regression.png","path":"img/paper=yolov3-bbox-regression.png","modified":0,"renderable":0},{"_id":"source/img/paper_visconvnet_layer1_demo.png","path":"img/paper_visconvnet_layer1_demo.png","modified":0,"renderable":0},{"_id":"source/img/paper_visconvnet_uppooling.png","path":"img/paper_visconvnet_uppooling.png","modified":0,"renderable":0},{"_id":"source/img/pytorch_logo.png","path":"img/pytorch_logo.png","modified":0,"renderable":0},{"_id":"source/img/qicizuobiao.png","path":"img/qicizuobiao.png","modified":0,"renderable":0},{"_id":"source/img/ransac_step.png","path":"img/ransac_step.png","modified":0,"renderable":0},{"_id":"source/img/residualnet_unit.png","path":"img/residualnet_unit.png","modified":0,"renderable":0},{"_id":"source/img/rotation.png","path":"img/rotation.png","modified":0,"renderable":0},{"_id":"source/img/set-env-in-notebook-choose-kernel.png","path":"img/set-env-in-notebook-choose-kernel.png","modified":0,"renderable":0},{"_id":"source/img/set-env-in-notebook-change-kernel.png","path":"img/set-env-in-notebook-change-kernel.png","modified":0,"renderable":0},{"_id":"source/img/shell-programming-bash-logo.png","path":"img/shell-programming-bash-logo.png","modified":0,"renderable":0},{"_id":"source/img/sift_dominant_orientation.png","path":"img/sift_dominant_orientation.png","modified":0,"renderable":0},{"_id":"source/img/sift_picture.jpg","path":"img/sift_picture.jpg","modified":0,"renderable":0},{"_id":"source/img/silver_rl_bellman_equation_matrix.png","path":"img/silver_rl_bellman_equation_matrix.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_bellman_equation_figure.png","path":"img/silver_rl_bellman_equation_figure.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_bellman_equation_solution.png","path":"img/silver_rl_bellman_equation_solution.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_policy_evaluating_demo.png","path":"img/silver_rl_dp_policy_evaluating_demo.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_policy_evaluating_demo_result.png","path":"img/silver_rl_dp_policy_evaluating_demo_result.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp.png","path":"img/silver_rl_mdp.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_optimal_policy.png","path":"img/silver_rl_mdp_optimal_policy.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_optimal_vq_relationship.png","path":"img/silver_rl_mdp_optimal_vq_relationship.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_optimal_vq_relationship2.png","path":"img/silver_rl_mdp_optimal_vq_relationship2.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_vq_relationship2.png","path":"img/silver_rl_mdp_vq_relationship2.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_vq_relationship.png","path":"img/silver_rl_mdp_vq_relationship.png","modified":0,"renderable":0},{"_id":"source/img/svd_picture.jpg","path":"img/svd_picture.jpg","modified":0,"renderable":0},{"_id":"source/img/svd_ranking.png","path":"img/svd_ranking.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_bbox_location.png","path":"img/yolo2_bbox_location.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_bbox_param.png","path":"img/yolo2_bbox_param.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_cluster_result.png","path":"img/yolo2_cluster_result.png","modified":0,"renderable":0},{"_id":"source/img/bug_pycaffe_nvidia_smi_result.png","path":"img/bug_pycaffe_nvidia_smi_result.png","modified":0,"renderable":0},{"_id":"source/img/caffe-net-demo.jpg","path":"img/caffe-net-demo.jpg","modified":0,"renderable":0},{"_id":"source/img/caffe_bn_bp_of_bn.jpg","path":"img/caffe_bn_bp_of_bn.jpg","modified":0,"renderable":0},{"_id":"source/img/caffe_mathfunctions_useuva.png","path":"img/caffe_mathfunctions_useuva.png","modified":0,"renderable":0},{"_id":"source/img/caffe_syncedmem_blob_flow.jpg","path":"img/caffe_syncedmem_blob_flow.jpg","modified":0,"renderable":0},{"_id":"source/img/caffe_syncedmem_transfer.png","path":"img/caffe_syncedmem_transfer.png","modified":0,"renderable":0},{"_id":"source/img/canny_linking.png","path":"img/canny_linking.png","modified":0,"renderable":0},{"_id":"source/img/canny_nms.png","path":"img/canny_nms.png","modified":0,"renderable":0},{"_id":"source/img/case_6_m.png","path":"img/case_6_m.png","modified":0,"renderable":0},{"_id":"source/img/conv-in-caffe-im2col-2.png","path":"img/conv-in-caffe-im2col-2.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_crossfade.gif","path":"img/cs131_opticalflow_assignment_crossfade.gif","modified":0,"renderable":0},{"_id":"source/img/corner_window_fun.png","path":"img/corner_window_fun.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_flowwarped.gif","path":"img/cs131_opticalflow_assignment_flowwarped.gif","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_forwardwarped.gif","path":"img/cs131_opticalflow_assignment_forwardwarped.gif","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_demo.jpg","path":"img/cs131_opticalflow_demo.jpg","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_lkrelationshipwithharris.png","path":"img/cs131_opticalflow_lkrelationshipwithharris.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_lkleastsquare.png","path":"img/cs131_opticalflow_lkleastsquare.png","modified":0,"renderable":0},{"_id":"source/img/differences-of-deep-learning-frameworks-22-638.jpg","path":"img/differences-of-deep-learning-frameworks-22-638.jpg","modified":0,"renderable":0},{"_id":"source/img/doc2dash_how_to_add_docset.jpg","path":"img/doc2dash_how_to_add_docset.jpg","modified":0,"renderable":0},{"_id":"source/img/edge_camera_man.png","path":"img/edge_camera_man.png","modified":0,"renderable":0},{"_id":"source/img/doxygen_picture.png","path":"img/doxygen_picture.png","modified":0,"renderable":0},{"_id":"source/img/edge_deriative.png","path":"img/edge_deriative.png","modified":0,"renderable":0},{"_id":"source/img/effectivecpp_06_joke.jpg","path":"img/effectivecpp_06_joke.jpg","modified":0,"renderable":0},{"_id":"source/img/god_use_vpn.png","path":"img/god_use_vpn.png","modified":0,"renderable":0},{"_id":"source/img/harris_non_scale_constant.png","path":"img/harris_non_scale_constant.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_feed_forward_nn.png","path":"img/hinton_02_feed_forward_nn.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_perceptron_xor.png","path":"img/hinton_02_perceptron_xor.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_recurrent_nn.png","path":"img/hinton_02_recurrent_nn.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_why_training_works_1.png","path":"img/hinton_02_why_training_works_1.png","modified":0,"renderable":0},{"_id":"source/img/meanshift_kernel_function.png","path":"img/meanshift_kernel_function.png","modified":0,"renderable":0},{"_id":"source/img/meanshift_gradient_of_density.png","path":"img/meanshift_gradient_of_density.png","modified":0,"renderable":0},{"_id":"source/img/paer_visconvnet_deconvnet_structure.png","path":"img/paer_visconvnet_deconvnet_structure.png","modified":0,"renderable":0},{"_id":"source/img/paper-fpn-different-with-related-work.png","path":"img/paper-fpn-different-with-related-work.png","modified":0,"renderable":0},{"_id":"source/img/paper-inq-quantize-set.png","path":"img/paper-inq-quantize-set.png","modified":0,"renderable":0},{"_id":"source/img/paper-mobilenet-net-arch.png","path":"img/paper-mobilenet-net-arch.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-algrithem.png","path":"img/paper-pruning-network-algrithem.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-lstm.png","path":"img/paper-pruning-network-lstm.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-regularization.png","path":"img/paper-pruning-network-regularization.png","modified":0,"renderable":0},{"_id":"source/img/paper-pruning-network-results.png","path":"img/paper-pruning-network-results.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeezenet-benchmark.png","path":"img/paper-squeezenet-benchmark.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeezenet-pct-impact.png","path":"img/paper-squeezenet-pct-impact.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeezenet-fire-module.png","path":"img/paper-squeezenet-fire-module.png","modified":0,"renderable":0},{"_id":"source/img/paper-ssldnn-random-sparity-is-bad.png","path":"img/paper-ssldnn-random-sparity-is-bad.png","modified":0,"renderable":0},{"_id":"source/img/paper-ssldnn.png","path":"img/paper-ssldnn.png","modified":0,"renderable":0},{"_id":"source/img/paper-xception-experiment-intermediate-activation.png","path":"img/paper-xception-experiment-intermediate-activation.png","modified":0,"renderable":0},{"_id":"source/img/paper-yolov3-comparison-retinanet.png","path":"img/paper-yolov3-comparison-retinanet.png","modified":0,"renderable":0},{"_id":"source/img/paper-yolov3-comparisons.png","path":"img/paper-yolov3-comparisons.png","modified":0,"renderable":0},{"_id":"source/img/paper-yolov3-darknet53.png","path":"img/paper-yolov3-darknet53.png","modified":0,"renderable":0},{"_id":"source/img/patch_average_intensity_scale_constant.png","path":"img/patch_average_intensity_scale_constant.png","modified":0,"renderable":0},{"_id":"source/img/qicizuobiao_transform.png","path":"img/qicizuobiao_transform.png","modified":0,"renderable":0},{"_id":"source/img/residualnet_bottleneck_unit.png","path":"img/residualnet_bottleneck_unit.png","modified":0,"renderable":0},{"_id":"source/img/residualnet_improved_structure.png","path":"img/residualnet_improved_structure.png","modified":0,"renderable":0},{"_id":"source/img/rotation_matrix.png","path":"img/rotation_matrix.png","modified":0,"renderable":0},{"_id":"source/img/sift_detection_maximum.png","path":"img/sift_detection_maximum.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_detailed_prioritized_dp.png","path":"img/silver_rl_dp_detailed_prioritized_dp.png","modified":0,"renderable":0},{"_id":"source/img/silver_mdp_value_function.png","path":"img/silver_mdp_value_function.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_improve_policy_greedily_proof_2.png","path":"img/silver_rl_dp_improve_policy_greedily_proof_2.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_inplace_value_iteration.png","path":"img/silver_rl_dp_inplace_value_iteration.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_synchronous_value_iteration.png","path":"img/silver_rl_dp_synchronous_value_iteration.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_realtime_dp.png","path":"img/silver_rl_dp_realtime_dp.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_value_iteration_demo.png","path":"img/silver_rl_dp_value_iteration_demo.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_optimal_qq_relationship.png","path":"img/silver_rl_mdp_optimal_qq_relationship.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_qq_relationship.png","path":"img/silver_rl_mdp_qq_relationship.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_optimal_vv_relationship.png","path":"img/silver_rl_mdp_optimal_vv_relationship.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_mdp_vv_relationship.png","path":"img/silver_rl_mdp_vv_relationship.png","modified":0,"renderable":0},{"_id":"source/img/svd_superman.png","path":"img/svd_superman.png","modified":0,"renderable":0},{"_id":"source/img/video_linear_alg_essential_linear_equation.png","path":"img/video_linear_alg_essential_linear_equation.png","modified":0,"renderable":0},{"_id":"source/img/yolo1_loss_fun.png","path":"img/yolo1_loss_fun.png","modified":0,"renderable":0},{"_id":"source/img/yolo1_network_arch.png","path":"img/yolo1_network_arch.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_different_methods_comparation.png","path":"img/yolo2_different_methods_comparation.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_different_methods_improvement.png","path":"img/yolo2_different_methods_improvement.png","modified":0,"renderable":0},{"_id":"source/img/yolov3-comparision-with-retina.png","path":"img/yolov3-comparision-with-retina.png","modified":0,"renderable":0},{"_id":"source/img/camera_translation_rotation.png","path":"img/camera_translation_rotation.png","modified":0,"renderable":0},{"_id":"source/img/conv-in-caffe-im2col-followed-gemm.png","path":"img/conv-in-caffe-im2col-followed-gemm.png","modified":0,"renderable":0},{"_id":"source/img/conv-in-caffe-naive-loop.png","path":"img/conv-in-caffe-naive-loop.png","modified":0,"renderable":0},{"_id":"source/img/corner_judge_2.png","path":"img/corner_judge_2.png","modified":0,"renderable":0},{"_id":"source/img/corner_judge.png","path":"img/corner_judge.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_flowwarped.png","path":"img/cs131_opticalflow_assignment_flowwarped.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_forwardwarped.png","path":"img/cs131_opticalflow_assignment_forwardwarped.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_lkequation.png","path":"img/cs131_opticalflow_lkequation.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_lkharris.png","path":"img/cs131_opticalflow_lkharris.png","modified":0,"renderable":0},{"_id":"source/img/epipolar_constraint_1.png","path":"img/epipolar_constraint_1.png","modified":0,"renderable":0},{"_id":"source/img/epipolar_fig.png","path":"img/epipolar_fig.png","modified":0,"renderable":0},{"_id":"source/img/generic_projection_matrix.png","path":"img/generic_projection_matrix.png","modified":0,"renderable":0},{"_id":"source/img/fun_noise.png","path":"img/fun_noise.png","modified":0,"renderable":0},{"_id":"source/img/hinton_01_mnist_example.png","path":"img/hinton_01_mnist_example.png","modified":0,"renderable":0},{"_id":"source/img/hinton_01_sigmoid_function.png","path":"img/hinton_01_sigmoid_function.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_rnn_app.png","path":"img/hinton_02_rnn_app.png","modified":0,"renderable":0},{"_id":"source/img/hinton_02_perceptron_paradigm_for_pattern_recong.png","path":"img/hinton_02_perceptron_paradigm_for_pattern_recong.png","modified":0,"renderable":0},{"_id":"source/img/hinton_06_adamax.png","path":"img/hinton_06_adamax.png","modified":0,"renderable":0},{"_id":"source/img/ipsec_ios_vpn_setting.png","path":"img/ipsec_ios_vpn_setting.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_object_fun_vs_k.png","path":"img/kmeans_object_fun_vs_k.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_sensitive_to_outlier.png","path":"img/kmeans_sensitive_to_outlier.png","modified":0,"renderable":0},{"_id":"source/img/original_superman.png","path":"img/original_superman.png","modified":0,"renderable":0},{"_id":"source/img/paper-fpn-different-pyramids.png","path":"img/paper-fpn-different-pyramids.png","modified":0,"renderable":0},{"_id":"source/img/paper-inq-different-quantize.png","path":"img/paper-inq-different-quantize.png","modified":0,"renderable":0},{"_id":"source/img/paper-squeezenet-macroarch.png","path":"img/paper-squeezenet-macroarch.png","modified":0,"renderable":0},{"_id":"source/img/ransac_k.png","path":"img/ransac_k.png","modified":0,"renderable":0},{"_id":"source/img/residualnet_deepnet_problem.png","path":"img/residualnet_deepnet_problem.png","modified":0,"renderable":0},{"_id":"source/img/residualnet_comparison_with_plainnet.png","path":"img/residualnet_comparison_with_plainnet.png","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_improve_policy_greedily_proof.png","path":"img/silver_rl_dp_improve_policy_greedily_proof.png","modified":0,"renderable":0},{"_id":"source/img/what_is_corner.png","path":"img/what_is_corner.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_different_methods_comparation_in_table.png","path":"img/yolo2_different_methods_comparation_in_table.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"source/img/caffe_image.jpg","path":"img/caffe_image.jpg","modified":0,"renderable":0},{"_id":"source/img/caffe_bn_what_is_bn.jpg","path":"img/caffe_bn_what_is_bn.jpg","modified":0,"renderable":0},{"_id":"source/img/just-a-joke.png","path":"img/just-a-joke.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_bigger_demo.png","path":"img/kmeans_bigger_demo.png","modified":0,"renderable":0},{"_id":"source/img/paper-model-pruning-net-sliming-procedure.png","path":"img/paper-model-pruning-net-sliming-procedure.png","modified":0,"renderable":0},{"_id":"source/img/paper-xception-arch.png","path":"img/paper-xception-arch.png","modified":0,"renderable":0},{"_id":"source/img/pinhole_camera_model.png","path":"img/pinhole_camera_model.png","modified":0,"renderable":0},{"_id":"source/img/resnet-164layer-cifar10-testing.jpg","path":"img/resnet-164layer-cifar10-testing.jpg","modified":0,"renderable":0},{"_id":"source/img/resnet-164layer-cifar10-training.jpg","path":"img/resnet-164layer-cifar10-training.jpg","modified":0,"renderable":0},{"_id":"source/img/silver_rl_dp_synchronous_dp_algorithms.png","path":"img/silver_rl_dp_synchronous_dp_algorithms.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_dartnet_19_structure.png","path":"img/yolo2_dartnet_19_structure.png","modified":0,"renderable":0},{"_id":"source/avatar/liumengli.jpg","path":"avatar/liumengli.jpg","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_assignment_crossfade.png","path":"img/cs131_opticalflow_assignment_crossfade.png","modified":0,"renderable":0},{"_id":"source/img/cs131_opticalflow_pyramid.png","path":"img/cs131_opticalflow_pyramid.png","modified":0,"renderable":0},{"_id":"source/img/mathfunctions_time_distribution.png","path":"img/mathfunctions_time_distribution.png","modified":0,"renderable":0},{"_id":"source/img/paper-nst-imagenet-results.png","path":"img/paper-nst-imagenet-results.png","modified":0,"renderable":0},{"_id":"source/img/paper-nst-visulization-teacher-student-feature-map.png","path":"img/paper-nst-visulization-teacher-student-feature-map.png","modified":0,"renderable":0},{"_id":"source/img/useful_tools_colored_man_pages.jpg","path":"img/useful_tools_colored_man_pages.jpg","modified":0,"renderable":0},{"_id":"source/img/ubuntu_exfat.png","path":"img/ubuntu_exfat.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"source/img/bash-programming-comparing-string.jpg","path":"img/bash-programming-comparing-string.jpg","modified":0,"renderable":0},{"_id":"source/img/hinton_06_nesterov_momentum.png","path":"img/hinton_06_nesterov_momentum.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_demo.png","path":"img/kmeans_demo.png","modified":0,"renderable":0},{"_id":"source/img/svd_flower.png","path":"img/svd_flower.png","modified":0,"renderable":0},{"_id":"source/img/video_linear_alg_essential.png","path":"img/video_linear_alg_essential.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"source/img/dog_x.png","path":"img/dog_x.png","modified":0,"renderable":0},{"_id":"source/img/paper-inq-result.png","path":"img/paper-inq-result.png","modified":0,"renderable":0},{"_id":"source/img/paper-nst-cifar10-results.png","path":"img/paper-nst-cifar10-results.png","modified":0,"renderable":0},{"_id":"source/img/paper-nst-kt-like-what-you-like.gif","path":"img/paper-nst-kt-like-what-you-like.gif","modified":0,"renderable":0},{"_id":"source/img/paper-nst-pascal-voc-results.png","path":"img/paper-nst-pascal-voc-results.png","modified":0,"renderable":0},{"_id":"source/img/paper-nst-student-and-teacher.png","path":"img/paper-nst-student-and-teacher.png","modified":0,"renderable":0},{"_id":"source/img/ransac_line_fit.png","path":"img/ransac_line_fit.png","modified":0,"renderable":0},{"_id":"source/img/regex_picture.jpg","path":"img/regex_picture.jpg","modified":0,"renderable":0},{"_id":"source/img/sift_dog.png","path":"img/sift_dog.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"source/img/hinton_06_learningrate.png","path":"img/hinton_06_learningrate.png","modified":0,"renderable":0},{"_id":"source/img/paper-summary-model-compression-autopruner-alg.png","path":"img/paper-summary-model-compression-autopruner-alg.png","modified":0,"renderable":0},{"_id":"source/img/sift_experiment_1.png","path":"img/sift_experiment_1.png","modified":0,"renderable":0},{"_id":"source/img/warpctc_intro.png","path":"img/warpctc_intro.png","modified":0,"renderable":0},{"_id":"source/img/yolo1_detection_system.png","path":"img/yolo1_detection_system.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"source/img/camera_model_things_to_remember.png","path":"img/camera_model_things_to_remember.png","modified":0,"renderable":0},{"_id":"source/img/hinton_06_rmsprop_improvement.png","path":"img/hinton_06_rmsprop_improvement.png","modified":0,"renderable":0},{"_id":"source/img/paper_visconvnet_demo.png","path":"img/paper_visconvnet_demo.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"source/img/cs131_linear_algebra.jpg","path":"img/cs131_linear_algebra.jpg","modified":0,"renderable":0},{"_id":"source/img/hinton_02_weight_space_hyperplane.png","path":"img/hinton_02_weight_space_hyperplane.png","modified":0,"renderable":0},{"_id":"source/img/hinton_06_summary.png","path":"img/hinton_06_summary.png","modified":0,"renderable":0},{"_id":"source/img/hinton_06_tricks_for_adaptive_lr.png","path":"img/hinton_06_tricks_for_adaptive_lr.png","modified":0,"renderable":0},{"_id":"source/img/shell-programming-if-operators.jpg","path":"img/shell-programming-if-operators.jpg","modified":0,"renderable":0},{"_id":"source/img/paper-summary-autopruner-arch.png","path":"img/paper-summary-autopruner-arch.png","modified":0,"renderable":0},{"_id":"source/img/yolo2_result.png","path":"img/yolo2_result.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"source/img/convolution.png","path":"img/convolution.png","modified":0,"renderable":0},{"_id":"source/img/dog_different_size.png","path":"img/dog_different_size.png","modified":0,"renderable":0},{"_id":"source/img/shell-programming-system-variables.jpg","path":"img/shell-programming-system-variables.jpg","modified":0,"renderable":0},{"_id":"source/img/shell-programming-wild-cards.jpg","path":"img/shell-programming-wild-cards.jpg","modified":0,"renderable":0},{"_id":"source/img/vim-config-demo.png","path":"img/vim-config-demo.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/img/doc2dash_pytorch_example.jpg","path":"img/doc2dash_pytorch_example.jpg","modified":0,"renderable":0},{"_id":"source/img/focal_loss_vs_ce_loss.jpg","path":"img/focal_loss_vs_ce_loss.jpg","modified":0,"renderable":0},{"_id":"source/img/kmeans_scaling_up.png","path":"img/kmeans_scaling_up.png","modified":0,"renderable":0},{"_id":"source/img/paper-model-pruning-filter-pruning-sensitivity-results.png","path":"img/paper-model-pruning-filter-pruning-sensitivity-results.png","modified":0,"renderable":0},{"_id":"source/img/contours_evaluation_optimizers.gif","path":"img/contours_evaluation_optimizers.gif","modified":0,"renderable":0},{"_id":"source/img/mathfunctions_im2col.png","path":"img/mathfunctions_im2col.png","modified":0,"renderable":0},{"_id":"source/img/yolo1_basic_idea.png","path":"img/yolo1_basic_idea.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_algorithm.png","path":"img/kmeans_algorithm.png","modified":0,"renderable":0},{"_id":"source/img/paper-inq-algorithm-demo.png","path":"img/paper-inq-algorithm-demo.png","modified":0,"renderable":0},{"_id":"source/img/sift_experiment_2.png","path":"img/sift_experiment_2.png","modified":0,"renderable":0},{"_id":"source/img/caffe_mathfunctions_uvarequirement.png","path":"img/caffe_mathfunctions_uvarequirement.png","modified":0,"renderable":0},{"_id":"source/img/focal_loss_different_model_comparison.jpg","path":"img/focal_loss_different_model_comparison.jpg","modified":0,"renderable":0},{"_id":"source/img/projective_geometry_property_1.png","path":"img/projective_geometry_property_1.png","modified":0,"renderable":0},{"_id":"source/img/kmeans_image_seg_via_intensity.png","path":"img/kmeans_image_seg_via_intensity.png","modified":0,"renderable":0},{"_id":"source/img/projective_geometry_property_2.png","path":"img/projective_geometry_property_2.png","modified":0,"renderable":0},{"_id":"source/img/caffe_mathfunctions_whatisuva.png","path":"img/caffe_mathfunctions_whatisuva.png","modified":0,"renderable":0},{"_id":"source/img/camera_geometry_application.png","path":"img/camera_geometry_application.png","modified":0,"renderable":0},{"_id":"source/img/image_matching_hard.png","path":"img/image_matching_hard.png","modified":0,"renderable":0},{"_id":"source/img/conv_opt_intro_conv_set.png","path":"img/conv_opt_intro_conv_set.png","modified":0,"renderable":0},{"_id":"source/img/convex_opt_intro_convex_fun.png","path":"img/convex_opt_intro_convex_fun.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"3467af724139f96b33dd1327fd0a324ebc0ea8a8","modified":1538555853478},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1540624613270},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1540624613269},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1540624613269},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1540624613270},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1540624613270},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1540624613270},{"_id":"themes/next/README.en.md","hash":"3b0c7998cf17f9cf9e1a5bfcd65679a43a00c817","modified":1540624613271},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1540624613271},{"_id":"themes/next/_config.yml","hash":"c679ad2e7bb223fd92cf4d660137dc9dca55a561","modified":1540624613271},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1540624613271},{"_id":"themes/next/gulpfile.coffee","hash":"61ef0606a8134894d7ac796bc8d0fa4ba6a94483","modified":1540624613272},{"_id":"themes/next/package.json","hash":"877cb98025e59015532c4c9a04a33e2af4ad56f9","modified":1540624613294},{"_id":"source/_posts/bug-pycaffe-jupyternotebook-awaiting-for-data.md","hash":"1870545b62eadefc675c84c3c4e7aab7589c6c95","modified":1540624612373},{"_id":"source/_posts/bug-pycaffe-using-cublas.md","hash":"982c0939246612cbde22f35e9fafb0034979e8c7","modified":1540624612376},{"_id":"source/_posts/build-caffe-ubuntu.md","hash":"e08f1d5390815fb605c46e2afe73dfed154a6558","modified":1540624612376},{"_id":"source/_posts/caffe-batch-norm.md","hash":"b4266bd2a6cb0936717f547cf4c3e77b098e8ed5","modified":1540624612377},{"_id":"source/_posts/caffe-hack-python-interface.md","hash":"98559906af98d43a72b1748054c3f05fbe06c73f","modified":1540624612378},{"_id":"source/_posts/caffe-syncedmem.md","hash":"a396a680d316516793c5776abb33a75f4d06694f","modified":1540624612380},{"_id":"source/_posts/caffe-net.md","hash":"8281b53cf415c303cd541133519f269f9eeb7cd8","modified":1540624612379},{"_id":"source/_posts/conv-in-caffe.md","hash":"13dfe4a4357f300b79cf605ab2913a3889e5ddea","modified":1540624612381},{"_id":"source/_posts/cs131-camera.md","hash":"9da13519e583f76d96d6bbe8cd37a032b03d7cdb","modified":1540624612381},{"_id":"source/_posts/convex-optimization-intro.md","hash":"e5f2d419f4c6c527d105fe73dfb5fd39847e0d0e","modified":1542475312392},{"_id":"source/_posts/cs131-edge-detection.md","hash":"a02d1bef37b25b7b0fd159019533bd02637be85b","modified":1540624612381},{"_id":"source/_posts/cs131-filter-svd.md","hash":"d5ce30bc545a605ee347da5a58bea06db82dbe22","modified":1540624612382},{"_id":"source/_posts/cs131-finding-features.md","hash":"1390fe3ca5f3c751c869dfc4a15602d800b81c09","modified":1540624612382},{"_id":"source/_posts/cs131-kmeans.md","hash":"6bbf310095da3bdf051e605922083e66a33ad17c","modified":1540624612383},{"_id":"source/_posts/cs131-linear-alg.md","hash":"4c5c80a2cc18eb517c439a7056e6d6ef58330378","modified":1540624612383},{"_id":"source/_posts/cs131-mean-shift.md","hash":"d8b930ef584ec81102059e8fffee7f590a00da32","modified":1540624612384},{"_id":"source/_posts/cs131-opticalflow.md","hash":"621691965416bf03b6751d09bbc9eaffe6f0e4b8","modified":1540624612384},{"_id":"source/_posts/cs131-sift.md","hash":"c2d4392bb366299e96cfca061390bf79d8174e3c","modified":1540624612385},{"_id":"source/_posts/cs229-supervised-learning.md","hash":"648d9e10ce940ba047471b4506f5f690e213c6ce","modified":1540624612386},{"_id":"source/_posts/debugging-with-ipdb.md","hash":"19098a1bd7ba33848a3f01f7da51c61fd6393ba6","modified":1540624612387},{"_id":"source/_posts/digitalocean-shadowsocks.md","hash":"5f2576b1f7bbe7586c5f793740522765db66c516","modified":1540624612388},{"_id":"source/_posts/doc2dash-usage.md","hash":"06ec8f2abc8e0e33061b72ba714ca8036e9b9a84","modified":1540624612388},{"_id":"source/_posts/effective-cpp-02.md","hash":"89c73725e3c1685a5e7bcd4a5f49258a0534ef84","modified":1540624612389},{"_id":"source/_posts/effective-cpp-01.md","hash":"4abab2c9963faac02536630230ba45dfa638d169","modified":1540624612389},{"_id":"source/_posts/effective-cpp-03.md","hash":"a77eb64d1d0da11e5fd69e5d6cd9237e6709bef4","modified":1540624612389},{"_id":"source/_posts/effective-cpp-04.md","hash":"56e86176464d3526e2bc81730586797c0df17641","modified":1540624612390},{"_id":"source/_posts/effective-cpp-07.md","hash":"9e1bdeada5048e08c7531bd0e8b114e880bdf03b","modified":1540624612392},{"_id":"source/_posts/effective-cpp-05.md","hash":"6aaaad76185c4c262e7ce6f5ae2bd8f4f4e1692e","modified":1540624612391},{"_id":"source/_posts/effective-cpp-08.md","hash":"cf3ad741018efe0911b74f229dcbc9616e86b082","modified":1540624612393},{"_id":"source/_posts/effective-cpp-06.md","hash":"a97c471b35cd485babdaa22b726879380be07a8d","modified":1540624612392},{"_id":"source/_posts/fuck-gfw.md","hash":"90086691982d3249a50e58b5e9e1eab118914b53","modified":1540624612394},{"_id":"source/_posts/focal-loss-paper.md","hash":"3f4893dc8ec20067bf415ce0a197a38a9af11ba9","modified":1540624612393},{"_id":"source/_posts/hello-world.md","hash":"4f8e32b2e53a4fac4c027bcef5f29a060b3ff949","modified":1540624612396},{"_id":"source/_posts/gsl-with-vs.md","hash":"0c68ecdd482dc8447b15003cefa2da5ec812d2e2","modified":1540624612395},{"_id":"source/_posts/hinton-nnml-01.md","hash":"6476c725e2436ecc85324bf0ea67e04cc3497614","modified":1540624612396},{"_id":"source/_posts/hinton-nnml-02.md","hash":"47d42cb75ce78cd13cff05471495ced79d284305","modified":1540624612397},{"_id":"source/_posts/hinton-nnml-06.md","hash":"92f039cb1e302c7be3909455efb4572a1da3f625","modified":1540624612398},{"_id":"source/_posts/inq-paper.md","hash":"2ec103e894968e0b6bb10bb119f9914405c67300","modified":1540624612398},{"_id":"source/_posts/knowledge-distilling.md","hash":"ac188e8ee6e70238b6f299f42a966c94bdee02b2","modified":1540624612401},{"_id":"source/_posts/install-ubuntu-in-dell.md","hash":"9a2e106f5f540d528edc913d57796b70640fb8c1","modified":1540624612399},{"_id":"source/_posts/jupyternotebook-remote-useage.md","hash":"7b918275be8efb37a05afa7491e7f8ab44bebf2d","modified":1540624612400},{"_id":"source/_posts/learn-pyqt.md","hash":"d56d516a5f1327d60b77c9e4e81aaca94b801363","modified":1540624612401},{"_id":"source/_posts/mac-update-mojave.md","hash":"ca0536169a503e2bed08cfdd85c82dcd59835ec6","modified":1540624612401},{"_id":"source/_posts/mathfunctions-in-caffe.md","hash":"d81f68345b9d1467338a9a902eef6af2b62dbcde","modified":1540624612402},{"_id":"source/_posts/mxnet-fit-usage.md","hash":"01dba5ef12ed8e6f59aa4dd39c9c28d0cb856e5d","modified":1540624612402},{"_id":"source/_posts/newton-method.md","hash":"c12870fb67badb70ba2a0f4a51f616eef93a3dcf","modified":1540624612403},{"_id":"source/_posts/paper-knowledge-transfer-neural-selectivity-transfer.md","hash":"00b4e5bfa86459fdf2f9d0f66db5216fbe64f932","modified":1540624612405},{"_id":"source/_posts/paper-mobilenet.md","hash":"405818475f060c6b012f1d031c496493e5e21b44","modified":1540624612405},{"_id":"source/_posts/paper-fpn.md","hash":"fdc0fc15e59cbcf8fa7bbecfd6e156bb8e93ddd3","modified":1540624612404},{"_id":"source/_posts/paper-network-prune-hansong.md","hash":"1cfff0c8b8ef28868c8c870559b86f68f50e104b","modified":1540624612406},{"_id":"source/_posts/paper-ssl-dnn.md","hash":"05feeae8ec9ac6719fcd36b391d8ebbc7529818a","modified":1540624612409},{"_id":"source/_posts/paper-squeezenet.md","hash":"23beb8377788cada030385e29d5fe9da04271e7f","modified":1540624612408},{"_id":"source/_posts/paper-rethinking-the-value-of-network-pruning.md","hash":"04d84001a78d027d9e81387243b0ece4c89c62be","modified":1540624612407},{"_id":"source/_posts/paper-summary-model-pruning.md","hash":"6df90e7885260ef440b053cd0ffe31f779c1af78","modified":1540624612410},{"_id":"source/_posts/paper-xception.md","hash":"44a54ccc140d3fede4f6b03af770241c7cc808e5","modified":1540624612411},{"_id":"source/_posts/paper-yolov3.md","hash":"a29f708d7e17f86af1d1b2472c1b92f924662b81","modified":1540624612412},{"_id":"source/_posts/paper-visualize-convnet.md","hash":"a59849e00b9cdcabff77707fb5df0d6a3bcef7d7","modified":1540624612411},{"_id":"source/_posts/python-reg-exp.md","hash":"6e9499e3e519b41e5fff1627d04e9f3ee2003432","modified":1540624612413},{"_id":"source/_posts/python-iter-generator.md","hash":"1555669f41aec84762e9d345fed081640ffbf532","modified":1540624612413},{"_id":"source/_posts/pytorch-040-migration-guide.md","hash":"2614b32162818948ef66ce0347b2f9fcb883a0ba","modified":1540624612414},{"_id":"source/_posts/residualnet-paper2-identitymapping.md","hash":"1a7f16cc067e358c15af4a62ba3c80978fc71e89","modified":1540624612416},{"_id":"source/_posts/pytorch-mnist-example.md","hash":"3ad4cd4f67cde2515e08def0a4214499d5b51e29","modified":1540624612415},{"_id":"source/_posts/residualnet-paper.md","hash":"83b8830740628e82ad4c3c6ded7e564d5e4e0d02","modified":1540624612416},{"_id":"source/_posts/pytorch-tutor-01.md","hash":"cfe0effb4933e2daba0ae90882f8ca785fecc0a5","modified":1540624612415},{"_id":"source/_posts/set-env-in-jupyternotebook.md","hash":"d55b2eff613740c347490adb4bb16008a80c7840","modified":1540624612417},{"_id":"source/_posts/shell-programming.md","hash":"38e8fecf7c36701bb8dea89552ab8d0b2abc83af","modified":1540624612417},{"_id":"source/_posts/silver-rl-dp.md","hash":"e71580ef3c92cf2dd905923857c105ad37cc2b96","modified":1540624612418},{"_id":"source/_posts/silver-rl-mdp.md","hash":"ae6f085514a39cbe86add05f700e74645a701d57","modified":1540624612418},{"_id":"source/_posts/use-doxygen.md","hash":"065620944cfe7c382ddd26f7e48cdc8b868f7336","modified":1540624612419},{"_id":"source/_posts/useful-tools-list.md","hash":"d51c10d5365f78f3e30cd09bdfc1551ab9524a0d","modified":1540624612420},{"_id":"source/_posts/ubuntu-cannot-mount-exfat-disk.md","hash":"0d7e85f790b76454d056d29fb3c31eb9dcb52e93","modified":1540624612418},{"_id":"source/_posts/video-linear-alg-essential-property.md","hash":"816cafa7a5b551bfa2ac3ee2e402cc77dd64d821","modified":1540624612420},{"_id":"source/_posts/vim-you-complete-me.md","hash":"9d8661b9f0d1cd6d044ccbaff3d735a108cf6880","modified":1540624612421},{"_id":"source/_posts/warpctc-caffe.md","hash":"e0b82a11af55cafd21e5ee59f33be9361db2a3e3","modified":1540624612421},{"_id":"source/_posts/yolo-cfg-parser.md","hash":"4f2a9ada97562a75545b599bfa016a393203960d","modified":1540624612422},{"_id":"source/about/index.md","hash":"b74a0d866deabb668895c0df0386f9f54fe7ada9","modified":1540624612425},{"_id":"source/tags/index.md","hash":"373c64088bf05b888f592ce18dd880fdbc87140b","modified":1540624613221},{"_id":"source/_posts/yolo-paper.md","hash":"9ff9ad75d3229f29b43c6a991b5fea98dd59f45f","modified":1540624612423},{"_id":"source/img/caffe-hack-pycaffe-python-cpp-binding.jpg","hash":"9965a71838fbf4c4598a9b5ec35fd3aa230e511f","modified":1540624612440},{"_id":"source/img/caffe_mathfunctions_gpuisnuclearweapon.jpg","hash":"0de63da28688d902aa01233db9255068a81f7031","modified":1540624612450},{"_id":"source/img/camera_skew.png","hash":"c02198d706e8366ffd307fccc931f0400317642c","modified":1540624612515},{"_id":"source/img/captcha_test_accuracy.png","hash":"74880dfb9c94598cad889c939017bbc9e8576250","modified":1540624612521},{"_id":"source/img/captcha_train_loss.png","hash":"7bb018f8aec8b99b91679e18db2916dfea5d5495","modified":1540624612521},{"_id":"source/img/case_1_m.png","hash":"6d4b596285b981d003a660d3ce03a95a74946576","modified":1540624612522},{"_id":"source/img/case_4_m.png","hash":"85dee8dc61da967d28caa56a10d949f9de5b2e24","modified":1540624612527},{"_id":"source/img/case_3_m.png","hash":"b2d5bc2d469bbf0e4a4534c191feb4a30132e5cc","modified":1540624612525},{"_id":"source/img/case_2_m.png","hash":"ced9ffe517ff6250f0f6a4e402897592233018ba","modified":1540624612524},{"_id":"source/img/conv-in-caffe-im2col-1.png","hash":"978fc174bdde302d5917259d3accfded2ec680a4","modified":1540624612542},{"_id":"source/img/case_m_5.png","hash":"dca097cea37695ed4b237671b017c2f04940de8e","modified":1540624612529},{"_id":"source/img/conv-in-caffe-im2col-3.png","hash":"4f32b2a30a00f0b20d81e472e5f8f4373fb06fbf","modified":1540624612544},{"_id":"source/img/convex_opt_intro_title_pic.png","hash":"104e43aea89f97f9d601fb201baa3aecbb089d40","modified":1542473352747},{"_id":"source/img/corner_type_1.png","hash":"4c431c0faf73514d013771932114831969ab3038","modified":1540624612567},{"_id":"source/img/cs131_opticalflow_brightnessconstancy_assumption.png","hash":"a80570ae3e40181cd337fd8a210f9455326094d4","modified":1540624612591},{"_id":"source/img/cs229-supervised-learning-least-square-normal-equation.png","hash":"4915a005769553575540f941fb325c5147da3f76","modified":1540624612604},{"_id":"source/img/cs229-supervised-learning-sigmoid.png","hash":"a33c1eeedb216eb7f8ce7be2b69c90e284555c5f","modified":1540624612605},{"_id":"source/img/cs229-supervised-learning-some-useful-matrix-derivatives.png","hash":"1e0238a3eb66cf3ec7ecb6a2d8b17568967586a5","modified":1540624612605},{"_id":"source/img/effectivecpp_02_pointers.png","hash":"11c3156dfc9b34242a0a53785da8e1c544bd8702","modified":1540624612639},{"_id":"source/img/effective_cpp_07_joke.jpg","hash":"08743427f366b31f4d155e80394b78076852773f","modified":1540624612638},{"_id":"source/img/effectivecpp_01_cpp_rely_on_renpin.jpg","hash":"a9608a9d7d702c0f94912d77a5e340bdbf791093","modified":1540624612638},{"_id":"source/img/effectivecpp_04_cwithclass.jpg","hash":"0f8efb48280903e335e75869cb1534664f87a608","modified":1540624612639},{"_id":"source/img/effectivecpp_08_memory_leak_everywherre.jpg","hash":"ad604af84e93047fd6527c0899b4c47a67910df5","modified":1540624612641},{"_id":"source/img/effectivecpp_diamond.png","hash":"93e89a2b9476a7cf1aa87e91d54866564eadd5cc","modified":1540624612642},{"_id":"source/img/effectivecpp_strategy_pattern.png","hash":"4b3cbc58261b48a08a53e2a402e0c33697726d1d","modified":1540624612642},{"_id":"source/img/gsl_picture.jpg","hash":"1f4b216b84bae09a72bac183d04503ecf5215a0c","modified":1540624612683},{"_id":"source/img/helloworld_hexo.png","hash":"f4227d5040c36734b9fb0d5f57eb1f6669199b87","modified":1540624612690},{"_id":"source/img/hack-pycaffe-code-organization.png","hash":"06879d67d05b5a8196bbd8fe3af2c8bdf25e64b8","modified":1540624612684},{"_id":"source/img/hinton_01_neuron_commucation.png","hash":"92bd15934436c01e73af2a84c82cc9f29eec6cec","modified":1540624612692},{"_id":"source/img/hinton_02_margin.png","hash":"38eb68b50c0dbcebcb217edafee7aff6c5742d1d","modified":1540624612699},{"_id":"source/img/hinton_01_neuron_structure.png","hash":"270884f27a9a78e6285ca96902d8e96cc7ae05e7","modified":1540624612693},{"_id":"source/img/hinton_02_perceptron_gragh.png","hash":"542614250f7f25345633c3cacf780370c9edc70b","modified":1540624612700},{"_id":"source/img/hinton_06_maanmian.jpg","hash":"85a0994193b98d60aafc366a8558064b7c323983","modified":1540624612722},{"_id":"source/img/hinton_brainsimulator.jpg","hash":"f823531a7ff9b1d12be0e1e7dfa337c83caaf805","modified":1540624612749},{"_id":"source/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg","hash":"f8b3e8d9d6254897e7ef25bd237f4cfeac0a19d9","modified":1540624612771},{"_id":"source/img/install_ubuntu_in_dell_weixiaojiuhao.jpg","hash":"c730683b4d25f4c69b15dc08875a397063fc8722","modified":1540624612771},{"_id":"source/img/jupyternotebook_logo.png","hash":"d6e1c6cf1171c28573949ef19f9cadfc19092a07","modified":1540624612776},{"_id":"source/img/install_ubuntu_in_dell_kaiyuandafahao.jpg","hash":"6a46ba1d17ae795fae0d82939b4138cec87db7a2","modified":1540624612771},{"_id":"source/img/kmeans_data_demo.png","hash":"f7cf89ccebbfd8d9b3ea5ab2b82f0fe52722755a","modified":1540624612794},{"_id":"source/img/kmeans_success.png","hash":"0fa428daf7f61a07b3d0c1946de4d6aa98fe0647","modified":1540624612828},{"_id":"source/img/line_fit_demo.png","hash":"0916a1148ce54c4b0f9bfc2dde33bd35782bf724","modified":1540624612829},{"_id":"source/img/meanshift_simple_demo.png","hash":"201a77852c5d0c90c1fa0369d07599cb5237e2e5","modified":1540624612847},{"_id":"source/img/meanshift_basics.jpg","hash":"6461e3234fbae264333a7c1a9cf74b1faf1fe7b5","modified":1540624612843},{"_id":"source/img/mnist_example.png","hash":"998011e1ab53d491adec736cebc319511764561e","modified":1540624612848},{"_id":"source/img/newton-method-demo.gif","hash":"58114cedf610fe6b1a1869a8b8f67f76a507314c","modified":1540624612848},{"_id":"source/img/paper-fpn-lateral-connection.png","hash":"555b8fcceea3b2aa20d624231868cba9dc2f39e3","modified":1540624612855},{"_id":"source/img/paper-mobilenet-alpha-compact.png","hash":"739a183dd6cc2b943f1cbac8de20497a9958ce70","modified":1540624612875},{"_id":"source/img/paper-mobilenet-comparision-with-other-model.png","hash":"47e16889a138472824ae93bd7e138f41d6bc7a08","modified":1540624612877},{"_id":"source/img/paper-mobilenet-alpha-rho-effect.png","hash":"54de0a42b4b8bc38881c71f65ecd2bbcf4b34c7f","modified":1540624612876},{"_id":"source/img/paper-mobilenet-conv-unit.png","hash":"337447acfa5b51a021be0520623d1408cb4401f8","modified":1540624612878},{"_id":"source/img/paper-mobilenet-depthwise-separable-conv.png","hash":"119718b3be5a533644e3b1d83798d7a682349900","modified":1540624612879},{"_id":"source/img/paper-mobilenet-depthwise-vs-full-conv.png","hash":"c1a14f06d66fb870b4dfa224f0819ff5c7abcb1f","modified":1540624612880},{"_id":"source/img/paper-mobilenet-narrow-vs-shallow-net.png","hash":"7e2bc177415e20500616b86f1f0426aa85a9d29b","modified":1540624612880},{"_id":"source/img/paper-mobilenet-rho-compact.png","hash":"8e1447091ebad3c621405aa17bee52df104a404d","modified":1540624612883},{"_id":"source/img/paper-model-pruning-why-so-baixue.jpg","hash":"a6a0b8820db5aeb46c4152045328fb98e1b0715a","modified":1540624612894},{"_id":"source/img/paper-pruning-network-demo.png","hash":"1673097bbc83f10f817221231fc4498067a3fcff","modified":1540624612920},{"_id":"source/img/paper-pruning-network-layer-sensitivity.png","hash":"2f96f72b4e316cbef4fd2ca5e26d2811e962dc5e","modified":1540624612922},{"_id":"source/img/paper-pruning-network-iterative-pruning.png","hash":"5fbeb25e30228716789ce5ce01c30fc166559d50","modified":1540624612921},{"_id":"source/img/paper-pruning-network-energy-for-different-memory-hieracy.png","hash":"cd846fc5c332af56c6c9b2d0e55edaec58797bd7","modified":1540624612921},{"_id":"source/img/paper-squeeze-sr-impact.png","hash":"057fe25117e179fb5621730cd9afd68a4600c039","modified":1540624612929},{"_id":"source/img/paper-squeezenet-bypass.png","hash":"62811d618a6747b6bd872b3a8946e7720194d77d","modified":1540624612932},{"_id":"source/img/paper-ssldnn-experiment-on-lenet.png","hash":"b62370119b99bc6c9a74c6e676adf6d5d64514ae","modified":1540624612938},{"_id":"source/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png","hash":"82d99a5b4a1b55ec1368e72279513ee67600be09","modified":1540624612939},{"_id":"source/img/paper-xception-equivalent-inception-module.png","hash":"ebcbb946f5f5c999ef9e571318ac190134bae4d5","modified":1540624612958},{"_id":"source/img/paper-summary-model-pruning-joke.jpg","hash":"3d22acad1a54f4e71f0ab3a65a181294f1904710","modified":1540624612954},{"_id":"source/img/paper-xception-extreme-version.png","hash":"a947d5165939d5949775de455b876638a29f0aaa","modified":1540624612960},{"_id":"source/img/paper-xception-inception-module.png","hash":"6832cfc7dfe9b570aab3db68a73bf9cea3633beb","modified":1540624612961},{"_id":"source/img/paper-xception-simplified-inception-module.png","hash":"f06b2886721c55e327b8245a1d022759d5ad3831","modified":1540624612962},{"_id":"source/img/paper=yolov3-bbox-regression.png","hash":"70c179ff055cac2b563708c1f56fbf2ebef29450","modified":1540624612968},{"_id":"source/img/paper_visconvnet_layer1_demo.png","hash":"22df5fcf87f3d3515f434c392bfae960d3d1b4ed","modified":1540624612975},{"_id":"source/img/paper_visconvnet_uppooling.png","hash":"b8f7e0e31a0bef2556a3affe550f65383b7a5041","modified":1540624612976},{"_id":"source/img/pytorch_logo.png","hash":"6fd1856de312e104cc62ad804b6006d205b74c74","modified":1540624613012},{"_id":"source/img/qicizuobiao.png","hash":"2bd2071a724832d96284a6d5a685991ab087f801","modified":1540624613013},{"_id":"source/img/ransac_step.png","hash":"eb9e2d50c4920cfd4516c9e7df2c981d8544b118","modified":1540624613023},{"_id":"source/img/residualnet_unit.png","hash":"d86018307f8101c6d010174d81490ebf1277b09a","modified":1540624613042},{"_id":"source/img/rotation.png","hash":"11557a269f79012091059c15602438a69a211721","modified":1540624613046},{"_id":"source/img/set-env-in-notebook-choose-kernel.png","hash":"ffde7cb9dfb4f6404a42ab5503a981051399e5c0","modified":1540624613051},{"_id":"source/img/set-env-in-notebook-change-kernel.png","hash":"ea03e063f5abfee0f22eaf370ec2c6b4ee5599c5","modified":1540624613050},{"_id":"source/img/shell-programming-bash-logo.png","hash":"8501d934280e5144af436b03b0b815474dfd79b0","modified":1540624613052},{"_id":"source/img/sift_dominant_orientation.png","hash":"9a5a1538b25d9b7edcc18e23ad8a41fdaea341c8","modified":1540624613088},{"_id":"source/img/sift_picture.jpg","hash":"7c6be74bdd2c1ee630ba913e39012e8d515dc920","modified":1540624613114},{"_id":"source/img/silver_rl_bellman_equation_matrix.png","hash":"26f1c7be02d145832d2d5537b588a5bd12aad13a","modified":1540624613117},{"_id":"source/img/silver_rl_bellman_equation_figure.png","hash":"9e2cade1db517dc26ba4d845dbca0633006ebee2","modified":1540624613116},{"_id":"source/img/silver_rl_bellman_equation_solution.png","hash":"63ca3871282327e8815e7873780721075e34ea2a","modified":1540624613118},{"_id":"source/img/silver_rl_dp_policy_evaluating_demo.png","hash":"87a5e83dd518ce1b2ced9fd33534da4905689878","modified":1540624613124},{"_id":"source/img/silver_rl_dp_policy_evaluating_demo_result.png","hash":"13e05cadf85bdb48873c76a308b6f96d3e9b4bed","modified":1540624613125},{"_id":"source/img/silver_rl_mdp.png","hash":"b021de45efc46674613a7848ef36104e5f7e0021","modified":1540624613131},{"_id":"source/img/silver_rl_mdp_optimal_policy.png","hash":"a0c1ff0323b1af537c2be1ebc9d312e6e8a65933","modified":1540624613131},{"_id":"source/img/silver_rl_mdp_optimal_vq_relationship.png","hash":"c63650bcd9ff2f206f5af900b68f503ee94eb0d7","modified":1540624613134},{"_id":"source/img/silver_rl_mdp_optimal_vq_relationship2.png","hash":"20b91ee1732002cc624b1c8c0a213616e45068a9","modified":1540624613135},{"_id":"source/img/silver_rl_mdp_vq_relationship2.png","hash":"33d92cd984cda6d2299ac0b9d29067ee6c6ff9bb","modified":1540624613139},{"_id":"source/img/silver_rl_mdp_vq_relationship.png","hash":"4e125735fa32b5d1131fbbaa3d903200376fef67","modified":1540624613138},{"_id":"source/img/svd_picture.jpg","hash":"10cae458d21313eb9409e87c7a680c79d188f395","modified":1540624613146},{"_id":"source/img/svd_ranking.png","hash":"6cae2c6139567934a59a8e93d9672633d1016e1a","modified":1540624613146},{"_id":"source/img/yolo2_bbox_location.png","hash":"0c2f9c8b0bf4993abf1596869028fc69c2774dfd","modified":1540624613203},{"_id":"source/img/yolo2_bbox_param.png","hash":"5be107b1b67e823d3a2dd05f385dc98d3588dabf","modified":1540624613203},{"_id":"source/img/yolo2_cluster_result.png","hash":"1378adcf8ae8e6db2e7f1f81a9e6d6c8ec849fbb","modified":1540624613204},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1540624613270},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1540624613270},{"_id":"themes/next/languages/default.yml","hash":"767470a80dc257e23e14c3a78e8c52a46c9d6209","modified":1540624613272},{"_id":"themes/next/languages/fr-FR.yml","hash":"9fca01ef917d33ae2ae6bc04561ec6799dff5351","modified":1540624613272},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1540624613272},{"_id":"themes/next/languages/en.yml","hash":"40057d6608e825d06e0864bac4dcd27ed88ada87","modified":1540624613272},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1540624613273},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1540624613273},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1540624613273},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1540624613273},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1540624613274},{"_id":"themes/next/languages/ru.yml","hash":"257d11e626cbe4b9b78785a764190b9278f95c28","modified":1540624613274},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f6c9fafa0f5f0050cd07ca2cf5e38fbae3e28145","modified":1540624613274},{"_id":"themes/next/languages/zh-hk.yml","hash":"34c84c6d04447a25bd5eac576922a13947c000e2","modified":1540624613275},{"_id":"themes/next/languages/zh-tw.yml","hash":"c97a5c41149de9b17f33439b0ecf0eff6fdae50e","modified":1540624613275},{"_id":"themes/next/layout/_layout.swig","hash":"7a1e4443c3ba1e08c20e64ddbf0b8255d034dab0","modified":1540624613276},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1540624613292},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1540624613293},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1540624613293},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1540624613293},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1540624613293},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1540624613294},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1540624613294},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1540624613295},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1540624613360},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1540624613361},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1540624613361},{"_id":"source/img/bug_pycaffe_nvidia_smi_result.png","hash":"a37d08333c232762669204e8ec9cb900bb5dde6c","modified":1540624612439},{"_id":"source/img/caffe-net-demo.jpg","hash":"7d473c03a6bee2d215b1ce78e75e89689e276b01","modified":1540624612442},{"_id":"source/img/caffe_bn_bp_of_bn.jpg","hash":"e16455064f7de834d18e74b45b18dc86da509c22","modified":1540624612443},{"_id":"source/img/caffe_mathfunctions_useuva.png","hash":"0eabfe2a025f3466bd353d99402bef456c6601f7","modified":1540624612452},{"_id":"source/img/caffe_syncedmem_blob_flow.jpg","hash":"7c240c8e7d2a9cc67bcabb0f24aafa1394a90ec1","modified":1540624612480},{"_id":"source/img/caffe_syncedmem_transfer.png","hash":"77a0421f7f3b5e866d8bbd391dbb6920e8892ade","modified":1540624612485},{"_id":"source/img/canny_linking.png","hash":"8545dcacf874990d7d1b1ae074abbf4eb694f382","modified":1540624612519},{"_id":"source/img/canny_nms.png","hash":"363582d281cb85ba31ebf20dff0b1e7e7c2588cb","modified":1540624612521},{"_id":"source/img/case_6_m.png","hash":"bbd8245d6e3478b0287629f778aa8489489f3a37","modified":1540624612528},{"_id":"source/img/conv-in-caffe-im2col-2.png","hash":"1693d6c83fc30c56e485f8ff1fc25eb753f06cda","modified":1540624612544},{"_id":"source/img/cs131_opticalflow_assignment_crossfade.gif","hash":"8bf5d5fc72d00b2f155f9b4a5c639351d090ca19","modified":1540624612578},{"_id":"source/img/corner_window_fun.png","hash":"81b549c79bbe2bec390aab961ea503d9e80980a5","modified":1540624612568},{"_id":"source/img/cs131_opticalflow_assignment_flowwarped.gif","hash":"4f64ac26d3a4b4221a2b3fbd38e67cd45472be53","modified":1540624612585},{"_id":"source/img/cs131_opticalflow_assignment_forwardwarped.gif","hash":"3c6c979437f88d25448586b18af08cae3c1d6a4b","modified":1540624612588},{"_id":"source/img/cs131_opticalflow_demo.jpg","hash":"1fd9ea1700ad63bdff80c64c15e4782267ce8a1d","modified":1540624612593},{"_id":"source/img/cs131_opticalflow_lkrelationshipwithharris.png","hash":"9f369b094c44815373463074924559381f479055","modified":1540624612600},{"_id":"source/img/cs131_opticalflow_lkleastsquare.png","hash":"2c10891de2393d326d2c14698feb9dbf32f46802","modified":1540624612598},{"_id":"source/img/differences-of-deep-learning-frameworks-22-638.jpg","hash":"fbea0a3dbab07d87b6080c66e867bb2636117189","modified":1540624612607},{"_id":"source/img/doc2dash_how_to_add_docset.jpg","hash":"67d4b405e4c9de0b21df1ee874d20bcbece0d3ca","modified":1540624612608},{"_id":"source/img/edge_camera_man.png","hash":"99c2057614bdc949df7310fded651a0ea80e4e5e","modified":1540624612636},{"_id":"source/img/doxygen_picture.png","hash":"f4236c94b6b661d6d54343d58e5fefbdc2d98160","modified":1540624612634},{"_id":"source/img/edge_deriative.png","hash":"a26ae2c627cdf6b95419c89d52689ad06fdb7d0d","modified":1540624612637},{"_id":"source/img/effectivecpp_06_joke.jpg","hash":"7bbd12277769af9f7f43bc2792df18a6b65e114c","modified":1540624612640},{"_id":"source/img/god_use_vpn.png","hash":"9eac5df14cdc99596cd1872c4f958e60a943d90e","modified":1540624612681},{"_id":"source/img/harris_non_scale_constant.png","hash":"e36afe38ba3f1e428c435b00c12d030c43edb108","modified":1540624612689},{"_id":"source/img/hinton_02_feed_forward_nn.png","hash":"1a76251378e9133204889641bb2d132a061069eb","modified":1540624612697},{"_id":"source/img/hinton_02_perceptron_xor.png","hash":"6f771f53c343e41c919763be0d28445eea9bca94","modified":1540624612703},{"_id":"source/img/hinton_02_recurrent_nn.png","hash":"f8f5606d55a8d381fad8ee4db97ab1e41db63bcf","modified":1540624612704},{"_id":"source/img/hinton_02_why_training_works_1.png","hash":"b60f818d861af5c6b91617d78d85cdc381894dfe","modified":1540624612712},{"_id":"source/img/meanshift_kernel_function.png","hash":"8cababe376a596d11fce090968d0b3046c9fbaa6","modified":1540624612846},{"_id":"source/img/meanshift_gradient_of_density.png","hash":"1a33449962e301dc741e56673579e055f3d41aab","modified":1540624612844},{"_id":"source/img/paer_visconvnet_deconvnet_structure.png","hash":"6197239b8da88442d8858a4e3cce341f247d9411","modified":1540624612851},{"_id":"source/img/paper-fpn-different-with-related-work.png","hash":"15d20cbcca8a9e7d876bf9bb4ad0446aafcf6575","modified":1540624612854},{"_id":"source/img/paper-inq-quantize-set.png","hash":"7038d10998546436dd75632ecabd146c943d0dc6","modified":1540624612868},{"_id":"source/img/paper-mobilenet-net-arch.png","hash":"df426645944e9e43ae31a1d27e11b0ff09e241ae","modified":1540624612882},{"_id":"source/img/paper-pruning-network-algrithem.png","hash":"017b0a3ce924eff0f530cd18562b04e8e72bf3f1","modified":1540624612919},{"_id":"source/img/paper-pruning-network-lstm.png","hash":"f69d6f3fac24e0f5ee5a3e21253191a9c49c8101","modified":1540624612924},{"_id":"source/img/paper-pruning-network-regularization.png","hash":"320a5182f03203e6b47191a1268ae4eb14bf0e23","modified":1540624612926},{"_id":"source/img/paper-pruning-network-results.png","hash":"e204166ea91a8f7d4261624c30c53ce23b6ab3af","modified":1540624612927},{"_id":"source/img/paper-squeezenet-benchmark.png","hash":"e732391e8b13c571f6d1054ee3e1c7b11f24eaf5","modified":1540624612931},{"_id":"source/img/paper-squeezenet-pct-impact.png","hash":"2d6b71258886d53aba1a481393514bad5f770424","modified":1540624612937},{"_id":"source/img/paper-squeezenet-fire-module.png","hash":"cc4f13dc1c165af7e49cd486a679cf624c2a1d1d","modified":1540624612934},{"_id":"source/img/paper-ssldnn-random-sparity-is-bad.png","hash":"d193776bef8717cd09cdd43c35fac2fca7a03230","modified":1540624612940},{"_id":"source/img/paper-ssldnn.png","hash":"9e5be04a3bc183c2c442819e4b08ec4f584d64a1","modified":1540624612941},{"_id":"source/img/paper-xception-experiment-intermediate-activation.png","hash":"bd38231fda95333e0e0256650910770b02dc6470","modified":1540624612959},{"_id":"source/img/paper-yolov3-comparison-retinanet.png","hash":"2e1e590d05707d54d633a2611709a2981f0edf9e","modified":1540624612964},{"_id":"source/img/paper-yolov3-comparisons.png","hash":"4b447fefe85d05c326e16d3b07bd2a2f2c6effef","modified":1540624612966},{"_id":"source/img/paper-yolov3-darknet53.png","hash":"a4630c02a6baaab34cd913246661e2db6850e4bd","modified":1540624612967},{"_id":"source/img/patch_average_intensity_scale_constant.png","hash":"bd0609e8de60de54e12c47ef7416c972f3582a0b","modified":1540624612977},{"_id":"source/img/qicizuobiao_transform.png","hash":"06b6ea9933a6d47c79b700f5c2d3c83e9cd4602f","modified":1540624613015},{"_id":"source/img/residualnet_bottleneck_unit.png","hash":"e0bc9a473bc68919afc7cd7b8fcd19262f223ae4","modified":1540624613033},{"_id":"source/img/residualnet_improved_structure.png","hash":"5a3aba104935d6be97dc2b5567c83e3a71cace88","modified":1540624613040},{"_id":"source/img/rotation_matrix.png","hash":"35aed3946385abfcd448fe99c796db440ea0ddb6","modified":1540624613049},{"_id":"source/img/sift_detection_maximum.png","hash":"eaa0c3e9bda32792b35008184e794bd3e8966cf4","modified":1540624613077},{"_id":"source/img/silver_rl_dp_detailed_prioritized_dp.png","hash":"5290a941f15980888f15c2fddaa049f6b0685f15","modified":1540624613118},{"_id":"source/img/silver_mdp_value_function.png","hash":"9a297ebb51eced462f17529af9e797370b2b837d","modified":1540624613116},{"_id":"source/img/silver_rl_dp_improve_policy_greedily_proof_2.png","hash":"1b94a0f3bebb5b840430afab177e6cce03f766e9","modified":1540624613122},{"_id":"source/img/silver_rl_dp_inplace_value_iteration.png","hash":"7c49c42afa727f6d5903848aeede42ee32c84704","modified":1540624613123},{"_id":"source/img/silver_rl_dp_synchronous_value_iteration.png","hash":"7a62cc20abef6add247d0ad8fe5061fb393f212c","modified":1540624613129},{"_id":"source/img/silver_rl_dp_realtime_dp.png","hash":"b50c4ebd39926014f294ff4e899eb88bbf2024fc","modified":1540624613126},{"_id":"source/img/silver_rl_dp_value_iteration_demo.png","hash":"24e1a868e5b085367fa9c06cc3f152ebf8d3ef95","modified":1540624613130},{"_id":"source/img/silver_rl_mdp_optimal_qq_relationship.png","hash":"2ee8fad62930a985f6edff667fc443915d5ddff3","modified":1540624613133},{"_id":"source/img/silver_rl_mdp_qq_relationship.png","hash":"6924625a90af23d3ac82a68c6cc667bc58513164","modified":1540624613137},{"_id":"source/img/silver_rl_mdp_optimal_vv_relationship.png","hash":"8fb74930631641a34ddc58e534f9b370666c4604","modified":1540624613136},{"_id":"source/img/silver_rl_mdp_vv_relationship.png","hash":"0f8f68c65bcad5d07cf4a5a4df12cc45a92dd771","modified":1540624613140},{"_id":"source/img/svd_superman.png","hash":"a4c3b97c4acfac14b978a6a00d163e2436227eda","modified":1540624613148},{"_id":"source/img/video_linear_alg_essential_linear_equation.png","hash":"678acc30007fe3cb83323a41b7152f8f2cf06e19","modified":1540624613163},{"_id":"source/img/yolo1_loss_fun.png","hash":"b3019b1551e05b6fc109dfa788408582d0855aa1","modified":1540624613200},{"_id":"source/img/yolo1_network_arch.png","hash":"eff2b8461119c0a1f32268ebe8a8bfb3e3a15b99","modified":1540624613202},{"_id":"source/img/yolo2_different_methods_comparation.png","hash":"abc4705828afe401a773a2ce29e4d2fc8474237a","modified":1540624613210},{"_id":"source/img/yolo2_different_methods_improvement.png","hash":"05ee7120be804c38a2867508e39aaaaeff7601ed","modified":1540624613215},{"_id":"source/img/yolov3-comparision-with-retina.png","hash":"6b8ca8c35609cd1c3707d2efbf5e0011ba496987","modified":1540624613221},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613324},{"_id":"source/_posts/.vscode/tags","hash":"9a081dd0c4bcf261823f304d3359c4eb49fa5a8f","modified":1540624612372},{"_id":"source/img/camera_translation_rotation.png","hash":"bd89b487aff4a1c8aa5faff2dd8280557b480478","modified":1540624612518},{"_id":"source/img/conv-in-caffe-im2col-followed-gemm.png","hash":"f7e50f1b9067d2af265a033883b66ca7f29b97ca","modified":1540624612546},{"_id":"source/img/conv-in-caffe-naive-loop.png","hash":"19daff554efd52644e600916b24faf6039b213c5","modified":1540624612548},{"_id":"source/img/corner_judge_2.png","hash":"d6daba0908de0a3686bc925c31f7c34adb4068f2","modified":1540624612567},{"_id":"source/img/corner_judge.png","hash":"4020cd84f4ea052bcc10ce09f25bd1bad8f5c293","modified":1540624612562},{"_id":"source/img/cs131_opticalflow_assignment_flowwarped.png","hash":"0794e55fa4ffeb0dc577744ba79efd8412870c5f","modified":1540624612586},{"_id":"source/img/cs131_opticalflow_assignment_forwardwarped.png","hash":"8112a39170254906989b5898a3f1a74215912d7a","modified":1540624612590},{"_id":"source/img/cs131_opticalflow_lkequation.png","hash":"ef0e3ea55870aa40e8abafcac5474371200cc6ed","modified":1540624612595},{"_id":"source/img/cs131_opticalflow_lkharris.png","hash":"d5f8d63186a593dbd437f888123c594d6668f528","modified":1540624612597},{"_id":"source/img/epipolar_constraint_1.png","hash":"25afbc27d8c7d984106b8fd65fff9aa4a97f624b","modified":1540624612645},{"_id":"source/img/epipolar_fig.png","hash":"ae34928aff5f8125b99f237c7e0dd1ee0b006839","modified":1540624612647},{"_id":"source/img/generic_projection_matrix.png","hash":"4bf8906146b76f3fc74891042de14982eece2346","modified":1540624612681},{"_id":"source/img/fun_noise.png","hash":"b1e7adbf4ffd2801b0685be5213579bf0f7d16e3","modified":1540624612676},{"_id":"source/img/hinton_01_mnist_example.png","hash":"6b2b2ea6952bb910fc5f1b32a86eece597835201","modified":1540624612692},{"_id":"source/img/hinton_01_sigmoid_function.png","hash":"57d2d037299607eb36d1cbcbbb48d1571814a448","modified":1540624612695},{"_id":"source/img/hinton_02_rnn_app.png","hash":"bc1a0a9bc95f2b1148ce46fb1a65eba8c526ab86","modified":1540624612705},{"_id":"source/img/hinton_02_perceptron_paradigm_for_pattern_recong.png","hash":"8bc1af8fa449ed6ff9ec79a58916fe9e31156db9","modified":1540624612701},{"_id":"source/img/hinton_06_adamax.png","hash":"0400a21629be95ec17fa7f0f887484d2a577adfc","modified":1540624612715},{"_id":"source/img/ipsec_ios_vpn_setting.png","hash":"a8cbce62cec6b3fe876ab1c8dd0efb06f69225ee","modified":1540624612776},{"_id":"source/img/kmeans_object_fun_vs_k.png","hash":"f543e4d170edba374ceea98bb8d3904c4a557a16","modified":1540624612816},{"_id":"source/img/kmeans_sensitive_to_outlier.png","hash":"a933295f1867a5684dd984d327f588de1a0f9fe8","modified":1540624612828},{"_id":"source/img/original_superman.png","hash":"310f3412935a64309e53d8e1d8403dd1c52206c8","modified":1540624612850},{"_id":"source/img/paper-fpn-different-pyramids.png","hash":"2827c0ff4fa7b528380d2dc73022d1609261dd4d","modified":1540624612853},{"_id":"source/img/paper-inq-different-quantize.png","hash":"1d704fafbcfbf6186cf9983e3c31c7b3a4db3ac9","modified":1540624612867},{"_id":"source/img/paper-squeezenet-macroarch.png","hash":"4eacdf5bd74dd46c592353a1170354ccb0390d1f","modified":1540624612935},{"_id":"source/img/ransac_k.png","hash":"abe2b6c3ff381e1c113c96b4839e579a59da8da0","modified":1540624613017},{"_id":"source/img/residualnet_deepnet_problem.png","hash":"dfa7ac480ee5ddd4d705dbd5b5ca75ee83b760f3","modified":1540624613039},{"_id":"source/img/residualnet_comparison_with_plainnet.png","hash":"1e838d861721ee62022309681e671d9b2cbe127e","modified":1540624613037},{"_id":"source/img/silver_rl_dp_improve_policy_greedily_proof.png","hash":"d665413bc7cd0e317e29f8ea91a3ba0a0fde2446","modified":1540624613121},{"_id":"source/img/what_is_corner.png","hash":"18bd784f1845b9252f72cb54e0128157db10a940","modified":1540624613181},{"_id":"source/img/yolo2_different_methods_comparation_in_table.png","hash":"7d0294948cc1680535e3dd04c179583005e07efa","modified":1540624613214},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1540624613276},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1540624613276},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1540624613277},{"_id":"themes/next/layout/_macro/post.swig","hash":"e6016def9b512188f4c2725399c9adc7bc41cdae","modified":1540624613277},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1540624613277},{"_id":"themes/next/layout/_partials/comments.swig","hash":"57377fdc1c435962e24bb6823ddd4c8f8fe73110","modified":1540624613278},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1540624613277},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"43d8830bb19da4fc7a5773866be19fa066b62645","modified":1540624613277},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1540624613278},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1540624613278},{"_id":"themes/next/layout/_partials/head.swig","hash":"ca56f92e2fa82b03853869f5073ee1a5626a4796","modified":1540624613278},{"_id":"themes/next/layout/_partials/header.swig","hash":"adab5c3f7b173f1b45454787f39dde07aea03483","modified":1540624613279},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"39d613e5a9f8389d4ea52d6082502af8e833b9f2","modified":1540624613279},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1540624613279},{"_id":"themes/next/layout/_partials/search.swig","hash":"1431719d1dbba3f5ee385eebc46376d1a960b2d5","modified":1540624613279},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1540624613282},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1540624613282},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1540624613283},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"4512867d80d9eddfc3a0f5fea3c456f33aa9d522","modified":1540624613292},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1540624613295},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1540624613295},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1540624613295},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1540624613296},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1540624613296},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1540624613323},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1540624613324},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1540624613324},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1540624613325},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1540624613325},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1540624613325},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1540624613326},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1540624613326},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1540624613326},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1540624613326},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1540624613326},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1540624613326},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1540624613327},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1540624613327},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1540624613327},{"_id":"source/img/caffe_image.jpg","hash":"a183ae9970b3fddd258210175a9f2f3ac62306be","modified":1540624612448},{"_id":"source/img/caffe_bn_what_is_bn.jpg","hash":"1b142a77b6478e2c4588189f6b5a49046181c09e","modified":1540624612446},{"_id":"source/img/just-a-joke.png","hash":"704a94cdda9d91c3a247b6fa0bb76e850c247f43","modified":1540624612779},{"_id":"source/img/kmeans_bigger_demo.png","hash":"926e9588bdb1c1bba243b0702ccfa959a4f46715","modified":1540624612793},{"_id":"source/img/paper-model-pruning-net-sliming-procedure.png","hash":"11087898398d068258b45222260bd9492547fd8f","modified":1540624612893},{"_id":"source/img/paper-xception-arch.png","hash":"96879eb571d1011504360aeac5594572ccf6fb2d","modified":1540624612957},{"_id":"source/img/pinhole_camera_model.png","hash":"b72eab7554feea7be265c28d0b11efc3156dae40","modified":1540624612980},{"_id":"source/img/resnet-164layer-cifar10-testing.jpg","hash":"9e93b700ba1e13d33b855dacdaa00f18dc8fdc18","modified":1540624613043},{"_id":"source/img/resnet-164layer-cifar10-training.jpg","hash":"cc95edb475c1657ada111dacb8824edbad7f3937","modified":1540624613046},{"_id":"source/img/silver_rl_dp_synchronous_dp_algorithms.png","hash":"5ad9c56b5c6e5ed4a802ee9e74df6c3b5f4fc87a","modified":1540624613128},{"_id":"source/img/yolo2_dartnet_19_structure.png","hash":"4f2a9c8c3d17fe4dacb97d3964dd568493c45422","modified":1540624613208},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613283},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613283},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613315},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613315},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613316},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613322},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1540624613323},{"_id":"source/avatar/liumengli.jpg","hash":"4069caff1851227a11b74759a75bec586c568cd3","modified":1540624612429},{"_id":"source/img/cs131_opticalflow_assignment_crossfade.png","hash":"11dadc455195bb31907dcdabe424d6661b83a44f","modified":1540624612584},{"_id":"source/img/cs131_opticalflow_pyramid.png","hash":"fa06334cf6cb2ae8524478a83da662d931bbbb76","modified":1540624612603},{"_id":"source/img/mathfunctions_time_distribution.png","hash":"de743cc640396c72f76ebded8086f567d12eca53","modified":1540624612841},{"_id":"source/img/paper-nst-imagenet-results.png","hash":"0818b963fe2a6fed9d6fa9d31d0358104f35d01d","modified":1540624612901},{"_id":"source/img/paper-nst-visulization-teacher-student-feature-map.png","hash":"34425594579ac566ba2fba085128d02632262fc6","modified":1540624612917},{"_id":"source/img/useful_tools_colored_man_pages.jpg","hash":"3a5796889bdd602b146661232f4861f59b37962b","modified":1540624613156},{"_id":"source/img/ubuntu_exfat.png","hash":"7651aac6370650a2038383cc327f596bbaf9da90","modified":1540624613153},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1540624613275},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"636f1181dd5887a70b4a08ca8f655d4e46635792","modified":1540624613276},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1540624613279},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1540624613279},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1540624613280},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1540624613280},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1540624613280},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1540624613281},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1540624613281},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1540624613282},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1540624613282},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1540624613283},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1540624613284},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"394d9fff7951287cc90f52acc2d4cbfd1bae079d","modified":1540624613284},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"ac88399b75144f35a806aad3b64797f3ac73a48e","modified":1540624613288},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1540624613290},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"b460e27db3dcd4ab40b17d8926a5c4e624f293a9","modified":1540624613290},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1540624613291},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1540624613291},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1540624613290},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1540624613315},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1540624613316},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1540624613316},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1540624613322},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c459aa6d607d8bcb747544e74f6ad0b8374aa3b1","modified":1540624613322},{"_id":"themes/next/source/css/_variables/base.styl","hash":"fc185c6cec79593775d1c2440dbe2a71cfbe2e99","modified":1540624613323},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1540624613327},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1540624613328},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1540624613328},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1540624613328},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1540624613329},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1540624613328},{"_id":"themes/next/source/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1540624613329},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1540624613328},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1540624613330},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1540624613334},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1540624613342},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1540624613342},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1540624613342},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1540624613342},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"c1072942459fa0880e8a33a1bd929176b62b4171","modified":1540624613343},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1540624613343},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1540624613344},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1540624613344},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1540624613344},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1540624613353},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1540624613354},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1540624613354},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1540624613354},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1540624613354},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1540624613354},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1540624613355},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1540624613356},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1540624613356},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1540624613360},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1540624613360},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1540624613359},{"_id":"source/img/bash-programming-comparing-string.jpg","hash":"a55e9ef5954a7961eccdaff14dd06c923a259cd3","modified":1540624612438},{"_id":"source/img/hinton_06_nesterov_momentum.png","hash":"5833f7accf4067323716b32a794f468eddbfc654","modified":1540624612727},{"_id":"source/img/kmeans_demo.png","hash":"b10c3c2d5eaf201c0111cde24cc8d3c4533134dd","modified":1540624612800},{"_id":"source/img/svd_flower.png","hash":"e1924f7eaf2a920c769fd63ba27baf210adf59c7","modified":1540624613144},{"_id":"source/img/video_linear_alg_essential.png","hash":"e11c2c04b910a7b9f1a5ccaee3ae9dbb67fca666","modified":1540624613160},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1540624613353},{"_id":"source/img/dog_x.png","hash":"5672ad3c046997781703816e4d58d3961fe26eeb","modified":1540624612632},{"_id":"source/img/paper-inq-result.png","hash":"704d4b7ef16f3d6f4fc7929c9b020c993f2c8fbd","modified":1540624612874},{"_id":"source/img/paper-nst-cifar10-results.png","hash":"4d0376d630a428b4111ca4ae8243f96d2f66cfde","modified":1540624612897},{"_id":"source/img/paper-nst-kt-like-what-you-like.gif","hash":"c74a6fd3ff10a6be03626fe218dd1cf58a51460c","modified":1540624612905},{"_id":"source/img/paper-nst-pascal-voc-results.png","hash":"eaa76c77ef1b207e83ebb0b09c8fdc39f80ae5da","modified":1540624612909},{"_id":"source/img/paper-nst-student-and-teacher.png","hash":"768a1527c938b74ee4e98353acf390dc1fe8380d","modified":1540624612913},{"_id":"source/img/ransac_line_fit.png","hash":"f3711368fa15222a40f134c267842999574277e2","modified":1540624613022},{"_id":"source/img/regex_picture.jpg","hash":"1744ddfe9d73a4af202364cbea16ba0f2211dc50","modified":1540624613030},{"_id":"source/img/sift_dog.png","hash":"60371c0dbb5dfae010c84c59227dac9d878d3530","modified":1540624613086},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1540624613284},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1540624613285},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1540624613284},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1540624613286},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1540624613287},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1540624613286},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1540624613287},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1540624613288},{"_id":"themes/next/layout/_scripts/third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1540624613289},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1540624613288},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1540624613289},{"_id":"themes/next/layout/_scripts/third-party/comments/livere.swig","hash":"3603a438495bde6fb869447f8f7613cac36d366e","modified":1540624613289},{"_id":"themes/next/layout/_scripts/third-party/comments/youyan.swig","hash":"ea8078fa9e10be2bb042749d8b6a97adc38f914c","modified":1540624613289},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1540624613296},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1540624613297},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1540624613297},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1540624613297},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1540624613302},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1540624613310},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1540624613313},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1540624613313},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1540624613314},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1540624613314},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1540624613314},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1540624613314},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1540624613316},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1540624613317},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1540624613317},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1540624613317},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1540624613317},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1540624613318},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1540624613318},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1540624613319},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1540624613319},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1540624613320},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1540624613320},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1540624613320},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"ff9f163bb05c0709577040a875924d36c9ab99d6","modified":1540624613320},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"dcf9fe43b2ef78b923118ba39efedb38760e76b1","modified":1540624613321},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"1408209dfb9a22a0982a30bdbd14842c2b53f264","modified":1540624613321},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9b63bd8effc7cf4b96acdea4d73add7df934a222","modified":1540624613321},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1540624613321},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1540624613322},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"9ccee9189c910b8a264802d7b2ec305d12dedcd0","modified":1540624613329},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1540624613336},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1540624613337},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1540624613337},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1540624613338},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1540624613337},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1540624613338},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1540624613340},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1540624613341},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1540624613341},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1540624613343},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1540624613343},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1540624613344},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1540624613345},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1540624613345},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1540624613355},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1540624613356},{"_id":"source/img/hinton_06_learningrate.png","hash":"a5bda32c1be2372d1fd48bb3ecfb70ea730865a5","modified":1540624612721},{"_id":"source/img/paper-summary-model-compression-autopruner-alg.png","hash":"e80ee8af03b69e19788e4c046b65b62c4e4d3cae","modified":1540624612953},{"_id":"source/img/sift_experiment_1.png","hash":"87873fe348c7cb572b8d499730cf2ebc86a1e4ef","modified":1540624613094},{"_id":"source/img/warpctc_intro.png","hash":"2521cbdd73abfb274c8cb3cdd3bb91f86a4d3866","modified":1540624613178},{"_id":"source/img/yolo1_detection_system.png","hash":"3406908556a3d80fc565a94f6e394bfba6c69413","modified":1540624613197},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1540624613346},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1540624613348},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1540624613352},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1540624613352},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1540624613359},{"_id":"source/img/camera_model_things_to_remember.png","hash":"687a27be2aa5a335814315d19421f29fa79fee06","modified":1540624612513},{"_id":"source/img/hinton_06_rmsprop_improvement.png","hash":"f76c1f27120142ab5168c03fc5e74b54aaf71147","modified":1540624612732},{"_id":"source/img/paper_visconvnet_demo.png","hash":"e993b59e5f7edf3c3c0e1a54cb60a087affe43fc","modified":1540624612974},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1540624613297},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1540624613298},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1540624613299},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1540624613299},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1540624613298},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4b7f81e1006e7acee3d1c840ccba155239f830cc","modified":1540624613300},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1540624613300},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1540624613299},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1540624613300},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1540624613301},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1540624613301},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1540624613301},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1540624613301},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1540624613302},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"fdfadbb4483043c7e0afd541ee9712389e633517","modified":1540624613303},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1540624613304},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1540624613305},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1540624613305},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1540624613305},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"7f1aab694caf603809e33cff82beea84cd0128fd","modified":1540624613305},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"c6dab7661a6b8c678b21b7eb273cef7100f970f6","modified":1540624613305},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1540624613306},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1540624613306},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1540624613306},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1540624613307},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"bfd806d0a9f21446a22df82ac02e37d0075cc3b5","modified":1540624613307},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1540624613308},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1540624613308},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1540624613308},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1540624613309},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1540624613309},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1540624613309},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1540624613309},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1540624613309},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1540624613310},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1540624613310},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1540624613310},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1540624613311},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1540624613311},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"3eb73cee103b810fa56901577ecb9c9bb1793cff","modified":1540624613311},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"eba491ae624b4c843c8be4c94a044085dad4ba0f","modified":1540624613311},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"637c6b32c58ecf40041be6e911471cd82671919b","modified":1540624613312},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1540624613313},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1540624613318},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1540624613319},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1540624613320},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1540624613338},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1540624613339},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1540624613339},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1540624613339},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1540624613340},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1540624613340},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1540624613350},{"_id":"source/img/cs131_linear_algebra.jpg","hash":"dd19d6b5b0e026d3c5b1ead3951b6f5073081fa1","modified":1540624612576},{"_id":"source/img/hinton_02_weight_space_hyperplane.png","hash":"314f5c910d1af6909a5082f8ec29b166ffb39547","modified":1540624612711},{"_id":"source/img/hinton_06_summary.png","hash":"b7d44b6002db12d33f2b178b3e1582873f86a5fb","modified":1540624612740},{"_id":"source/img/hinton_06_tricks_for_adaptive_lr.png","hash":"39f3a8ca2940809101656e31f39ef9e402cb9020","modified":1540624612747},{"_id":"source/img/shell-programming-if-operators.jpg","hash":"c09d8ef7ac6057bb185a277ad20da9fc1d6cc8f3","modified":1540624613058},{"_id":"source/img/paper-summary-autopruner-arch.png","hash":"dba436f6e54bc09a959897218ea3fb9bac7ef445","modified":1540624612948},{"_id":"source/img/yolo2_result.png","hash":"6241714e33480315ec130b1dcd17db56f098db9b","modified":1540624613219},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1540624613333},{"_id":"source/img/convolution.png","hash":"af8e2638d7e484d8267a49ed11d3f3239fa19107","modified":1540624612558},{"_id":"source/img/dog_different_size.png","hash":"c8d097879dcfffa7cf6138b01b22d4792d56522c","modified":1540624612626},{"_id":"source/img/shell-programming-system-variables.jpg","hash":"1fff44fae6634a8f565e48bd2cb93edfddb3ca9d","modified":1540624613065},{"_id":"source/img/shell-programming-wild-cards.jpg","hash":"cc83510fd340cb6c52322243329f1fbdbb88b206","modified":1540624613073},{"_id":"source/img/vim-config-demo.png","hash":"b5dadb1e84ddeb6ff6034ac5ec861a7cf596a64e","modified":1540624613169},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1540624613349},{"_id":"source/img/doc2dash_pytorch_example.jpg","hash":"1759b9f8332ce27123acd68a7bd2782df8d116d9","modified":1540624612614},{"_id":"source/img/focal_loss_vs_ce_loss.jpg","hash":"970dfffff9326032aef74e41e625076dbbd81d36","modified":1540624612671},{"_id":"source/img/kmeans_scaling_up.png","hash":"df16837a020113c80b953765d2b21932dd275d23","modified":1540624612825},{"_id":"source/img/paper-model-pruning-filter-pruning-sensitivity-results.png","hash":"e403070370111ebacab6e1d3f7015c4d02ff5451","modified":1540624612890},{"_id":"source/img/contours_evaluation_optimizers.gif","hash":"0d4d768dcedf08df014f790f86d4f771451b7825","modified":1540624612541},{"_id":"source/img/mathfunctions_im2col.png","hash":"70a0a79092024dddbc2d0ab462fa006166a4e8a4","modified":1540624612835},{"_id":"source/img/yolo1_basic_idea.png","hash":"831008124b5bd8e25e5b8986cf40fb75767b1d03","modified":1540624613190},{"_id":"source/img/kmeans_algorithm.png","hash":"89598b129b98c9da0eb309911b84eb2e49ff38c6","modified":1540624612789},{"_id":"source/img/paper-inq-algorithm-demo.png","hash":"af7996102c20fdb841d3d4eb09cf34661f8f9bc3","modified":1540624612864},{"_id":"source/img/sift_experiment_2.png","hash":"c1e482a1e85026664f33ce2dd7e72e3e3a58c0fc","modified":1540624613111},{"_id":"source/img/caffe_mathfunctions_uvarequirement.png","hash":"935d56ac8e8689f8aebaf5fa61d1e93a81ec0209","modified":1540624612461},{"_id":"source/img/focal_loss_different_model_comparison.jpg","hash":"14f51cb35df20ca182a069f519da9f7cb98a13d6","modified":1540624612662},{"_id":"source/img/projective_geometry_property_1.png","hash":"ee1d6866a25eb2822cd8adb7b8666ae653a8bf45","modified":1540624612988},{"_id":"source/img/kmeans_image_seg_via_intensity.png","hash":"9a3c60d288ba39bbe659cf84ed941c53ea501eeb","modified":1540624612812},{"_id":"source/img/projective_geometry_property_2.png","hash":"1d0b53aa8901c0dc46673762820683b3afd4202b","modified":1540624613008},{"_id":"source/img/caffe_mathfunctions_whatisuva.png","hash":"a26ef96adcdcf217927372d898ef336766bec67e","modified":1540624612477},{"_id":"source/img/camera_geometry_application.png","hash":"cb34e60657f460f4cf120b740180740d721256e4","modified":1540624612502},{"_id":"source/img/image_matching_hard.png","hash":"4a09523ad90bb2d41a391edb8fd69bfed2cdf8e9","modified":1540624612768},{"_id":"source/img/convex_opt_intro_convex_fun.png","hash":"a9a90e6924f4905083340707d22e30c3c539daa8","modified":1542475228901},{"_id":"source/img/conv_opt_intro_conv_set.png","hash":"16823cbad8550f8c3278a774de868deced959277","modified":1542474270251},{"_id":"public/search.xml","hash":"12231a9df88234b4aee39277224fc3ca78afa069","modified":1552107531130},{"_id":"public/atom.xml","hash":"b59b2526f337c92d8789e8c2ba64d102fee3e50a","modified":1552107531129},{"_id":"public/about/index.html","hash":"f93a18ed01baea11a28c0059873f62a883cd9d8f","modified":1552107538343},{"_id":"public/tags/index.html","hash":"f76499df01e07264e227322585fca71cdb4210c4","modified":1552107538430},{"_id":"public/2018/10/22/paper-rethinking-the-value-of-network-pruning/index.html","hash":"755cc50a325b200d0909055022150137169f5c28","modified":1552107538431},{"_id":"public/2018/10/03/paper-summary-model-pruning/index.html","hash":"2799efcd56f22861443f4ce22f60aadf6982fd36","modified":1552107538593},{"_id":"public/2018/10/02/vim-you-complete-me/index.html","hash":"87495d26c73faf0728c40d5f81888178bf5978b8","modified":1552107538593},{"_id":"public/2018/10/02/paper-knowledge-transfer-neural-selectivity-transfer/index.html","hash":"4cda219dabc880362b0df11ce2aa353b4af420d3","modified":1552107538593},{"_id":"public/2018/10/27/mac-update-mojave/index.html","hash":"e5a28c49adbd77113985ab3f8bf2dac41f82e874","modified":1552107538593},{"_id":"public/2018/04/09/set-env-in-jupyternotebook/index.html","hash":"41d71ad9497f73a2abd8f9bca5dffc084ff7353e","modified":1552107538593},{"_id":"public/2018/10/02/mxnet-fit-usage/index.html","hash":"ca1e19ad2059a7ca40a4071cbfc108ae9d3a7585","modified":1552107538593},{"_id":"public/2018/04/02/paper-fpn/index.html","hash":"1266ac95b83e2f4745b867d351081295ba7e3dbb","modified":1552107538593},{"_id":"public/2018/06/07/knowledge-distilling/index.html","hash":"fcb7d53df7155955acab0c864a78583bd3c7c4a6","modified":1552107538594},{"_id":"public/2018/04/01/paper-yolov3/index.html","hash":"e07d7748b0341ffc4fe7b94ada9ab760af161914","modified":1552107538593},{"_id":"public/2018/03/24/paper-squeezenet/index.html","hash":"e61a83ae33074e72eea0f0e1cec0c45bd518fb61","modified":1552107538593},{"_id":"public/2018/03/23/paper-mobilenet/index.html","hash":"bbfd7042d6e00188920694579390ef13ffe48e16","modified":1552107538593},{"_id":"public/2018/03/21/cs229-supervised-learning/index.html","hash":"b478bd0341e759c9221d4ab80da3b4a9d6bd87a7","modified":1552107538593},{"_id":"public/2018/03/22/paper-xception/index.html","hash":"35195e71faa4e7e8a269e3eeecf983ae20bbd352","modified":1552107538593},{"_id":"public/2018/03/16/caffe-hack-python-interface/index.html","hash":"fd9cea95540fc2872c3a81180681dff5d97ae42d","modified":1552107538593},{"_id":"public/2018/02/28/caffe-net/index.html","hash":"65de844f614d7be2a3e992ab5f13a18830693883","modified":1552107538594},{"_id":"public/2018/04/03/newton-method/index.html","hash":"9cbb92d48a10a2c4dc30581a6171231a775e1c1a","modified":1552107538593},{"_id":"public/2018/02/27/bug-pycaffe-jupyternotebook-awaiting-for-data/index.html","hash":"5b75025d8b4f639004d804b47572eeaf3aafe66b","modified":1552107538594},{"_id":"public/2018/02/26/conv-in-caffe/index.html","hash":"430edfd0d23d63b6c5f1eed637fec277fd7b8794","modified":1552107538594},{"_id":"public/2018/02/24/paper-ssl-dnn/index.html","hash":"0f51f86fbe3a72e1749af9baf39676a78fdbb4f5","modified":1552107538594},{"_id":"public/2018/02/08/paper-visualize-convnet/index.html","hash":"24c6cf4323ec0e62b408000db15d093c20de7a27","modified":1552107538594},{"_id":"public/2018/01/25/inq-paper/index.html","hash":"d6afe0511b8f9534038eb6b5af85f5b28431a42d","modified":1552107538594},{"_id":"public/2018/01/12/caffe-syncedmem/index.html","hash":"e924c864adc58542396eca09344554ab4dfd0b82","modified":1552107538594},{"_id":"public/2018/02/08/bug-pycaffe-using-cublas/index.html","hash":"dde5f54f73b488ce5569e5a003a5a8c796cbf646","modified":1552107538594},{"_id":"public/2018/01/08/caffe-batch-norm/index.html","hash":"8a4c49253daa866e3d7d72845f1c638546b5438d","modified":1552107538594},{"_id":"public/2017/11/10/shell-programming/index.html","hash":"a66199213b981ecf9bf8d4c6b39352daf545f97f","modified":1552107538594},{"_id":"public/2017/10/27/fuck-gfw/index.html","hash":"cb6464a2bc3e71532ce4299728f5908c0f153ccd","modified":1552107538594},{"_id":"public/2017/10/22/useful-tools-list/index.html","hash":"68a5544545abf45eafadadc230290a671fe3eda0","modified":1552107538594},{"_id":"public/2017/08/26/doc2dash-usage/index.html","hash":"adac3e32133f7237909981d8732fe13202447f8b","modified":1552107538594},{"_id":"public/2018/11/18/convex-optimization-intro/index.html","hash":"00ad01379bf005c77a3ef3cc5ef4108476c70a42","modified":1542475340476},{"_id":"public/2018/03/14/paper-network-prune-hansong/index.html","hash":"5174a80215f2899a10d018f5f63297139186149b","modified":1552107538594},{"_id":"public/2017/08/21/debugging-with-ipdb/index.html","hash":"3c6366e58b297a46cf93237863c40372189b6630","modified":1552107538594},{"_id":"public/2017/08/10/install-ubuntu-in-dell/index.html","hash":"13ea82f1176b5d8551cb21bc879d7bc668a70f3c","modified":1552107538594},{"_id":"public/2017/07/03/effective-cpp-08/index.html","hash":"b5d081a8864814c5442337504a67b17a7e66a6df","modified":1552107538595},{"_id":"public/2017/06/25/hinton-nnml-06/index.html","hash":"2dadc647768071a0a34ff8b8bbbcd0ae59cebc21","modified":1552107538594},{"_id":"public/2017/08/29/learn-pyqt/index.html","hash":"03465ffb89b32c5b7746c9b3cda021bfdc640fec","modified":1552107538595},{"_id":"public/2018/04/27/pytorch-040-migration-guide/index.html","hash":"e216a68a0607633b44af180463dcfbf1101f319d","modified":1552107538594},{"_id":"public/2017/06/23/effective-cpp-07/index.html","hash":"0689ab6c6b07cec02e5319b5d11c131166c2099f","modified":1552107538595},{"_id":"public/2017/05/31/silver-rl-mdp/index.html","hash":"75a28992f404df11178b619e5e2dc27826d7151d","modified":1552107538595},{"_id":"public/2017/05/25/hinton-nnml-02/index.html","hash":"e8ba9ce228ef19dec471fac0fce9a71ba08bd06b","modified":1552107538595},{"_id":"public/2017/05/04/ubuntu-cannot-mount-exfat-disk/index.html","hash":"e0c3b174293af8de07b5cf4a0edfcc63c2a6527c","modified":1552107538595},{"_id":"public/2017/05/03/hinton-nnml-01/index.html","hash":"812584a556715e696e58980521ab4edbdd5492ac","modified":1552107538595},{"_id":"public/2017/05/03/cs131-opticalflow/index.html","hash":"b35b65d8266f742947af39606c2051eef7650708","modified":1552107538595},{"_id":"public/2017/05/01/effective-cpp-05/index.html","hash":"d8d63155816ea1c2367aaf643f02871e8490d31a","modified":1552107538595},{"_id":"public/2017/04/29/effective-cpp-04/index.html","hash":"3a7839a5dd7e51bbb475af955f5b792926f4eb09","modified":1552107538595},{"_id":"public/2017/08/14/focal-loss-paper/index.html","hash":"af3220a1283c544ac5adac21f1f9f0b3b6f8374e","modified":1552107538594},{"_id":"public/2017/04/25/effective-cpp-03/index.html","hash":"b5754c628ec671636f3c8d11afebd2567798a9b7","modified":1552107538595},{"_id":"public/2017/06/17/effective-cpp-06/index.html","hash":"c19b9803c1bca286d24d8a364ef6bc1021321cd5","modified":1552107538595},{"_id":"public/2017/04/24/effective-cpp-02/index.html","hash":"e58357eb1a89c74a38322737efbf84fc1dd4a05f","modified":1552107538595},{"_id":"public/2017/04/21/python-iter-generator/index.html","hash":"03ebc604ceec67d081da7c66131f48955fcaf0e7","modified":1552107538596},{"_id":"public/2017/03/08/mathfunctions-in-caffe/index.html","hash":"41f4a5bc342a898d2f5bd085877c691bdfe60bb9","modified":1552107538596},{"_id":"public/2017/06/06/silver-rl-dp/index.html","hash":"120e610207a1bdcf41a75b62e3c105c8f9cb0ad7","modified":1552107538595},{"_id":"public/2017/03/05/residualnet-paper/index.html","hash":"b722dc726bbd99ed9adc48fc9f0223aed3be1207","modified":1552107538596},{"_id":"public/2017/03/04/pytorch-mnist-example/index.html","hash":"0a2bf8f170fa7588a79bc83d541678c8c8bf3f56","modified":1552107538596},{"_id":"public/2017/03/06/yolo-cfg-parser/index.html","hash":"c9a29e796f776f58b975baacf0281e708bdbbece","modified":1552107538596},{"_id":"public/2017/02/25/pytorch-tutor-01/index.html","hash":"bd2fa5bd6dbd914a3c9ef37e09830424fb49f13a","modified":1552107538596},{"_id":"public/2017/02/26/jupyternotebook-remote-useage/index.html","hash":"664274cf92d7f3e00dc7f710901893b0e0769c19","modified":1552107538596},{"_id":"public/2017/04/20/effective-cpp-01/index.html","hash":"04438428224a497d69b8a533dfd64addfed0ffaf","modified":1552107538596},{"_id":"public/2017/03/07/residualnet-paper2-identitymapping/index.html","hash":"89f46a3385e31f1cd405623156531340056b4d12","modified":1552107538596},{"_id":"public/2017/02/22/warpctc-caffe/index.html","hash":"058cef66f650da2a54e44bd971a6f101b5280549","modified":1552107538596},{"_id":"public/2017/02/08/digitalocean-shadowsocks/index.html","hash":"f38c2a8910476e9abe83ee0974a3e13067c2a8fd","modified":1552107538597},{"_id":"public/2017/02/05/video-linear-alg-essential-property/index.html","hash":"11fca242cd2644939f7c7acaecb728c354d614ec","modified":1552107538597},{"_id":"public/2017/02/05/cs131-kmeans/index.html","hash":"9a7cbc6dcc18109ebf05a6ad2f68db985aeec8af","modified":1552107538596},{"_id":"public/2017/02/04/yolo-paper/index.html","hash":"6940a23c552029422c8bb98cf6f2382e684463a7","modified":1552107538597},{"_id":"public/2017/01/30/cs131-sift/index.html","hash":"aab1cba430b60e462ecf19c40a26ebf8c66561f6","modified":1552107538597},{"_id":"public/2017/01/25/cs131-finding-features/index.html","hash":"94f5b898507c601dd4b7d8470d44366aa0d7a1c9","modified":1552107538597},{"_id":"public/2017/02/12/cs131-mean-shift/index.html","hash":"ff079c16a905bca48ae9df678a13c4680e69bbd4","modified":1552107538596},{"_id":"public/2017/02/09/build-caffe-ubuntu/index.html","hash":"c88fe826fd25d8a3ed1a64e3d022e5ec029578a4","modified":1552107538596},{"_id":"public/2017/01/23/cs131-filter-svd/index.html","hash":"c75a8f8aecedc064308e228a7e3ef13158ca56ba","modified":1552107538597},{"_id":"public/2016/12/16/use-doxygen/index.html","hash":"b1d4bbd2dd27677b5b94ac6918c91d061fe7e581","modified":1552107538597},{"_id":"public/2017/01/22/cs131-linear-alg/index.html","hash":"7489738e217148041617135a817b7ec272136775","modified":1552107538597},{"_id":"public/2017/02/02/cs131-camera/index.html","hash":"36c33f28337b3e214c8c6bfc5cd26c88b3c0f6df","modified":1552107538597},{"_id":"public/2016/12/16/hello-world/index.html","hash":"7c761c389ad9f35aeb2343f7c82ef18596245869","modified":1552107538597},{"_id":"public/2014/07/17/python-reg-exp/index.html","hash":"72a533dbbe38ef31d71ddf132d1f6af342a97831","modified":1552107538597},{"_id":"public/archives/index.html","hash":"76d0c60f87107befcec9484c0b9a96ee53a11148","modified":1552107538597},{"_id":"public/archives/page/2/index.html","hash":"50bb02d8889fcc9f8e0e1dae034865aebe6fa31d","modified":1552107538597},{"_id":"public/archives/page/3/index.html","hash":"c91302f177bfc75264a8919b7280220a44bb8450","modified":1552107538597},{"_id":"public/archives/page/4/index.html","hash":"0878358d49afbe65d1b571d4dce6ab4194c96c16","modified":1552107538597},{"_id":"public/archives/page/5/index.html","hash":"9dfc0bd5ec0aac3103d5c9f58f5fd62bb02b343f","modified":1552107538598},{"_id":"public/archives/page/7/index.html","hash":"14641b5ad18dabc76c32b1807be02a7d756e6d28","modified":1552107538598},{"_id":"public/archives/page/6/index.html","hash":"7175b65bfe524b34c8bff0ccb89258b175f9b056","modified":1552107538597},{"_id":"public/archives/2014/index.html","hash":"c622f5b5309e3b9574adbdc11c5bb027e0312c15","modified":1552107538598},{"_id":"public/archives/page/8/index.html","hash":"2fae62cb6895964479d0eeee8aae60fd71e73cc2","modified":1552107538597},{"_id":"public/archives/2014/07/index.html","hash":"e4e9de04d43ebb7c4e51c9f4f2afcb7e6dcd3979","modified":1552107538598},{"_id":"public/archives/2016/index.html","hash":"41fa6719b69f7fd77c2583da17299a764ad9ef95","modified":1552107538598},{"_id":"public/archives/2016/12/index.html","hash":"5724b026a0007ba3b76d8796655fc6d785808d6d","modified":1552107538599},{"_id":"public/archives/2017/index.html","hash":"82852fa1bce67325d3c046058e3fafd7d32cab9a","modified":1552107538598},{"_id":"public/archives/2017/page/2/index.html","hash":"9834c8c207bfcdb701514861175cfe04c8caec2f","modified":1552107538598},{"_id":"public/archives/2017/page/3/index.html","hash":"de740ca1963dcb6ceaddef1ba46f7a57976a6505","modified":1552107538598},{"_id":"public/archives/2017/page/4/index.html","hash":"cf23644c48a956dcfcbfa166b59b079accf2c8c9","modified":1552107538598},{"_id":"public/archives/2017/page/5/index.html","hash":"72433638aaec2f5a25dc330e679acccbdc56fe11","modified":1552107538598},{"_id":"public/archives/2017/01/index.html","hash":"f7b184dd8823af7fb2c11cb0bcf238efc24e629c","modified":1552107538598},{"_id":"public/archives/2017/03/index.html","hash":"d303846f60665adfd87c1ed527ba9b2b1104cf04","modified":1552107538598},{"_id":"public/archives/2017/04/index.html","hash":"7091c029129d3d64c9cccb05bf37d5278bf0cf38","modified":1552107538598},{"_id":"public/archives/2017/02/index.html","hash":"d33345d797146917c304747012b097a703faf730","modified":1552107538598},{"_id":"public/archives/2017/05/index.html","hash":"89bbf4e1051187a5e4c948322dd103956706725f","modified":1552107538599},{"_id":"public/archives/2017/06/index.html","hash":"6a6fe4ebefaadb67cd90b16ae0c74f177db45045","modified":1552107538598},{"_id":"public/archives/2017/07/index.html","hash":"fe279bc22b532cd92cf48007c4a944564751211c","modified":1552107538598},{"_id":"public/archives/2017/08/index.html","hash":"6abd054dc5e481a5f1b27bf075cc1e2279c07e5a","modified":1552107538598},{"_id":"public/archives/2017/10/index.html","hash":"0efd4c11e4184e587eb9a2d88e5727db6f7ca698","modified":1552107538598},{"_id":"public/archives/2017/11/index.html","hash":"fefaedf720c14f4ec3267b87f5a1f6e89acd5f46","modified":1552107538599},{"_id":"public/archives/2018/index.html","hash":"62a5a7b9dfbeee45389591eae0c45481f746f870","modified":1552107538599},{"_id":"public/archives/2018/page/2/index.html","hash":"1e9eacac022fb10d82f379f8dde8388b2c5cf65f","modified":1552107538599},{"_id":"public/archives/2018/01/index.html","hash":"d1080acca2bfb8265b7e08fc46d51ad8f6c660df","modified":1552107538599},{"_id":"public/archives/2018/02/index.html","hash":"f8b956b8df560d92bc23572ae13fe0bd0f1e9639","modified":1552107538599},{"_id":"public/2017/01/24/cs131-edge-detection/index.html","hash":"e87290d908a4e93cfb03ed21e29537d09cf4318f","modified":1552107538597},{"_id":"public/archives/2018/04/index.html","hash":"7efd65fd282a69fb0799712d8493b04a370c3fad","modified":1552107538603},{"_id":"public/archives/2018/06/index.html","hash":"d268610a2bbc02c2191cabd0a6f60172cab825c2","modified":1552107538599},{"_id":"public/archives/2018/10/index.html","hash":"222069890246731bc9f3b80b33a991decedb8408","modified":1552107538599},{"_id":"public/index.html","hash":"d16de265b8a335d8ad51b1173796104e430a3c1e","modified":1552107538603},{"_id":"public/page/2/index.html","hash":"81cdcf214ea58fc8a5da52b3cc709f6f2f557a10","modified":1552107538603},{"_id":"public/page/3/index.html","hash":"23569a1fc89f851f4f684ba9bd7b093780ad653e","modified":1552107538603},{"_id":"public/page/4/index.html","hash":"000ed2efdf0fc6738e175c4e6ea28ad9ed8ea0ff","modified":1552107538603},{"_id":"public/page/5/index.html","hash":"77d3a93cbfbcf4d9b6479313fbdc32096fb6b436","modified":1552107538603},{"_id":"public/page/6/index.html","hash":"426fbce09e0aa112196c38e90a2d926626452bd5","modified":1552107538603},{"_id":"public/page/7/index.html","hash":"10da6e82480a43e5cdb2b4b0eefb5bdc880df092","modified":1552107538603},{"_id":"public/page/8/index.html","hash":"3658a53ce18f1bf97f9a1ece3ddcefeafc54009d","modified":1552107538603},{"_id":"public/tags/caffe/index.html","hash":"4fb91515a6d30f1e2927c4c4db2f552dc4c24be2","modified":1552107538599},{"_id":"public/tags/python/index.html","hash":"9bbfd977927a95c5eb8080f563ab1fcc684f7fb9","modified":1552107538599},{"_id":"public/tags/debug/index.html","hash":"53eaf11a66230924457394147a28bcbf32093a64","modified":1552107538599},{"_id":"public/tags/tool/index.html","hash":"a9941d05942f57e1fec8272d51cc257209d2c5f7","modified":1552107538599},{"_id":"public/tags/cs131/index.html","hash":"11962bc6693afbd193c3584e7bfb0948f8c22f76","modified":1552107538599},{"_id":"public/tags//index.html","hash":"37a2986198dd2596d4e6dadf1afd9752bd6b489b","modified":1552107538599},{"_id":"public/tags//page/2/index.html","hash":"f7e4dc89ace86fa2bff7e55f36e59d55951150bc","modified":1552107538600},{"_id":"public/tags/math/index.html","hash":"4a8384c4e17571c899ba12899844d4d87e4b0dbe","modified":1552107538600},{"_id":"public/tags/cs229/index.html","hash":"711b4a74dba714bd106ea32bd7626e6824bd7a8f","modified":1552107538600},{"_id":"public/tags/cpp/index.html","hash":"b4058020a7002c73e4e7c9fb4cc5115c87b60975","modified":1552107538600},{"_id":"public/tags//index.html","hash":"76e8dce45ea2be6c0d6f5fa3275e1d7f47390d12","modified":1552107538600},{"_id":"public/tags/paper/index.html","hash":"a4247c00dbaed58b6bad73ca029df68f0fab28b0","modified":1552107538600},{"_id":"public/tags/paper/page/2/index.html","hash":"f59f3b3448661fa0e6052dca225d77070c8fdaa4","modified":1552107538600},{"_id":"public/tags/deep-learning/index.html","hash":"9890070ca93da0dd4bebe77ff1591b7de7a103d5","modified":1552107538600},{"_id":"public/tags/deep-learning/page/2/index.html","hash":"fad044824d3a369c59ef59be88e2f8d0b0d9fd48","modified":1552107538600},{"_id":"public/tags/deep-learning/page/3/index.html","hash":"bc85cc555469c35d68cc5ef8a902ec6fbabe8d68","modified":1552107538600},{"_id":"public/tags/pytorch/index.html","hash":"1e8856e0272417b15cfe9e3fe35c1cfdcde54fca","modified":1552107538602},{"_id":"public/tags/quantization/index.html","hash":"05bfa5a66abb23a1274c9f1c3f04ef62af342433","modified":1552107538600},{"_id":"public/tags/model-compression/index.html","hash":"03a7cb587f2d4729531425032164642f9471bcd2","modified":1552107538602},{"_id":"public/tags/ubuntu/index.html","hash":"3a46aaa1d1afc44df544227cb77ddffaacc2c8de","modified":1552107538602},{"_id":"public/2016/12/16/gsl-with-vs/index.html","hash":"8b5e87c1c5ca0c5602d67f4a8129dac4db3ac8e6","modified":1552107538597},{"_id":"public/tags/qt/index.html","hash":"6ccfddcfa84519418277d28cdf6b008386e9c4a6","modified":1552107538602},{"_id":"public/tags/model-arch/index.html","hash":"398affae827a8eed95250d8ff746c7f2cdcde384","modified":1552107538602},{"_id":"public/tags/mxnet/index.html","hash":"0d26a126b2063e097e8d12212d2156ea6578aebb","modified":1552107538602},{"_id":"public/tags/detection/index.html","hash":"66a48161d6665260ad689b9f23a9bebfae6fc108","modified":1552107538602},{"_id":"public/tags/yolo/index.html","hash":"eb32a818d6cf73fc196a3eab91f4d5ff933d0427","modified":1552107538602},{"_id":"public/tags/visulization/index.html","hash":"587df8be11774930d3abfb0341124b7b6cf2471c","modified":1552107538602},{"_id":"public/tags/linux/index.html","hash":"323a866fc11fabcdf31d19be8d4cd16c31ecbd4d","modified":1552107538602},{"_id":"public/tags/shell/index.html","hash":"fb28318bff02796914a1a9236fcff7e72d721d0b","modified":1552107538602},{"_id":"public/tags/reinforcement-learning/index.html","hash":"1b1d55056d5f69d8c4a11f6422d33f70628d2e79","modified":1552107538603},{"_id":"public/tags/doxygen/index.html","hash":"8f05bd2ae5aa56f32793a4804ceafac0a2a8d012","modified":1552107538602},{"_id":"public/tags/vim/index.html","hash":"e5a4d7ee7bf1740c8e238de73c8ba4a650969b0d","modified":1552107538603},{"_id":"public/tags/tools/index.html","hash":"97986b1631de8bec47602dbd19c1af32d32676b8","modified":1552107538603},{"_id":"public/archives/2018/page/3/index.html","hash":"9959a5f1e9adeefb122b8065c6861d00f9626ad1","modified":1552107538599},{"_id":"public/archives/2018/03/index.html","hash":"ab8a6894f0f65727ab11cf93201ad18c0894f5fa","modified":1552107538599},{"_id":"public/archives/2018/11/index.html","hash":"401f98bbad75d464b360e67afa05cb6a174c5ca0","modified":1542475340489},{"_id":"public/img/convex_opt_intro_title_pic.png","hash":"104e43aea89f97f9d601fb201baa3aecbb089d40","modified":1542475340489},{"_id":"public/img/convex_opt_intro_convex_fun.png","hash":"a9a90e6924f4905083340707d22e30c3c539daa8","modified":1542475340489},{"_id":"public/img/conv_opt_intro_conv_set.png","hash":"16823cbad8550f8c3278a774de868deced959277","modified":1542475340492},{"_id":"source/cache/convex-optimization-intro.md","hash":"e5f2d419f4c6c527d105fe73dfb5fd39847e0d0e","modified":1542475408640},{"_id":"source/_posts/darknet-caffe-converter.md","hash":"47c1d29c225b9683f642fe3ef27bfe0ebe28e525","modified":1552107515441},{"_id":"public/cache/convex-optimization-intro.html","hash":"e19fa386d638a9167f4c6ed8b30791c8a7ea7cbe","modified":1552107538592},{"_id":"public/2019/03/09/darknet-caffe-converter/index.html","hash":"e688846943696bd97a480e835384ace195156ef8","modified":1552107538593},{"_id":"public/archives/2019/03/index.html","hash":"a987dcd8666064f8fcda282f84a2af36fe9fedf4","modified":1552107538606},{"_id":"public/archives/2019/index.html","hash":"f7df09f6a418bada4223a4bb88f9f445a68db633","modified":1552107538606},{"_id":"public/tags/caffe/page/2/index.html","hash":"b582b467e9e040a3f6fd3c8fc1c06efd2da6fb95","modified":1552107538607}],"Category":[],"Data":[],"Page":[{"date":"2017-03-05T04:29:26.000Z","comments":0,"_content":"\n\n[](http://csicdgz.bit.edu.cn/index.htm)[](http://chw.azurewebsites.net/)[](http://www.ict.cas.cn)\n\nxmfbit[A.T.]gmail.com(A.T. => @)\n\n\n","source":"about/index.md","raw":"---\ndate: 2017-03-05 12:29:26\ncomments: false\n---\n\n\n[](http://csicdgz.bit.edu.cn/index.htm)[](http://chw.azurewebsites.net/)[](http://www.ict.cas.cn)\n\nxmfbit[A.T.]gmail.com(A.T. => @)\n\n\n","updated":"2018-10-27T07:16:52.425Z","path":"about/index.html","title":"","layout":"page","_id":"cjolov8he0001ae7ba772hisf","content":"<p></p>\n<p><a href=\"http://csicdgz.bit.edu.cn/index.htm\" target=\"_blank\" rel=\"external\"></a><a href=\"http://chw.azurewebsites.net/\" target=\"_blank\" rel=\"external\"></a><a href=\"http://www.ict.cas.cn\" target=\"_blank\" rel=\"external\"></a></p>\n<p>xmfbit[A.T.]gmail.com(A.T. =&gt; @)</p>\n<p></p>\n","excerpt":"","more":"<p></p>\n<p><a href=\"http://csicdgz.bit.edu.cn/index.htm\"></a><a href=\"http://chw.azurewebsites.net/\"></a><a href=\"http://www.ict.cas.cn\"></a></p>\n<p>xmfbit[A.T.]gmail.com(A.T. =&gt; @)</p>\n<p></p>\n"},{"title":"","date":"2016-12-17T12:10:38.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: \ndate: 2016-12-17 20:10:38\ntype: tags\ncomments: false\n---\n","updated":"2018-10-27T07:16:53.221Z","path":"tags/index.html","layout":"page","_id":"cjolov8hm0003ae7bufoh9r7x","content":"","excerpt":"","more":""},{"title":"SVM","date":"2018-11-17T16:27:37.000Z","tags":["math"],"_content":"CS229KKTSVMSVM\n\n![](/img/convex_opt_intro_title_pic.png)\n<!-- more -->\n\n## \n\n\n### \n$C$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$C$\n\n$$\\theta x + (1-\\theta)y \\in C$$\n\n$C$$C$$t = \\theta x + (1-\\theta) y$$t - y = \\theta(x-y)$$t-y$$x-y$$\\theta$$t$\n\n![](/img/conv_opt_intro_conv_set.png)\n\n\n\n- $\\mathbb{R}^n$\n- $\\\\{ x; \\Vert x\\Vert_p \\le 1\\\\}$\n- \n\n### \n$f$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$f$\n\n$$f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta) f(y)$$\n\n$\\mathbb{R}$\n![](/img/convex_opt_intro_convex_fun.png)\n\n## \n\n### \n\n### \n\n## \n\n### \n\n### \n\n### KKT\n\n## SVM\n\n### \n\n### \n\n### \n\n## \n- [Boyd](http://web.stanford.edu/~boyd/cvxbook/)\n- [CS229](http://cs229.stanford.edu/section/cs229-cvxopt.pdf)","source":"cache/convex-optimization-intro.md","raw":"---\ntitle: SVM\ndate: 2018-11-18 00:27:37\ntags:\n    - math\n---\nCS229KKTSVMSVM\n\n![](/img/convex_opt_intro_title_pic.png)\n<!-- more -->\n\n## \n\n\n### \n$C$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$C$\n\n$$\\theta x + (1-\\theta)y \\in C$$\n\n$C$$C$$t = \\theta x + (1-\\theta) y$$t - y = \\theta(x-y)$$t-y$$x-y$$\\theta$$t$\n\n![](/img/conv_opt_intro_conv_set.png)\n\n\n\n- $\\mathbb{R}^n$\n- $\\\\{ x; \\Vert x\\Vert_p \\le 1\\\\}$\n- \n\n### \n$f$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$f$\n\n$$f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta) f(y)$$\n\n$\\mathbb{R}$\n![](/img/convex_opt_intro_convex_fun.png)\n\n## \n\n### \n\n### \n\n## \n\n### \n\n### \n\n### KKT\n\n## SVM\n\n### \n\n### \n\n### \n\n## \n- [Boyd](http://web.stanford.edu/~boyd/cvxbook/)\n- [CS229](http://cs229.stanford.edu/section/cs229-cvxopt.pdf)","updated":"2018-11-17T17:23:28.640Z","path":"cache/convex-optimization-intro.html","_id":"cjt10gmbr00004t7bp8qqb7wc","comments":1,"layout":"page","content":"<p>CS229KKTSVMSVM</p>\n<p><img src=\"/img/convex_opt_intro_title_pic.png\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$C$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$C$</p>\n<script type=\"math/tex; mode=display\">\\theta x + (1-\\theta)y \\in C</script><p>$C$$C$$t = \\theta x + (1-\\theta) y$$t - y = \\theta(x-y)$$t-y$$x-y$$\\theta$$t$</p>\n<p><img src=\"/img/conv_opt_intro_conv_set.png\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>$\\mathbb{R}^n$</li>\n<li>$\\{ x; \\Vert x\\Vert_p \\le 1\\}$</li>\n<li></li>\n</ul>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>$f$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$f$</p>\n<script type=\"math/tex; mode=display\">f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta) f(y)</script><p>$\\mathbb{R}$<br><img src=\"/img/convex_opt_intro_convex_fun.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"KKT\"><a href=\"#KKT\" class=\"headerlink\" title=\"KKT\"></a>KKT</h3><h2 id=\"SVM\"><a href=\"#SVM\" class=\"headerlink\" title=\"SVM\"></a>SVM</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"http://web.stanford.edu/~boyd/cvxbook/\" target=\"_blank\" rel=\"external\">Boyd</a></li>\n<li><a href=\"http://cs229.stanford.edu/section/cs229-cvxopt.pdf\" target=\"_blank\" rel=\"external\">CS229</a></li>\n</ul>\n","excerpt":"<p>CS229KKTSVMSVM</p>\n<p><img src=\"/img/convex_opt_intro_title_pic.png\" alt=\"\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$C$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$C$</p>\n<script type=\"math/tex; mode=display\">\\theta x + (1-\\theta)y \\in C</script><p>$C$$C$$t = \\theta x + (1-\\theta) y$$t - y = \\theta(x-y)$$t-y$$x-y$$\\theta$$t$</p>\n<p><img src=\"/img/conv_opt_intro_conv_set.png\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>$\\mathbb{R}^n$</li>\n<li>$\\{ x; \\Vert x\\Vert_p \\le 1\\}$</li>\n<li></li>\n</ul>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>$f$$x$$y$$\\theta \\in [0,1]$$\\theta \\in \\mathbb{R}$$f$</p>\n<script type=\"math/tex; mode=display\">f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta) f(y)</script><p>$\\mathbb{R}$<br><img src=\"/img/convex_opt_intro_convex_fun.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"KKT\"><a href=\"#KKT\" class=\"headerlink\" title=\"KKT\"></a>KKT</h3><h2 id=\"SVM\"><a href=\"#SVM\" class=\"headerlink\" title=\"SVM\"></a>SVM</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"http://web.stanford.edu/~boyd/cvxbook/\">Boyd</a></li>\n<li><a href=\"http://cs229.stanford.edu/section/cs229-cvxopt.pdf\">CS229</a></li>\n</ul>"}],"Post":[{"title":"bug - JupyterNotebookpycaffe","date":"2018-02-27T05:30:25.000Z","_content":"JupyteNotebookpycaffenotebookcaffemodel\n\n## bug\nnotebookLMDBStackOverflow[Can't load 2 models in pycaffe](https://stackoverflow.com/questions/37260158/cant-load-2-models-in-pycaffe)\n\n## \npycaffejupyter-notebooknotebookLMDBLMDBcopyprototxtLMDB","source":"_posts/bug-pycaffe-jupyternotebook-awaiting-for-data.md","raw":"---\ntitle: bug - JupyterNotebookpycaffe\ndate: 2018-02-27 13:30:25\ntags:\n    - caffe\n    - python\n    - debug\n---\nJupyteNotebookpycaffenotebookcaffemodel\n\n## bug\nnotebookLMDBStackOverflow[Can't load 2 models in pycaffe](https://stackoverflow.com/questions/37260158/cant-load-2-models-in-pycaffe)\n\n## \npycaffejupyter-notebooknotebookLMDBLMDBcopyprototxtLMDB","slug":"bug-pycaffe-jupyternotebook-awaiting-for-data","published":1,"updated":"2018-10-27T07:16:52.373Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8h40000ae7b84r94vpo","content":"<p>JupyteNotebookpycaffenotebookcaffemodel</p>\n<h2 id=\"bug\"><a href=\"#bug\" class=\"headerlink\" title=\"bug\"></a>bug</h2><p>notebookLMDBStackOverflow<a href=\"https://stackoverflow.com/questions/37260158/cant-load-2-models-in-pycaffe\" target=\"_blank\" rel=\"external\">Cant load 2 models in pycaffe</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>pycaffejupyter-notebooknotebookLMDBLMDBcopyprototxtLMDB</p>\n","excerpt":"","more":"<p>JupyteNotebookpycaffenotebookcaffemodel</p>\n<h2 id=\"bug\"><a href=\"#bug\" class=\"headerlink\" title=\"bug\"></a>bug</h2><p>notebookLMDBStackOverflow<a href=\"https://stackoverflow.com/questions/37260158/cant-load-2-models-in-pycaffe\">Cant load 2 models in pycaffe</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>pycaffejupyter-notebooknotebookLMDBLMDBcopyprototxtLMDB</p>\n"},{"title":"bug - Cannot create Cublas handle. Cublas won't be available.","date":"2018-02-08T06:16:53.000Z","_content":"CaffebugC++python\n```\ncommon.cpp:114] Cannot create Cublas handle. Cublas won't be available.\ncommon.cpp:121] Cannot create Curand generator. Curand won't be available.\n```\n<!-- more -->\n\npython\n\nGoogle\n\nissue: [Cannot use Caffe on another GPU when GPU 0 has full memory](https://github.com/BVLC/caffe/issues/440)GPU@longjon\n![nvidia-smi](/img/bug_pycaffe_nvidia_smi_result.png)\n\n`CUDA_VISIBLE_DEVICES`Caffe\n```bash\nCUDA_VISIBLE_DEVICES=2 python my_script.py --gpu_id=0\n```\n\n\n\npycaffe","source":"_posts/bug-pycaffe-using-cublas.md","raw":"---\ntitle: bug - Cannot create Cublas handle. Cublas won't be available.\ndate: 2018-02-08 14:16:53\ntags:\n    - caffe\n    - python\n    - debug\n---\nCaffebugC++python\n```\ncommon.cpp:114] Cannot create Cublas handle. Cublas won't be available.\ncommon.cpp:121] Cannot create Curand generator. Curand won't be available.\n```\n<!-- more -->\n\npython\n\nGoogle\n\nissue: [Cannot use Caffe on another GPU when GPU 0 has full memory](https://github.com/BVLC/caffe/issues/440)GPU@longjon\n![nvidia-smi](/img/bug_pycaffe_nvidia_smi_result.png)\n\n`CUDA_VISIBLE_DEVICES`Caffe\n```bash\nCUDA_VISIBLE_DEVICES=2 python my_script.py --gpu_id=0\n```\n\n\n\npycaffe","slug":"bug-pycaffe-using-cublas","published":1,"updated":"2018-10-27T07:16:52.376Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8hi0002ae7bx1uyik45","content":"<p>CaffebugC++python<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">common.cpp:114] Cannot create Cublas handle. Cublas won&apos;t be available.</div><div class=\"line\">common.cpp:121] Cannot create Curand generator. Curand won&apos;t be available.</div></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p>python</p>\n<p>Google</p>\n<p>issue: <a href=\"https://github.com/BVLC/caffe/issues/440\" target=\"_blank\" rel=\"external\">Cannot use Caffe on another GPU when GPU 0 has full memory</a>GPU@longjon<br><img src=\"/img/bug_pycaffe_nvidia_smi_result.png\" alt=\"nvidia-smi\"></p>\n<p><code>CUDA_VISIBLE_DEVICES</code>Caffe<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">CUDA_VISIBLE_DEVICES=2 python my_script.py --gpu_id=0</div></pre></td></tr></table></figure></p>\n<p></p>\n<p>pycaffe</p>\n","excerpt":"<p>CaffebugC++python<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">common.cpp:114] Cannot create Cublas handle. Cublas won&apos;t be available.</div><div class=\"line\">common.cpp:121] Cannot create Curand generator. Curand won&apos;t be available.</div></pre></td></tr></table></figure></p>","more":"<p>python</p>\n<p>Google</p>\n<p>issue: <a href=\"https://github.com/BVLC/caffe/issues/440\">Cannot use Caffe on another GPU when GPU 0 has full memory</a>GPU@longjon<br><img src=\"/img/bug_pycaffe_nvidia_smi_result.png\" alt=\"nvidia-smi\"></p>\n<p><code>CUDA_VISIBLE_DEVICES</code>Caffe<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">CUDA_VISIBLE_DEVICES=2 python my_script.py --gpu_id=0</div></pre></td></tr></table></figure></p>\n<p></p>\n<p>pycaffe</p>"},{"title":"Ubuntu14.04Caffe","date":"2017-02-09T12:59:05.000Z","_content":"CaffeJia YangqingUbuntu14.04.3DELL7559Caffepythonimport errorHDF5\n\n![caffe](/img/caffe_image.jpg)\n\n<!-- more -->\n## Makefile.config\ngithubcloneCaffeMakefile.configCUDNNAnaconda Python\n\n``` bash\n## Refer to http://caffe.berkeleyvision.org/installation.html\n# Contributions simplifying and improving our build system are welcome!\n\n# cuDNN acceleration switch (uncomment to build with cuDNN).\nUSE_CUDNN := 1    # cudnn\n\n# CPU-only switch (uncomment to build without GPU support).\n# CPU_ONLY := 1\n\n# uncomment to disable IO dependencies and corresponding data layers\n# USE_OPENCV := 0\n# USE_LEVELDB := 0\n# USE_LMDB := 0\n\n# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)\n#\tYou should not set this flag if you will be reading LMDBs with any\n#\tpossibility of simultaneous read and write\n# ALLOW_LMDB_NOLOCK := 1\n\n# Uncomment if you're using OpenCV 3\n# OPENCV_VERSION := 3\n\n# To customize your choice of compiler, uncomment and set the following.\n# N.B. the default for Linux is g++ and the default for OSX is clang++\n# CUSTOM_CXX := g++\n\n# CUDA directory contains bin/ and lib/ directories that we need.\nCUDA_DIR := /usr/local/cuda\n# On Ubuntu 14.04, if cuda tools are installed via\n# \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:\n# CUDA_DIR := /usr\n\n# CUDA architecture setting: going with all of them.\n# For CUDA < 6.0, comment the *_50 lines for compatibility.\n# sm_2021\n# nvcc\nCUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\\n\t\t-gencode arch=compute_35,code=sm_35 \\\n\t\t-gencode arch=compute_50,code=sm_50 \\\n\t\t-gencode arch=compute_50,code=compute_50\n\n# BLAS choice:\n# atlas for ATLAS (default)\n# mkl for MKL\n# open for OpenBlas\nBLAS := atlas\n# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n# Leave commented to accept the defaults for your choice of BLAS\n# (which should work)!\n# BLAS_INCLUDE := /path/to/your/blas\n# BLAS_LIB := /path/to/your/blas\n\n# Homebrew puts openblas in a directory that is not on the standard search path\n# BLAS_INCLUDE := $(shell brew --prefix openblas)/include\n# BLAS_LIB := $(shell brew --prefix openblas)/lib\n\n# This is required only if you will compile the matlab interface.\n# MATLAB directory should contain the mex binary in /bin.\n# MATLAB_DIR := /usr/local\n# MATLAB_DIR := /Applications/MATLAB_R2012b.app\n\n# NOTE: this is required only if you will compile the python interface.\n# We need to be able to find Python.h and numpy/arrayobject.h.\nPYTHON_INCLUDE := /usr/include/python2.7 \\\n\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\n# Anaconda Python distribution is quite popular. Include path:\n# Verify anaconda location, sometimes it's in root.\n# Anaconda\nANACONDA_HOME := $(HOME)/anaconda2\n PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n\t\t $(ANACONDA_HOME)/include/python2.7 \\\n\t\t $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include\n\n# Uncomment to use Python 3 (default is Python 2)\n# PYTHON_LIBRARIES := boost_python3 python3.5m\n# PYTHON_INCLUDE := /usr/include/python3.5m \\\n#                 /usr/lib/python3.5/dist-packages/numpy/core/include\n\n# We need to be able to find libpythonX.X.so or .dylib.\n#PYTHON_LIB := /usr/lib\n PYTHON_LIB := $(ANACONDA_HOME)/lib\n\n# Homebrew installs numpy in a non standard path (keg only)\n# PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n# PYTHON_LIB += $(shell brew --prefix numpy)/lib\n\n# Uncomment to support layers written in Python (will link against Python libs)\nWITH_PYTHON_LAYER := 1\n\n# Whatever else you find you need goes here.\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib\n\n# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies\n# INCLUDE_DIRS += $(shell brew --prefix)/include\n# LIBRARY_DIRS += $(shell brew --prefix)/lib\n\n# NCCL acceleration switch (uncomment to build with NCCL)\n# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)\n# USE_NCCL := 1\n\n# Uncomment to use `pkg-config` to specify OpenCV library paths.\n# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\n# USE_PKG_CONFIG := 1\n\n# N.B. both build and distribute dirs are cleared on `make clean`\nBUILD_DIR := build\nDISTRIBUTE_DIR := distribute\n\n# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171\n# DEBUG := 1\n\n# The ID of the GPU that 'make runtest' will use to run unit tests.\nTEST_GPUID := 0\n\n# enable pretty build (comment to see full commands)\nQ ?= @\n```\n\nCUDNNNvidia`include``/usr/local/cuda-8.0/include``lib``/usr/loca/cuda-8.0/lib64`\n\n## \n`make -j8``make pycaffe`python`.bashrc`\n```\nexport PYTHONPATH=/path_to_caffe/python:$PYTHONPATH\n```\n\n`import caffe`\n```\nImportError: libcudnn.so.5: cannot open shared object file: No such file or directory\n```\nGitHub issue[](https://github.com/NVIDIA/DIGITS/issues/8)\n```\nsudo ldconfig /usr/local/cuda/lib64\n```\n\n\n```\nImportError: No module named google.protobuf.internal\n```\nG+ caffe-user group[](https://groups.google.com/forum/#!topic/caffe-users/9Q10WkpCGxs)\n```\npip install protobuf\n```\n\nSSH`ipython`caffe\n\n`make test; make runtest`HDF5AnacondaHDF5\n\n```\nerror while loading shared libraries: libhdf5_hl.so.10: cannot open shared object file: No such file or directory\n```\n\nGitHub[](https://github.com/BVLC/caffe/issues/1463)\n\n```\ncd /usr/lib/x86_64-linux-gnu\nsudo ln -s libhdf5.so.7 libhdf5.so.10\nsudo ln -s libhdf5_hl.so.7 libhdf5_hl.so.10\n```\n\nMKLMKL`/opt/intel/mkl``sudo``/etc/ld.so.conf.d/``intel_mkl_setttings.conf`MKL\n```\n/opt/intel/mkl/lib/intel64_lin/\n```\n`sudo ldconfig`\n\n## \n`make runtest`test`example`LeNet\n```\ncd $CAFFE_ROOT\n./data/mnist/get_mnist.sh\n./examples/mnist/create_mnist.sh\n./examples/mnist/train_lenet.sh\n```\n","source":"_posts/build-caffe-ubuntu.md","raw":"---\ntitle: Ubuntu14.04Caffe\ndate: 2017-02-09 20:59:05\ntags:\n    - tool\n    - caffe\n---\nCaffeJia YangqingUbuntu14.04.3DELL7559Caffepythonimport errorHDF5\n\n![caffe](/img/caffe_image.jpg)\n\n<!-- more -->\n## Makefile.config\ngithubcloneCaffeMakefile.configCUDNNAnaconda Python\n\n``` bash\n## Refer to http://caffe.berkeleyvision.org/installation.html\n# Contributions simplifying and improving our build system are welcome!\n\n# cuDNN acceleration switch (uncomment to build with cuDNN).\nUSE_CUDNN := 1    # cudnn\n\n# CPU-only switch (uncomment to build without GPU support).\n# CPU_ONLY := 1\n\n# uncomment to disable IO dependencies and corresponding data layers\n# USE_OPENCV := 0\n# USE_LEVELDB := 0\n# USE_LMDB := 0\n\n# uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)\n#\tYou should not set this flag if you will be reading LMDBs with any\n#\tpossibility of simultaneous read and write\n# ALLOW_LMDB_NOLOCK := 1\n\n# Uncomment if you're using OpenCV 3\n# OPENCV_VERSION := 3\n\n# To customize your choice of compiler, uncomment and set the following.\n# N.B. the default for Linux is g++ and the default for OSX is clang++\n# CUSTOM_CXX := g++\n\n# CUDA directory contains bin/ and lib/ directories that we need.\nCUDA_DIR := /usr/local/cuda\n# On Ubuntu 14.04, if cuda tools are installed via\n# \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:\n# CUDA_DIR := /usr\n\n# CUDA architecture setting: going with all of them.\n# For CUDA < 6.0, comment the *_50 lines for compatibility.\n# sm_2021\n# nvcc\nCUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\\n\t\t-gencode arch=compute_35,code=sm_35 \\\n\t\t-gencode arch=compute_50,code=sm_50 \\\n\t\t-gencode arch=compute_50,code=compute_50\n\n# BLAS choice:\n# atlas for ATLAS (default)\n# mkl for MKL\n# open for OpenBlas\nBLAS := atlas\n# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\n# Leave commented to accept the defaults for your choice of BLAS\n# (which should work)!\n# BLAS_INCLUDE := /path/to/your/blas\n# BLAS_LIB := /path/to/your/blas\n\n# Homebrew puts openblas in a directory that is not on the standard search path\n# BLAS_INCLUDE := $(shell brew --prefix openblas)/include\n# BLAS_LIB := $(shell brew --prefix openblas)/lib\n\n# This is required only if you will compile the matlab interface.\n# MATLAB directory should contain the mex binary in /bin.\n# MATLAB_DIR := /usr/local\n# MATLAB_DIR := /Applications/MATLAB_R2012b.app\n\n# NOTE: this is required only if you will compile the python interface.\n# We need to be able to find Python.h and numpy/arrayobject.h.\nPYTHON_INCLUDE := /usr/include/python2.7 \\\n\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\n# Anaconda Python distribution is quite popular. Include path:\n# Verify anaconda location, sometimes it's in root.\n# Anaconda\nANACONDA_HOME := $(HOME)/anaconda2\n PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\\n\t\t $(ANACONDA_HOME)/include/python2.7 \\\n\t\t $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include\n\n# Uncomment to use Python 3 (default is Python 2)\n# PYTHON_LIBRARIES := boost_python3 python3.5m\n# PYTHON_INCLUDE := /usr/include/python3.5m \\\n#                 /usr/lib/python3.5/dist-packages/numpy/core/include\n\n# We need to be able to find libpythonX.X.so or .dylib.\n#PYTHON_LIB := /usr/lib\n PYTHON_LIB := $(ANACONDA_HOME)/lib\n\n# Homebrew installs numpy in a non standard path (keg only)\n# PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include\n# PYTHON_LIB += $(shell brew --prefix numpy)/lib\n\n# Uncomment to support layers written in Python (will link against Python libs)\nWITH_PYTHON_LAYER := 1\n\n# Whatever else you find you need goes here.\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib\n\n# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies\n# INCLUDE_DIRS += $(shell brew --prefix)/include\n# LIBRARY_DIRS += $(shell brew --prefix)/lib\n\n# NCCL acceleration switch (uncomment to build with NCCL)\n# https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)\n# USE_NCCL := 1\n\n# Uncomment to use `pkg-config` to specify OpenCV library paths.\n# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\n# USE_PKG_CONFIG := 1\n\n# N.B. both build and distribute dirs are cleared on `make clean`\nBUILD_DIR := build\nDISTRIBUTE_DIR := distribute\n\n# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171\n# DEBUG := 1\n\n# The ID of the GPU that 'make runtest' will use to run unit tests.\nTEST_GPUID := 0\n\n# enable pretty build (comment to see full commands)\nQ ?= @\n```\n\nCUDNNNvidia`include``/usr/local/cuda-8.0/include``lib``/usr/loca/cuda-8.0/lib64`\n\n## \n`make -j8``make pycaffe`python`.bashrc`\n```\nexport PYTHONPATH=/path_to_caffe/python:$PYTHONPATH\n```\n\n`import caffe`\n```\nImportError: libcudnn.so.5: cannot open shared object file: No such file or directory\n```\nGitHub issue[](https://github.com/NVIDIA/DIGITS/issues/8)\n```\nsudo ldconfig /usr/local/cuda/lib64\n```\n\n\n```\nImportError: No module named google.protobuf.internal\n```\nG+ caffe-user group[](https://groups.google.com/forum/#!topic/caffe-users/9Q10WkpCGxs)\n```\npip install protobuf\n```\n\nSSH`ipython`caffe\n\n`make test; make runtest`HDF5AnacondaHDF5\n\n```\nerror while loading shared libraries: libhdf5_hl.so.10: cannot open shared object file: No such file or directory\n```\n\nGitHub[](https://github.com/BVLC/caffe/issues/1463)\n\n```\ncd /usr/lib/x86_64-linux-gnu\nsudo ln -s libhdf5.so.7 libhdf5.so.10\nsudo ln -s libhdf5_hl.so.7 libhdf5_hl.so.10\n```\n\nMKLMKL`/opt/intel/mkl``sudo``/etc/ld.so.conf.d/``intel_mkl_setttings.conf`MKL\n```\n/opt/intel/mkl/lib/intel64_lin/\n```\n`sudo ldconfig`\n\n## \n`make runtest`test`example`LeNet\n```\ncd $CAFFE_ROOT\n./data/mnist/get_mnist.sh\n./examples/mnist/create_mnist.sh\n./examples/mnist/train_lenet.sh\n```\n","slug":"build-caffe-ubuntu","published":1,"updated":"2018-10-27T07:16:52.376Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8hu0005ae7bwpovv1cx","content":"<p>CaffeJia YangqingUbuntu14.04.3DELL7559Caffepythonimport errorHDF5</p>\n<p><img src=\"/img/caffe_image.jpg\" alt=\"caffe\"></p>\n<a id=\"more\"></a>\n<h2 id=\"Makefile-config\"><a href=\"#Makefile-config\" class=\"headerlink\" title=\"Makefile.config\"></a>Makefile.config</h2><p>githubcloneCaffeMakefile.configCUDNNAnaconda Python</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## Refer to http://caffe.berkeleyvision.org/installation.html</span></div><div class=\"line\"><span class=\"comment\"># Contributions simplifying and improving our build system are welcome!</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># cuDNN acceleration switch (uncomment to build with cuDNN).</span></div><div class=\"line\">USE_CUDNN := 1    <span class=\"comment\"># cudnn</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CPU-only switch (uncomment to build without GPU support).</span></div><div class=\"line\"><span class=\"comment\"># CPU_ONLY := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># uncomment to disable IO dependencies and corresponding data layers</span></div><div class=\"line\"><span class=\"comment\"># USE_OPENCV := 0</span></div><div class=\"line\"><span class=\"comment\"># USE_LEVELDB := 0</span></div><div class=\"line\"><span class=\"comment\"># USE_LMDB := 0</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)</span></div><div class=\"line\"><span class=\"comment\">#\tYou should not set this flag if you will be reading LMDBs with any</span></div><div class=\"line\"><span class=\"comment\">#\tpossibility of simultaneous read and write</span></div><div class=\"line\"><span class=\"comment\"># ALLOW_LMDB_NOLOCK := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment if you're using OpenCV 3</span></div><div class=\"line\"><span class=\"comment\"># OPENCV_VERSION := 3</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># To customize your choice of compiler, uncomment and set the following.</span></div><div class=\"line\"><span class=\"comment\"># N.B. the default for Linux is g++ and the default for OSX is clang++</span></div><div class=\"line\"><span class=\"comment\"># CUSTOM_CXX := g++</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CUDA directory contains bin/ and lib/ directories that we need.</span></div><div class=\"line\">CUDA_DIR := /usr/<span class=\"built_in\">local</span>/cuda</div><div class=\"line\"><span class=\"comment\"># On Ubuntu 14.04, if cuda tools are installed via</span></div><div class=\"line\"><span class=\"comment\"># \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:</span></div><div class=\"line\"><span class=\"comment\"># CUDA_DIR := /usr</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CUDA architecture setting: going with all of them.</span></div><div class=\"line\"><span class=\"comment\"># For CUDA &lt; 6.0, comment the *_50 lines for compatibility.</span></div><div class=\"line\"><span class=\"comment\"># sm_2021</span></div><div class=\"line\"><span class=\"comment\"># nvcc</span></div><div class=\"line\">CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\</div><div class=\"line\">\t\t-gencode arch=compute_35,code=sm_35 \\</div><div class=\"line\">\t\t-gencode arch=compute_50,code=sm_50 \\</div><div class=\"line\">\t\t-gencode arch=compute_50,code=compute_50</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># BLAS choice:</span></div><div class=\"line\"><span class=\"comment\"># atlas for ATLAS (default)</span></div><div class=\"line\"><span class=\"comment\"># mkl for MKL</span></div><div class=\"line\"><span class=\"comment\"># open for OpenBlas</span></div><div class=\"line\">BLAS := atlas</div><div class=\"line\"><span class=\"comment\"># Custom (MKL/ATLAS/OpenBLAS) include and lib directories.</span></div><div class=\"line\"><span class=\"comment\"># Leave commented to accept the defaults for your choice of BLAS</span></div><div class=\"line\"><span class=\"comment\"># (which should work)!</span></div><div class=\"line\"><span class=\"comment\"># BLAS_INCLUDE := /path/to/your/blas</span></div><div class=\"line\"><span class=\"comment\"># BLAS_LIB := /path/to/your/blas</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Homebrew puts openblas in a directory that is not on the standard search path</span></div><div class=\"line\"><span class=\"comment\"># BLAS_INCLUDE := $(shell brew --prefix openblas)/include</span></div><div class=\"line\"><span class=\"comment\"># BLAS_LIB := $(shell brew --prefix openblas)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># This is required only if you will compile the matlab interface.</span></div><div class=\"line\"><span class=\"comment\"># MATLAB directory should contain the mex binary in /bin.</span></div><div class=\"line\"><span class=\"comment\"># MATLAB_DIR := /usr/local</span></div><div class=\"line\"><span class=\"comment\"># MATLAB_DIR := /Applications/MATLAB_R2012b.app</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># <span class=\"doctag\">NOTE:</span> this is required only if you will compile the python interface.</span></div><div class=\"line\"><span class=\"comment\"># We need to be able to find Python.h and numpy/arrayobject.h.</span></div><div class=\"line\">PYTHON_INCLUDE := /usr/include/python2.7 \\</div><div class=\"line\">\t\t/usr/lib/python2.7/dist-packages/numpy/core/include</div><div class=\"line\"><span class=\"comment\"># Anaconda Python distribution is quite popular. Include path:</span></div><div class=\"line\"><span class=\"comment\"># Verify anaconda location, sometimes it's in root.</span></div><div class=\"line\"><span class=\"comment\"># Anaconda</span></div><div class=\"line\">ANACONDA_HOME := $(HOME)/anaconda2</div><div class=\"line\"> PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\</div><div class=\"line\">\t\t $(ANACONDA_HOME)/include/python2.7 \\</div><div class=\"line\">\t\t $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to use Python 3 (default is Python 2)</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_LIBRARIES := boost_python3 python3.5m</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_INCLUDE := /usr/include/python3.5m \\</span></div><div class=\"line\"><span class=\"comment\">#                 /usr/lib/python3.5/dist-packages/numpy/core/include</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># We need to be able to find libpythonX.X.so or .dylib.</span></div><div class=\"line\"><span class=\"comment\">#PYTHON_LIB := /usr/lib</span></div><div class=\"line\"> PYTHON_LIB := $(ANACONDA_HOME)/lib</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Homebrew installs numpy in a non standard path (keg only)</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_LIB += $(shell brew --prefix numpy)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to support layers written in Python (will link against Python libs)</span></div><div class=\"line\">WITH_PYTHON_LAYER := 1</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Whatever else you find you need goes here.</span></div><div class=\"line\">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class=\"built_in\">local</span>/include</div><div class=\"line\">LIBRARY_DIRS := $(PYTHON_LIB) /usr/<span class=\"built_in\">local</span>/lib /usr/lib</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies</span></div><div class=\"line\"><span class=\"comment\"># INCLUDE_DIRS += $(shell brew --prefix)/include</span></div><div class=\"line\"><span class=\"comment\"># LIBRARY_DIRS += $(shell brew --prefix)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># NCCL acceleration switch (uncomment to build with NCCL)</span></div><div class=\"line\"><span class=\"comment\"># https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)</span></div><div class=\"line\"><span class=\"comment\"># USE_NCCL := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to use `pkg-config` to specify OpenCV library paths.</span></div><div class=\"line\"><span class=\"comment\"># (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)</span></div><div class=\"line\"><span class=\"comment\"># USE_PKG_CONFIG := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># N.B. both build and distribute dirs are cleared on `make clean`</span></div><div class=\"line\">BUILD_DIR := build</div><div class=\"line\">DISTRIBUTE_DIR := distribute</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171</span></div><div class=\"line\"><span class=\"comment\"># DEBUG := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># The ID of the GPU that 'make runtest' will use to run unit tests.</span></div><div class=\"line\">TEST_GPUID := 0</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># enable pretty build (comment to see full commands)</span></div><div class=\"line\">Q ?= @</div></pre></td></tr></table></figure>\n<p>CUDNNNvidia<code>include</code><code>/usr/local/cuda-8.0/include</code><code>lib</code><code>/usr/loca/cuda-8.0/lib64</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>make -j8</code><code>make pycaffe</code>python<code>.bashrc</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PYTHONPATH=/path_to_caffe/python:$PYTHONPATH</div></pre></td></tr></table></figure></p>\n<p><code>import caffe</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory</div></pre></td></tr></table></figure></p>\n<p>GitHub issue<a href=\"https://github.com/NVIDIA/DIGITS/issues/8\" target=\"_blank\" rel=\"external\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo ldconfig /usr/local/cuda/lib64</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImportError: No module named google.protobuf.internal</div></pre></td></tr></table></figure></p>\n<p>G+ caffe-user group<a href=\"https://groups.google.com/forum/#!topic/caffe-users/9Q10WkpCGxs\" target=\"_blank\" rel=\"external\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install protobuf</div></pre></td></tr></table></figure></p>\n<p>SSH<code>ipython</code>caffe</p>\n<p><code>make test; make runtest</code>HDF5AnacondaHDF5</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">error while loading shared libraries: libhdf5_hl.so.10: cannot open shared object file: No such file or directory</div></pre></td></tr></table></figure>\n<p>GitHub<a href=\"https://github.com/BVLC/caffe/issues/1463\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/lib/x86_64-linux-gnu</div><div class=\"line\">sudo ln -s libhdf5.so.7 libhdf5.so.10</div><div class=\"line\">sudo ln -s libhdf5_hl.so.7 libhdf5_hl.so.10</div></pre></td></tr></table></figure>\n<p>MKLMKL<code>/opt/intel/mkl</code><code>sudo</code><code>/etc/ld.so.conf.d/</code><code>intel_mkl_setttings.conf</code>MKL<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">/opt/intel/mkl/lib/intel64_lin/</div></pre></td></tr></table></figure></p>\n<p><code>sudo ldconfig</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>make runtest</code>test<code>example</code>LeNet<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd $CAFFE_ROOT</div><div class=\"line\">./data/mnist/get_mnist.sh</div><div class=\"line\">./examples/mnist/create_mnist.sh</div><div class=\"line\">./examples/mnist/train_lenet.sh</div></pre></td></tr></table></figure></p>\n","excerpt":"<p>CaffeJia YangqingUbuntu14.04.3DELL7559Caffepythonimport errorHDF5</p>\n<p><img src=\"/img/caffe_image.jpg\" alt=\"caffe\"></p>","more":"<h2 id=\"Makefile-config\"><a href=\"#Makefile-config\" class=\"headerlink\" title=\"Makefile.config\"></a>Makefile.config</h2><p>githubcloneCaffeMakefile.configCUDNNAnaconda Python</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## Refer to http://caffe.berkeleyvision.org/installation.html</span></div><div class=\"line\"><span class=\"comment\"># Contributions simplifying and improving our build system are welcome!</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># cuDNN acceleration switch (uncomment to build with cuDNN).</span></div><div class=\"line\">USE_CUDNN := 1    <span class=\"comment\"># cudnn</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CPU-only switch (uncomment to build without GPU support).</span></div><div class=\"line\"><span class=\"comment\"># CPU_ONLY := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># uncomment to disable IO dependencies and corresponding data layers</span></div><div class=\"line\"><span class=\"comment\"># USE_OPENCV := 0</span></div><div class=\"line\"><span class=\"comment\"># USE_LEVELDB := 0</span></div><div class=\"line\"><span class=\"comment\"># USE_LMDB := 0</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># uncomment to allow MDB_NOLOCK when reading LMDB files (only if necessary)</span></div><div class=\"line\"><span class=\"comment\">#\tYou should not set this flag if you will be reading LMDBs with any</span></div><div class=\"line\"><span class=\"comment\">#\tpossibility of simultaneous read and write</span></div><div class=\"line\"><span class=\"comment\"># ALLOW_LMDB_NOLOCK := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment if you're using OpenCV 3</span></div><div class=\"line\"><span class=\"comment\"># OPENCV_VERSION := 3</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># To customize your choice of compiler, uncomment and set the following.</span></div><div class=\"line\"><span class=\"comment\"># N.B. the default for Linux is g++ and the default for OSX is clang++</span></div><div class=\"line\"><span class=\"comment\"># CUSTOM_CXX := g++</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CUDA directory contains bin/ and lib/ directories that we need.</span></div><div class=\"line\">CUDA_DIR := /usr/<span class=\"built_in\">local</span>/cuda</div><div class=\"line\"><span class=\"comment\"># On Ubuntu 14.04, if cuda tools are installed via</span></div><div class=\"line\"><span class=\"comment\"># \"sudo apt-get install nvidia-cuda-toolkit\" then use this instead:</span></div><div class=\"line\"><span class=\"comment\"># CUDA_DIR := /usr</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># CUDA architecture setting: going with all of them.</span></div><div class=\"line\"><span class=\"comment\"># For CUDA &lt; 6.0, comment the *_50 lines for compatibility.</span></div><div class=\"line\"><span class=\"comment\"># sm_2021</span></div><div class=\"line\"><span class=\"comment\"># nvcc</span></div><div class=\"line\">CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\</div><div class=\"line\">\t\t-gencode arch=compute_35,code=sm_35 \\</div><div class=\"line\">\t\t-gencode arch=compute_50,code=sm_50 \\</div><div class=\"line\">\t\t-gencode arch=compute_50,code=compute_50</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># BLAS choice:</span></div><div class=\"line\"><span class=\"comment\"># atlas for ATLAS (default)</span></div><div class=\"line\"><span class=\"comment\"># mkl for MKL</span></div><div class=\"line\"><span class=\"comment\"># open for OpenBlas</span></div><div class=\"line\">BLAS := atlas</div><div class=\"line\"><span class=\"comment\"># Custom (MKL/ATLAS/OpenBLAS) include and lib directories.</span></div><div class=\"line\"><span class=\"comment\"># Leave commented to accept the defaults for your choice of BLAS</span></div><div class=\"line\"><span class=\"comment\"># (which should work)!</span></div><div class=\"line\"><span class=\"comment\"># BLAS_INCLUDE := /path/to/your/blas</span></div><div class=\"line\"><span class=\"comment\"># BLAS_LIB := /path/to/your/blas</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Homebrew puts openblas in a directory that is not on the standard search path</span></div><div class=\"line\"><span class=\"comment\"># BLAS_INCLUDE := $(shell brew --prefix openblas)/include</span></div><div class=\"line\"><span class=\"comment\"># BLAS_LIB := $(shell brew --prefix openblas)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># This is required only if you will compile the matlab interface.</span></div><div class=\"line\"><span class=\"comment\"># MATLAB directory should contain the mex binary in /bin.</span></div><div class=\"line\"><span class=\"comment\"># MATLAB_DIR := /usr/local</span></div><div class=\"line\"><span class=\"comment\"># MATLAB_DIR := /Applications/MATLAB_R2012b.app</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># <span class=\"doctag\">NOTE:</span> this is required only if you will compile the python interface.</span></div><div class=\"line\"><span class=\"comment\"># We need to be able to find Python.h and numpy/arrayobject.h.</span></div><div class=\"line\">PYTHON_INCLUDE := /usr/include/python2.7 \\</div><div class=\"line\">\t\t/usr/lib/python2.7/dist-packages/numpy/core/include</div><div class=\"line\"><span class=\"comment\"># Anaconda Python distribution is quite popular. Include path:</span></div><div class=\"line\"><span class=\"comment\"># Verify anaconda location, sometimes it's in root.</span></div><div class=\"line\"><span class=\"comment\"># Anaconda</span></div><div class=\"line\">ANACONDA_HOME := $(HOME)/anaconda2</div><div class=\"line\"> PYTHON_INCLUDE := $(ANACONDA_HOME)/include \\</div><div class=\"line\">\t\t $(ANACONDA_HOME)/include/python2.7 \\</div><div class=\"line\">\t\t $(ANACONDA_HOME)/lib/python2.7/site-packages/numpy/core/include</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to use Python 3 (default is Python 2)</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_LIBRARIES := boost_python3 python3.5m</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_INCLUDE := /usr/include/python3.5m \\</span></div><div class=\"line\"><span class=\"comment\">#                 /usr/lib/python3.5/dist-packages/numpy/core/include</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># We need to be able to find libpythonX.X.so or .dylib.</span></div><div class=\"line\"><span class=\"comment\">#PYTHON_LIB := /usr/lib</span></div><div class=\"line\"> PYTHON_LIB := $(ANACONDA_HOME)/lib</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Homebrew installs numpy in a non standard path (keg only)</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_INCLUDE += $(dir $(shell python -c 'import numpy.core; print(numpy.core.__file__)'))/include</span></div><div class=\"line\"><span class=\"comment\"># PYTHON_LIB += $(shell brew --prefix numpy)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to support layers written in Python (will link against Python libs)</span></div><div class=\"line\">WITH_PYTHON_LAYER := 1</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Whatever else you find you need goes here.</span></div><div class=\"line\">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class=\"built_in\">local</span>/include</div><div class=\"line\">LIBRARY_DIRS := $(PYTHON_LIB) /usr/<span class=\"built_in\">local</span>/lib /usr/lib</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies</span></div><div class=\"line\"><span class=\"comment\"># INCLUDE_DIRS += $(shell brew --prefix)/include</span></div><div class=\"line\"><span class=\"comment\"># LIBRARY_DIRS += $(shell brew --prefix)/lib</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># NCCL acceleration switch (uncomment to build with NCCL)</span></div><div class=\"line\"><span class=\"comment\"># https://github.com/NVIDIA/nccl (last tested version: v1.2.3-1+cuda8.0)</span></div><div class=\"line\"><span class=\"comment\"># USE_NCCL := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment to use `pkg-config` to specify OpenCV library paths.</span></div><div class=\"line\"><span class=\"comment\"># (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)</span></div><div class=\"line\"><span class=\"comment\"># USE_PKG_CONFIG := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># N.B. both build and distribute dirs are cleared on `make clean`</span></div><div class=\"line\">BUILD_DIR := build</div><div class=\"line\">DISTRIBUTE_DIR := distribute</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171</span></div><div class=\"line\"><span class=\"comment\"># DEBUG := 1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># The ID of the GPU that 'make runtest' will use to run unit tests.</span></div><div class=\"line\">TEST_GPUID := 0</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># enable pretty build (comment to see full commands)</span></div><div class=\"line\">Q ?= @</div></pre></td></tr></table></figure>\n<p>CUDNNNvidia<code>include</code><code>/usr/local/cuda-8.0/include</code><code>lib</code><code>/usr/loca/cuda-8.0/lib64</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>make -j8</code><code>make pycaffe</code>python<code>.bashrc</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export PYTHONPATH=/path_to_caffe/python:$PYTHONPATH</div></pre></td></tr></table></figure></p>\n<p><code>import caffe</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory</div></pre></td></tr></table></figure></p>\n<p>GitHub issue<a href=\"https://github.com/NVIDIA/DIGITS/issues/8\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo ldconfig /usr/local/cuda/lib64</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ImportError: No module named google.protobuf.internal</div></pre></td></tr></table></figure></p>\n<p>G+ caffe-user group<a href=\"https://groups.google.com/forum/#!topic/caffe-users/9Q10WkpCGxs\"></a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install protobuf</div></pre></td></tr></table></figure></p>\n<p>SSH<code>ipython</code>caffe</p>\n<p><code>make test; make runtest</code>HDF5AnacondaHDF5</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">error while loading shared libraries: libhdf5_hl.so.10: cannot open shared object file: No such file or directory</div></pre></td></tr></table></figure>\n<p>GitHub<a href=\"https://github.com/BVLC/caffe/issues/1463\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd /usr/lib/x86_64-linux-gnu</div><div class=\"line\">sudo ln -s libhdf5.so.7 libhdf5.so.10</div><div class=\"line\">sudo ln -s libhdf5_hl.so.7 libhdf5_hl.so.10</div></pre></td></tr></table></figure>\n<p>MKLMKL<code>/opt/intel/mkl</code><code>sudo</code><code>/etc/ld.so.conf.d/</code><code>intel_mkl_setttings.conf</code>MKL<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">/opt/intel/mkl/lib/intel64_lin/</div></pre></td></tr></table></figure></p>\n<p><code>sudo ldconfig</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>make runtest</code>test<code>example</code>LeNet<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd $CAFFE_ROOT</div><div class=\"line\">./data/mnist/get_mnist.sh</div><div class=\"line\">./examples/mnist/create_mnist.sh</div><div class=\"line\">./examples/mnist/train_lenet.sh</div></pre></td></tr></table></figure></p>"},{"title":"CaffeBatchNorm","date":"2018-01-08T12:12:44.000Z","_content":"CaffeBN\n<!-- more -->\n\n## BN\n\nBNBN\n\nBNBatch NormalizationGoogle[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)BN\n\nBNblobchannelinference$x$$\\epsilon$$0$$i$channelindex\n$$\\hat{x_i} = \\frac{x_i-\\mu_i}{\\sqrt{Var(x_i)+\\epsilon}}$$\n\nIdentity Map($y = x$)$\\gamma$$\\beta$BN$y$\n$$y_i = \\gamma \\hat{x_i} + \\beta$$\n\nBN\n![BN](/img/caffe_bn_what_is_bn.jpg)\n\ninferenceBNBNCaffe\n\n## BN in Caffe\nBVLCCaffeBNScaleBNNormalizationScale\n\nHe KaimingResidual Net50[](https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-50-deploy.prototxt#L21)`batch_norm_param``use_global_stats``true`inferenceScale`bias_term: true`\n\n```\nlayer {\n\tbottom: \"conv1\"\n\ttop: \"conv1\"\n\tname: \"bn_conv1\"\n\ttype: \"BatchNorm\"\n\tbatch_norm_param {\n\t\tuse_global_stats: true\n\t}\n}\n\nlayer {\n\tbottom: \"conv1\"\n\ttop: \"conv1\"\n\tname: \"scale_conv1\"\n\ttype: \"Scale\"\n\tscale_param {\n\t\tbias_term: true\n\t}\n}\n```\nCaffeBN\n\n## BatchNorm \nCaffeBNScale\n### proto\n`caffe.proto`BN\n```\nmessage BatchNormParameter {\n  // If false, normalization is performed over the current mini-batch\n  // and global statistics are accumulated (but not yet used) by a moving\n  // average.\n  // If true, those accumulated mean and variance values are used for the\n  // normalization.\n  // By default, it is set to false when the network is in the training\n  // phase and true when the network is in the testing phase.\n  // Falsemini-batch\n  // batch\n  // True\n  // BNtraintest phase\n  // trainfalsetesttrue\n  optional bool use_global_stats = 1;\n  \n  // What fraction of the moving average remains each iteration?\n  // Smaller values make the moving average decay faster, giving more\n  // weight to the recent values.\n  // Each iteration updates the moving average @f$S_{t-1}@f$ with the\n  // current mean @f$ Y_t @f$ by\n  // @f$ S_t = (1-\\beta)Y_t + \\beta \\cdot S_{t-1} @f$, where @f$ \\beta @f$\n  // is the moving_average_fraction parameter.\n  // BN\n  // St = (1-beta)*Yt + beta*S_{t-1}\n  // StYtbatch\n  // beta\n  optional float moving_average_fraction = 2 [default = .999];\n  \n  // Small value to add to the variance estimate so that we don't divide by\n  // zero.\n  // 0eps\n  optional float eps = 3 [default = 1e-5];\n}\n```\n\nOKBN`use_global_stats`\n\n### SetUp\nBNSetUptraintestprototxt`use_global_stats`BN`use_global_stats`\n\nBNblobBN3blobwiki[moving average](https://wiki2.org/en/Moving_average)\n\n``` cpp\ntemplate <typename Dtype>\nvoid BatchNormLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,\n      const vector<Blob<Dtype>*>& top) {\n  BatchNormParameter param = this->layer_param_.batch_norm_param();\n  moving_average_fraction_ = param.moving_average_fraction();\n  // TESTmeanvar\n  use_global_stats_ = this->phase_ == TEST;\n  if (param.has_use_global_stats())\n    use_global_stats_ = param.use_global_stats();\n  // channels\n  // 1D\n  if (bottom[0]->num_axes() == 1)\n    channels_ = 1;\n  else\n    channels_ = bottom[0]->shape(1);\n  eps_ = param.eps();\n  if (this->blobs_.size() > 0) {\n    LOG(INFO) << \"Skipping parameter initialization\";\n  } else {\n    // 3\n    this->blobs_.resize(3);\n    vector<int> sz;\n    sz.push_back(channels_);\n    // mean var1Dchannels\n    // channel\n    // for c in range(channels):\n    //     x_hat[c] = (x[c] - mean[c]) / std[c]\n    this->blobs_[0].reset(new Blob<Dtype>(sz));\n    this->blobs_[1].reset(new Blob<Dtype>(sz));\n    // \n    sz[0] = 1;\n    this->blobs_[2].reset(new Blob<Dtype>(sz));\n    for (int i = 0; i < 3; ++i) {\n      caffe_set(this->blobs_[i]->count(), Dtype(0),\n                this->blobs_[i]->mutable_cpu_data());\n    }\n  }\n  // Mask statistics from optimization by setting local learning rates\n  // for mean, variance, and the bias correction to zero.\n  // mean  stdlearning rate\n  // 0\n  for (int i = 0; i < this->blobs_.size(); ++i) {\n    if (this->layer_param_.param_size() == i) {\n      ParamSpec* fixed_param_spec = this->layer_param_.add_param();\n      fixed_param_spec->set_lr_mult(0.f);\n    } else {\n      CHECK_EQ(this->layer_param_.param(i).lr_mult(), 0.f)\n          << \"Cannot configure batch normalization statistics as layer \"\n          << \"parameters.\";\n    }\n  }\n}\n```\n\nstream$\\alpha$\n$$S_t = \\alpha Y_t + (1-\\alpha) S_{t-1}$$\n\n\n$$S_t = \\frac{\\text{WeightedSum}_n}{\\text{WeightedCount}_n}$$\n\n$$\\text{WeightedSum}_n = Y_t + (1-\\alpha) \\text{WeightedSum}_{n-1}$$\n$$\\text{WeightedCount}_n = 1 + (1-\\alpha) \\text{WeightedCount}_{n-1}$$\n\nCaffeBN`blobs_[0]``blobs_[1]`$\\text{WeightedSum}\\_n$`blos_[2]`$\\text{WeightedCount}\\_n$meanvar\n```\nmu = blobs_[0] / blobs_[2]\nvar = blobs_[1] / blobs_[2]\n```\n\n### Forward\nForward CPUbatchmeanvar\n``` cpp\ntemplate <typename Dtype>\nvoid BatchNormLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,\n    const vector<Blob<Dtype>*>& top) {\n  const Dtype* bottom_data = bottom[0]->cpu_data();\n  Dtype* top_data = top[0]->mutable_cpu_data();\n  int num = bottom[0]->shape(0);\n  int spatial_dim = bottom[0]->count()/(bottom[0]->shape(0)*channels_);\n\n  // bottomtop\n  if (bottom[0] != top[0]) {\n    caffe_copy(bottom[0]->count(), bottom_data, top_data);\n  }\n\n  // meanvar\n  if (use_global_stats_) {\n    // use the stored mean/variance estimates.\n    const Dtype scale_factor = this->blobs_[2]->cpu_data()[0] == 0 ?\n        0 : 1 / this->blobs_[2]->cpu_data()[0];\n    // mean = blobs[0] / blobs[2]\n    caffe_cpu_scale(variance_.count(), scale_factor,\n        this->blobs_[0]->cpu_data(), mean_.mutable_cpu_data());\n    // var = blobs[1] / blobs[2]\n    caffe_cpu_scale(variance_.count(), scale_factor,\n        this->blobs_[1]->cpu_data(), variance_.mutable_cpu_data());\n  } else {\n    // batchmeanvar\n    // compute mean\n    // spatial_sum_multiplier_1\n    // batch_sum_multiplier_1\n    // gemv y = alpha*A*x + beta*y\n    // bottom_data1\n    // \n    // channels_ * num\n    // channelfeature map\n    // out[n][c]nsamplecchannel\n    //  1. / (num * spatial_dim) \n    caffe_cpu_gemv<Dtype>(CblasNoTrans, channels_ * num, spatial_dim,\n        1. / (num * spatial_dim), bottom_data,\n        spatial_sum_multiplier_.cpu_data(), 0.,\n        num_by_chans_.mutable_cpu_data());\n    // CblasTrans\n    // channel\n    //  num * spatial_dim \n    // batch\n    caffe_cpu_gemv<Dtype>(CblasTrans, num, channels_, 1.,\n        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), 0.,\n        mean_.mutable_cpu_data());\n  }\n\n  // subtract mean\n  // gemm C = alpha*A*B + beta*C\n  // broadcasting subtraction\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, num, channels_, 1, 1,\n      batch_sum_multiplier_.cpu_data(), mean_.cpu_data(), 0.,\n      num_by_chans_.mutable_cpu_data());\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels_ * num,\n      spatial_dim, 1, -1, num_by_chans_.cpu_data(),\n      spatial_sum_multiplier_.cpu_data(), 1., top_data);\n\n  // var\n  if (!use_global_stats_) {\n    // compute variance using var(X) = E((X-EX)^2)\n    caffe_sqr<Dtype>(top[0]->count(), top_data,\n                     temp_.mutable_cpu_data());  // (X-EX)^2\n    caffe_cpu_gemv<Dtype>(CblasNoTrans, channels_ * num, spatial_dim,\n        1. / (num * spatial_dim), temp_.cpu_data(),\n        spatial_sum_multiplier_.cpu_data(), 0.,\n        num_by_chans_.mutable_cpu_data());\n    caffe_cpu_gemv<Dtype>(CblasTrans, num, channels_, 1.,\n        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), 0.,\n        variance_.mutable_cpu_data());  // E((X_EX)^2)\n\n    // compute and save moving average\n    // \n    this->blobs_[2]->mutable_cpu_data()[0] *= moving_average_fraction_;\n    this->blobs_[2]->mutable_cpu_data()[0] += 1;\n    caffe_cpu_axpby(mean_.count(), Dtype(1), mean_.cpu_data(),\n        moving_average_fraction_, this->blobs_[0]->mutable_cpu_data());\n    int m = bottom[0]->count()/channels_;\n    Dtype bias_correction_factor = m > 1 ? Dtype(m)/(m-1) : 1;\n    caffe_cpu_axpby(variance_.count(), bias_correction_factor,\n        variance_.cpu_data(), moving_average_fraction_,\n        this->blobs_[1]->mutable_cpu_data());\n  }\n\n  // normalize variance\n  caffe_add_scalar(variance_.count(), eps_, variance_.mutable_cpu_data());\n  caffe_sqrt(variance_.count(), variance_.cpu_data(),\n             variance_.mutable_cpu_data());\n\n  // replicate variance to input size\n  // broadcasting\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, num, channels_, 1, 1,\n      batch_sum_multiplier_.cpu_data(), variance_.cpu_data(), 0.,\n      num_by_chans_.mutable_cpu_data());\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels_ * num,\n      spatial_dim, 1, 1., num_by_chans_.cpu_data(),\n      spatial_sum_multiplier_.cpu_data(), 0., temp_.mutable_cpu_data());\n  caffe_div(temp_.count(), top_data, temp_.cpu_data(), top_data);\n  // TODO(cdoersch): The caching is only needed because later in-place layers\n  //                 might clobber the data.  Can we skip this if they won't?\n  caffe_copy(x_norm_.count(), top_data,\n      x_norm_.mutable_cpu_data());\n}\n```\n`blobs_[2]`$m\\_t$$t$`blobs_[2]`$\\text{WeightedCount}\\_n$$\\alpha$`moving_average_fraction_`\n\n$$m_t = 1 + \\alpha m_{t-1}$$\n\n$m\\_t$$t=\\infty$$m\\_{\\infty}=\\frac{1}{1-\\alpha}$\n\n### Backward\nBP\n\n- `use_global_stats == true`BN\n$$BN(x) = \\frac{x-\\mu}{\\sqrt{Var}}$$\n\n$$\\frac{\\partial L}{\\partial x} = \\frac{1}{\\sqrt{Var}}\\frac{\\partial L}{\\partial y}$$\n\n`temp_`broadcasting`x``Forward`\n``` cpp\nif (use_global_stats_) {\n  caffe_div(temp_.count(), top_diff, temp_.cpu_data(), bottom_diff);\n  return;\n}\n```\n\n- `use_global_stats == false`BN$\\mu$$Var(x)$batch`x`[](https://kevinzakka.github.io/2016/09/14/batch_normalization/)\n![BP](/img/caffe_bn_bp_of_bn.jpg)\n\n$y$$\\hat{x_i}$$m$Caffe BNBP\n$$\\frac{\\partial f}{\\partial x_i} = \\frac{\\frac{\\partial f}{\\partial y}-E[\\frac{\\partial f}{\\partial y}]-yE[\\frac{\\partial f}{\\partial y}y]}{\\sqrt{\\sigma^2+\\epsilon}}$$\n``` cpp\n  // if Y = (X-mean(X))/(sqrt(var(X)+eps)), then\n  //\n  // dE(Y)/dX =\n  //   (dE/dY - mean(dE/dY) - mean(dE/dY \\cdot Y) \\cdot Y)\n  //     ./ sqrt(var(X) + eps)\n  //\n  // where \\cdot and ./ are hadamard product and elementwise division,\n  // respectively, dE/dY is the top diff, and mean/var/sum are all computed\n  // along all dimensions except the channels dimension.  In the above\n  // equation, the operations allow for expansion (i.e. broadcast) along all\n  // dimensions except the channels dimension where required.\n```\nbroadcastingCaffeBNBNScale\n\n## Scale\nCaffeScaleCaffeScale\n- blobblobblobbroadcasting\n- blobblob`gamma`\n- `bias_term: true`\n\nBN\n","source":"_posts/caffe-batch-norm.md","raw":"---\ntitle: CaffeBatchNorm\ndate: 2018-01-08 20:12:44\ntags:\n     - caffe\n---\nCaffeBN\n<!-- more -->\n\n## BN\n\nBNBN\n\nBNBatch NormalizationGoogle[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)BN\n\nBNblobchannelinference$x$$\\epsilon$$0$$i$channelindex\n$$\\hat{x_i} = \\frac{x_i-\\mu_i}{\\sqrt{Var(x_i)+\\epsilon}}$$\n\nIdentity Map($y = x$)$\\gamma$$\\beta$BN$y$\n$$y_i = \\gamma \\hat{x_i} + \\beta$$\n\nBN\n![BN](/img/caffe_bn_what_is_bn.jpg)\n\ninferenceBNBNCaffe\n\n## BN in Caffe\nBVLCCaffeBNScaleBNNormalizationScale\n\nHe KaimingResidual Net50[](https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-50-deploy.prototxt#L21)`batch_norm_param``use_global_stats``true`inferenceScale`bias_term: true`\n\n```\nlayer {\n\tbottom: \"conv1\"\n\ttop: \"conv1\"\n\tname: \"bn_conv1\"\n\ttype: \"BatchNorm\"\n\tbatch_norm_param {\n\t\tuse_global_stats: true\n\t}\n}\n\nlayer {\n\tbottom: \"conv1\"\n\ttop: \"conv1\"\n\tname: \"scale_conv1\"\n\ttype: \"Scale\"\n\tscale_param {\n\t\tbias_term: true\n\t}\n}\n```\nCaffeBN\n\n## BatchNorm \nCaffeBNScale\n### proto\n`caffe.proto`BN\n```\nmessage BatchNormParameter {\n  // If false, normalization is performed over the current mini-batch\n  // and global statistics are accumulated (but not yet used) by a moving\n  // average.\n  // If true, those accumulated mean and variance values are used for the\n  // normalization.\n  // By default, it is set to false when the network is in the training\n  // phase and true when the network is in the testing phase.\n  // Falsemini-batch\n  // batch\n  // True\n  // BNtraintest phase\n  // trainfalsetesttrue\n  optional bool use_global_stats = 1;\n  \n  // What fraction of the moving average remains each iteration?\n  // Smaller values make the moving average decay faster, giving more\n  // weight to the recent values.\n  // Each iteration updates the moving average @f$S_{t-1}@f$ with the\n  // current mean @f$ Y_t @f$ by\n  // @f$ S_t = (1-\\beta)Y_t + \\beta \\cdot S_{t-1} @f$, where @f$ \\beta @f$\n  // is the moving_average_fraction parameter.\n  // BN\n  // St = (1-beta)*Yt + beta*S_{t-1}\n  // StYtbatch\n  // beta\n  optional float moving_average_fraction = 2 [default = .999];\n  \n  // Small value to add to the variance estimate so that we don't divide by\n  // zero.\n  // 0eps\n  optional float eps = 3 [default = 1e-5];\n}\n```\n\nOKBN`use_global_stats`\n\n### SetUp\nBNSetUptraintestprototxt`use_global_stats`BN`use_global_stats`\n\nBNblobBN3blobwiki[moving average](https://wiki2.org/en/Moving_average)\n\n``` cpp\ntemplate <typename Dtype>\nvoid BatchNormLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,\n      const vector<Blob<Dtype>*>& top) {\n  BatchNormParameter param = this->layer_param_.batch_norm_param();\n  moving_average_fraction_ = param.moving_average_fraction();\n  // TESTmeanvar\n  use_global_stats_ = this->phase_ == TEST;\n  if (param.has_use_global_stats())\n    use_global_stats_ = param.use_global_stats();\n  // channels\n  // 1D\n  if (bottom[0]->num_axes() == 1)\n    channels_ = 1;\n  else\n    channels_ = bottom[0]->shape(1);\n  eps_ = param.eps();\n  if (this->blobs_.size() > 0) {\n    LOG(INFO) << \"Skipping parameter initialization\";\n  } else {\n    // 3\n    this->blobs_.resize(3);\n    vector<int> sz;\n    sz.push_back(channels_);\n    // mean var1Dchannels\n    // channel\n    // for c in range(channels):\n    //     x_hat[c] = (x[c] - mean[c]) / std[c]\n    this->blobs_[0].reset(new Blob<Dtype>(sz));\n    this->blobs_[1].reset(new Blob<Dtype>(sz));\n    // \n    sz[0] = 1;\n    this->blobs_[2].reset(new Blob<Dtype>(sz));\n    for (int i = 0; i < 3; ++i) {\n      caffe_set(this->blobs_[i]->count(), Dtype(0),\n                this->blobs_[i]->mutable_cpu_data());\n    }\n  }\n  // Mask statistics from optimization by setting local learning rates\n  // for mean, variance, and the bias correction to zero.\n  // mean  stdlearning rate\n  // 0\n  for (int i = 0; i < this->blobs_.size(); ++i) {\n    if (this->layer_param_.param_size() == i) {\n      ParamSpec* fixed_param_spec = this->layer_param_.add_param();\n      fixed_param_spec->set_lr_mult(0.f);\n    } else {\n      CHECK_EQ(this->layer_param_.param(i).lr_mult(), 0.f)\n          << \"Cannot configure batch normalization statistics as layer \"\n          << \"parameters.\";\n    }\n  }\n}\n```\n\nstream$\\alpha$\n$$S_t = \\alpha Y_t + (1-\\alpha) S_{t-1}$$\n\n\n$$S_t = \\frac{\\text{WeightedSum}_n}{\\text{WeightedCount}_n}$$\n\n$$\\text{WeightedSum}_n = Y_t + (1-\\alpha) \\text{WeightedSum}_{n-1}$$\n$$\\text{WeightedCount}_n = 1 + (1-\\alpha) \\text{WeightedCount}_{n-1}$$\n\nCaffeBN`blobs_[0]``blobs_[1]`$\\text{WeightedSum}\\_n$`blos_[2]`$\\text{WeightedCount}\\_n$meanvar\n```\nmu = blobs_[0] / blobs_[2]\nvar = blobs_[1] / blobs_[2]\n```\n\n### Forward\nForward CPUbatchmeanvar\n``` cpp\ntemplate <typename Dtype>\nvoid BatchNormLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,\n    const vector<Blob<Dtype>*>& top) {\n  const Dtype* bottom_data = bottom[0]->cpu_data();\n  Dtype* top_data = top[0]->mutable_cpu_data();\n  int num = bottom[0]->shape(0);\n  int spatial_dim = bottom[0]->count()/(bottom[0]->shape(0)*channels_);\n\n  // bottomtop\n  if (bottom[0] != top[0]) {\n    caffe_copy(bottom[0]->count(), bottom_data, top_data);\n  }\n\n  // meanvar\n  if (use_global_stats_) {\n    // use the stored mean/variance estimates.\n    const Dtype scale_factor = this->blobs_[2]->cpu_data()[0] == 0 ?\n        0 : 1 / this->blobs_[2]->cpu_data()[0];\n    // mean = blobs[0] / blobs[2]\n    caffe_cpu_scale(variance_.count(), scale_factor,\n        this->blobs_[0]->cpu_data(), mean_.mutable_cpu_data());\n    // var = blobs[1] / blobs[2]\n    caffe_cpu_scale(variance_.count(), scale_factor,\n        this->blobs_[1]->cpu_data(), variance_.mutable_cpu_data());\n  } else {\n    // batchmeanvar\n    // compute mean\n    // spatial_sum_multiplier_1\n    // batch_sum_multiplier_1\n    // gemv y = alpha*A*x + beta*y\n    // bottom_data1\n    // \n    // channels_ * num\n    // channelfeature map\n    // out[n][c]nsamplecchannel\n    //  1. / (num * spatial_dim) \n    caffe_cpu_gemv<Dtype>(CblasNoTrans, channels_ * num, spatial_dim,\n        1. / (num * spatial_dim), bottom_data,\n        spatial_sum_multiplier_.cpu_data(), 0.,\n        num_by_chans_.mutable_cpu_data());\n    // CblasTrans\n    // channel\n    //  num * spatial_dim \n    // batch\n    caffe_cpu_gemv<Dtype>(CblasTrans, num, channels_, 1.,\n        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), 0.,\n        mean_.mutable_cpu_data());\n  }\n\n  // subtract mean\n  // gemm C = alpha*A*B + beta*C\n  // broadcasting subtraction\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, num, channels_, 1, 1,\n      batch_sum_multiplier_.cpu_data(), mean_.cpu_data(), 0.,\n      num_by_chans_.mutable_cpu_data());\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels_ * num,\n      spatial_dim, 1, -1, num_by_chans_.cpu_data(),\n      spatial_sum_multiplier_.cpu_data(), 1., top_data);\n\n  // var\n  if (!use_global_stats_) {\n    // compute variance using var(X) = E((X-EX)^2)\n    caffe_sqr<Dtype>(top[0]->count(), top_data,\n                     temp_.mutable_cpu_data());  // (X-EX)^2\n    caffe_cpu_gemv<Dtype>(CblasNoTrans, channels_ * num, spatial_dim,\n        1. / (num * spatial_dim), temp_.cpu_data(),\n        spatial_sum_multiplier_.cpu_data(), 0.,\n        num_by_chans_.mutable_cpu_data());\n    caffe_cpu_gemv<Dtype>(CblasTrans, num, channels_, 1.,\n        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), 0.,\n        variance_.mutable_cpu_data());  // E((X_EX)^2)\n\n    // compute and save moving average\n    // \n    this->blobs_[2]->mutable_cpu_data()[0] *= moving_average_fraction_;\n    this->blobs_[2]->mutable_cpu_data()[0] += 1;\n    caffe_cpu_axpby(mean_.count(), Dtype(1), mean_.cpu_data(),\n        moving_average_fraction_, this->blobs_[0]->mutable_cpu_data());\n    int m = bottom[0]->count()/channels_;\n    Dtype bias_correction_factor = m > 1 ? Dtype(m)/(m-1) : 1;\n    caffe_cpu_axpby(variance_.count(), bias_correction_factor,\n        variance_.cpu_data(), moving_average_fraction_,\n        this->blobs_[1]->mutable_cpu_data());\n  }\n\n  // normalize variance\n  caffe_add_scalar(variance_.count(), eps_, variance_.mutable_cpu_data());\n  caffe_sqrt(variance_.count(), variance_.cpu_data(),\n             variance_.mutable_cpu_data());\n\n  // replicate variance to input size\n  // broadcasting\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, num, channels_, 1, 1,\n      batch_sum_multiplier_.cpu_data(), variance_.cpu_data(), 0.,\n      num_by_chans_.mutable_cpu_data());\n  caffe_cpu_gemm<Dtype>(CblasNoTrans, CblasNoTrans, channels_ * num,\n      spatial_dim, 1, 1., num_by_chans_.cpu_data(),\n      spatial_sum_multiplier_.cpu_data(), 0., temp_.mutable_cpu_data());\n  caffe_div(temp_.count(), top_data, temp_.cpu_data(), top_data);\n  // TODO(cdoersch): The caching is only needed because later in-place layers\n  //                 might clobber the data.  Can we skip this if they won't?\n  caffe_copy(x_norm_.count(), top_data,\n      x_norm_.mutable_cpu_data());\n}\n```\n`blobs_[2]`$m\\_t$$t$`blobs_[2]`$\\text{WeightedCount}\\_n$$\\alpha$`moving_average_fraction_`\n\n$$m_t = 1 + \\alpha m_{t-1}$$\n\n$m\\_t$$t=\\infty$$m\\_{\\infty}=\\frac{1}{1-\\alpha}$\n\n### Backward\nBP\n\n- `use_global_stats == true`BN\n$$BN(x) = \\frac{x-\\mu}{\\sqrt{Var}}$$\n\n$$\\frac{\\partial L}{\\partial x} = \\frac{1}{\\sqrt{Var}}\\frac{\\partial L}{\\partial y}$$\n\n`temp_`broadcasting`x``Forward`\n``` cpp\nif (use_global_stats_) {\n  caffe_div(temp_.count(), top_diff, temp_.cpu_data(), bottom_diff);\n  return;\n}\n```\n\n- `use_global_stats == false`BN$\\mu$$Var(x)$batch`x`[](https://kevinzakka.github.io/2016/09/14/batch_normalization/)\n![BP](/img/caffe_bn_bp_of_bn.jpg)\n\n$y$$\\hat{x_i}$$m$Caffe BNBP\n$$\\frac{\\partial f}{\\partial x_i} = \\frac{\\frac{\\partial f}{\\partial y}-E[\\frac{\\partial f}{\\partial y}]-yE[\\frac{\\partial f}{\\partial y}y]}{\\sqrt{\\sigma^2+\\epsilon}}$$\n``` cpp\n  // if Y = (X-mean(X))/(sqrt(var(X)+eps)), then\n  //\n  // dE(Y)/dX =\n  //   (dE/dY - mean(dE/dY) - mean(dE/dY \\cdot Y) \\cdot Y)\n  //     ./ sqrt(var(X) + eps)\n  //\n  // where \\cdot and ./ are hadamard product and elementwise division,\n  // respectively, dE/dY is the top diff, and mean/var/sum are all computed\n  // along all dimensions except the channels dimension.  In the above\n  // equation, the operations allow for expansion (i.e. broadcast) along all\n  // dimensions except the channels dimension where required.\n```\nbroadcastingCaffeBNBNScale\n\n## Scale\nCaffeScaleCaffeScale\n- blobblobblobbroadcasting\n- blobblob`gamma`\n- `bias_term: true`\n\nBN\n","slug":"caffe-batch-norm","published":1,"updated":"2018-10-27T07:16:52.377Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8hx0006ae7bxvgoysqy","content":"<p>CaffeBN<br><a id=\"more\"></a></p>\n<h2 id=\"BN\"><a href=\"#BN\" class=\"headerlink\" title=\"BN\"></a>BN</h2><p>BNBN</p>\n<p>BNBatch NormalizationGoogle<a href=\"https://arxiv.org/pdf/1502.03167.pdf\" target=\"_blank\" rel=\"external\">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>BN</p>\n<p>BNblobchannelinference$x$$\\epsilon$$0$$i$channelindex</p>\n<script type=\"math/tex; mode=display\">\\hat{x_i} = \\frac{x_i-\\mu_i}{\\sqrt{Var(x_i)+\\epsilon}}</script><p>Identity Map($y = x$)$\\gamma$$\\beta$BN$y$</p>\n<script type=\"math/tex; mode=display\">y_i = \\gamma \\hat{x_i} + \\beta</script><p>BN<br><img src=\"/img/caffe_bn_what_is_bn.jpg\" alt=\"BN\"></p>\n<p>inferenceBNBNCaffe</p>\n<h2 id=\"BN-in-Caffe\"><a href=\"#BN-in-Caffe\" class=\"headerlink\" title=\"BN in Caffe\"></a>BN in Caffe</h2><p>BVLCCaffeBNScaleBNNormalizationScale</p>\n<p>He KaimingResidual Net50<a href=\"https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-50-deploy.prototxt#L21\" target=\"_blank\" rel=\"external\"></a><code>batch_norm_param</code><code>use_global_stats</code><code>true</code>inferenceScale<code>bias_term: true</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">\tbottom: &quot;conv1&quot;</div><div class=\"line\">\ttop: &quot;conv1&quot;</div><div class=\"line\">\tname: &quot;bn_conv1&quot;</div><div class=\"line\">\ttype: &quot;BatchNorm&quot;</div><div class=\"line\">\tbatch_norm_param &#123;</div><div class=\"line\">\t\tuse_global_stats: true</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">layer &#123;</div><div class=\"line\">\tbottom: &quot;conv1&quot;</div><div class=\"line\">\ttop: &quot;conv1&quot;</div><div class=\"line\">\tname: &quot;scale_conv1&quot;</div><div class=\"line\">\ttype: &quot;Scale&quot;</div><div class=\"line\">\tscale_param &#123;</div><div class=\"line\">\t\tbias_term: true</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>CaffeBN</p>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p>CaffeBNScale</p>\n<h3 id=\"proto\"><a href=\"#proto\" class=\"headerlink\" title=\"proto\"></a>proto</h3><p><code>caffe.proto</code>BN<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">message BatchNormParameter &#123;</div><div class=\"line\">  // If false, normalization is performed over the current mini-batch</div><div class=\"line\">  // and global statistics are accumulated (but not yet used) by a moving</div><div class=\"line\">  // average.</div><div class=\"line\">  // If true, those accumulated mean and variance values are used for the</div><div class=\"line\">  // normalization.</div><div class=\"line\">  // By default, it is set to false when the network is in the training</div><div class=\"line\">  // phase and true when the network is in the testing phase.</div><div class=\"line\">  // Falsemini-batch</div><div class=\"line\">  // batch</div><div class=\"line\">  // True</div><div class=\"line\">  // BNtraintest phase</div><div class=\"line\">  // trainfalsetesttrue</div><div class=\"line\">  optional bool use_global_stats = 1;</div><div class=\"line\">  </div><div class=\"line\">  // What fraction of the moving average remains each iteration?</div><div class=\"line\">  // Smaller values make the moving average decay faster, giving more</div><div class=\"line\">  // weight to the recent values.</div><div class=\"line\">  // Each iteration updates the moving average @f$S_&#123;t-1&#125;@f$ with the</div><div class=\"line\">  // current mean @f$ Y_t @f$ by</div><div class=\"line\">  // @f$ S_t = (1-\\beta)Y_t + \\beta \\cdot S_&#123;t-1&#125; @f$, where @f$ \\beta @f$</div><div class=\"line\">  // is the moving_average_fraction parameter.</div><div class=\"line\">  // BN</div><div class=\"line\">  // St = (1-beta)*Yt + beta*S_&#123;t-1&#125;</div><div class=\"line\">  // StYtbatch</div><div class=\"line\">  // beta</div><div class=\"line\">  optional float moving_average_fraction = 2 [default = .999];</div><div class=\"line\">  </div><div class=\"line\">  // Small value to add to the variance estimate so that we don&apos;t divide by</div><div class=\"line\">  // zero.</div><div class=\"line\">  // 0eps</div><div class=\"line\">  optional float eps = 3 [default = 1e-5];</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>OKBN<code>use_global_stats</code></p>\n<h3 id=\"SetUp\"><a href=\"#SetUp\" class=\"headerlink\" title=\"SetUp\"></a>SetUp</h3><p>BNSetUptraintestprototxt<code>use_global_stats</code>BN<code>use_global_stats</code></p>\n<p>BNblobBN3blobwiki<a href=\"https://wiki2.org/en/Moving_average\" target=\"_blank\" rel=\"external\">moving average</a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> BatchNormLayer&lt;Dtype&gt;::LayerSetUp(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class=\"line\">      <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">  BatchNormParameter param = <span class=\"keyword\">this</span>-&gt;layer_param_.batch_norm_param();</div><div class=\"line\">  moving_average_fraction_ = param.moving_average_fraction();</div><div class=\"line\">  <span class=\"comment\">// TESTmeanvar</span></div><div class=\"line\">  use_global_stats_ = <span class=\"keyword\">this</span>-&gt;phase_ == TEST;</div><div class=\"line\">  <span class=\"keyword\">if</span> (param.has_use_global_stats())</div><div class=\"line\">    use_global_stats_ = param.use_global_stats();</div><div class=\"line\">  <span class=\"comment\">// channels</span></div><div class=\"line\">  <span class=\"comment\">// 1D</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (bottom[<span class=\"number\">0</span>]-&gt;num_axes() == <span class=\"number\">1</span>)</div><div class=\"line\">    channels_ = <span class=\"number\">1</span>;</div><div class=\"line\">  <span class=\"keyword\">else</span></div><div class=\"line\">    channels_ = bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">1</span>);</div><div class=\"line\">  eps_ = param.eps();</div><div class=\"line\">  <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>-&gt;blobs_.size() &gt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">    LOG(INFO) &lt;&lt; <span class=\"string\">\"Skipping parameter initialization\"</span>;</div><div class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">    <span class=\"comment\">// 3</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_.resize(<span class=\"number\">3</span>);</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sz;</div><div class=\"line\">    sz.push_back(channels_);</div><div class=\"line\">    <span class=\"comment\">// mean var1Dchannels</span></div><div class=\"line\">    <span class=\"comment\">// channel</span></div><div class=\"line\">    <span class=\"comment\">// for c in range(channels):</span></div><div class=\"line\">    <span class=\"comment\">//     x_hat[c] = (x[c] - mean[c]) / std[c]</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    sz[<span class=\"number\">0</span>] = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">3</span>; ++i) &#123;</div><div class=\"line\">      caffe_set(<span class=\"keyword\">this</span>-&gt;blobs_[i]-&gt;count(), Dtype(<span class=\"number\">0</span>),</div><div class=\"line\">                <span class=\"keyword\">this</span>-&gt;blobs_[i]-&gt;mutable_cpu_data());</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"comment\">// Mask statistics from optimization by setting local learning rates</span></div><div class=\"line\">  <span class=\"comment\">// for mean, variance, and the bias correction to zero.</span></div><div class=\"line\">  <span class=\"comment\">// mean  stdlearning rate</span></div><div class=\"line\">  <span class=\"comment\">// 0</span></div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>-&gt;blobs_.size(); ++i) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>-&gt;layer_param_.param_size() == i) &#123;</div><div class=\"line\">      ParamSpec* fixed_param_spec = <span class=\"keyword\">this</span>-&gt;layer_param_.add_param();</div><div class=\"line\">      fixed_param_spec-&gt;set_lr_mult(<span class=\"number\">0.f</span>);</div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">      CHECK_EQ(<span class=\"keyword\">this</span>-&gt;layer_param_.param(i).lr_mult(), <span class=\"number\">0.f</span>)</div><div class=\"line\">          &lt;&lt; <span class=\"string\">\"Cannot configure batch normalization statistics as layer \"</span></div><div class=\"line\">          &lt;&lt; <span class=\"string\">\"parameters.\"</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>stream$\\alpha$</p>\n<script type=\"math/tex; mode=display\">S_t = \\alpha Y_t + (1-\\alpha) S_{t-1}</script><p></p>\n<script type=\"math/tex; mode=display\">S_t = \\frac{\\text{WeightedSum}_n}{\\text{WeightedCount}_n}</script><p><script type=\"math/tex\">\\text{WeightedSum}_n = Y_t + (1-\\alpha) \\text{WeightedSum}_{n-1}</script></p>\n<script type=\"math/tex; mode=display\">\\text{WeightedCount}_n = 1 + (1-\\alpha) \\text{WeightedCount}_{n-1}</script><p>CaffeBN<code>blobs_[0]</code><code>blobs_[1]</code>$\\text{WeightedSum}_n$<code>blos_[2]</code>$\\text{WeightedCount}_n$meanvar<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">mu = blobs_[0] / blobs_[2]</div><div class=\"line\">var = blobs_[1] / blobs_[2]</div></pre></td></tr></table></figure></p>\n<h3 id=\"Forward\"><a href=\"#Forward\" class=\"headerlink\" title=\"Forward\"></a>Forward</h3><p>Forward CPUbatchmeanvar<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> BatchNormLayer&lt;Dtype&gt;::Forward_cpu(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> Dtype* bottom_data = bottom[<span class=\"number\">0</span>]-&gt;cpu_data();</div><div class=\"line\">  Dtype* top_data = top[<span class=\"number\">0</span>]-&gt;mutable_cpu_data();</div><div class=\"line\">  <span class=\"keyword\">int</span> num = bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">0</span>);</div><div class=\"line\">  <span class=\"keyword\">int</span> spatial_dim = bottom[<span class=\"number\">0</span>]-&gt;count()/(bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">0</span>)*channels_);</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// bottomtop</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (bottom[<span class=\"number\">0</span>] != top[<span class=\"number\">0</span>]) &#123;</div><div class=\"line\">    caffe_copy(bottom[<span class=\"number\">0</span>]-&gt;count(), bottom_data, top_data);</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// meanvar</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (use_global_stats_) &#123;</div><div class=\"line\">    <span class=\"comment\">// use the stored mean/variance estimates.</span></div><div class=\"line\">    <span class=\"keyword\">const</span> Dtype scale_factor = <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;cpu_data()[<span class=\"number\">0</span>] == <span class=\"number\">0</span> ?</div><div class=\"line\">        <span class=\"number\">0</span> : <span class=\"number\">1</span> / <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;cpu_data()[<span class=\"number\">0</span>];</div><div class=\"line\">    <span class=\"comment\">// mean = blobs[0] / blobs[2]</span></div><div class=\"line\">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>]-&gt;cpu_data(), mean_.mutable_cpu_data());</div><div class=\"line\">    <span class=\"comment\">// var = blobs[1] / blobs[2]</span></div><div class=\"line\">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>]-&gt;cpu_data(), variance_.mutable_cpu_data());</div><div class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">    <span class=\"comment\">// batchmeanvar</span></div><div class=\"line\">    <span class=\"comment\">// compute mean</span></div><div class=\"line\">    <span class=\"comment\">// spatial_sum_multiplier_1</span></div><div class=\"line\">    <span class=\"comment\">// batch_sum_multiplier_1</span></div><div class=\"line\">    <span class=\"comment\">// gemv y = alpha*A*x + beta*y</span></div><div class=\"line\">    <span class=\"comment\">// bottom_data1</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"comment\">// channels_ * num</span></div><div class=\"line\">    <span class=\"comment\">// channelfeature map</span></div><div class=\"line\">    <span class=\"comment\">// out[n][c]nsamplecchannel</span></div><div class=\"line\">    <span class=\"comment\">//  1. / (num * spatial_dim) </span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class=\"line\">        <span class=\"number\">1.</span> / (num * spatial_dim), bottom_data,</div><div class=\"line\">        spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        num_by_chans_.mutable_cpu_data());</div><div class=\"line\">    <span class=\"comment\">// CblasTrans</span></div><div class=\"line\">    <span class=\"comment\">// channel</span></div><div class=\"line\">    <span class=\"comment\">//  num * spatial_dim </span></div><div class=\"line\">    <span class=\"comment\">// batch</span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class=\"number\">1.</span>,</div><div class=\"line\">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        mean_.mutable_cpu_data());</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// subtract mean</span></div><div class=\"line\">  <span class=\"comment\">// gemm C = alpha*A*B + beta*C</span></div><div class=\"line\">  <span class=\"comment\">// broadcasting subtraction</span></div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class=\"number\">1</span>, <span class=\"number\">1</span>,</div><div class=\"line\">      batch_sum_multiplier_.cpu_data(), mean_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">      num_by_chans_.mutable_cpu_data());</div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class=\"line\">      spatial_dim, <span class=\"number\">1</span>, <span class=\"number\">-1</span>, num_by_chans_.cpu_data(),</div><div class=\"line\">      spatial_sum_multiplier_.cpu_data(), <span class=\"number\">1.</span>, top_data);</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// var</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (!use_global_stats_) &#123;</div><div class=\"line\">    <span class=\"comment\">// compute variance using var(X) = E((X-EX)^2)</span></div><div class=\"line\">    caffe_sqr&lt;Dtype&gt;(top[<span class=\"number\">0</span>]-&gt;count(), top_data,</div><div class=\"line\">                     temp_.mutable_cpu_data());  <span class=\"comment\">// (X-EX)^2</span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class=\"line\">        <span class=\"number\">1.</span> / (num * spatial_dim), temp_.cpu_data(),</div><div class=\"line\">        spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        num_by_chans_.mutable_cpu_data());</div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class=\"number\">1.</span>,</div><div class=\"line\">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        variance_.mutable_cpu_data());  <span class=\"comment\">// E((X_EX)^2)</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// compute and save moving average</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;mutable_cpu_data()[<span class=\"number\">0</span>] *= moving_average_fraction_;</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;mutable_cpu_data()[<span class=\"number\">0</span>] += <span class=\"number\">1</span>;</div><div class=\"line\">    caffe_cpu_axpby(mean_.count(), Dtype(<span class=\"number\">1</span>), mean_.cpu_data(),</div><div class=\"line\">        moving_average_fraction_, <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>]-&gt;mutable_cpu_data());</div><div class=\"line\">    <span class=\"keyword\">int</span> m = bottom[<span class=\"number\">0</span>]-&gt;count()/channels_;</div><div class=\"line\">    Dtype bias_correction_factor = m &gt; <span class=\"number\">1</span> ? Dtype(m)/(m<span class=\"number\">-1</span>) : <span class=\"number\">1</span>;</div><div class=\"line\">    caffe_cpu_axpby(variance_.count(), bias_correction_factor,</div><div class=\"line\">        variance_.cpu_data(), moving_average_fraction_,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>]-&gt;mutable_cpu_data());</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// normalize variance</span></div><div class=\"line\">  caffe_add_scalar(variance_.count(), eps_, variance_.mutable_cpu_data());</div><div class=\"line\">  caffe_sqrt(variance_.count(), variance_.cpu_data(),</div><div class=\"line\">             variance_.mutable_cpu_data());</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// replicate variance to input size</span></div><div class=\"line\">  <span class=\"comment\">// broadcasting</span></div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class=\"number\">1</span>, <span class=\"number\">1</span>,</div><div class=\"line\">      batch_sum_multiplier_.cpu_data(), variance_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">      num_by_chans_.mutable_cpu_data());</div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class=\"line\">      spatial_dim, <span class=\"number\">1</span>, <span class=\"number\">1.</span>, num_by_chans_.cpu_data(),</div><div class=\"line\">      spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>, temp_.mutable_cpu_data());</div><div class=\"line\">  caffe_div(temp_.count(), top_data, temp_.cpu_data(), top_data);</div><div class=\"line\">  <span class=\"comment\">// TODO(cdoersch): The caching is only needed because later in-place layers</span></div><div class=\"line\">  <span class=\"comment\">//                 might clobber the data.  Can we skip this if they won't?</span></div><div class=\"line\">  caffe_copy(x_norm_.count(), top_data,</div><div class=\"line\">      x_norm_.mutable_cpu_data());</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>blobs_[2]</code>$m_t$$t$<code>blobs_[2]</code>$\\text{WeightedCount}_n$$\\alpha$<code>moving_average_fraction_</code></p>\n<script type=\"math/tex; mode=display\">m_t = 1 + \\alpha m_{t-1}</script><p>$m_t$$t=\\infty$$m_{\\infty}=\\frac{1}{1-\\alpha}$</p>\n<h3 id=\"Backward\"><a href=\"#Backward\" class=\"headerlink\" title=\"Backward\"></a>Backward</h3><p>BP</p>\n<ul>\n<li><code>use_global_stats == true</code>BN<script type=\"math/tex; mode=display\">BN(x) = \\frac{x-\\mu}{\\sqrt{Var}}</script><script type=\"math/tex; mode=display\">\\frac{\\partial L}{\\partial x} = \\frac{1}{\\sqrt{Var}}\\frac{\\partial L}{\\partial y}</script></li>\n</ul>\n<p><code>temp_</code>broadcasting<code>x</code><code>Forward</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (use_global_stats_) &#123;</div><div class=\"line\">  caffe_div(temp_.count(), top_diff, temp_.cpu_data(), bottom_diff);</div><div class=\"line\">  <span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<ul>\n<li><code>use_global_stats == false</code>BN$\\mu$$Var(x)$batch<code>x</code><a href=\"https://kevinzakka.github.io/2016/09/14/batch_normalization/\" target=\"_blank\" rel=\"external\"></a><br><img src=\"/img/caffe_bn_bp_of_bn.jpg\" alt=\"BP\"></li>\n</ul>\n<p>$y$$\\hat{x_i}$$m$Caffe BNBP</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial f}{\\partial x_i} = \\frac{\\frac{\\partial f}{\\partial y}-E[\\frac{\\partial f}{\\partial y}]-yE[\\frac{\\partial f}{\\partial y}y]}{\\sqrt{\\sigma^2+\\epsilon}}</script><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// if Y = (X-mean(X))/(sqrt(var(X)+eps)), then</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// dE(Y)/dX =</span></div><div class=\"line\"><span class=\"comment\">//   (dE/dY - mean(dE/dY) - mean(dE/dY \\cdot Y) \\cdot Y)</span></div><div class=\"line\"><span class=\"comment\">//     ./ sqrt(var(X) + eps)</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// where \\cdot and ./ are hadamard product and elementwise division,</span></div><div class=\"line\"><span class=\"comment\">// respectively, dE/dY is the top diff, and mean/var/sum are all computed</span></div><div class=\"line\"><span class=\"comment\">// along all dimensions except the channels dimension.  In the above</span></div><div class=\"line\"><span class=\"comment\">// equation, the operations allow for expansion (i.e. broadcast) along all</span></div><div class=\"line\"><span class=\"comment\">// dimensions except the channels dimension where required.</span></div></pre></td></tr></table></figure>\n<p>broadcastingCaffeBNBNScale</p>\n<h2 id=\"Scale\"><a href=\"#Scale\" class=\"headerlink\" title=\"Scale\"></a>Scale</h2><p>CaffeScaleCaffeScale</p>\n<ul>\n<li>blobblobblobbroadcasting</li>\n<li>blobblob<code>gamma</code></li>\n<li><code>bias_term: true</code></li>\n</ul>\n<p>BN</p>\n","excerpt":"<p>CaffeBN<br>","more":"</p>\n<h2 id=\"BN\"><a href=\"#BN\" class=\"headerlink\" title=\"BN\"></a>BN</h2><p>BNBN</p>\n<p>BNBatch NormalizationGoogle<a href=\"https://arxiv.org/pdf/1502.03167.pdf\">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>BN</p>\n<p>BNblobchannelinference$x$$\\epsilon$$0$$i$channelindex</p>\n<script type=\"math/tex; mode=display\">\\hat{x_i} = \\frac{x_i-\\mu_i}{\\sqrt{Var(x_i)+\\epsilon}}</script><p>Identity Map($y = x$)$\\gamma$$\\beta$BN$y$</p>\n<script type=\"math/tex; mode=display\">y_i = \\gamma \\hat{x_i} + \\beta</script><p>BN<br><img src=\"/img/caffe_bn_what_is_bn.jpg\" alt=\"BN\"></p>\n<p>inferenceBNBNCaffe</p>\n<h2 id=\"BN-in-Caffe\"><a href=\"#BN-in-Caffe\" class=\"headerlink\" title=\"BN in Caffe\"></a>BN in Caffe</h2><p>BVLCCaffeBNScaleBNNormalizationScale</p>\n<p>He KaimingResidual Net50<a href=\"https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-50-deploy.prototxt#L21\"></a><code>batch_norm_param</code><code>use_global_stats</code><code>true</code>inferenceScale<code>bias_term: true</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">\tbottom: &quot;conv1&quot;</div><div class=\"line\">\ttop: &quot;conv1&quot;</div><div class=\"line\">\tname: &quot;bn_conv1&quot;</div><div class=\"line\">\ttype: &quot;BatchNorm&quot;</div><div class=\"line\">\tbatch_norm_param &#123;</div><div class=\"line\">\t\tuse_global_stats: true</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">layer &#123;</div><div class=\"line\">\tbottom: &quot;conv1&quot;</div><div class=\"line\">\ttop: &quot;conv1&quot;</div><div class=\"line\">\tname: &quot;scale_conv1&quot;</div><div class=\"line\">\ttype: &quot;Scale&quot;</div><div class=\"line\">\tscale_param &#123;</div><div class=\"line\">\t\tbias_term: true</div><div class=\"line\">\t&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>CaffeBN</p>\n<h2 id=\"BatchNorm-\"><a href=\"#BatchNorm-\" class=\"headerlink\" title=\"BatchNorm \"></a>BatchNorm </h2><p>CaffeBNScale</p>\n<h3 id=\"proto\"><a href=\"#proto\" class=\"headerlink\" title=\"proto\"></a>proto</h3><p><code>caffe.proto</code>BN<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\">message BatchNormParameter &#123;</div><div class=\"line\">  // If false, normalization is performed over the current mini-batch</div><div class=\"line\">  // and global statistics are accumulated (but not yet used) by a moving</div><div class=\"line\">  // average.</div><div class=\"line\">  // If true, those accumulated mean and variance values are used for the</div><div class=\"line\">  // normalization.</div><div class=\"line\">  // By default, it is set to false when the network is in the training</div><div class=\"line\">  // phase and true when the network is in the testing phase.</div><div class=\"line\">  // Falsemini-batch</div><div class=\"line\">  // batch</div><div class=\"line\">  // True</div><div class=\"line\">  // BNtraintest phase</div><div class=\"line\">  // trainfalsetesttrue</div><div class=\"line\">  optional bool use_global_stats = 1;</div><div class=\"line\">  </div><div class=\"line\">  // What fraction of the moving average remains each iteration?</div><div class=\"line\">  // Smaller values make the moving average decay faster, giving more</div><div class=\"line\">  // weight to the recent values.</div><div class=\"line\">  // Each iteration updates the moving average @f$S_&#123;t-1&#125;@f$ with the</div><div class=\"line\">  // current mean @f$ Y_t @f$ by</div><div class=\"line\">  // @f$ S_t = (1-\\beta)Y_t + \\beta \\cdot S_&#123;t-1&#125; @f$, where @f$ \\beta @f$</div><div class=\"line\">  // is the moving_average_fraction parameter.</div><div class=\"line\">  // BN</div><div class=\"line\">  // St = (1-beta)*Yt + beta*S_&#123;t-1&#125;</div><div class=\"line\">  // StYtbatch</div><div class=\"line\">  // beta</div><div class=\"line\">  optional float moving_average_fraction = 2 [default = .999];</div><div class=\"line\">  </div><div class=\"line\">  // Small value to add to the variance estimate so that we don&apos;t divide by</div><div class=\"line\">  // zero.</div><div class=\"line\">  // 0eps</div><div class=\"line\">  optional float eps = 3 [default = 1e-5];</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>OKBN<code>use_global_stats</code></p>\n<h3 id=\"SetUp\"><a href=\"#SetUp\" class=\"headerlink\" title=\"SetUp\"></a>SetUp</h3><p>BNSetUptraintestprototxt<code>use_global_stats</code>BN<code>use_global_stats</code></p>\n<p>BNblobBN3blobwiki<a href=\"https://wiki2.org/en/Moving_average\">moving average</a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> BatchNormLayer&lt;Dtype&gt;::LayerSetUp(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class=\"line\">      <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">  BatchNormParameter param = <span class=\"keyword\">this</span>-&gt;layer_param_.batch_norm_param();</div><div class=\"line\">  moving_average_fraction_ = param.moving_average_fraction();</div><div class=\"line\">  <span class=\"comment\">// TESTmeanvar</span></div><div class=\"line\">  use_global_stats_ = <span class=\"keyword\">this</span>-&gt;phase_ == TEST;</div><div class=\"line\">  <span class=\"keyword\">if</span> (param.has_use_global_stats())</div><div class=\"line\">    use_global_stats_ = param.use_global_stats();</div><div class=\"line\">  <span class=\"comment\">// channels</span></div><div class=\"line\">  <span class=\"comment\">// 1D</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (bottom[<span class=\"number\">0</span>]-&gt;num_axes() == <span class=\"number\">1</span>)</div><div class=\"line\">    channels_ = <span class=\"number\">1</span>;</div><div class=\"line\">  <span class=\"keyword\">else</span></div><div class=\"line\">    channels_ = bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">1</span>);</div><div class=\"line\">  eps_ = param.eps();</div><div class=\"line\">  <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>-&gt;blobs_.size() &gt; <span class=\"number\">0</span>) &#123;</div><div class=\"line\">    LOG(INFO) &lt;&lt; <span class=\"string\">\"Skipping parameter initialization\"</span>;</div><div class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">    <span class=\"comment\">// 3</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_.resize(<span class=\"number\">3</span>);</div><div class=\"line\">    <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; sz;</div><div class=\"line\">    sz.push_back(channels_);</div><div class=\"line\">    <span class=\"comment\">// mean var1Dchannels</span></div><div class=\"line\">    <span class=\"comment\">// channel</span></div><div class=\"line\">    <span class=\"comment\">// for c in range(channels):</span></div><div class=\"line\">    <span class=\"comment\">//     x_hat[c] = (x[c] - mean[c]) / std[c]</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    sz[<span class=\"number\">0</span>] = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>].reset(<span class=\"keyword\">new</span> Blob&lt;Dtype&gt;(sz));</div><div class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">3</span>; ++i) &#123;</div><div class=\"line\">      caffe_set(<span class=\"keyword\">this</span>-&gt;blobs_[i]-&gt;count(), Dtype(<span class=\"number\">0</span>),</div><div class=\"line\">                <span class=\"keyword\">this</span>-&gt;blobs_[i]-&gt;mutable_cpu_data());</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"comment\">// Mask statistics from optimization by setting local learning rates</span></div><div class=\"line\">  <span class=\"comment\">// for mean, variance, and the bias correction to zero.</span></div><div class=\"line\">  <span class=\"comment\">// mean  stdlearning rate</span></div><div class=\"line\">  <span class=\"comment\">// 0</span></div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"keyword\">this</span>-&gt;blobs_.size(); ++i) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>-&gt;layer_param_.param_size() == i) &#123;</div><div class=\"line\">      ParamSpec* fixed_param_spec = <span class=\"keyword\">this</span>-&gt;layer_param_.add_param();</div><div class=\"line\">      fixed_param_spec-&gt;set_lr_mult(<span class=\"number\">0.f</span>);</div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">      CHECK_EQ(<span class=\"keyword\">this</span>-&gt;layer_param_.param(i).lr_mult(), <span class=\"number\">0.f</span>)</div><div class=\"line\">          &lt;&lt; <span class=\"string\">\"Cannot configure batch normalization statistics as layer \"</span></div><div class=\"line\">          &lt;&lt; <span class=\"string\">\"parameters.\"</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>stream$\\alpha$</p>\n<script type=\"math/tex; mode=display\">S_t = \\alpha Y_t + (1-\\alpha) S_{t-1}</script><p></p>\n<script type=\"math/tex; mode=display\">S_t = \\frac{\\text{WeightedSum}_n}{\\text{WeightedCount}_n}</script><p><script type=\"math/tex\">\\text{WeightedSum}_n = Y_t + (1-\\alpha) \\text{WeightedSum}_{n-1}</script></p>\n<script type=\"math/tex; mode=display\">\\text{WeightedCount}_n = 1 + (1-\\alpha) \\text{WeightedCount}_{n-1}</script><p>CaffeBN<code>blobs_[0]</code><code>blobs_[1]</code>$\\text{WeightedSum}_n$<code>blos_[2]</code>$\\text{WeightedCount}_n$meanvar<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">mu = blobs_[0] / blobs_[2]</div><div class=\"line\">var = blobs_[1] / blobs_[2]</div></pre></td></tr></table></figure></p>\n<h3 id=\"Forward\"><a href=\"#Forward\" class=\"headerlink\" title=\"Forward\"></a>Forward</h3><p>Forward CPUbatchmeanvar<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> BatchNormLayer&lt;Dtype&gt;::Forward_cpu(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> Dtype* bottom_data = bottom[<span class=\"number\">0</span>]-&gt;cpu_data();</div><div class=\"line\">  Dtype* top_data = top[<span class=\"number\">0</span>]-&gt;mutable_cpu_data();</div><div class=\"line\">  <span class=\"keyword\">int</span> num = bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">0</span>);</div><div class=\"line\">  <span class=\"keyword\">int</span> spatial_dim = bottom[<span class=\"number\">0</span>]-&gt;count()/(bottom[<span class=\"number\">0</span>]-&gt;shape(<span class=\"number\">0</span>)*channels_);</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// bottomtop</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (bottom[<span class=\"number\">0</span>] != top[<span class=\"number\">0</span>]) &#123;</div><div class=\"line\">    caffe_copy(bottom[<span class=\"number\">0</span>]-&gt;count(), bottom_data, top_data);</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// meanvar</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (use_global_stats_) &#123;</div><div class=\"line\">    <span class=\"comment\">// use the stored mean/variance estimates.</span></div><div class=\"line\">    <span class=\"keyword\">const</span> Dtype scale_factor = <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;cpu_data()[<span class=\"number\">0</span>] == <span class=\"number\">0</span> ?</div><div class=\"line\">        <span class=\"number\">0</span> : <span class=\"number\">1</span> / <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;cpu_data()[<span class=\"number\">0</span>];</div><div class=\"line\">    <span class=\"comment\">// mean = blobs[0] / blobs[2]</span></div><div class=\"line\">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>]-&gt;cpu_data(), mean_.mutable_cpu_data());</div><div class=\"line\">    <span class=\"comment\">// var = blobs[1] / blobs[2]</span></div><div class=\"line\">    caffe_cpu_scale(variance_.count(), scale_factor,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>]-&gt;cpu_data(), variance_.mutable_cpu_data());</div><div class=\"line\">  &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">    <span class=\"comment\">// batchmeanvar</span></div><div class=\"line\">    <span class=\"comment\">// compute mean</span></div><div class=\"line\">    <span class=\"comment\">// spatial_sum_multiplier_1</span></div><div class=\"line\">    <span class=\"comment\">// batch_sum_multiplier_1</span></div><div class=\"line\">    <span class=\"comment\">// gemv y = alpha*A*x + beta*y</span></div><div class=\"line\">    <span class=\"comment\">// bottom_data1</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"comment\">// channels_ * num</span></div><div class=\"line\">    <span class=\"comment\">// channelfeature map</span></div><div class=\"line\">    <span class=\"comment\">// out[n][c]nsamplecchannel</span></div><div class=\"line\">    <span class=\"comment\">//  1. / (num * spatial_dim) </span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class=\"line\">        <span class=\"number\">1.</span> / (num * spatial_dim), bottom_data,</div><div class=\"line\">        spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        num_by_chans_.mutable_cpu_data());</div><div class=\"line\">    <span class=\"comment\">// CblasTrans</span></div><div class=\"line\">    <span class=\"comment\">// channel</span></div><div class=\"line\">    <span class=\"comment\">//  num * spatial_dim </span></div><div class=\"line\">    <span class=\"comment\">// batch</span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class=\"number\">1.</span>,</div><div class=\"line\">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        mean_.mutable_cpu_data());</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// subtract mean</span></div><div class=\"line\">  <span class=\"comment\">// gemm C = alpha*A*B + beta*C</span></div><div class=\"line\">  <span class=\"comment\">// broadcasting subtraction</span></div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class=\"number\">1</span>, <span class=\"number\">1</span>,</div><div class=\"line\">      batch_sum_multiplier_.cpu_data(), mean_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">      num_by_chans_.mutable_cpu_data());</div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class=\"line\">      spatial_dim, <span class=\"number\">1</span>, <span class=\"number\">-1</span>, num_by_chans_.cpu_data(),</div><div class=\"line\">      spatial_sum_multiplier_.cpu_data(), <span class=\"number\">1.</span>, top_data);</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// var</span></div><div class=\"line\">  <span class=\"keyword\">if</span> (!use_global_stats_) &#123;</div><div class=\"line\">    <span class=\"comment\">// compute variance using var(X) = E((X-EX)^2)</span></div><div class=\"line\">    caffe_sqr&lt;Dtype&gt;(top[<span class=\"number\">0</span>]-&gt;count(), top_data,</div><div class=\"line\">                     temp_.mutable_cpu_data());  <span class=\"comment\">// (X-EX)^2</span></div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, channels_ * num, spatial_dim,</div><div class=\"line\">        <span class=\"number\">1.</span> / (num * spatial_dim), temp_.cpu_data(),</div><div class=\"line\">        spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        num_by_chans_.mutable_cpu_data());</div><div class=\"line\">    caffe_cpu_gemv&lt;Dtype&gt;(CblasTrans, num, channels_, <span class=\"number\">1.</span>,</div><div class=\"line\">        num_by_chans_.cpu_data(), batch_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">        variance_.mutable_cpu_data());  <span class=\"comment\">// E((X_EX)^2)</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// compute and save moving average</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;mutable_cpu_data()[<span class=\"number\">0</span>] *= moving_average_fraction_;</div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">2</span>]-&gt;mutable_cpu_data()[<span class=\"number\">0</span>] += <span class=\"number\">1</span>;</div><div class=\"line\">    caffe_cpu_axpby(mean_.count(), Dtype(<span class=\"number\">1</span>), mean_.cpu_data(),</div><div class=\"line\">        moving_average_fraction_, <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">0</span>]-&gt;mutable_cpu_data());</div><div class=\"line\">    <span class=\"keyword\">int</span> m = bottom[<span class=\"number\">0</span>]-&gt;count()/channels_;</div><div class=\"line\">    Dtype bias_correction_factor = m &gt; <span class=\"number\">1</span> ? Dtype(m)/(m<span class=\"number\">-1</span>) : <span class=\"number\">1</span>;</div><div class=\"line\">    caffe_cpu_axpby(variance_.count(), bias_correction_factor,</div><div class=\"line\">        variance_.cpu_data(), moving_average_fraction_,</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;blobs_[<span class=\"number\">1</span>]-&gt;mutable_cpu_data());</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// normalize variance</span></div><div class=\"line\">  caffe_add_scalar(variance_.count(), eps_, variance_.mutable_cpu_data());</div><div class=\"line\">  caffe_sqrt(variance_.count(), variance_.cpu_data(),</div><div class=\"line\">             variance_.mutable_cpu_data());</div><div class=\"line\"></div><div class=\"line\">  <span class=\"comment\">// replicate variance to input size</span></div><div class=\"line\">  <span class=\"comment\">// broadcasting</span></div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num, channels_, <span class=\"number\">1</span>, <span class=\"number\">1</span>,</div><div class=\"line\">      batch_sum_multiplier_.cpu_data(), variance_.cpu_data(), <span class=\"number\">0.</span>,</div><div class=\"line\">      num_by_chans_.mutable_cpu_data());</div><div class=\"line\">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, channels_ * num,</div><div class=\"line\">      spatial_dim, <span class=\"number\">1</span>, <span class=\"number\">1.</span>, num_by_chans_.cpu_data(),</div><div class=\"line\">      spatial_sum_multiplier_.cpu_data(), <span class=\"number\">0.</span>, temp_.mutable_cpu_data());</div><div class=\"line\">  caffe_div(temp_.count(), top_data, temp_.cpu_data(), top_data);</div><div class=\"line\">  <span class=\"comment\">// TODO(cdoersch): The caching is only needed because later in-place layers</span></div><div class=\"line\">  <span class=\"comment\">//                 might clobber the data.  Can we skip this if they won't?</span></div><div class=\"line\">  caffe_copy(x_norm_.count(), top_data,</div><div class=\"line\">      x_norm_.mutable_cpu_data());</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>blobs_[2]</code>$m_t$$t$<code>blobs_[2]</code>$\\text{WeightedCount}_n$$\\alpha$<code>moving_average_fraction_</code></p>\n<script type=\"math/tex; mode=display\">m_t = 1 + \\alpha m_{t-1}</script><p>$m_t$$t=\\infty$$m_{\\infty}=\\frac{1}{1-\\alpha}$</p>\n<h3 id=\"Backward\"><a href=\"#Backward\" class=\"headerlink\" title=\"Backward\"></a>Backward</h3><p>BP</p>\n<ul>\n<li><code>use_global_stats == true</code>BN<script type=\"math/tex; mode=display\">BN(x) = \\frac{x-\\mu}{\\sqrt{Var}}</script><script type=\"math/tex; mode=display\">\\frac{\\partial L}{\\partial x} = \\frac{1}{\\sqrt{Var}}\\frac{\\partial L}{\\partial y}</script></li>\n</ul>\n<p><code>temp_</code>broadcasting<code>x</code><code>Forward</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (use_global_stats_) &#123;</div><div class=\"line\">  caffe_div(temp_.count(), top_diff, temp_.cpu_data(), bottom_diff);</div><div class=\"line\">  <span class=\"keyword\">return</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<ul>\n<li><code>use_global_stats == false</code>BN$\\mu$$Var(x)$batch<code>x</code><a href=\"https://kevinzakka.github.io/2016/09/14/batch_normalization/\"></a><br><img src=\"/img/caffe_bn_bp_of_bn.jpg\" alt=\"BP\"></li>\n</ul>\n<p>$y$$\\hat{x_i}$$m$Caffe BNBP</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial f}{\\partial x_i} = \\frac{\\frac{\\partial f}{\\partial y}-E[\\frac{\\partial f}{\\partial y}]-yE[\\frac{\\partial f}{\\partial y}y]}{\\sqrt{\\sigma^2+\\epsilon}}</script><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// if Y = (X-mean(X))/(sqrt(var(X)+eps)), then</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// dE(Y)/dX =</span></div><div class=\"line\"><span class=\"comment\">//   (dE/dY - mean(dE/dY) - mean(dE/dY \\cdot Y) \\cdot Y)</span></div><div class=\"line\"><span class=\"comment\">//     ./ sqrt(var(X) + eps)</span></div><div class=\"line\"><span class=\"comment\">//</span></div><div class=\"line\"><span class=\"comment\">// where \\cdot and ./ are hadamard product and elementwise division,</span></div><div class=\"line\"><span class=\"comment\">// respectively, dE/dY is the top diff, and mean/var/sum are all computed</span></div><div class=\"line\"><span class=\"comment\">// along all dimensions except the channels dimension.  In the above</span></div><div class=\"line\"><span class=\"comment\">// equation, the operations allow for expansion (i.e. broadcast) along all</span></div><div class=\"line\"><span class=\"comment\">// dimensions except the channels dimension where required.</span></div></pre></td></tr></table></figure>\n<p>broadcastingCaffeBNBNScale</p>\n<h2 id=\"Scale\"><a href=\"#Scale\" class=\"headerlink\" title=\"Scale\"></a>Scale</h2><p>CaffeScaleCaffeScale</p>\n<ul>\n<li>blobblobblobbroadcasting</li>\n<li>blobblob<code>gamma</code></li>\n<li><code>bias_term: true</code></li>\n</ul>\n<p>BN</p>"},{"title":"Hack PyCaffe","date":"2018-03-16T11:01:32.000Z","_content":"[Github: PyCaffe Tutorial](https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb)Hack PycaffeboostC++PythonPycaffePycaffe\n![Python&&CPP binding](/img/caffe-hack-pycaffe-python-cpp-binding.jpg)\n<!-- more -->\n\n## PyCaffe\nCaffe`python`PyCaffe`src``include`CaffeC++`python`PyCaffe`_caffe.cpp`python`_caffe.cpp`boostC++pythonpythonAPI\n![](/img/hack-pycaffe-code-organization.png)\n\n## Python\nC++PyCaffepython\n\n### PyCaffe\nPyCaffe`PyTorch``Transformer`APIPyCaffe`numpy``opencv`Caffe`python/caffe/__init__.py`import`caffe.io``python/caffe/io.py`\n\n### Caffe\nCaffe`pycaffe.py``Net`python`Net``<class>.<function> = my_function``_Net_forward``self`\n\n``` py\ndef _Net_forward(self, blobs=None, start=None, end=None, **kwargs):\n    # do something\nNet.forward = _Net_forward\n```\n\n`@property``self`\n\n``` py\n# This function will be called when accessing net.blobs\n@property\ndef _Net_blobs(self):\n    \"\"\"\n    An OrderedDict (bottom to top, i.e., input to output) of network\n    blobs indexed by name\n    \"\"\"\n    if not hasattr(self, '_blobs_dict'):\n        self._blobs_dict = OrderedDict(zip(self._blob_names, self._blobs))\n    return self._blobs_dict \n\n# Set the field `blobs` to call _Net_blobs\nNet.blobs = _Net_blobs\n```\n\nPyCaffe`Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver`\n\n## C++\nC++\n- \n- \n\n`python/caffe/_caffe.cpp`boostpythonC++\n\n`Blob`python`Blob``num`C++`Blob<Dtype>::num()`\n``` cpp\n.add_property(\"num\", &Blob<Dtype>::num)\n```\n\n`.def`python`Net_Save`python`Net``save`python`net.save(filename)`\n\n`_caffe,cpp``make pycaffe`\n\n``` cpp\n# Declare the function\nvoid Net_Save(const Net<Dtype>& net, string filename) {\n    // ...\n}\n\n// ...\n\nbp::class_<Net<Dtype>>(\"Net\", bp::no_init)\n# Now we can call net.save(file)\n.def(\"save\", &Net_Save)\n```\n\nboostpython[boost: python binding](http://www.boost.org/doc/libs/1_58_0/libs/python/doc/tutorial/doc/html/index.html)","source":"_posts/caffe-hack-python-interface.md","raw":"---\ntitle: Hack PyCaffe\ndate: 2018-03-16 19:01:32\ntags:\n    - caffe\n    - python\n---\n[Github: PyCaffe Tutorial](https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb)Hack PycaffeboostC++PythonPycaffePycaffe\n![Python&&CPP binding](/img/caffe-hack-pycaffe-python-cpp-binding.jpg)\n<!-- more -->\n\n## PyCaffe\nCaffe`python`PyCaffe`src``include`CaffeC++`python`PyCaffe`_caffe.cpp`python`_caffe.cpp`boostC++pythonpythonAPI\n![](/img/hack-pycaffe-code-organization.png)\n\n## Python\nC++PyCaffepython\n\n### PyCaffe\nPyCaffe`PyTorch``Transformer`APIPyCaffe`numpy``opencv`Caffe`python/caffe/__init__.py`import`caffe.io``python/caffe/io.py`\n\n### Caffe\nCaffe`pycaffe.py``Net`python`Net``<class>.<function> = my_function``_Net_forward``self`\n\n``` py\ndef _Net_forward(self, blobs=None, start=None, end=None, **kwargs):\n    # do something\nNet.forward = _Net_forward\n```\n\n`@property``self`\n\n``` py\n# This function will be called when accessing net.blobs\n@property\ndef _Net_blobs(self):\n    \"\"\"\n    An OrderedDict (bottom to top, i.e., input to output) of network\n    blobs indexed by name\n    \"\"\"\n    if not hasattr(self, '_blobs_dict'):\n        self._blobs_dict = OrderedDict(zip(self._blob_names, self._blobs))\n    return self._blobs_dict \n\n# Set the field `blobs` to call _Net_blobs\nNet.blobs = _Net_blobs\n```\n\nPyCaffe`Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver`\n\n## C++\nC++\n- \n- \n\n`python/caffe/_caffe.cpp`boostpythonC++\n\n`Blob`python`Blob``num`C++`Blob<Dtype>::num()`\n``` cpp\n.add_property(\"num\", &Blob<Dtype>::num)\n```\n\n`.def`python`Net_Save`python`Net``save`python`net.save(filename)`\n\n`_caffe,cpp``make pycaffe`\n\n``` cpp\n# Declare the function\nvoid Net_Save(const Net<Dtype>& net, string filename) {\n    // ...\n}\n\n// ...\n\nbp::class_<Net<Dtype>>(\"Net\", bp::no_init)\n# Now we can call net.save(file)\n.def(\"save\", &Net_Save)\n```\n\nboostpython[boost: python binding](http://www.boost.org/doc/libs/1_58_0/libs/python/doc/tutorial/doc/html/index.html)","slug":"caffe-hack-python-interface","published":1,"updated":"2018-10-27T07:16:52.378Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8i10007ae7bh0302s8i","content":"<p><a href=\"https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb\" target=\"_blank\" rel=\"external\">Github: PyCaffe Tutorial</a>Hack PycaffeboostC++PythonPycaffePycaffe<br><img src=\"/img/caffe-hack-pycaffe-python-cpp-binding.jpg\" alt=\"Python&amp;&amp;CPP binding\"><br><a id=\"more\"></a></p>\n<h2 id=\"PyCaffe\"><a href=\"#PyCaffe\" class=\"headerlink\" title=\"PyCaffe\"></a>PyCaffe</h2><p>Caffe<code>python</code>PyCaffe<code>src</code><code>include</code>CaffeC++<code>python</code>PyCaffe<code>_caffe.cpp</code>python<code>_caffe.cpp</code>boostC++pythonpythonAPI<br><img src=\"/img/hack-pycaffe-code-organization.png\" alt=\"\"></p>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><p>C++PyCaffepython</p>\n<h3 id=\"PyCaffe\"><a href=\"#PyCaffe\" class=\"headerlink\" title=\"PyCaffe\"></a>PyCaffe</h3><p>PyCaffe<code>PyTorch</code><code>Transformer</code>APIPyCaffe<code>numpy</code><code>opencv</code>Caffe<code>python/caffe/__init__.py</code>import<code>caffe.io</code><code>python/caffe/io.py</code></p>\n<h3 id=\"Caffe\"><a href=\"#Caffe\" class=\"headerlink\" title=\"Caffe\"></a>Caffe</h3><p>Caffe<code>pycaffe.py</code><code>Net</code>python<code>Net</code><code>&lt;class&gt;.&lt;function&gt; = my_function</code><code>_Net_forward</code><code>self</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_Net_forward</span><span class=\"params\">(self, blobs=None, start=None, end=None, **kwargs)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># do something</span></div><div class=\"line\">Net.forward = _Net_forward</div></pre></td></tr></table></figure>\n<p><code>@property</code><code>self</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># This function will be called when accessing net.blobs</span></div><div class=\"line\"><span class=\"meta\">@property</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_Net_blobs</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"</span></div><div class=\"line\">    An OrderedDict (bottom to top, i.e., input to output) of network</div><div class=\"line\">    blobs indexed by name</div><div class=\"line\">    \"\"\"</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> hasattr(self, <span class=\"string\">'_blobs_dict'</span>):</div><div class=\"line\">        self._blobs_dict = OrderedDict(zip(self._blob_names, self._blobs))</div><div class=\"line\">    <span class=\"keyword\">return</span> self._blobs_dict </div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Set the field `blobs` to call _Net_blobs</span></div><div class=\"line\">Net.blobs = _Net_blobs</div></pre></td></tr></table></figure>\n<p>PyCaffe<code>Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver</code></p>\n<h2 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++\"></a>C++</h2><p>C++</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><code>python/caffe/_caffe.cpp</code>boostpythonC++</p>\n<p><code>Blob</code>python<code>Blob</code><code>num</code>C++<code>Blob&lt;Dtype&gt;::num()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">.add_property(<span class=\"string\">\"num\"</span>, &amp;Blob&lt;Dtype&gt;::num)</div></pre></td></tr></table></figure></p>\n<p><code>.def</code>python<code>Net_Save</code>python<code>Net</code><code>save</code>python<code>net.save(filename)</code></p>\n<p><code>_caffe,cpp</code><code>make pycaffe</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"># <span class=\"function\">Declare the function</span></div><div class=\"line\"><span class=\"keyword\">void</span> <span class=\"title\">Net_Save</span><span class=\"params\">(<span class=\"keyword\">const</span> Net&lt;Dtype&gt;&amp; net, <span class=\"built_in\">string</span> filename)</span> &#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\"></div><div class=\"line\">bp::class_&lt;Net&lt;Dtype&gt;&gt;(<span class=\"string\">\"Net\"</span>, bp::no_init)</div><div class=\"line\"># Now we can call net.save(file)</div><div class=\"line\">.def(<span class=\"string\">\"save\"</span>, &amp;Net_Save)</div></pre></td></tr></table></figure>\n<p>boostpython<a href=\"http://www.boost.org/doc/libs/1_58_0/libs/python/doc/tutorial/doc/html/index.html\" target=\"_blank\" rel=\"external\">boost: python binding</a></p>\n","excerpt":"<p><a href=\"https://github.com/nitnelave/pycaffe_tutorial/blob/master/04%20Hacking%20the%20Python%20API.ipynb\">Github: PyCaffe Tutorial</a>Hack PycaffeboostC++PythonPycaffePycaffe<br><img src=\"/img/caffe-hack-pycaffe-python-cpp-binding.jpg\" alt=\"Python&amp;&amp;CPP binding\"><br>","more":"</p>\n<h2 id=\"PyCaffe\"><a href=\"#PyCaffe\" class=\"headerlink\" title=\"PyCaffe\"></a>PyCaffe</h2><p>Caffe<code>python</code>PyCaffe<code>src</code><code>include</code>CaffeC++<code>python</code>PyCaffe<code>_caffe.cpp</code>python<code>_caffe.cpp</code>boostC++pythonpythonAPI<br><img src=\"/img/hack-pycaffe-code-organization.png\" alt=\"\"></p>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><p>C++PyCaffepython</p>\n<h3 id=\"PyCaffe\"><a href=\"#PyCaffe\" class=\"headerlink\" title=\"PyCaffe\"></a>PyCaffe</h3><p>PyCaffe<code>PyTorch</code><code>Transformer</code>APIPyCaffe<code>numpy</code><code>opencv</code>Caffe<code>python/caffe/__init__.py</code>import<code>caffe.io</code><code>python/caffe/io.py</code></p>\n<h3 id=\"Caffe\"><a href=\"#Caffe\" class=\"headerlink\" title=\"Caffe\"></a>Caffe</h3><p>Caffe<code>pycaffe.py</code><code>Net</code>python<code>Net</code><code>&lt;class&gt;.&lt;function&gt; = my_function</code><code>_Net_forward</code><code>self</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_Net_forward</span><span class=\"params\">(self, blobs=None, start=None, end=None, **kwargs)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># do something</span></div><div class=\"line\">Net.forward = _Net_forward</div></pre></td></tr></table></figure>\n<p><code>@property</code><code>self</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># This function will be called when accessing net.blobs</span></div><div class=\"line\"><span class=\"meta\">@property</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_Net_blobs</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"</div><div class=\"line\">    An OrderedDict (bottom to top, i.e., input to output) of network</div><div class=\"line\">    blobs indexed by name</div><div class=\"line\">    \"\"\"</span></div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> hasattr(self, <span class=\"string\">'_blobs_dict'</span>):</div><div class=\"line\">        self._blobs_dict = OrderedDict(zip(self._blob_names, self._blobs))</div><div class=\"line\">    <span class=\"keyword\">return</span> self._blobs_dict </div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Set the field `blobs` to call _Net_blobs</span></div><div class=\"line\">Net.blobs = _Net_blobs</div></pre></td></tr></table></figure>\n<p>PyCaffe<code>Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver</code></p>\n<h2 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++\"></a>C++</h2><p>C++</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><code>python/caffe/_caffe.cpp</code>boostpythonC++</p>\n<p><code>Blob</code>python<code>Blob</code><code>num</code>C++<code>Blob&lt;Dtype&gt;::num()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">.add_property(<span class=\"string\">\"num\"</span>, &amp;Blob&lt;Dtype&gt;::num)</div></pre></td></tr></table></figure></p>\n<p><code>.def</code>python<code>Net_Save</code>python<code>Net</code><code>save</code>python<code>net.save(filename)</code></p>\n<p><code>_caffe,cpp</code><code>make pycaffe</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"># <span class=\"function\">Declare the function</div><div class=\"line\"><span class=\"keyword\">void</span> <span class=\"title\">Net_Save</span><span class=\"params\">(<span class=\"keyword\">const</span> Net&lt;Dtype&gt;&amp; net, <span class=\"built_in\">string</span> filename)</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\"></div><div class=\"line\">bp::class_&lt;Net&lt;Dtype&gt;&gt;(<span class=\"string\">\"Net\"</span>, bp::no_init)</div><div class=\"line\"># Now we can call net.save(file)</div><div class=\"line\">.def(<span class=\"string\">\"save\"</span>, &amp;Net_Save)</div></pre></td></tr></table></figure>\n<p>boostpython<a href=\"http://www.boost.org/doc/libs/1_58_0/libs/python/doc/tutorial/doc/html/index.html\">boost: python binding</a></p>"},{"title":"Caffe  SyncedMem","date":"2018-01-12T06:05:59.000Z","_content":"`Blob`CaffeTensorFlowPyTorchTensor`Blob``Layer``Blob``Layer`\n <img src=\"/img/caffe_syncedmem_blob_flow.jpg\" width = \"300\" height = \"200\" alt=\"blob\" align=center />\n\nCaffe`Blob``SyncedMem`HostdeviceCaffe`SyncedMem`\n<!-- more -->\n\n## SyncedMem\n`Blob`GPUGPUHostDevice\n\n## \n`SyncedMem``head_`\n\n``` cpp\n// in SyncedMem\nenum SyncedHead { UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED };\n// Git Gitrepo HEAD\n// \nSyncedHead head_;\n```\n\n`head_`\n![](/img/caffe_syncedmem_transfer.png)\n\n## \n`SyncedMem`\n\n``` cpp\n/**\n * @brief Manages memory allocation and synchronization between the host (CPU)\n *        and device (GPU).\n *\n * TODO(dox): more thorough description.\n */\nclass SyncedMemory {\n public:\n  SyncedMemory();\n  explicit SyncedMemory(size_t size);\n  ~SyncedMemory();\n  // CPU data\n  const void* cpu_data();\n  // CPU data\n  void set_cpu_data(void* data);\n  // GPU data\n  const void* gpu_data();\n  // GPU data\n  void set_gpu_data(void* data);\n  // CPU data\n  void* mutable_cpu_data();\n  // GPU data\n  void* mutable_gpu_data();\n  // CPU  GPUCPUGPU\n  enum SyncedHead { UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED };\n  SyncedHead head() { return head_; }\n  // \n  size_t size() { return size_; }\n\n#ifndef CPU_ONLY\n  void async_gpu_push(const cudaStream_t& stream);\n#endif\n\n private:\n  void check_device();\n\n  void to_cpu();\n  void to_gpu();\n  void* cpu_ptr_;\n  void* gpu_ptr_;\n  size_t size_;\n  SyncedHead head_;\n  bool own_cpu_data_;\n  bool cpu_malloc_use_cuda_;\n  bool own_gpu_data_;\n  // GPU\n  int device_;\n\n  DISABLE_COPY_AND_ASSIGN(SyncedMemory);\n};  // class SyncedMemory\n```\n\n`to_cpu()`\n\n``` cpp\ninline void SyncedMemory::to_gpu() {\n  // DEBUG\n  check_device();\n#ifndef CPU_ONLY\n  switch (head_) {\n  case UNINITIALIZED:\n    // ~\n    // GPU~\n    CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));\n    caffe_gpu_memset(size_, 0, gpu_ptr_);\n    // \n    head_ = HEAD_AT_GPU;\n    own_gpu_data_ = true;\n    break;\n  case HEAD_AT_CPU:\n    // CPU~\n    if (gpu_ptr_ == NULL) {\n      CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));\n      own_gpu_data_ = true;\n    }\n    // \n    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);\n    // \n    head_ = SYNCED;\n    break;\n  // GPU\n  case HEAD_AT_GPU:\n  case SYNCED:\n    break;\n  }\n#else\n  // NO_GPU FATAL ERROR\n  // GPU \n  NO_GPU;\n#endif\n}\n```\n\n`head_``SyncedMemory``own_gpu_data_``own_cpu_data_`CPUGPU`set_c/gpu_data`/\n\n\n\n","source":"_posts/caffe-syncedmem.md","raw":"---\ntitle: Caffe  SyncedMem\ndate: 2018-01-12 14:05:59\ntags:\n     - caffe\n---\n`Blob`CaffeTensorFlowPyTorchTensor`Blob``Layer``Blob``Layer`\n <img src=\"/img/caffe_syncedmem_blob_flow.jpg\" width = \"300\" height = \"200\" alt=\"blob\" align=center />\n\nCaffe`Blob``SyncedMem`HostdeviceCaffe`SyncedMem`\n<!-- more -->\n\n## SyncedMem\n`Blob`GPUGPUHostDevice\n\n## \n`SyncedMem``head_`\n\n``` cpp\n// in SyncedMem\nenum SyncedHead { UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED };\n// Git Gitrepo HEAD\n// \nSyncedHead head_;\n```\n\n`head_`\n![](/img/caffe_syncedmem_transfer.png)\n\n## \n`SyncedMem`\n\n``` cpp\n/**\n * @brief Manages memory allocation and synchronization between the host (CPU)\n *        and device (GPU).\n *\n * TODO(dox): more thorough description.\n */\nclass SyncedMemory {\n public:\n  SyncedMemory();\n  explicit SyncedMemory(size_t size);\n  ~SyncedMemory();\n  // CPU data\n  const void* cpu_data();\n  // CPU data\n  void set_cpu_data(void* data);\n  // GPU data\n  const void* gpu_data();\n  // GPU data\n  void set_gpu_data(void* data);\n  // CPU data\n  void* mutable_cpu_data();\n  // GPU data\n  void* mutable_gpu_data();\n  // CPU  GPUCPUGPU\n  enum SyncedHead { UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED };\n  SyncedHead head() { return head_; }\n  // \n  size_t size() { return size_; }\n\n#ifndef CPU_ONLY\n  void async_gpu_push(const cudaStream_t& stream);\n#endif\n\n private:\n  void check_device();\n\n  void to_cpu();\n  void to_gpu();\n  void* cpu_ptr_;\n  void* gpu_ptr_;\n  size_t size_;\n  SyncedHead head_;\n  bool own_cpu_data_;\n  bool cpu_malloc_use_cuda_;\n  bool own_gpu_data_;\n  // GPU\n  int device_;\n\n  DISABLE_COPY_AND_ASSIGN(SyncedMemory);\n};  // class SyncedMemory\n```\n\n`to_cpu()`\n\n``` cpp\ninline void SyncedMemory::to_gpu() {\n  // DEBUG\n  check_device();\n#ifndef CPU_ONLY\n  switch (head_) {\n  case UNINITIALIZED:\n    // ~\n    // GPU~\n    CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));\n    caffe_gpu_memset(size_, 0, gpu_ptr_);\n    // \n    head_ = HEAD_AT_GPU;\n    own_gpu_data_ = true;\n    break;\n  case HEAD_AT_CPU:\n    // CPU~\n    if (gpu_ptr_ == NULL) {\n      CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));\n      own_gpu_data_ = true;\n    }\n    // \n    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);\n    // \n    head_ = SYNCED;\n    break;\n  // GPU\n  case HEAD_AT_GPU:\n  case SYNCED:\n    break;\n  }\n#else\n  // NO_GPU FATAL ERROR\n  // GPU \n  NO_GPU;\n#endif\n}\n```\n\n`head_``SyncedMemory``own_gpu_data_``own_cpu_data_`CPUGPU`set_c/gpu_data`/\n\n\n\n","slug":"caffe-syncedmem","published":1,"updated":"2018-10-27T07:16:52.380Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8i8000aae7bjhbxnppg","content":"<p><code>Blob</code>CaffeTensorFlowPyTorchTensor<code>Blob</code><code>Layer</code><code>Blob</code><code>Layer</code><br> <img src=\"/img/caffe_syncedmem_blob_flow.jpg\" width=\"300\" height=\"200\" alt=\"blob\" align=\"center\"></p>\n<p>Caffe<code>Blob</code><code>SyncedMem</code>HostdeviceCaffe<code>SyncedMem</code><br><a id=\"more\"></a></p>\n<h2 id=\"SyncedMem\"><a href=\"#SyncedMem\" class=\"headerlink\" title=\"SyncedMem\"></a>SyncedMem</h2><p><code>Blob</code>GPUGPUHostDevice</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SyncedMem</code><code>head_</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// in SyncedMem</span></div><div class=\"line\"><span class=\"keyword\">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class=\"line\"><span class=\"comment\">// Git Gitrepo HEAD</span></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">SyncedHead head_;</div></pre></td></tr></table></figure>\n<p><code>head_</code><br><img src=\"/img/caffe_syncedmem_transfer.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SyncedMem</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</span></div><div class=\"line\"> * @brief Manages memory allocation and synchronization between the host (CPU)</div><div class=\"line\"> *        and device (GPU).</div><div class=\"line\"> *</div><div class=\"line\"> * TODO(dox): more thorough description.</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"keyword\">class</span> SyncedMemory &#123;</div><div class=\"line\"> <span class=\"keyword\">public</span>:</div><div class=\"line\">  SyncedMemory();</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">SyncedMemory</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size)</span></span>;</div><div class=\"line\">  ~SyncedMemory();</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* <span class=\"title\">cpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">set_cpu_data</span><span class=\"params\">(<span class=\"keyword\">void</span>* data)</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* <span class=\"title\">gpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">set_gpu_data</span><span class=\"params\">(<span class=\"keyword\">void</span>* data)</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">mutable_cpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">mutable_gpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU  GPUCPUGPU</span></div><div class=\"line\">  <span class=\"keyword\">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class=\"line\">  <span class=\"function\">SyncedHead <span class=\"title\">head</span><span class=\"params\">()</span> </span>&#123; <span class=\"keyword\">return</span> head_; &#125;</div><div class=\"line\">  <span class=\"comment\">// </span></div><div class=\"line\">  <span class=\"keyword\">size_t</span> size() &#123; <span class=\"keyword\">return</span> size_; &#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">async_gpu_push</span><span class=\"params\">(<span class=\"keyword\">const</span> cudaStream_t&amp; stream)</span></span>;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\"></div><div class=\"line\"> <span class=\"keyword\">private</span>:</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">check_device</span><span class=\"params\">()</span></span>;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">to_cpu</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">to_gpu</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"keyword\">void</span>* cpu_ptr_;</div><div class=\"line\">  <span class=\"keyword\">void</span>* gpu_ptr_;</div><div class=\"line\">  <span class=\"keyword\">size_t</span> size_;</div><div class=\"line\">  SyncedHead head_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> own_cpu_data_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> cpu_malloc_use_cuda_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> own_gpu_data_;</div><div class=\"line\">  <span class=\"comment\">// GPU</span></div><div class=\"line\">  <span class=\"keyword\">int</span> device_;</div><div class=\"line\"></div><div class=\"line\">  DISABLE_COPY_AND_ASSIGN(SyncedMemory);</div><div class=\"line\">&#125;;  <span class=\"comment\">// class SyncedMemory</span></div></pre></td></tr></table></figure>\n<p><code>to_cpu()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> SyncedMemory::to_gpu() &#123;</div><div class=\"line\">  <span class=\"comment\">// DEBUG</span></div><div class=\"line\">  check_device();</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">  <span class=\"keyword\">switch</span> (head_) &#123;</div><div class=\"line\">  <span class=\"keyword\">case</span> UNINITIALIZED:</div><div class=\"line\">    <span class=\"comment\">// ~</span></div><div class=\"line\">    <span class=\"comment\">// GPU~</span></div><div class=\"line\">    CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class=\"line\">    caffe_gpu_memset(size_, <span class=\"number\">0</span>, gpu_ptr_);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    head_ = HEAD_AT_GPU;</div><div class=\"line\">    own_gpu_data_ = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  <span class=\"keyword\">case</span> HEAD_AT_CPU:</div><div class=\"line\">    <span class=\"comment\">// CPU~</span></div><div class=\"line\">    <span class=\"keyword\">if</span> (gpu_ptr_ == <span class=\"literal\">NULL</span>) &#123;</div><div class=\"line\">      CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class=\"line\">      own_gpu_data_ = <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    head_ = SYNCED;</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  <span class=\"comment\">// GPU</span></div><div class=\"line\">  <span class=\"keyword\">case</span> HEAD_AT_GPU:</div><div class=\"line\">  <span class=\"keyword\">case</span> SYNCED:</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></div><div class=\"line\">  <span class=\"comment\">// NO_GPU FATAL ERROR</span></div><div class=\"line\">  <span class=\"comment\">// GPU </span></div><div class=\"line\">  NO_GPU;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>head_</code><code>SyncedMemory</code><code>own_gpu_data_</code><code>own_cpu_data_</code>CPUGPU<code>set_c/gpu_data</code>/</p>\n","excerpt":"<p><code>Blob</code>CaffeTensorFlowPyTorchTensor<code>Blob</code><code>Layer</code><code>Blob</code><code>Layer</code><br> <img src=\"/img/caffe_syncedmem_blob_flow.jpg\" width = \"300\" height = \"200\" alt=\"blob\" align=center /></p>\n<p>Caffe<code>Blob</code><code>SyncedMem</code>HostdeviceCaffe<code>SyncedMem</code><br>","more":"</p>\n<h2 id=\"SyncedMem\"><a href=\"#SyncedMem\" class=\"headerlink\" title=\"SyncedMem\"></a>SyncedMem</h2><p><code>Blob</code>GPUGPUHostDevice</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SyncedMem</code><code>head_</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// in SyncedMem</span></div><div class=\"line\"><span class=\"keyword\">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class=\"line\"><span class=\"comment\">// Git Gitrepo HEAD</span></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">SyncedHead head_;</div></pre></td></tr></table></figure>\n<p><code>head_</code><br><img src=\"/img/caffe_syncedmem_transfer.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SyncedMem</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">/**</div><div class=\"line\"> * @brief Manages memory allocation and synchronization between the host (CPU)</div><div class=\"line\"> *        and device (GPU).</div><div class=\"line\"> *</div><div class=\"line\"> * TODO(dox): more thorough description.</div><div class=\"line\"> */</span></div><div class=\"line\"><span class=\"keyword\">class</span> SyncedMemory &#123;</div><div class=\"line\"> <span class=\"keyword\">public</span>:</div><div class=\"line\">  SyncedMemory();</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">SyncedMemory</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size)</span></span>;</div><div class=\"line\">  ~SyncedMemory();</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* <span class=\"title\">cpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">set_cpu_data</span><span class=\"params\">(<span class=\"keyword\">void</span>* data)</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"keyword\">void</span>* <span class=\"title\">gpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">set_gpu_data</span><span class=\"params\">(<span class=\"keyword\">void</span>* data)</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">mutable_cpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// GPU data</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"title\">mutable_gpu_data</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"comment\">// CPU  GPUCPUGPU</span></div><div class=\"line\">  <span class=\"keyword\">enum</span> SyncedHead &#123; UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED &#125;;</div><div class=\"line\">  <span class=\"function\">SyncedHead <span class=\"title\">head</span><span class=\"params\">()</span> </span>&#123; <span class=\"keyword\">return</span> head_; &#125;</div><div class=\"line\">  <span class=\"comment\">// </span></div><div class=\"line\">  <span class=\"keyword\">size_t</span> size() &#123; <span class=\"keyword\">return</span> size_; &#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">async_gpu_push</span><span class=\"params\">(<span class=\"keyword\">const</span> cudaStream_t&amp; stream)</span></span>;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\"></div><div class=\"line\"> <span class=\"keyword\">private</span>:</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">check_device</span><span class=\"params\">()</span></span>;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">to_cpu</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">to_gpu</span><span class=\"params\">()</span></span>;</div><div class=\"line\">  <span class=\"keyword\">void</span>* cpu_ptr_;</div><div class=\"line\">  <span class=\"keyword\">void</span>* gpu_ptr_;</div><div class=\"line\">  <span class=\"keyword\">size_t</span> size_;</div><div class=\"line\">  SyncedHead head_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> own_cpu_data_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> cpu_malloc_use_cuda_;</div><div class=\"line\">  <span class=\"keyword\">bool</span> own_gpu_data_;</div><div class=\"line\">  <span class=\"comment\">// GPU</span></div><div class=\"line\">  <span class=\"keyword\">int</span> device_;</div><div class=\"line\"></div><div class=\"line\">  DISABLE_COPY_AND_ASSIGN(SyncedMemory);</div><div class=\"line\">&#125;;  <span class=\"comment\">// class SyncedMemory</span></div></pre></td></tr></table></figure>\n<p><code>to_cpu()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> SyncedMemory::to_gpu() &#123;</div><div class=\"line\">  <span class=\"comment\">// DEBUG</span></div><div class=\"line\">  check_device();</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">  <span class=\"keyword\">switch</span> (head_) &#123;</div><div class=\"line\">  <span class=\"keyword\">case</span> UNINITIALIZED:</div><div class=\"line\">    <span class=\"comment\">// ~</span></div><div class=\"line\">    <span class=\"comment\">// GPU~</span></div><div class=\"line\">    CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class=\"line\">    caffe_gpu_memset(size_, <span class=\"number\">0</span>, gpu_ptr_);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    head_ = HEAD_AT_GPU;</div><div class=\"line\">    own_gpu_data_ = <span class=\"literal\">true</span>;</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  <span class=\"keyword\">case</span> HEAD_AT_CPU:</div><div class=\"line\">    <span class=\"comment\">// CPU~</span></div><div class=\"line\">    <span class=\"keyword\">if</span> (gpu_ptr_ == <span class=\"literal\">NULL</span>) &#123;</div><div class=\"line\">      CUDA_CHECK(cudaMalloc(&amp;gpu_ptr_, size_));</div><div class=\"line\">      own_gpu_data_ = <span class=\"literal\">true</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    head_ = SYNCED;</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  <span class=\"comment\">// GPU</span></div><div class=\"line\">  <span class=\"keyword\">case</span> HEAD_AT_GPU:</div><div class=\"line\">  <span class=\"keyword\">case</span> SYNCED:</div><div class=\"line\">    <span class=\"keyword\">break</span>;</div><div class=\"line\">  &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></div><div class=\"line\">  <span class=\"comment\">// NO_GPU FATAL ERROR</span></div><div class=\"line\">  <span class=\"comment\">// GPU </span></div><div class=\"line\">  NO_GPU;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>head_</code><code>SyncedMemory</code><code>own_gpu_data_</code><code>own_cpu_data_</code>CPUGPU<code>set_c/gpu_data</code>/</p>"},{"title":"CaffeNet","date":"2018-02-28T02:16:43.000Z","_content":"Caffe`Net`Caffe`Net`\n<img src=\"/img/caffe-net-demo.jpg\" width = \"300\" height = \"200\" alt=\"Net\" align=center />\n<!-- more-->\n\n## proto\n```\nmessage NetParameter {\n  // net\n  optional string name = 1; // consider giving the network a name\n  // blob\n  // `InputParameter`\n  // DEPRECATED. See InputParameter. The input blobs to the network.\n  repeated string input = 3;\n  // DEPRECATED. See InputParameter. The shape of the input blobs.\n  repeated BlobShape input_shape = 8;\n\n  // 4D input dimensions -- deprecated.  Use \"input_shape\" instead.\n  // If specified, for each input blob there should be four\n  // values specifying the num, channels, height and width of the input blob.\n  // Thus, there should be a total of (4 * #input) numbers.\n  repeated int32 input_dim = 4;\n  \n  // Whether the network will force every layer to carry out backward operation.\n  // If set False, then whether to carry out backward is determined\n  // automatically according to the net structure and learning rates.\n  optional bool force_backward = 5 [default = false];\n  // The current \"state\" of the network, including the phase, level, and stage.\n  // Some layers may be included/excluded depending on this state and the states\n  // specified in the layers' include and exclude fields.\n  optional NetState state = 6;\n\n  // Print debugging information about results while running Net::Forward,\n  // Net::Backward, and Net::Update.\n  optional bool debug_info = 7 [default = false];\n\n  // The layers that make up the net.  Each of their configurations, including\n  // connectivity and behavior, is specified as a LayerParameter.\n  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.\n\n  // DEPRECATED: use 'layer' instead.\n  repeated V1LayerParameter layers = 2;\n}\n```\n\n### Input\n`train``deploy``train`$x$$y$$\\hat{y} = \\mathcal{F}_\\theta (x)$$y$bp$\\theta$\n\n\n`deploy``InputLayer``$CAFFE/models/bvlc_alexnet/deploy.prototxt`\n```\nlayer {\n  name: \"data\"\n  type: \"Input\"\n  // layerblobdatalayer\n  top: \"data\"\n  // blob10 x 3 x 227 x 227\n  // batch size = 10\n  // channel = 3, RGB\n  // image227 x 227\n  input_param { shape: { dim: 10 dim: 3 dim: 227 dim: 227 } }\n}\n```\n\n## \n`Net``$CAFFE/include/caffe/net.hpp`\n","source":"_posts/caffe-net.md","raw":"---\ntitle: CaffeNet\ndate: 2018-02-28 10:16:43\ntags:\n     - caffe\n---\nCaffe`Net`Caffe`Net`\n<img src=\"/img/caffe-net-demo.jpg\" width = \"300\" height = \"200\" alt=\"Net\" align=center />\n<!-- more-->\n\n## proto\n```\nmessage NetParameter {\n  // net\n  optional string name = 1; // consider giving the network a name\n  // blob\n  // `InputParameter`\n  // DEPRECATED. See InputParameter. The input blobs to the network.\n  repeated string input = 3;\n  // DEPRECATED. See InputParameter. The shape of the input blobs.\n  repeated BlobShape input_shape = 8;\n\n  // 4D input dimensions -- deprecated.  Use \"input_shape\" instead.\n  // If specified, for each input blob there should be four\n  // values specifying the num, channels, height and width of the input blob.\n  // Thus, there should be a total of (4 * #input) numbers.\n  repeated int32 input_dim = 4;\n  \n  // Whether the network will force every layer to carry out backward operation.\n  // If set False, then whether to carry out backward is determined\n  // automatically according to the net structure and learning rates.\n  optional bool force_backward = 5 [default = false];\n  // The current \"state\" of the network, including the phase, level, and stage.\n  // Some layers may be included/excluded depending on this state and the states\n  // specified in the layers' include and exclude fields.\n  optional NetState state = 6;\n\n  // Print debugging information about results while running Net::Forward,\n  // Net::Backward, and Net::Update.\n  optional bool debug_info = 7 [default = false];\n\n  // The layers that make up the net.  Each of their configurations, including\n  // connectivity and behavior, is specified as a LayerParameter.\n  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.\n\n  // DEPRECATED: use 'layer' instead.\n  repeated V1LayerParameter layers = 2;\n}\n```\n\n### Input\n`train``deploy``train`$x$$y$$\\hat{y} = \\mathcal{F}_\\theta (x)$$y$bp$\\theta$\n\n\n`deploy``InputLayer``$CAFFE/models/bvlc_alexnet/deploy.prototxt`\n```\nlayer {\n  name: \"data\"\n  type: \"Input\"\n  // layerblobdatalayer\n  top: \"data\"\n  // blob10 x 3 x 227 x 227\n  // batch size = 10\n  // channel = 3, RGB\n  // image227 x 227\n  input_param { shape: { dim: 10 dim: 3 dim: 227 dim: 227 } }\n}\n```\n\n## \n`Net``$CAFFE/include/caffe/net.hpp`\n","slug":"caffe-net","published":1,"updated":"2018-10-27T07:16:52.379Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ib000bae7btzewy29d","content":"<p>Caffe<code>Net</code>Caffe<code>Net</code><br><img src=\"/img/caffe-net-demo.jpg\" width=\"300\" height=\"200\" alt=\"Net\" align=\"center\"><br><a id=\"more\"></a></p>\n<h2 id=\"proto\"><a href=\"#proto\" class=\"headerlink\" title=\"proto\"></a>proto</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\">message NetParameter &#123;</div><div class=\"line\">  // net</div><div class=\"line\">  optional string name = 1; // consider giving the network a name</div><div class=\"line\">  // blob</div><div class=\"line\">  // `InputParameter`</div><div class=\"line\">  // DEPRECATED. See InputParameter. The input blobs to the network.</div><div class=\"line\">  repeated string input = 3;</div><div class=\"line\">  // DEPRECATED. See InputParameter. The shape of the input blobs.</div><div class=\"line\">  repeated BlobShape input_shape = 8;</div><div class=\"line\"></div><div class=\"line\">  // 4D input dimensions -- deprecated.  Use &quot;input_shape&quot; instead.</div><div class=\"line\">  // If specified, for each input blob there should be four</div><div class=\"line\">  // values specifying the num, channels, height and width of the input blob.</div><div class=\"line\">  // Thus, there should be a total of (4 * #input) numbers.</div><div class=\"line\">  repeated int32 input_dim = 4;</div><div class=\"line\">  </div><div class=\"line\">  // Whether the network will force every layer to carry out backward operation.</div><div class=\"line\">  // If set False, then whether to carry out backward is determined</div><div class=\"line\">  // automatically according to the net structure and learning rates.</div><div class=\"line\">  optional bool force_backward = 5 [default = false];</div><div class=\"line\">  // The current &quot;state&quot; of the network, including the phase, level, and stage.</div><div class=\"line\">  // Some layers may be included/excluded depending on this state and the states</div><div class=\"line\">  // specified in the layers&apos; include and exclude fields.</div><div class=\"line\">  optional NetState state = 6;</div><div class=\"line\"></div><div class=\"line\">  // Print debugging information about results while running Net::Forward,</div><div class=\"line\">  // Net::Backward, and Net::Update.</div><div class=\"line\">  optional bool debug_info = 7 [default = false];</div><div class=\"line\"></div><div class=\"line\">  // The layers that make up the net.  Each of their configurations, including</div><div class=\"line\">  // connectivity and behavior, is specified as a LayerParameter.</div><div class=\"line\">  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.</div><div class=\"line\"></div><div class=\"line\">  // DEPRECATED: use &apos;layer&apos; instead.</div><div class=\"line\">  repeated V1LayerParameter layers = 2;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Input\"><a href=\"#Input\" class=\"headerlink\" title=\"Input\"></a>Input</h3><p><code>train</code><code>deploy</code><code>train</code>$x$$y$$\\hat{y} = \\mathcal{F}_\\theta (x)$$y$bp$\\theta$</p>\n<p><code>deploy</code><code>InputLayer</code><code>$CAFFE/models/bvlc_alexnet/deploy.prototxt</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">  name: &quot;data&quot;</div><div class=\"line\">  type: &quot;Input&quot;</div><div class=\"line\">  // layerblobdatalayer</div><div class=\"line\">  top: &quot;data&quot;</div><div class=\"line\">  // blob10 x 3 x 227 x 227</div><div class=\"line\">  // batch size = 10</div><div class=\"line\">  // channel = 3, RGB</div><div class=\"line\">  // image227 x 227</div><div class=\"line\">  input_param &#123; shape: &#123; dim: 10 dim: 3 dim: 227 dim: 227 &#125; &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>Net</code><code>$CAFFE/include/caffe/net.hpp</code></p>\n","excerpt":"<p>Caffe<code>Net</code>Caffe<code>Net</code><br><img src=\"/img/caffe-net-demo.jpg\" width = \"300\" height = \"200\" alt=\"Net\" align=center /><br>","more":"</p>\n<h2 id=\"proto\"><a href=\"#proto\" class=\"headerlink\" title=\"proto\"></a>proto</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\">message NetParameter &#123;</div><div class=\"line\">  // net</div><div class=\"line\">  optional string name = 1; // consider giving the network a name</div><div class=\"line\">  // blob</div><div class=\"line\">  // `InputParameter`</div><div class=\"line\">  // DEPRECATED. See InputParameter. The input blobs to the network.</div><div class=\"line\">  repeated string input = 3;</div><div class=\"line\">  // DEPRECATED. See InputParameter. The shape of the input blobs.</div><div class=\"line\">  repeated BlobShape input_shape = 8;</div><div class=\"line\"></div><div class=\"line\">  // 4D input dimensions -- deprecated.  Use &quot;input_shape&quot; instead.</div><div class=\"line\">  // If specified, for each input blob there should be four</div><div class=\"line\">  // values specifying the num, channels, height and width of the input blob.</div><div class=\"line\">  // Thus, there should be a total of (4 * #input) numbers.</div><div class=\"line\">  repeated int32 input_dim = 4;</div><div class=\"line\">  </div><div class=\"line\">  // Whether the network will force every layer to carry out backward operation.</div><div class=\"line\">  // If set False, then whether to carry out backward is determined</div><div class=\"line\">  // automatically according to the net structure and learning rates.</div><div class=\"line\">  optional bool force_backward = 5 [default = false];</div><div class=\"line\">  // The current &quot;state&quot; of the network, including the phase, level, and stage.</div><div class=\"line\">  // Some layers may be included/excluded depending on this state and the states</div><div class=\"line\">  // specified in the layers&apos; include and exclude fields.</div><div class=\"line\">  optional NetState state = 6;</div><div class=\"line\"></div><div class=\"line\">  // Print debugging information about results while running Net::Forward,</div><div class=\"line\">  // Net::Backward, and Net::Update.</div><div class=\"line\">  optional bool debug_info = 7 [default = false];</div><div class=\"line\"></div><div class=\"line\">  // The layers that make up the net.  Each of their configurations, including</div><div class=\"line\">  // connectivity and behavior, is specified as a LayerParameter.</div><div class=\"line\">  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.</div><div class=\"line\"></div><div class=\"line\">  // DEPRECATED: use &apos;layer&apos; instead.</div><div class=\"line\">  repeated V1LayerParameter layers = 2;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Input\"><a href=\"#Input\" class=\"headerlink\" title=\"Input\"></a>Input</h3><p><code>train</code><code>deploy</code><code>train</code>$x$$y$$\\hat{y} = \\mathcal{F}_\\theta (x)$$y$bp$\\theta$</p>\n<p><code>deploy</code><code>InputLayer</code><code>$CAFFE/models/bvlc_alexnet/deploy.prototxt</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">  name: &quot;data&quot;</div><div class=\"line\">  type: &quot;Input&quot;</div><div class=\"line\">  // layerblobdatalayer</div><div class=\"line\">  top: &quot;data&quot;</div><div class=\"line\">  // blob10 x 3 x 227 x 227</div><div class=\"line\">  // batch size = 10</div><div class=\"line\">  // channel = 3, RGB</div><div class=\"line\">  // image227 x 227</div><div class=\"line\">  input_param &#123; shape: &#123; dim: 10 dim: 3 dim: 227 dim: 227 &#125; &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>Net</code><code>$CAFFE/include/caffe/net.hpp</code></p>"},{"title":"Caffe","date":"2018-02-26T07:26:09.000Z","_content":"[Caffe](https://www.zhihu.com/question/28385679)\n![Naive Loop](/img/conv-in-caffe-naive-loop.png)\n<!-- more -->\n\n`im2col`BLASGEMM\n![im2col->gemm](/img/conv-in-caffe-im2col-followed-gemm.png)\n\nim2colpatchfeature vectorpatch\n![patches](/img/conv-in-caffe-im2col-1.png)\n\n\n![](/img/conv-in-caffe-im2col-2.png)\n\n`c_out`\n![ to col](/img/conv-in-caffe-im2col-3.png)\n\n`A``F``i``F``i``A` `F_i * [A_1^T, A_2^T,  A_i^T]` `A``F*A^T`.\n\n`F``Cout x (C x K x K)`. Feature map matrix`(H x W) x (C x K x K)` `Cout x (H x W)`blob`Cout x H x W`\n\n[Convolution in Caffe: a memo](https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo)caffeconv","source":"_posts/conv-in-caffe.md","raw":"---\ntitle: Caffe\ndate: 2018-02-26 15:26:09\ntags:\n     - caffe\n---\n[Caffe](https://www.zhihu.com/question/28385679)\n![Naive Loop](/img/conv-in-caffe-naive-loop.png)\n<!-- more -->\n\n`im2col`BLASGEMM\n![im2col->gemm](/img/conv-in-caffe-im2col-followed-gemm.png)\n\nim2colpatchfeature vectorpatch\n![patches](/img/conv-in-caffe-im2col-1.png)\n\n\n![](/img/conv-in-caffe-im2col-2.png)\n\n`c_out`\n![ to col](/img/conv-in-caffe-im2col-3.png)\n\n`A``F``i``F``i``A` `F_i * [A_1^T, A_2^T,  A_i^T]` `A``F*A^T`.\n\n`F``Cout x (C x K x K)`. Feature map matrix`(H x W) x (C x K x K)` `Cout x (H x W)`blob`Cout x H x W`\n\n[Convolution in Caffe: a memo](https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo)caffeconv","slug":"conv-in-caffe","published":1,"updated":"2018-10-27T07:16:52.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ie000eae7bxv14kzpz","content":"<p><a href=\"https://www.zhihu.com/question/28385679\" target=\"_blank\" rel=\"external\">Caffe</a><br><img src=\"/img/conv-in-caffe-naive-loop.png\" alt=\"Naive Loop\"><br><a id=\"more\"></a></p>\n<p><code>im2col</code>BLASGEMM<br><img src=\"/img/conv-in-caffe-im2col-followed-gemm.png\" alt=\"im2col-&gt;gemm\"></p>\n<p>im2colpatchfeature vectorpatch<br><img src=\"/img/conv-in-caffe-im2col-1.png\" alt=\"patches\"></p>\n<p><br><img src=\"/img/conv-in-caffe-im2col-2.png\" alt=\"\"></p>\n<p><code>c_out</code><br><img src=\"/img/conv-in-caffe-im2col-3.png\" alt=\" to col\"></p>\n<p><code>A</code><code>F</code><code>i</code><code>F</code><code>i</code><code>A</code> <code>F_i * [A_1^T, A_2^T,  A_i^T]</code> <code>A</code><code>F*A^T</code>.</p>\n<p><code>F</code><code>Cout x (C x K x K)</code>. Feature map matrix<code>(H x W) x (C x K x K)</code> <code>Cout x (H x W)</code>blob<code>Cout x H x W</code></p>\n<p><a href=\"https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo\" target=\"_blank\" rel=\"external\">Convolution in Caffe: a memo</a>caffeconv</p>\n","excerpt":"<p><a href=\"https://www.zhihu.com/question/28385679\">Caffe</a><br><img src=\"/img/conv-in-caffe-naive-loop.png\" alt=\"Naive Loop\"><br>","more":"</p>\n<p><code>im2col</code>BLASGEMM<br><img src=\"/img/conv-in-caffe-im2col-followed-gemm.png\" alt=\"im2col-&gt;gemm\"></p>\n<p>im2colpatchfeature vectorpatch<br><img src=\"/img/conv-in-caffe-im2col-1.png\" alt=\"patches\"></p>\n<p><br><img src=\"/img/conv-in-caffe-im2col-2.png\" alt=\"\"></p>\n<p><code>c_out</code><br><img src=\"/img/conv-in-caffe-im2col-3.png\" alt=\" to col\"></p>\n<p><code>A</code><code>F</code><code>i</code><code>F</code><code>i</code><code>A</code> <code>F_i * [A_1^T, A_2^T,  A_i^T]</code> <code>A</code><code>F*A^T</code>.</p>\n<p><code>F</code><code>Cout x (C x K x K)</code>. Feature map matrix<code>(H x W) x (C x K x K)</code> <code>Cout x (H x W)</code>blob<code>Cout x H x W</code></p>\n<p><a href=\"https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo\">Convolution in Caffe: a memo</a>caffeconv</p>"},{"title":"CS131-","date":"2017-02-02T12:38:55.000Z","_content":"\n3D2D3D\n![](/img/camera_geometry_application.png)\n<!-- more -->\n## Pinhole Camera\n\n\n\n### \n\nProjective Geometry\n\n\n![1](/img/projective_geometry_property_1.png)\n\n3DVanishing point3D2DVanishing pointVanishing point\n![2](/img/projective_geometry_property_2.png)\n\n### \n$P$$O$$\\Pi^\\prime$$P^\\prime$\n![](/img/pinhole_camera_model.png)\n\n3D$P$$P^\\prime$\n$$\\left\\{\\begin{matrix}\nx^\\prime = fx/z \\\\\ny^\\prime = fy/z\n\\end{matrix}\\right.$$\n\n$z$$z$\n![](/img/qicizuobiao.png)\n\n3D2D3D4112D$M$$f$\n![](/img/qicizuobiao_transform.png)\n\n\n1. \n    - \n    - $(0, 0)$\n    - no skew\n2. \n    - \n    - \n\nno skew\n![what is \"skew\"?](/img/camera_skew.png)\n\nslide$M$\n\n#### \n$M$\n![case 1: M](/img/case_1_m.png)\n\n#### \n$(u_0, v_0)$$M$\n![case 2: M](/img/case_2_m.png)\n\n#### \n$x$$y$$f$\n![case 3: M](/img/case_3_m.png)\n\n#### no skew\n$x$$y$\n![case 4: M](/img/case_4_m.png)\n\n#### \n\n![](/img/camera_translation_rotation.png)\n\n3D$H$$H\\in \\mathbb{R}^{3\\times 4}$\n$$P^\\prime = MHP$$\n\n$\\mathbb{0}$\n![case 5: M](/img/case_m_5.png)\n\n\n![](/img/rotation_matrix.png)\n\n\n![case 6: M](/img/case_6_m.png)\n\n#### \n\n![](/img/generic_projection_matrix.png)\n\n5633\n\n\n![things to remember](/img/camera_model_things_to_remember.png)\n\n## \n\n### \n$O$$O^{'}$$P$\n\n![](/img/epipolar_fig.png)\n\n- $e$$e^\\prime$$OO^\\prime$\n- $O$$O^\\prime$$P$\n- $pe$$p^\\prime e^\\prime$\n- \n\n### \n\n\n$P$$p^\\prime$$M$$M^\\prime$$R$$T$$OO^\\prime$\n![1](/img/epipolar_constraint_1.png)\n\n[4](http://www.cnblogs.com/gemstone/articles/2294551.html)$p^\\prime$$O^\\prime$$O\\prime P$$p$\n$R(p-T) = p^\\prime$\n","source":"_posts/cs131-camera.md","raw":"---\ntitle: CS131-\ndate: 2017-02-02 20:38:55\ntags:\n     - cs131\n     - \n---\n\n3D2D3D\n![](/img/camera_geometry_application.png)\n<!-- more -->\n## Pinhole Camera\n\n\n\n### \n\nProjective Geometry\n\n\n![1](/img/projective_geometry_property_1.png)\n\n3DVanishing point3D2DVanishing pointVanishing point\n![2](/img/projective_geometry_property_2.png)\n\n### \n$P$$O$$\\Pi^\\prime$$P^\\prime$\n![](/img/pinhole_camera_model.png)\n\n3D$P$$P^\\prime$\n$$\\left\\{\\begin{matrix}\nx^\\prime = fx/z \\\\\ny^\\prime = fy/z\n\\end{matrix}\\right.$$\n\n$z$$z$\n![](/img/qicizuobiao.png)\n\n3D2D3D4112D$M$$f$\n![](/img/qicizuobiao_transform.png)\n\n\n1. \n    - \n    - $(0, 0)$\n    - no skew\n2. \n    - \n    - \n\nno skew\n![what is \"skew\"?](/img/camera_skew.png)\n\nslide$M$\n\n#### \n$M$\n![case 1: M](/img/case_1_m.png)\n\n#### \n$(u_0, v_0)$$M$\n![case 2: M](/img/case_2_m.png)\n\n#### \n$x$$y$$f$\n![case 3: M](/img/case_3_m.png)\n\n#### no skew\n$x$$y$\n![case 4: M](/img/case_4_m.png)\n\n#### \n\n![](/img/camera_translation_rotation.png)\n\n3D$H$$H\\in \\mathbb{R}^{3\\times 4}$\n$$P^\\prime = MHP$$\n\n$\\mathbb{0}$\n![case 5: M](/img/case_m_5.png)\n\n\n![](/img/rotation_matrix.png)\n\n\n![case 6: M](/img/case_6_m.png)\n\n#### \n\n![](/img/generic_projection_matrix.png)\n\n5633\n\n\n![things to remember](/img/camera_model_things_to_remember.png)\n\n## \n\n### \n$O$$O^{'}$$P$\n\n![](/img/epipolar_fig.png)\n\n- $e$$e^\\prime$$OO^\\prime$\n- $O$$O^\\prime$$P$\n- $pe$$p^\\prime e^\\prime$\n- \n\n### \n\n\n$P$$p^\\prime$$M$$M^\\prime$$R$$T$$OO^\\prime$\n![1](/img/epipolar_constraint_1.png)\n\n[4](http://www.cnblogs.com/gemstone/articles/2294551.html)$p^\\prime$$O^\\prime$$O\\prime P$$p$\n$R(p-T) = p^\\prime$\n","slug":"cs131-camera","published":1,"updated":"2018-10-27T07:16:52.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8if000gae7b9ggg7go8","content":"<p>3D2D3D<br><img src=\"/img/camera_geometry_application.png\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"Pinhole-Camera\"><a href=\"#Pinhole-Camera\" class=\"headerlink\" title=\"Pinhole Camera\"></a>Pinhole Camera</h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Projective Geometry</p>\n<p><br><img src=\"/img/projective_geometry_property_1.png\" alt=\"1\"></p>\n<p>3DVanishing point3D2DVanishing pointVanishing point<br><img src=\"/img/projective_geometry_property_2.png\" alt=\"2\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$P$$O$$\\Pi^\\prime$$P^\\prime$<br><img src=\"/img/pinhole_camera_model.png\" alt=\"\"></p>\n<p>3D$P$$P^\\prime$</p>\n<script type=\"math/tex; mode=display\">\\left\\{\\begin{matrix}\nx^\\prime = fx/z \\\\\ny^\\prime = fy/z\n\\end{matrix}\\right.</script><p>$z$$z$<br><img src=\"/img/qicizuobiao.png\" alt=\"\"></p>\n<p>3D2D3D4112D$M$$f$<br><img src=\"/img/qicizuobiao_transform.png\" alt=\"\"></p>\n<p></p>\n<ol>\n<li><ul>\n<li></li>\n<li>$(0, 0)$</li>\n<li>no skew</li>\n</ul>\n</li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<p>no skew<br><img src=\"/img/camera_skew.png\" alt=\"what is &quot;skew&quot;?\"></p>\n<p>slide$M$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$M$<br><img src=\"/img/case_1_m.png\" alt=\"case 1: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$(u_0, v_0)$$M$<br><img src=\"/img/case_2_m.png\" alt=\"case 2: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$x$$y$$f$<br><img src=\"/img/case_3_m.png\" alt=\"case 3: M\"></p>\n<h4 id=\"no-skew\"><a href=\"#no-skew\" class=\"headerlink\" title=\"no skew\"></a>no skew</h4><p>$x$$y$<br><img src=\"/img/case_4_m.png\" alt=\"case 4: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p><br><img src=\"/img/camera_translation_rotation.png\" alt=\"\"></p>\n<p>3D$H$$H\\in \\mathbb{R}^{3\\times 4}$</p>\n<script type=\"math/tex; mode=display\">P^\\prime = MHP</script><p>$\\mathbb{0}$<br><img src=\"/img/case_m_5.png\" alt=\"case 5: M\"></p>\n<p><br><img src=\"/img/rotation_matrix.png\" alt=\"\"></p>\n<p><br><img src=\"/img/case_6_m.png\" alt=\"case 6: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p><br><img src=\"/img/generic_projection_matrix.png\" alt=\"\"></p>\n<p>5633</p>\n<p><br><img src=\"/img/camera_model_things_to_remember.png\" alt=\"things to remember\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O$$O^{}$$P$</p>\n<p><img src=\"/img/epipolar_fig.png\" alt=\"\"></p>\n<ul>\n<li>$e$$e^\\prime$$OO^\\prime$</li>\n<li>$O$$O^\\prime$$P$</li>\n<li>$pe$$p^\\prime e^\\prime$</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$P$$p^\\prime$$M$$M^\\prime$$R$$T$$OO^\\prime$<br><img src=\"/img/epipolar_constraint_1.png\" alt=\"1\"></p>\n<p><a href=\"http://www.cnblogs.com/gemstone/articles/2294551.html\" target=\"_blank\" rel=\"external\">4</a>$p^\\prime$$O^\\prime$$O\\prime P$$p$<br>$R(p-T) = p^\\prime$</p>\n","excerpt":"<p>3D2D3D<br><img src=\"/img/camera_geometry_application.png\" alt=\"\"><br>","more":"</p>\n<h2 id=\"Pinhole-Camera\"><a href=\"#Pinhole-Camera\" class=\"headerlink\" title=\"Pinhole Camera\"></a>Pinhole Camera</h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Projective Geometry</p>\n<p><br><img src=\"/img/projective_geometry_property_1.png\" alt=\"1\"></p>\n<p>3DVanishing point3D2DVanishing pointVanishing point<br><img src=\"/img/projective_geometry_property_2.png\" alt=\"2\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$P$$O$$\\Pi^\\prime$$P^\\prime$<br><img src=\"/img/pinhole_camera_model.png\" alt=\"\"></p>\n<p>3D$P$$P^\\prime$</p>\n<script type=\"math/tex; mode=display\">\\left\\{\\begin{matrix}\nx^\\prime = fx/z \\\\\ny^\\prime = fy/z\n\\end{matrix}\\right.</script><p>$z$$z$<br><img src=\"/img/qicizuobiao.png\" alt=\"\"></p>\n<p>3D2D3D4112D$M$$f$<br><img src=\"/img/qicizuobiao_transform.png\" alt=\"\"></p>\n<p></p>\n<ol>\n<li><ul>\n<li></li>\n<li>$(0, 0)$</li>\n<li>no skew</li>\n</ul>\n</li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<p>no skew<br><img src=\"/img/camera_skew.png\" alt=\"what is &quot;skew&quot;?\"></p>\n<p>slide$M$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$M$<br><img src=\"/img/case_1_m.png\" alt=\"case 1: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$(u_0, v_0)$$M$<br><img src=\"/img/case_2_m.png\" alt=\"case 2: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$x$$y$$f$<br><img src=\"/img/case_3_m.png\" alt=\"case 3: M\"></p>\n<h4 id=\"no-skew\"><a href=\"#no-skew\" class=\"headerlink\" title=\"no skew\"></a>no skew</h4><p>$x$$y$<br><img src=\"/img/case_4_m.png\" alt=\"case 4: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p><br><img src=\"/img/camera_translation_rotation.png\" alt=\"\"></p>\n<p>3D$H$$H\\in \\mathbb{R}^{3\\times 4}$</p>\n<script type=\"math/tex; mode=display\">P^\\prime = MHP</script><p>$\\mathbb{0}$<br><img src=\"/img/case_m_5.png\" alt=\"case 5: M\"></p>\n<p><br><img src=\"/img/rotation_matrix.png\" alt=\"\"></p>\n<p><br><img src=\"/img/case_6_m.png\" alt=\"case 6: M\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p><br><img src=\"/img/generic_projection_matrix.png\" alt=\"\"></p>\n<p>5633</p>\n<p><br><img src=\"/img/camera_model_things_to_remember.png\" alt=\"things to remember\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O$$O^{}$$P$</p>\n<p><img src=\"/img/epipolar_fig.png\" alt=\"\"></p>\n<ul>\n<li>$e$$e^\\prime$$OO^\\prime$</li>\n<li>$O$$O^\\prime$$P$</li>\n<li>$pe$$p^\\prime e^\\prime$</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$P$$p^\\prime$$M$$M^\\prime$$R$$T$$OO^\\prime$<br><img src=\"/img/epipolar_constraint_1.png\" alt=\"1\"></p>\n<p><a href=\"http://www.cnblogs.com/gemstone/articles/2294551.html\">4</a>$p^\\prime$$O^\\prime$$O\\prime P$$p$<br>$R(p-T) = p^\\prime$</p>"},{"title":"CS131-","date":"2017-01-24T02:42:47.000Z","_content":"(Edge)\n\n![](/img/edge_camera_man.png)\n<!-- more -->\n## \n\n- \n- \n- \n\n## \n\n![](/img/edge_deriative.png)\n\n\n\n$x$$g_x = \\frac{\\partial f}{\\partial x}$$y$$g_y = \\frac{\\partial f}{\\partial y}$\n$$g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)$$\n\nSobel\n\n\n![](/img/fun_noise.png)\n\n## 1\n1\n\n$$\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g$$\n\nDoG(Deriative of Gaussian)$x$DoG\n![xDoG](/img/dog_x.png)\n\n\n![](/img/dog_different_size.png)\n\n## 2Canny\n2CannyCanny\n- DoG\n- $q$$p$$r$\n- $p$$r$$s$edge linking\n\n![nms](/img/canny_nms.png)\n![linking](/img/canny_linking.png)\n\nCanny`low``high`********edge linking`low`\n\n## 3RANSAC\nRANSAC\n\nRANSACfeature****featuremodelfeaturefeaturemodel\n\nRANSAC1\n![ransac step](/img/ransac_step.png)\n\nRANSAC\n![ransac line fit alg](/img/ransac_line_fit.png)\n\nRANSAC$y = 2x+1$\n\nRANSAC\n``` bash\nleast square: a = 3.319566, b = -1.446528\nransac method: a = 1.899640, b= 1.298608\n```\n![demo result](/img/line_fit_demo.png)\n\nMATLAB\n``` matlab\n%% generate data\nx = 0:1:10;\ny_gt = 2*x+1;\ny = y_gt + randn(size(y_gt));\nscatter(x, y, [], [1,0,0]);\nhold on\nout_x = 0:1:10;\nout_y = 5*rand(size(out_x)).*out_x + 4*rand(size(out_x));\nscatter(out_x, out_y, [], [0,0,1]);\nX = [x, out_x]';\nY = [y, out_y]';\nX = [X, ones(length(X), 1)];\n[a, b] = ls_fit(X, Y);\nplot(x, a*x+b, 'linestyle', '--', 'color', 'r');\n\n[ra, rb] = ransac_fit(X, Y, 100, 2, 0.5, 3);\nplot(x, ra*x+rb, 'linestyle', '-.', 'color', 'g');\nfprintf('least square: a = %f, b = %f\\n',a, b);\nfprintf('ransac method: a = %f, b= %f\\n', ra, rb)\nfunction [a, b] = ransac_fit(X, Y, k, n, t ,d)\n% ransac fit\n% k -- maximum iteration number\n% n -- smallest point numer required\n% t -- threshold to identify a point is fit well\n% d -- the number of nearby points to assert a model is fine\ndata = [X, Y];\nN = size(data, 1);\nbest_good_cnt = -1;\nbest_a = 0;\nbest_b = 0;\nfor i = 1:k\n    % sample point\n    idx = randsample(N, n);\n    data_sampled = data(idx, :);\n    % fit with least square\n    [a, b] = ls_fit(data_sampled(:, 1:2), data_sampled(:, 3));\n    % test model\n    not_sampled = ones(N, 1);\n    not_sampled(idx) = 0;\n    not_sampled_data = data(not_sampled == 1, :);\n    distance = abs(not_sampled_data(:, 1:2) * [a; b] - not_sampled_data(:, 3)) / sqrt(a^2+1);\n    inner_flag = distance < t;\n    good_cnt = sum(inner_flag);\n    if good_cnt >= d && good_cnt > best_good_cnt\n        best_good_cnt = good_cnt;\n        data_refine = data(find(inner_flag), :);\n        [a, b] = ls_fit(data_refine(:, 1:2), data_refine(:, 3));\n        best_a = a;\n        best_b = b;\n    end\n    fprintf('iteration %d, best_a = %f, best_b = %f\\n', i, best_a, best_b);\nend\na = best_a;\nb = best_b;\nend\n\nfunction [a, b] = ls_fit(X, Y)\n% least square fit\nA = X'*X\\X'*Y;\na = A(1);\nb = A(2);\nend\n```\n\nRANSAC$k$\n\n$\\omega$$n$demo$n=2$$\\omega^n$$n$$k$0$(1-\\omega^n)^k$1$k$$n$$\\omega$0.99$k$\n![k](/img/ransac_k.png)\n\nRANSAC$k$Hough\n","source":"_posts/cs131-edge-detection.md","raw":"---\ntitle: CS131-\ndate: 2017-01-24 10:42:47\ntags:\n     - cs131\n     - \n---\n(Edge)\n\n![](/img/edge_camera_man.png)\n<!-- more -->\n## \n\n- \n- \n- \n\n## \n\n![](/img/edge_deriative.png)\n\n\n\n$x$$g_x = \\frac{\\partial f}{\\partial x}$$y$$g_y = \\frac{\\partial f}{\\partial y}$\n$$g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)$$\n\nSobel\n\n\n![](/img/fun_noise.png)\n\n## 1\n1\n\n$$\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g$$\n\nDoG(Deriative of Gaussian)$x$DoG\n![xDoG](/img/dog_x.png)\n\n\n![](/img/dog_different_size.png)\n\n## 2Canny\n2CannyCanny\n- DoG\n- $q$$p$$r$\n- $p$$r$$s$edge linking\n\n![nms](/img/canny_nms.png)\n![linking](/img/canny_linking.png)\n\nCanny`low``high`********edge linking`low`\n\n## 3RANSAC\nRANSAC\n\nRANSACfeature****featuremodelfeaturefeaturemodel\n\nRANSAC1\n![ransac step](/img/ransac_step.png)\n\nRANSAC\n![ransac line fit alg](/img/ransac_line_fit.png)\n\nRANSAC$y = 2x+1$\n\nRANSAC\n``` bash\nleast square: a = 3.319566, b = -1.446528\nransac method: a = 1.899640, b= 1.298608\n```\n![demo result](/img/line_fit_demo.png)\n\nMATLAB\n``` matlab\n%% generate data\nx = 0:1:10;\ny_gt = 2*x+1;\ny = y_gt + randn(size(y_gt));\nscatter(x, y, [], [1,0,0]);\nhold on\nout_x = 0:1:10;\nout_y = 5*rand(size(out_x)).*out_x + 4*rand(size(out_x));\nscatter(out_x, out_y, [], [0,0,1]);\nX = [x, out_x]';\nY = [y, out_y]';\nX = [X, ones(length(X), 1)];\n[a, b] = ls_fit(X, Y);\nplot(x, a*x+b, 'linestyle', '--', 'color', 'r');\n\n[ra, rb] = ransac_fit(X, Y, 100, 2, 0.5, 3);\nplot(x, ra*x+rb, 'linestyle', '-.', 'color', 'g');\nfprintf('least square: a = %f, b = %f\\n',a, b);\nfprintf('ransac method: a = %f, b= %f\\n', ra, rb)\nfunction [a, b] = ransac_fit(X, Y, k, n, t ,d)\n% ransac fit\n% k -- maximum iteration number\n% n -- smallest point numer required\n% t -- threshold to identify a point is fit well\n% d -- the number of nearby points to assert a model is fine\ndata = [X, Y];\nN = size(data, 1);\nbest_good_cnt = -1;\nbest_a = 0;\nbest_b = 0;\nfor i = 1:k\n    % sample point\n    idx = randsample(N, n);\n    data_sampled = data(idx, :);\n    % fit with least square\n    [a, b] = ls_fit(data_sampled(:, 1:2), data_sampled(:, 3));\n    % test model\n    not_sampled = ones(N, 1);\n    not_sampled(idx) = 0;\n    not_sampled_data = data(not_sampled == 1, :);\n    distance = abs(not_sampled_data(:, 1:2) * [a; b] - not_sampled_data(:, 3)) / sqrt(a^2+1);\n    inner_flag = distance < t;\n    good_cnt = sum(inner_flag);\n    if good_cnt >= d && good_cnt > best_good_cnt\n        best_good_cnt = good_cnt;\n        data_refine = data(find(inner_flag), :);\n        [a, b] = ls_fit(data_refine(:, 1:2), data_refine(:, 3));\n        best_a = a;\n        best_b = b;\n    end\n    fprintf('iteration %d, best_a = %f, best_b = %f\\n', i, best_a, best_b);\nend\na = best_a;\nb = best_b;\nend\n\nfunction [a, b] = ls_fit(X, Y)\n% least square fit\nA = X'*X\\X'*Y;\na = A(1);\nb = A(2);\nend\n```\n\nRANSAC$k$\n\n$\\omega$$n$demo$n=2$$\\omega^n$$n$$k$0$(1-\\omega^n)^k$1$k$$n$$\\omega$0.99$k$\n![k](/img/ransac_k.png)\n\nRANSAC$k$Hough\n","slug":"cs131-edge-detection","published":1,"updated":"2018-10-27T07:16:52.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8im000lae7bryi7n7l5","content":"<p>(Edge)</p>\n<p><img src=\"/img/edge_camera_man.png\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><img src=\"/img/edge_deriative.png\" alt=\"\"></p>\n<p></p>\n<p>$x$$g_x = \\frac{\\partial f}{\\partial x}$$y$$g_y = \\frac{\\partial f}{\\partial y}$</p>\n<script type=\"math/tex; mode=display\">g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)</script><p>Sobel</p>\n<p><br><img src=\"/img/fun_noise.png\" alt=\"\"></p>\n<h2 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h2><p>1</p>\n<script type=\"math/tex; mode=display\">\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g</script><p>DoG(Deriative of Gaussian)$x$DoG<br><img src=\"/img/dog_x.png\" alt=\"xDoG\"></p>\n<p><br><img src=\"/img/dog_different_size.png\" alt=\"\"></p>\n<h2 id=\"2Canny\"><a href=\"#2Canny\" class=\"headerlink\" title=\"2Canny\"></a>2Canny</h2><p>2CannyCanny</p>\n<ul>\n<li>DoG</li>\n<li>$q$$p$$r$</li>\n<li>$p$$r$$s$edge linking</li>\n</ul>\n<p><img src=\"/img/canny_nms.png\" alt=\"nms\"><br><img src=\"/img/canny_linking.png\" alt=\"linking\"></p>\n<p>Canny<code>low</code><code>high</code><strong></strong><strong></strong>edge linking<code>low</code></p>\n<h2 id=\"3RANSAC\"><a href=\"#3RANSAC\" class=\"headerlink\" title=\"3RANSAC\"></a>3RANSAC</h2><p>RANSAC</p>\n<p>RANSACfeature<strong></strong>featuremodelfeaturefeaturemodel</p>\n<p>RANSAC1<br><img src=\"/img/ransac_step.png\" alt=\"ransac step\"></p>\n<p>RANSAC<br><img src=\"/img/ransac_line_fit.png\" alt=\"ransac line fit alg\"></p>\n<p>RANSAC$y = 2x+1$</p>\n<p>RANSAC<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">least square: a = 3.319566, b = -1.446528</div><div class=\"line\">ransac method: a = 1.899640, b= 1.298608</div></pre></td></tr></table></figure></p>\n<p><img src=\"/img/line_fit_demo.png\" alt=\"demo result\"></p>\n<p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">y_gt = <span class=\"number\">2</span>*x+<span class=\"number\">1</span>;</div><div class=\"line\">y = y_gt + <span class=\"built_in\">randn</span>(<span class=\"built_in\">size</span>(y_gt));</div><div class=\"line\">scatter(x, y, [], [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>]);</div><div class=\"line\">hold on</div><div class=\"line\">out_x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">out_y = <span class=\"number\">5</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x)).*out_x + <span class=\"number\">4</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x));</div><div class=\"line\">scatter(out_x, out_y, [], [<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]);</div><div class=\"line\">X = [x, out_x]';</div><div class=\"line\">Y = [y, out_y]';</div><div class=\"line\">X = [X, ones(length(X), <span class=\"number\">1</span>)];</div><div class=\"line\">[a, b] = ls_fit(X, Y);</div><div class=\"line\">plot(x, a*x+b, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'--'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'r'</span>);</div><div class=\"line\"></div><div class=\"line\">[ra, rb] = ransac_fit(X, Y, <span class=\"number\">100</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>, <span class=\"number\">3</span>);</div><div class=\"line\">plot(x, ra*x+rb, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'-.'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\">fprintf(<span class=\"string\">'least square: a = %f, b = %f\\n'</span>,a, b);</div><div class=\"line\">fprintf(<span class=\"string\">'ransac method: a = %f, b= %f\\n'</span>, ra, rb)</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ransac_fit</span><span class=\"params\">(X, Y, k, n, t ,d)</span></span></div><div class=\"line\"><span class=\"comment\">% ransac fit</span></div><div class=\"line\"><span class=\"comment\">% k -- maximum iteration number</span></div><div class=\"line\"><span class=\"comment\">% n -- smallest point numer required</span></div><div class=\"line\"><span class=\"comment\">% t -- threshold to identify a point is fit well</span></div><div class=\"line\"><span class=\"comment\">% d -- the number of nearby points to assert a model is fine</span></div><div class=\"line\">data = [X, Y];</div><div class=\"line\">N = <span class=\"built_in\">size</span>(data, <span class=\"number\">1</span>);</div><div class=\"line\">best_good_cnt = <span class=\"number\">-1</span>;</div><div class=\"line\">best_a = <span class=\"number\">0</span>;</div><div class=\"line\">best_b = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:k</div><div class=\"line\">    <span class=\"comment\">% sample point</span></div><div class=\"line\">    idx = randsample(N, n);</div><div class=\"line\">    data_sampled = data(idx, :);</div><div class=\"line\">    <span class=\"comment\">% fit with least square</span></div><div class=\"line\">    [a, b] = ls_fit(data_sampled(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_sampled(:, <span class=\"number\">3</span>));</div><div class=\"line\">    <span class=\"comment\">% test model</span></div><div class=\"line\">    not_sampled = <span class=\"built_in\">ones</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">    not_sampled(idx) = <span class=\"number\">0</span>;</div><div class=\"line\">    not_sampled_data = data(not_sampled == <span class=\"number\">1</span>, :);</div><div class=\"line\">    distance = <span class=\"built_in\">abs</span>(not_sampled_data(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>) * [a; b] - not_sampled_data(:, <span class=\"number\">3</span>)) / <span class=\"built_in\">sqrt</span>(a^<span class=\"number\">2</span>+<span class=\"number\">1</span>);</div><div class=\"line\">    inner_flag = distance &lt; t;</div><div class=\"line\">    good_cnt = sum(inner_flag);</div><div class=\"line\">    <span class=\"keyword\">if</span> good_cnt &gt;= d &amp;&amp; good_cnt &gt; best_good_cnt</div><div class=\"line\">        best_good_cnt = good_cnt;</div><div class=\"line\">        data_refine = data(<span class=\"built_in\">find</span>(inner_flag), :);</div><div class=\"line\">        [a, b] = ls_fit(data_refine(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_refine(:, <span class=\"number\">3</span>));</div><div class=\"line\">        best_a = a;</div><div class=\"line\">        best_b = b;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'iteration %d, best_a = %f, best_b = %f\\n'</span>, <span class=\"built_in\">i</span>, best_a, best_b);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">a = best_a;</div><div class=\"line\">b = best_b;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ls_fit</span><span class=\"params\">(X, Y)</span></span></div><div class=\"line\"><span class=\"comment\">% least square fit</span></div><div class=\"line\">A = X'*X\\X'*Y;</div><div class=\"line\">a = A(<span class=\"number\">1</span>);</div><div class=\"line\">b = A(<span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>RANSAC$k$</p>\n<p>$\\omega$$n$demo$n=2$$\\omega^n$$n$$k$0$(1-\\omega^n)^k$1$k$$n$$\\omega$0.99$k$<br><img src=\"/img/ransac_k.png\" alt=\"k\"></p>\n<p>RANSAC$k$Hough</p>\n","excerpt":"<p>(Edge)</p>\n<p><img src=\"/img/edge_camera_man.png\" alt=\"\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><img src=\"/img/edge_deriative.png\" alt=\"\"></p>\n<p></p>\n<p>$x$$g_x = \\frac{\\partial f}{\\partial x}$$y$$g_y = \\frac{\\partial f}{\\partial y}$</p>\n<script type=\"math/tex; mode=display\">g = \\lbrack g_x, g_y\\rbrack, \\theta = \\arctan(g_y/g_x)</script><p>Sobel</p>\n<p><br><img src=\"/img/fun_noise.png\" alt=\"\"></p>\n<h2 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h2><p>1</p>\n<script type=\"math/tex; mode=display\">\\frac{d}{dx}(f\\ast g) = f\\ast\\frac{d}{dx}g</script><p>DoG(Deriative of Gaussian)$x$DoG<br><img src=\"/img/dog_x.png\" alt=\"xDoG\"></p>\n<p><br><img src=\"/img/dog_different_size.png\" alt=\"\"></p>\n<h2 id=\"2Canny\"><a href=\"#2Canny\" class=\"headerlink\" title=\"2Canny\"></a>2Canny</h2><p>2CannyCanny</p>\n<ul>\n<li>DoG</li>\n<li>$q$$p$$r$</li>\n<li>$p$$r$$s$edge linking</li>\n</ul>\n<p><img src=\"/img/canny_nms.png\" alt=\"nms\"><br><img src=\"/img/canny_linking.png\" alt=\"linking\"></p>\n<p>Canny<code>low</code><code>high</code><strong></strong><strong></strong>edge linking<code>low</code></p>\n<h2 id=\"3RANSAC\"><a href=\"#3RANSAC\" class=\"headerlink\" title=\"3RANSAC\"></a>3RANSAC</h2><p>RANSAC</p>\n<p>RANSACfeature<strong></strong>featuremodelfeaturefeaturemodel</p>\n<p>RANSAC1<br><img src=\"/img/ransac_step.png\" alt=\"ransac step\"></p>\n<p>RANSAC<br><img src=\"/img/ransac_line_fit.png\" alt=\"ransac line fit alg\"></p>\n<p>RANSAC$y = 2x+1$</p>\n<p>RANSAC<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">least square: a = 3.319566, b = -1.446528</div><div class=\"line\">ransac method: a = 1.899640, b= 1.298608</div></pre></td></tr></table></figure></p>\n<p><img src=\"/img/line_fit_demo.png\" alt=\"demo result\"></p>\n<p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">y_gt = <span class=\"number\">2</span>*x+<span class=\"number\">1</span>;</div><div class=\"line\">y = y_gt + <span class=\"built_in\">randn</span>(<span class=\"built_in\">size</span>(y_gt));</div><div class=\"line\">scatter(x, y, [], [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>]);</div><div class=\"line\">hold on</div><div class=\"line\">out_x = <span class=\"number\">0</span>:<span class=\"number\">1</span>:<span class=\"number\">10</span>;</div><div class=\"line\">out_y = <span class=\"number\">5</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x)).*out_x + <span class=\"number\">4</span>*<span class=\"built_in\">rand</span>(<span class=\"built_in\">size</span>(out_x));</div><div class=\"line\">scatter(out_x, out_y, [], [<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>]);</div><div class=\"line\">X = [x, out_x]';</div><div class=\"line\">Y = [y, out_y]';</div><div class=\"line\">X = [X, ones(length(X), <span class=\"number\">1</span>)];</div><div class=\"line\">[a, b] = ls_fit(X, Y);</div><div class=\"line\">plot(x, a*x+b, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'--'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'r'</span>);</div><div class=\"line\"></div><div class=\"line\">[ra, rb] = ransac_fit(X, Y, <span class=\"number\">100</span>, <span class=\"number\">2</span>, <span class=\"number\">0.5</span>, <span class=\"number\">3</span>);</div><div class=\"line\">plot(x, ra*x+rb, <span class=\"string\">'linestyle'</span>, <span class=\"string\">'-.'</span>, <span class=\"string\">'color'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\">fprintf(<span class=\"string\">'least square: a = %f, b = %f\\n'</span>,a, b);</div><div class=\"line\">fprintf(<span class=\"string\">'ransac method: a = %f, b= %f\\n'</span>, ra, rb)</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ransac_fit</span><span class=\"params\">(X, Y, k, n, t ,d)</span></span></div><div class=\"line\"><span class=\"comment\">% ransac fit</span></div><div class=\"line\"><span class=\"comment\">% k -- maximum iteration number</span></div><div class=\"line\"><span class=\"comment\">% n -- smallest point numer required</span></div><div class=\"line\"><span class=\"comment\">% t -- threshold to identify a point is fit well</span></div><div class=\"line\"><span class=\"comment\">% d -- the number of nearby points to assert a model is fine</span></div><div class=\"line\">data = [X, Y];</div><div class=\"line\">N = <span class=\"built_in\">size</span>(data, <span class=\"number\">1</span>);</div><div class=\"line\">best_good_cnt = <span class=\"number\">-1</span>;</div><div class=\"line\">best_a = <span class=\"number\">0</span>;</div><div class=\"line\">best_b = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:k</div><div class=\"line\">    <span class=\"comment\">% sample point</span></div><div class=\"line\">    idx = randsample(N, n);</div><div class=\"line\">    data_sampled = data(idx, :);</div><div class=\"line\">    <span class=\"comment\">% fit with least square</span></div><div class=\"line\">    [a, b] = ls_fit(data_sampled(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_sampled(:, <span class=\"number\">3</span>));</div><div class=\"line\">    <span class=\"comment\">% test model</span></div><div class=\"line\">    not_sampled = <span class=\"built_in\">ones</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">    not_sampled(idx) = <span class=\"number\">0</span>;</div><div class=\"line\">    not_sampled_data = data(not_sampled == <span class=\"number\">1</span>, :);</div><div class=\"line\">    distance = <span class=\"built_in\">abs</span>(not_sampled_data(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>) * [a; b] - not_sampled_data(:, <span class=\"number\">3</span>)) / <span class=\"built_in\">sqrt</span>(a^<span class=\"number\">2</span>+<span class=\"number\">1</span>);</div><div class=\"line\">    inner_flag = distance &lt; t;</div><div class=\"line\">    good_cnt = sum(inner_flag);</div><div class=\"line\">    <span class=\"keyword\">if</span> good_cnt &gt;= d &amp;&amp; good_cnt &gt; best_good_cnt</div><div class=\"line\">        best_good_cnt = good_cnt;</div><div class=\"line\">        data_refine = data(<span class=\"built_in\">find</span>(inner_flag), :);</div><div class=\"line\">        [a, b] = ls_fit(data_refine(:, <span class=\"number\">1</span>:<span class=\"number\">2</span>), data_refine(:, <span class=\"number\">3</span>));</div><div class=\"line\">        best_a = a;</div><div class=\"line\">        best_b = b;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'iteration %d, best_a = %f, best_b = %f\\n'</span>, <span class=\"built_in\">i</span>, best_a, best_b);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">a = best_a;</div><div class=\"line\">b = best_b;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[a, b]</span> = <span class=\"title\">ls_fit</span><span class=\"params\">(X, Y)</span></span></div><div class=\"line\"><span class=\"comment\">% least square fit</span></div><div class=\"line\">A = X'*X\\X'*Y;</div><div class=\"line\">a = A(<span class=\"number\">1</span>);</div><div class=\"line\">b = A(<span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>RANSAC$k$</p>\n<p>$\\omega$$n$demo$n=2$$\\omega^n$$n$$k$0$(1-\\omega^n)^k$1$k$$n$$\\omega$0.99$k$<br><img src=\"/img/ransac_k.png\" alt=\"k\"></p>\n<p>RANSAC$k$Hough</p>"},{"title":"CS131-SVD","date":"2017-01-23T04:19:05.000Z","_content":"\n$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$$c$channelchannel\n\n![SVD](/img/svd_picture.jpg)\n\n<!-- more -->\n## \nkernelkernelkernel[](http://blog.csdn.net/zouxy09/article/details/49080029)\n![](/img/convolution.png)\n\npaddingpadding\n- zero padding0\n- edge replication\n- mirror extension\n\n## 1\n### 0255\n\nkoffsetMATLAB`uint8`0255\n``` matlab\nscale_ratio = 255.0 / (max_val - min_val);\noffset = -min_val * scale_ratio;\nfixedimg = scale_ratio * dark + offset;\n```\n\n### SVD\n\nSVD\n![SVD](/img/svd_ranking.png)\n\n#### MATLAB\n1050 100k=10k\n![](/img/svd_flower.png)\n\nMATLAB\n``` matlab\n%% read image\nim = imread('./flower.bmp');\nim_gray = double(rgb2gray(im));\n[u, s, v] = svd(im_gray);\n%% get sigular value\nsigma = diag(s);\ntop_k = sigma(1:10);\nfigure\nplot(1:length(sigma), sigma, 'r-', 'marker', 's', 'markerfacecolor', 'g');\n\nfigure\nsubplot(2, 2, 1);\nimshow(uint8(im_gray));\ntitle('flower.bmp')\nindex = 2;\nfor k = [10, 50, 100]\n    uk = u(:, 1:k);\n    sk = s(1:k, 1:k);\n    vk = v(:, 1:k);\n    im_rec = uk * sk * vk';\n    subplot(2, 2, index);\n    index = index + 1;\n    imshow(uint8(im_rec));\n    title(sprintf('k = %d', k));\nend\n```\n\n#### SVD\n\n\nSVD$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$$\\mathbf{U}$$\\mathbf{V^\\dagger}$\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}\n$$\n\n\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}\n$$\n\n\n\n$$\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n$r$$k > r$$\\sigma_k = 0$\n\n$$\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n[](https://zh.wikipedia.org/wiki/)\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert$$\n\n$u_i$$v_i$1.\n\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n\n\n$$e \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n### SVD\n\n$f$\n- $f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$\n- $f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$\n- $f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$\n\n2\n$$\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}\n$$\n\n$x$2\n\n2\n\n$x$SVD\n$$(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x$$\n$U^\\dagger U = I$\n\n$V^\\dagger x$$\\omega = V\\dagger x$\n$$(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega$$\n\n2$\\Sigma \\omega$$\\omega$$\\omega$\n\n$\\Sigma$$\\omega$$\\sigma_i$\n\n$$\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}\n$$\n\n\n\n$$\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2$$\n\n$\\omega_1 = 1$, $\\omega_k = 0, k > 1$\n\n2\n\nFrobenius norm\n$$\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}$$\n\nF\n\n$$\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)$$\n\nSVD$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$\n\n\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)$$\n\n$V^\\dagger = V^{-1}$$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2$$\n\nF\n\n$$\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}$$\n","source":"_posts/cs131-filter-svd.md","raw":"---\ntitle: CS131-SVD\ndate: 2017-01-23 12:19:05\ntags:\n     - cs131\n     - \n---\n\n$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$$c$channelchannel\n\n![SVD](/img/svd_picture.jpg)\n\n<!-- more -->\n## \nkernelkernelkernel[](http://blog.csdn.net/zouxy09/article/details/49080029)\n![](/img/convolution.png)\n\npaddingpadding\n- zero padding0\n- edge replication\n- mirror extension\n\n## 1\n### 0255\n\nkoffsetMATLAB`uint8`0255\n``` matlab\nscale_ratio = 255.0 / (max_val - min_val);\noffset = -min_val * scale_ratio;\nfixedimg = scale_ratio * dark + offset;\n```\n\n### SVD\n\nSVD\n![SVD](/img/svd_ranking.png)\n\n#### MATLAB\n1050 100k=10k\n![](/img/svd_flower.png)\n\nMATLAB\n``` matlab\n%% read image\nim = imread('./flower.bmp');\nim_gray = double(rgb2gray(im));\n[u, s, v] = svd(im_gray);\n%% get sigular value\nsigma = diag(s);\ntop_k = sigma(1:10);\nfigure\nplot(1:length(sigma), sigma, 'r-', 'marker', 's', 'markerfacecolor', 'g');\n\nfigure\nsubplot(2, 2, 1);\nimshow(uint8(im_gray));\ntitle('flower.bmp')\nindex = 2;\nfor k = [10, 50, 100]\n    uk = u(:, 1:k);\n    sk = s(1:k, 1:k);\n    vk = v(:, 1:k);\n    im_rec = uk * sk * vk';\n    subplot(2, 2, index);\n    index = index + 1;\n    imshow(uint8(im_rec));\n    title(sprintf('k = %d', k));\nend\n```\n\n#### SVD\n\n\nSVD$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$$\\mathbf{U}$$\\mathbf{V^\\dagger}$\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}\n$$\n\n\n$$\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}\n$$\n\n\n\n$$\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n$r$$k > r$$\\sigma_k = 0$\n\n$$\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger$$\n\n[](https://zh.wikipedia.org/wiki/)\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert$$\n\n$u_i$$v_i$1.\n\n$$\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n\n\n$$e \\le \\sum_{i=k+1}^{r}\\sigma_i$$\n\n### SVD\n\n$f$\n- $f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$\n- $f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$\n- $f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$\n\n2\n$$\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}\n$$\n\n$x$2\n\n2\n\n$x$SVD\n$$(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x$$\n$U^\\dagger U = I$\n\n$V^\\dagger x$$\\omega = V\\dagger x$\n$$(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega$$\n\n2$\\Sigma \\omega$$\\omega$$\\omega$\n\n$\\Sigma$$\\omega$$\\sigma_i$\n\n$$\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}\n$$\n\n\n\n$$\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2$$\n\n$\\omega_1 = 1$, $\\omega_k = 0, k > 1$\n\n2\n\nFrobenius norm\n$$\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}$$\n\nF\n\n$$\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)$$\n\nSVD$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$\n\n\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)$$\n\n$V^\\dagger = V^{-1}$$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$\n$$\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2$$\n\nF\n\n$$\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}$$\n","slug":"cs131-filter-svd","published":1,"updated":"2018-10-27T07:16:52.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ir000oae7bx4hbobzt","content":"<p>$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$$c$channelchannel</p>\n<p><img src=\"/img/svd_picture.jpg\" alt=\"SVD\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>kernelkernelkernel<a href=\"http://blog.csdn.net/zouxy09/article/details/49080029\" target=\"_blank\" rel=\"external\"></a><br><img src=\"/img/convolution.png\" alt=\"\"></p>\n<p>paddingpadding</p>\n<ul>\n<li>zero padding0</li>\n<li>edge replication</li>\n<li>mirror extension</li>\n</ul>\n<h2 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h2><h3 id=\"0255\"><a href=\"#0255\" class=\"headerlink\" title=\"0255\"></a>0255</h3><p>koffsetMATLAB<code>uint8</code>0255<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">scale_ratio = <span class=\"number\">255.0</span> / (max_val - min_val);</div><div class=\"line\">offset = -min_val * scale_ratio;</div><div class=\"line\">fixedimg = scale_ratio * dark + offset;</div></pre></td></tr></table></figure></p>\n<h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>SVD<br><img src=\"/img/svd_ranking.png\" alt=\"SVD\"></p>\n<h4 id=\"MATLAB\"><a href=\"#MATLAB\" class=\"headerlink\" title=\"MATLAB\"></a>MATLAB</h4><p>1050 100k=10k<br><img src=\"/img/svd_flower.png\" alt=\"\"></p>\n<p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% read image</span></div><div class=\"line\">im = imread(<span class=\"string\">'./flower.bmp'</span>);</div><div class=\"line\">im_gray = double(rgb2gray(im));</div><div class=\"line\">[u, s, v] = svd(im_gray);</div><div class=\"line\"><span class=\"comment\">%% get sigular value</span></div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">top_k = sigma(<span class=\"number\">1</span>:<span class=\"number\">10</span>);</div><div class=\"line\">figure</div><div class=\"line\">plot(<span class=\"number\">1</span>:<span class=\"built_in\">length</span>(sigma), sigma, <span class=\"string\">'r-'</span>, <span class=\"string\">'marker'</span>, <span class=\"string\">'s'</span>, <span class=\"string\">'markerfacecolor'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\"></div><div class=\"line\">figure</div><div class=\"line\">subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>);</div><div class=\"line\">imshow(uint8(im_gray));</div><div class=\"line\">title(<span class=\"string\">'flower.bmp'</span>)</div><div class=\"line\">index = <span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> k = [<span class=\"number\">10</span>, <span class=\"number\">50</span>, <span class=\"number\">100</span>]</div><div class=\"line\">    uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    sk = s(<span class=\"number\">1</span>:k, <span class=\"number\">1</span>:k);</div><div class=\"line\">    vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    im_rec = uk * sk * vk';</div><div class=\"line\">    subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, index);</div><div class=\"line\">    index = index + <span class=\"number\">1</span>;</div><div class=\"line\">    imshow(uint8(im_rec));</div><div class=\"line\">    title(sprintf(<span class=\"string\">'k = %d'</span>, k));</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h4><p></p>\n<p>SVD$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$$\\mathbf{U}$$\\mathbf{V^\\dagger}$</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger</script><p>$r$$k &gt; r$$\\sigma_k = 0$</p>\n<p><script type=\"math/tex\">\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger</script></p>\n<p><a href=\"https://zh.wikipedia.org/wiki/\" target=\"_blank\" rel=\"external\"></a></p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert</script><p>$u_i$$v_i$1.</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i</script><p></p>\n<script type=\"math/tex; mode=display\">e \\le \\sum_{i=k+1}^{r}\\sigma_i</script><h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>$f$</p>\n<ul>\n<li>$f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$</li>\n<li>$f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$</li>\n<li>$f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$</li>\n</ul>\n<p>2</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}</script><p>$x$2</p>\n<p>2</p>\n<p>$x$SVD</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x</script><p>$U^\\dagger U = I$</p>\n<p>$V^\\dagger x$$\\omega = V\\dagger x$</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega</script><p>2$\\Sigma \\omega$$\\omega$$\\omega$</p>\n<p>$\\Sigma$$\\omega$$\\sigma_i$</p>\n<script type=\"math/tex; mode=display\">\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2</script><p>$\\omega_1 = 1$, $\\omega_k = 0, k &gt; 1$</p>\n<p>2</p>\n<p>Frobenius norm</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}</script><p>F</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)</script><p>SVD$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)</script><p>$V^\\dagger = V^{-1}$$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2</script><p>F</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}</script>","excerpt":"<p>$\\mathbb{R}^2 \\rightarrow \\mathbb{R}^c$$c$channelchannel</p>\n<p><img src=\"/img/svd_picture.jpg\" alt=\"SVD\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>kernelkernelkernel<a href=\"http://blog.csdn.net/zouxy09/article/details/49080029\"></a><br><img src=\"/img/convolution.png\" alt=\"\"></p>\n<p>paddingpadding</p>\n<ul>\n<li>zero padding0</li>\n<li>edge replication</li>\n<li>mirror extension</li>\n</ul>\n<h2 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h2><h3 id=\"0255\"><a href=\"#0255\" class=\"headerlink\" title=\"0255\"></a>0255</h3><p>koffsetMATLAB<code>uint8</code>0255<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">scale_ratio = <span class=\"number\">255.0</span> / (max_val - min_val);</div><div class=\"line\">offset = -min_val * scale_ratio;</div><div class=\"line\">fixedimg = scale_ratio * dark + offset;</div></pre></td></tr></table></figure></p>\n<h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>SVD<br><img src=\"/img/svd_ranking.png\" alt=\"SVD\"></p>\n<h4 id=\"MATLAB\"><a href=\"#MATLAB\" class=\"headerlink\" title=\"MATLAB\"></a>MATLAB</h4><p>1050 100k=10k<br><img src=\"/img/svd_flower.png\" alt=\"\"></p>\n<p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% read image</span></div><div class=\"line\">im = imread(<span class=\"string\">'./flower.bmp'</span>);</div><div class=\"line\">im_gray = double(rgb2gray(im));</div><div class=\"line\">[u, s, v] = svd(im_gray);</div><div class=\"line\"><span class=\"comment\">%% get sigular value</span></div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">top_k = sigma(<span class=\"number\">1</span>:<span class=\"number\">10</span>);</div><div class=\"line\">figure</div><div class=\"line\">plot(<span class=\"number\">1</span>:<span class=\"built_in\">length</span>(sigma), sigma, <span class=\"string\">'r-'</span>, <span class=\"string\">'marker'</span>, <span class=\"string\">'s'</span>, <span class=\"string\">'markerfacecolor'</span>, <span class=\"string\">'g'</span>);</div><div class=\"line\"></div><div class=\"line\">figure</div><div class=\"line\">subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>);</div><div class=\"line\">imshow(uint8(im_gray));</div><div class=\"line\">title(<span class=\"string\">'flower.bmp'</span>)</div><div class=\"line\">index = <span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> k = [<span class=\"number\">10</span>, <span class=\"number\">50</span>, <span class=\"number\">100</span>]</div><div class=\"line\">    uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    sk = s(<span class=\"number\">1</span>:k, <span class=\"number\">1</span>:k);</div><div class=\"line\">    vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">    im_rec = uk * sk * vk';</div><div class=\"line\">    subplot(<span class=\"number\">2</span>, <span class=\"number\">2</span>, index);</div><div class=\"line\">    index = index + <span class=\"number\">1</span>;</div><div class=\"line\">    imshow(uint8(im_rec));</div><div class=\"line\">    title(sprintf(<span class=\"string\">'k = %d'</span>, k));</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<h4 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h4><p></p>\n<p>SVD$\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V^\\dagger} = \\mathbf{A}$$\\mathbf{U}$$\\mathbf{V^\\dagger}$</p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_1^\\dagger\\\\\\\\\nv_2^\\dagger\\\\\\\\\n\\dots\\\\\\\\\nv_m^\\dagger\n\\end{bmatrix}=\\mathbf{A}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\nu_1 & u_2 &\\vdots  &u_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 &  &  & \\\\\\\\\n &  \\sigma_2&  & \\\\\\\\\n &  &  \\ddots& \\\\\\\\\n &  &  &\\sigma_m\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sigma_1u_1 & \\sigma_2u_2 &\\vdots  &\\sigma_nu_n\n\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">\\mathbf{A} = \\sum_{i = 1}^{r}\\sigma_iu_iv_i^\\dagger</script><p>$r$$k &gt; r$$\\sigma_k = 0$</p>\n<p><script type=\"math/tex\">\\mathbf{A} - \\hat{\\mathbf{A}} = \\sum_{i = k+1}^{r}\\sigma_iu_iv_i^\\dagger</script></p>\n<p><a href=\"https://zh.wikipedia.org/wiki/\"></a></p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i\\left\\lVert u_i\\right\\rVert\\left\\lVert v_i^\\dagger\\right\\rVert</script><p>$u_i$$v_i$1.</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A} - \\hat{\\mathbf{A}}\\right\\rVert \\le \\sum_{i=k+1}^{r}\\sigma_i</script><p></p>\n<script type=\"math/tex; mode=display\">e \\le \\sum_{i=k+1}^{r}\\sigma_i</script><h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>$f$</p>\n<ul>\n<li>$f(\\mathbf{A}) = \\mathbf{0} \\Leftrightarrow \\mathbf{A} = \\mathbf{0}$</li>\n<li>$f(c\\mathbf{A}) = c f(\\mathbf{A}), \\forall c \\in \\mathbb{R}$</li>\n<li>$f(\\mathbf{A+b}) \\le f(\\mathbf{A}) + f(\\mathbf{B})$</li>\n</ul>\n<p>2</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert\\mathbf{A}\\right\\rVert_2 = \\max{\\sqrt{(\\mathbf{A}x)^\\dagger\\mathbf{A}x}}</script><p>$x$2</p>\n<p>2</p>\n<p>$x$SVD</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = x^\\dagger V \\Sigma^\\dagger \\Sigma V^\\dagger x</script><p>$U^\\dagger U = I$</p>\n<p>$V^\\dagger x$$\\omega = V\\dagger x$</p>\n<script type=\"math/tex; mode=display\">(Ax)^\\dagger Ax = (\\Sigma \\omega)^\\dagger \\Sigma \\omega</script><p>2$\\Sigma \\omega$$\\omega$$\\omega$</p>\n<p>$\\Sigma$$\\omega$$\\sigma_i$</p>\n<script type=\"math/tex; mode=display\">\\Sigma \\omega =\n\\begin{bmatrix}\n\\sigma_1 \\omega_1\\\\\\\\\n\\sigma_2 \\omega_2\\\\\\\\\n\\cdots\\\\\\\\\n\\sigma_n \\omega_n\n\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">\\left\\lVert \\Sigma \\omega \\right \\rVert ^2 = \\sum_{i=1}^{n}\\sigma_i^2 \\omega_i^2 \\le \\sigma_{1} \\sum_{i=1}^{n}\\omega_i^2 = \\sigma_1^2</script><p>$\\omega_1 = 1$, $\\omega_k = 0, k &gt; 1$</p>\n<p>2</p>\n<p>Frobenius norm</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A \\right\\rVert_{F} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}\\left\\vert a_{i,j}\\right\\rvert}</script><p>F</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right \\rVert_F^2 = \\text{trace}(A^\\dagger A)</script><p>SVD$\\text{trace}(A^\\dagger A) = \\sum_{i=1}^{r}\\sigma_i^2$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(V\\Sigma^\\dagger\\Sigma V^\\dagger)</script><p>$V^\\dagger = V^{-1}$$\\text{trace}(BAB^{-1}) = \\text{trace}(A)$</p>\n<script type=\"math/tex; mode=display\">\\text{trace}(A^\\dagger A) = \\text{trace}(\\Sigma^\\dagger \\Sigma) = \\sum_{i=1}^{r}\\sigma_i^2</script><p>F</p>\n<script type=\"math/tex; mode=display\">\\left\\lVert A\\right\\rVert_F= \\sqrt{\\sum_{i=1}^{r}\\sigma_i^2}</script>"},{"title":"CS131-(Harris )","date":"2017-01-25T02:51:47.000Z","_content":"\nfeaturefeatureimage matchingmatchingSLAMfeature\n\nkey pointlocal featureHarrisSIFT\n\n![image matching example](/img/image_matching_hard.png)\n\n<!-- more -->\n\n## Harris\ncorneredgeedge\n![what is corner](/img/what_is_corner.png)\n\n[Harris](http://www.bmva.org/bmvc/1988/avc-88-023.pdf)Harris\n\n$$E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2$$\n\n$w$gaussian\n![window function](/img/corner_window_fun.png)\n\n\n$$I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v$$\n\n\n$$E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}$$\n\n\n$$M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}$$\n\n$w_{i,j} = 1$\n$$M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}$$\n\ncornerxy$I_y$$I_x=0$$I_x$$I_y = 0$\n$$M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}$$\n![M](/img/corner_type_1.png)\n\ncorner$M$\n$$M = R^{-1}\\Sigma R, \\text{}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}$$\n\n$M$000flat point$\\lambda_1$$\\lambda_2$\n![M](/img/corner_judge.png)\n\n \n $$\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$$\n![theta](/img/corner_judge_2.png)\n\ngaussian\n$$w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)$$\n","source":"_posts/cs131-finding-features.md","raw":"---\ntitle: CS131-(Harris )\ndate: 2017-01-25 10:51:47\ntags:\n    - cs131\n    - \n---\n\nfeaturefeatureimage matchingmatchingSLAMfeature\n\nkey pointlocal featureHarrisSIFT\n\n![image matching example](/img/image_matching_hard.png)\n\n<!-- more -->\n\n## Harris\ncorneredgeedge\n![what is corner](/img/what_is_corner.png)\n\n[Harris](http://www.bmva.org/bmvc/1988/avc-88-023.pdf)Harris\n\n$$E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2$$\n\n$w$gaussian\n![window function](/img/corner_window_fun.png)\n\n\n$$I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v$$\n\n\n$$E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}$$\n\n\n$$M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}$$\n\n$w_{i,j} = 1$\n$$M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}$$\n\ncornerxy$I_y$$I_x=0$$I_x$$I_y = 0$\n$$M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}$$\n![M](/img/corner_type_1.png)\n\ncorner$M$\n$$M = R^{-1}\\Sigma R, \\text{}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}$$\n\n$M$000flat point$\\lambda_1$$\\lambda_2$\n![M](/img/corner_judge.png)\n\n \n $$\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2$$\n![theta](/img/corner_judge_2.png)\n\ngaussian\n$$w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)$$\n","slug":"cs131-finding-features","published":1,"updated":"2018-10-27T07:16:52.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ix000qae7b0i2kl844","content":"<p>featurefeatureimage matchingmatchingSLAMfeature</p>\n<p>key pointlocal featureHarrisSIFT</p>\n<p><img src=\"/img/image_matching_hard.png\" alt=\"image matching example\"></p>\n<a id=\"more\"></a>\n<h2 id=\"Harris\"><a href=\"#Harris\" class=\"headerlink\" title=\"Harris\"></a>Harris</h2><p>corneredgeedge<br><img src=\"/img/what_is_corner.png\" alt=\"what is corner\"></p>\n<p><a href=\"http://www.bmva.org/bmvc/1988/avc-88-023.pdf\" target=\"_blank\" rel=\"external\">Harris</a>Harris<br></p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2</script><p>$w$gaussian<br><img src=\"/img/corner_window_fun.png\" alt=\"window function\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v</script><p></p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}</script><p>$w_{i,j} = 1$</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}</script><p>cornerxy$I_y$$I_x=0$$I_x$$I_y = 0$</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}</script><p><img src=\"/img/corner_type_1.png\" alt=\"M\"></p>\n<p>corner$M$</p>\n<script type=\"math/tex; mode=display\">M = R^{-1}\\Sigma R, \\text{}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}</script><p>$M$000flat point$\\lambda_1$$\\lambda_2$<br><img src=\"/img/corner_judge.png\" alt=\"M\"></p>\n<p> </p>\n<script type=\"math/tex; mode=display\">\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2</script><p><img src=\"/img/corner_judge_2.png\" alt=\"theta\"></p>\n<p>gaussian</p>\n<script type=\"math/tex; mode=display\">w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)</script>","excerpt":"<p>featurefeatureimage matchingmatchingSLAMfeature</p>\n<p>key pointlocal featureHarrisSIFT</p>\n<p><img src=\"/img/image_matching_hard.png\" alt=\"image matching example\"></p>","more":"<h2 id=\"Harris\"><a href=\"#Harris\" class=\"headerlink\" title=\"Harris\"></a>Harris</h2><p>corneredgeedge<br><img src=\"/img/what_is_corner.png\" alt=\"what is corner\"></p>\n<p><a href=\"http://www.bmva.org/bmvc/1988/avc-88-023.pdf\">Harris</a>Harris<br></p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_x\\sum_yw(x,y)[I(x+u, y+v) - I(x,y)]^2</script><p>$w$gaussian<br><img src=\"/img/corner_window_fun.png\" alt=\"window function\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v) = I(x,y) + I_x(x,y)u+I_y(x,y)v</script><p></p>\n<script type=\"math/tex; mode=display\">E(u,v) = \\sum_{x,y}w(I_xu+I_yv)^2 = \\begin{bmatrix}u&v\\end{bmatrix}M\\begin{bmatrix}u\\\\\\\\v\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">M = w\\begin{bmatrix}I_x^2& I_xI_y\\\\\\\\I_xI_y&I_y^2\\end{bmatrix}</script><p>$w_{i,j} = 1$</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\sum I_xI_x& \\sum I_xI_y\\\\\\\\\\sum I_xI_y&\\sum I_yI_y\\end{bmatrix} = \\sum \\begin{bmatrix}I_x \\\\\\\\I_y\\end{bmatrix}\\begin{bmatrix}I_x &I_y\\end{bmatrix}</script><p>cornerxy$I_y$$I_x=0$$I_x$$I_y = 0$</p>\n<script type=\"math/tex; mode=display\">M = \\begin{bmatrix}\\lambda_1 & 0 \\\\\\\\ 0&\\lambda_2 \\end{bmatrix}</script><p><img src=\"/img/corner_type_1.png\" alt=\"M\"></p>\n<p>corner$M$</p>\n<script type=\"math/tex; mode=display\">M = R^{-1}\\Sigma R, \\text{}\\Sigma = \\begin{bmatrix}\\lambda_1&0\\\\\\\\0&\\lambda_2\\end{bmatrix}</script><p>$M$000flat point$\\lambda_1$$\\lambda_2$<br><img src=\"/img/corner_judge.png\" alt=\"M\"></p>\n<p> </p>\n<script type=\"math/tex; mode=display\">\\theta = \\det(M)-\\alpha\\text{trace}(M)^2 = \\lambda_1\\lambda_2-\\alpha(\\lambda_1+\\lambda_2)^2</script><p><img src=\"/img/corner_judge_2.png\" alt=\"theta\"></p>\n<p>gaussian</p>\n<script type=\"math/tex; mode=display\">w(x,y) = \\exp(-(x^2+y^2)/2\\sigma^2)</script>"},{"title":"CS131-KMeans","date":"2017-02-05T15:07:00.000Z","_content":"[K-Means](https://zh.wikipedia.org/wiki/K-)n$k$Sum of Square DistanceSSD\n$$\\text{SSD} = \\sum_{i=1}^{k}\\sum_{x\\in c_i}(x-c_i)^2$$\n![K-Means Demo](/img/kmeans_demo.png)\n\n<!-- more -->\n## \nK-Means$c^\\ast$$\\delta^\\ast$$c\\_{i}^\\ast$$\\delta\\_{ij}^\\ast$$\\lbrace 0,1\\rbrace$$x_j$$i$\n\n\n$$c^\\ast, \\delta^\\ast = \\arg\\min_{c,\\delta} \\frac{1}{N}\\sum_{j=1}^{N}\\sum_{i=1}^{k}\\delta_{i,j}(c_i-x_j)^2$$\n\n$c\\_i$$\\delta\\_{i,j}$K-Means\n\nK-MeansEM\n\n## \nK-Means\n![K-Means](/img/kmeans_algorithm.png)\n\n$N$$\\lbrace x_1, \\dots, x_N\\rbrace, x_i\\in\\mathbb{R}^D$$k$\n\n$\\mu_i, i = 1,\\dots, k$\n\n## \n### \nK-Means$k$\n- kmeans++spread-out\n  $P = \\omega(x-c_i)^2$$\\omega$\n\n- \n\n### K\n$k$$k$\n\n$k$$k$$1$$4$$k$$k=2$elbow point$k$2\n![K](/img/kmeans_object_fun_vs_k.png)\n\n### \ncluster\n- \n- \n- [Kernel K-Means](http://www.public.asu.edu/~jye02/CLASSES/Fall-2005/PAPERS/kdd_spectral_kernelkmeans.pdf)\n\n### \n\n- \n- assign\n- \n\n## K-Means\nK-MeansFeature SpaceRGB1D3DFeature Space\n![1](/img/kmeans_image_seg_via_intensity.png)\n\nSpatial CoherentFeature Space\n\n2012PAMI[SLIC Superpixels Compared to State-of-the-art Superpixel Methods](https://infoscience.epfl.ch/record/177415/files/Superpixel_PAMI2011-2.pdf)K-Means\n\n## \nK-Meansconditional variancegood represention of data\n\n\n- outlieroutlierclusterK-Medians\n![outlier](/img/kmeans_sensitive_to_outlier.png)\n- clusterFuzzy K-Meanssoft assignment\n- round shapecluster\n- Spectral Clusteringkernel K-Means\n\nK-Means\n![K-Means Scaling Up](/img/kmeans_scaling_up.png)\n\n## MATLAB\nK-Means demo$K = 3$cluster$N$`scatter`\n\n`my_kmeans`kmeans`my`$K$assignmentassignment$J$\n\ndebugK-Means\n\n``` matlab\n%% generate data\nK = 3;   % number of clusters\npos = [-5, 5; 0, 1; 3, 6];  % position of cluster centers\nN = 20;    % number of data points\nR = 3;     % radius of clusters\ndata = zeros(N, 2);    % data\nclass = zeros(N, 1);   % index of cluster\n\nfor i = 1:N\n    idx = randi(3, 1);\n    dr = R*rand();\n    data(i, :) = pos(idx, :) + [dr*cos(rand()*2*pi), dr*sin(rand()*2*pi)];\n    class(i) = idx;\nend\n\n%% visualization data points\nfigure\nhold on\ncolor = [1,0,0; 0,1,0; 0,0,1];\nfor i = 1:K\n    x = data(class == i, 1);\n    y = data(class == i, 2);\n    scatter(x, y, 150, repmat(color(i,:), [length(x), 1]), 'filled');\nend\n\n%% K-Means\nbest_J = 1E100;\nbest_idx = 0;\nfor times = 1:5  % 5 times experiments to choose the best result\n    [mu, assignment, J] = my_kmeans(data, K);\n    if best_J > J\n        best_idx = times;\n        best_J = J;\n    end\n    fprintf('%d experiment: J = %f\\n', times, J);\n    disp(mu);\nend\nfprintf('best: %d experiment: J = %f\\n', best_idx, best_J);\n\n%% basic functions\nfunction J = ssd(X, mu, assignment)\n% sum of square distance\n% X -- data, N*D matrix\n% mu -- centers of clusters, K*D matrix\n% assignment -- current assignment of data to clusters\nJ = 0;\nK = size(mu, 1);\nfor k = 1:K\n    x_k = X(assignment == k, :);\n    mu_k = mu(k, :);\n    err2 = bsxfun(@minus, x_k, mu_k).^2;\n    J = J + sum(err2(:));\nend\nJ = J / size(X, 1);\nend\n\nfunction mu = compute_mu(X, assignment, K)\nmu = zeros(K, size(X, 2));\nfor k = 1:K\n    x_k = X(assignment == k, :);\n    mu(k, :) = mean(x_k, 1);\nend\nend\n\nfunction assignment = assign(X, mu)\n% assign data points to clusters\nN = size(X, 1);\nassignment = zeros(N, 1);\nfor i = 1:N\n    x = X(i, :);\n    err2 = bsxfun(@minus, x, mu).^2;\n    dis = sum(err2, 2);\n    [~, idx] = min(dis);\n    assignment(i) = idx;\nend\nend\n\nfunction [mu, assignment, J] = my_kmeans(X, K)\nN = size(X, 1);\nassignment = zeros(N, 1);\nidx = randsample(N, K);\nmu = X(idx, :);\n\n% for i = 1:K\n%     for j = 1:N\n%         if assignment_gt(j) == i\n%             mu(i,:) = X(j,:);\n%             break;\n%         end\n%     end\n% end\nfigure\nhold on\ncolor = [1,0,0; 0,1,0; 0,0,1];\nscatter(mu(:,1), mu(:,2), 200, color, 'd');\nfor iter = 1:20\n    assignment_prev = assignment;\n    assignment = assign(X, mu);\n    if assignment == assignment_prev\n        break;\n    end\n    mu_prev = mu;\n    mu = compute_mu(X, assignment, K);\n    scatter(mu(:, 1), mu(:, 2), 200, color, 'd');\n    MU = zeros(2*K, 2);\n    MU(1:2:end, :) = mu_prev;\n    MU(2:2:end, :) = mu;\n    mu_x = reshape(MU(:, 1), [], K);\n    mu_y = reshape(MU(:, 2), [], K);\n    plot(mu_x, mu_y, 'k-.');\n\nend\nfor i = 1:K\n    x = X(assignment == i, 1);\n    y = X(assignment == i, 2);\n    scatter(x, y, 150, repmat(color(i,:), [length(x), 1]), 'filled');\nend\nJ = ssd(X, mu, assignment);\nend\n```\n\ndemo$5$cluster\n![K-Means](/img/kmeans_data_demo.png)\n\nclusterclustercluster\n\n![K-Means](/img/kmeans_success.png)\n\n~\n![](/img/kmeans_bigger_demo.png)\n## PS\ntipMarkdownLaTexMarkdown\n```\n$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$\n```\n$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$\n\n\n```\n$c\\_{i}^\\ast$ XXX $\\delta\\_{ij}^\\ast$\n```\n$c\\_{i}^\\ast$ XXX $\\delta\\_{ij}^\\ast$\n\n[](http://lukang.me/2014/mathjax-for-hexo.html)\n","source":"_posts/cs131-kmeans.md","raw":"---\ntitle: CS131-KMeans\ndate: 2017-02-05 23:07:00\ntags:\n    - cs131\n    - \n---\n[K-Means](https://zh.wikipedia.org/wiki/K-)n$k$Sum of Square DistanceSSD\n$$\\text{SSD} = \\sum_{i=1}^{k}\\sum_{x\\in c_i}(x-c_i)^2$$\n![K-Means Demo](/img/kmeans_demo.png)\n\n<!-- more -->\n## \nK-Means$c^\\ast$$\\delta^\\ast$$c\\_{i}^\\ast$$\\delta\\_{ij}^\\ast$$\\lbrace 0,1\\rbrace$$x_j$$i$\n\n\n$$c^\\ast, \\delta^\\ast = \\arg\\min_{c,\\delta} \\frac{1}{N}\\sum_{j=1}^{N}\\sum_{i=1}^{k}\\delta_{i,j}(c_i-x_j)^2$$\n\n$c\\_i$$\\delta\\_{i,j}$K-Means\n\nK-MeansEM\n\n## \nK-Means\n![K-Means](/img/kmeans_algorithm.png)\n\n$N$$\\lbrace x_1, \\dots, x_N\\rbrace, x_i\\in\\mathbb{R}^D$$k$\n\n$\\mu_i, i = 1,\\dots, k$\n\n## \n### \nK-Means$k$\n- kmeans++spread-out\n  $P = \\omega(x-c_i)^2$$\\omega$\n\n- \n\n### K\n$k$$k$\n\n$k$$k$$1$$4$$k$$k=2$elbow point$k$2\n![K](/img/kmeans_object_fun_vs_k.png)\n\n### \ncluster\n- \n- \n- [Kernel K-Means](http://www.public.asu.edu/~jye02/CLASSES/Fall-2005/PAPERS/kdd_spectral_kernelkmeans.pdf)\n\n### \n\n- \n- assign\n- \n\n## K-Means\nK-MeansFeature SpaceRGB1D3DFeature Space\n![1](/img/kmeans_image_seg_via_intensity.png)\n\nSpatial CoherentFeature Space\n\n2012PAMI[SLIC Superpixels Compared to State-of-the-art Superpixel Methods](https://infoscience.epfl.ch/record/177415/files/Superpixel_PAMI2011-2.pdf)K-Means\n\n## \nK-Meansconditional variancegood represention of data\n\n\n- outlieroutlierclusterK-Medians\n![outlier](/img/kmeans_sensitive_to_outlier.png)\n- clusterFuzzy K-Meanssoft assignment\n- round shapecluster\n- Spectral Clusteringkernel K-Means\n\nK-Means\n![K-Means Scaling Up](/img/kmeans_scaling_up.png)\n\n## MATLAB\nK-Means demo$K = 3$cluster$N$`scatter`\n\n`my_kmeans`kmeans`my`$K$assignmentassignment$J$\n\ndebugK-Means\n\n``` matlab\n%% generate data\nK = 3;   % number of clusters\npos = [-5, 5; 0, 1; 3, 6];  % position of cluster centers\nN = 20;    % number of data points\nR = 3;     % radius of clusters\ndata = zeros(N, 2);    % data\nclass = zeros(N, 1);   % index of cluster\n\nfor i = 1:N\n    idx = randi(3, 1);\n    dr = R*rand();\n    data(i, :) = pos(idx, :) + [dr*cos(rand()*2*pi), dr*sin(rand()*2*pi)];\n    class(i) = idx;\nend\n\n%% visualization data points\nfigure\nhold on\ncolor = [1,0,0; 0,1,0; 0,0,1];\nfor i = 1:K\n    x = data(class == i, 1);\n    y = data(class == i, 2);\n    scatter(x, y, 150, repmat(color(i,:), [length(x), 1]), 'filled');\nend\n\n%% K-Means\nbest_J = 1E100;\nbest_idx = 0;\nfor times = 1:5  % 5 times experiments to choose the best result\n    [mu, assignment, J] = my_kmeans(data, K);\n    if best_J > J\n        best_idx = times;\n        best_J = J;\n    end\n    fprintf('%d experiment: J = %f\\n', times, J);\n    disp(mu);\nend\nfprintf('best: %d experiment: J = %f\\n', best_idx, best_J);\n\n%% basic functions\nfunction J = ssd(X, mu, assignment)\n% sum of square distance\n% X -- data, N*D matrix\n% mu -- centers of clusters, K*D matrix\n% assignment -- current assignment of data to clusters\nJ = 0;\nK = size(mu, 1);\nfor k = 1:K\n    x_k = X(assignment == k, :);\n    mu_k = mu(k, :);\n    err2 = bsxfun(@minus, x_k, mu_k).^2;\n    J = J + sum(err2(:));\nend\nJ = J / size(X, 1);\nend\n\nfunction mu = compute_mu(X, assignment, K)\nmu = zeros(K, size(X, 2));\nfor k = 1:K\n    x_k = X(assignment == k, :);\n    mu(k, :) = mean(x_k, 1);\nend\nend\n\nfunction assignment = assign(X, mu)\n% assign data points to clusters\nN = size(X, 1);\nassignment = zeros(N, 1);\nfor i = 1:N\n    x = X(i, :);\n    err2 = bsxfun(@minus, x, mu).^2;\n    dis = sum(err2, 2);\n    [~, idx] = min(dis);\n    assignment(i) = idx;\nend\nend\n\nfunction [mu, assignment, J] = my_kmeans(X, K)\nN = size(X, 1);\nassignment = zeros(N, 1);\nidx = randsample(N, K);\nmu = X(idx, :);\n\n% for i = 1:K\n%     for j = 1:N\n%         if assignment_gt(j) == i\n%             mu(i,:) = X(j,:);\n%             break;\n%         end\n%     end\n% end\nfigure\nhold on\ncolor = [1,0,0; 0,1,0; 0,0,1];\nscatter(mu(:,1), mu(:,2), 200, color, 'd');\nfor iter = 1:20\n    assignment_prev = assignment;\n    assignment = assign(X, mu);\n    if assignment == assignment_prev\n        break;\n    end\n    mu_prev = mu;\n    mu = compute_mu(X, assignment, K);\n    scatter(mu(:, 1), mu(:, 2), 200, color, 'd');\n    MU = zeros(2*K, 2);\n    MU(1:2:end, :) = mu_prev;\n    MU(2:2:end, :) = mu;\n    mu_x = reshape(MU(:, 1), [], K);\n    mu_y = reshape(MU(:, 2), [], K);\n    plot(mu_x, mu_y, 'k-.');\n\nend\nfor i = 1:K\n    x = X(assignment == i, 1);\n    y = X(assignment == i, 2);\n    scatter(x, y, 150, repmat(color(i,:), [length(x), 1]), 'filled');\nend\nJ = ssd(X, mu, assignment);\nend\n```\n\ndemo$5$cluster\n![K-Means](/img/kmeans_data_demo.png)\n\nclusterclustercluster\n\n![K-Means](/img/kmeans_success.png)\n\n~\n![](/img/kmeans_bigger_demo.png)\n## PS\ntipMarkdownLaTexMarkdown\n```\n$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$\n```\n$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$\n\n\n```\n$c\\_{i}^\\ast$ XXX $\\delta\\_{ij}^\\ast$\n```\n$c\\_{i}^\\ast$ XXX $\\delta\\_{ij}^\\ast$\n\n[](http://lukang.me/2014/mathjax-for-hexo.html)\n","slug":"cs131-kmeans","published":1,"updated":"2018-10-27T07:16:52.383Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8j0000sae7bkcjecorl","content":"<p><a href=\"https://zh.wikipedia.org/wiki/K-\" target=\"_blank\" rel=\"external\">K-Means</a>n$k$Sum of Square DistanceSSD</p>\n<script type=\"math/tex; mode=display\">\\text{SSD} = \\sum_{i=1}^{k}\\sum_{x\\in c_i}(x-c_i)^2</script><p><img src=\"/img/kmeans_demo.png\" alt=\"K-Means Demo\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Means$c^\\ast$$\\delta^\\ast$$c_{i}^\\ast$$\\delta_{ij}^\\ast$$\\lbrace 0,1\\rbrace$$x_j$$i$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">c^\\ast, \\delta^\\ast = \\arg\\min_{c,\\delta} \\frac{1}{N}\\sum_{j=1}^{N}\\sum_{i=1}^{k}\\delta_{i,j}(c_i-x_j)^2</script><p>$c_i$$\\delta_{i,j}$K-Means</p>\n<p>K-MeansEM</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Means<br><img src=\"/img/kmeans_algorithm.png\" alt=\"K-Means\"></p>\n<p>$N$$\\lbrace x_1, \\dots, x_N\\rbrace, x_i\\in\\mathbb{R}^D$$k$</p>\n<p>$\\mu_i, i = 1,\\dots, k$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>K-Means$k$</p>\n<ul>\n<li><p>kmeans++spread-out<br>$P = \\omega(x-c_i)^2$$\\omega$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h3 id=\"K\"><a href=\"#K\" class=\"headerlink\" title=\"K\"></a>K</h3><p>$k$$k$</p>\n<p>$k$$k$$1$$4$$k$$k=2$elbow point$k$2<br><img src=\"/img/kmeans_object_fun_vs_k.png\" alt=\"K\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>cluster</p>\n<ul>\n<li></li>\n<li></li>\n<li><a href=\"http://www.public.asu.edu/~jye02/CLASSES/Fall-2005/PAPERS/kdd_spectral_kernelkmeans.pdf\" target=\"_blank\" rel=\"external\">Kernel K-Means</a></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li></li>\n<li>assign</li>\n<li></li>\n</ul>\n<h2 id=\"K-Means\"><a href=\"#K-Means\" class=\"headerlink\" title=\"K-Means\"></a>K-Means</h2><p>K-MeansFeature SpaceRGB1D3DFeature Space<br><img src=\"/img/kmeans_image_seg_via_intensity.png\" alt=\"1\"></p>\n<p>Spatial CoherentFeature Space</p>\n<p>2012PAMI<a href=\"https://infoscience.epfl.ch/record/177415/files/Superpixel_PAMI2011-2.pdf\" target=\"_blank\" rel=\"external\">SLIC Superpixels Compared to State-of-the-art Superpixel Methods</a>K-Means</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Meansconditional variancegood represention of data</p>\n<p></p>\n<ul>\n<li>outlieroutlierclusterK-Medians<br><img src=\"/img/kmeans_sensitive_to_outlier.png\" alt=\"outlier\"></li>\n<li>clusterFuzzy K-Meanssoft assignment</li>\n<li>round shapecluster</li>\n<li>Spectral Clusteringkernel K-Means</li>\n</ul>\n<p>K-Means<br><img src=\"/img/kmeans_scaling_up.png\" alt=\"K-Means Scaling Up\"></p>\n<h2 id=\"MATLAB\"><a href=\"#MATLAB\" class=\"headerlink\" title=\"MATLAB\"></a>MATLAB</h2><p>K-Means demo$K = 3$cluster$N$<code>scatter</code></p>\n<p><code>my_kmeans</code>kmeans<code>my</code>$K$assignmentassignment$J$</p>\n<p>debugK-Means</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">K = <span class=\"number\">3</span>;   <span class=\"comment\">% number of clusters</span></div><div class=\"line\">pos = [<span class=\"number\">-5</span>, <span class=\"number\">5</span>; <span class=\"number\">0</span>, <span class=\"number\">1</span>; <span class=\"number\">3</span>, <span class=\"number\">6</span>];  <span class=\"comment\">% position of cluster centers</span></div><div class=\"line\">N = <span class=\"number\">20</span>;    <span class=\"comment\">% number of data points</span></div><div class=\"line\">R = <span class=\"number\">3</span>;     <span class=\"comment\">% radius of clusters</span></div><div class=\"line\">data = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">2</span>);    <span class=\"comment\">% data</span></div><div class=\"line\">class = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);   <span class=\"comment\">% index of cluster</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N</div><div class=\"line\">    idx = randi(<span class=\"number\">3</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    dr = R*<span class=\"built_in\">rand</span>();</div><div class=\"line\">    data(<span class=\"built_in\">i</span>, :) = pos(idx, :) + [dr*cos(rand()*<span class=\"number\">2</span>*pi), dr*sin(rand()*<span class=\"number\">2</span>*pi)];</div><div class=\"line\">    class(<span class=\"built_in\">i</span>) = idx;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% visualization data points</span></div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">color = [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:K</div><div class=\"line\">    x = data(class == <span class=\"built_in\">i</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    y = data(class == <span class=\"built_in\">i</span>, <span class=\"number\">2</span>);</div><div class=\"line\">    scatter(x, y, <span class=\"number\">150</span>, <span class=\"built_in\">repmat</span>(color(<span class=\"built_in\">i</span>,:), [length(x), <span class=\"number\">1</span>]), <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% K-Means</span></div><div class=\"line\">best_J = <span class=\"number\">1E100</span>;</div><div class=\"line\">best_idx = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> times = <span class=\"number\">1</span>:<span class=\"number\">5</span>  <span class=\"comment\">% 5 times experiments to choose the best result</span></div><div class=\"line\">    [mu, assignment, J] = my_kmeans(data, K);</div><div class=\"line\">    <span class=\"keyword\">if</span> best_J &gt; J</div><div class=\"line\">        best_idx = times;</div><div class=\"line\">        best_J = J;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'%d experiment: J = %f\\n'</span>, times, J);</div><div class=\"line\">    <span class=\"built_in\">disp</span>(mu);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">fprintf(<span class=\"string\">'best: %d experiment: J = %f\\n'</span>, best_idx, best_J);</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% basic functions</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">J</span> = <span class=\"title\">ssd</span><span class=\"params\">(X, mu, assignment)</span></span></div><div class=\"line\"><span class=\"comment\">% sum of square distance</span></div><div class=\"line\"><span class=\"comment\">% X -- data, N*D matrix</span></div><div class=\"line\"><span class=\"comment\">% mu -- centers of clusters, K*D matrix</span></div><div class=\"line\"><span class=\"comment\">% assignment -- current assignment of data to clusters</span></div><div class=\"line\">J = <span class=\"number\">0</span>;</div><div class=\"line\">K = <span class=\"built_in\">size</span>(mu, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> k = <span class=\"number\">1</span>:K</div><div class=\"line\">    x_k = X(assignment == k, :);</div><div class=\"line\">    mu_k = mu(k, :);</div><div class=\"line\">    err2 = <span class=\"built_in\">bsxfun</span>(@minus, x_k, mu_k).^<span class=\"number\">2</span>;</div><div class=\"line\">    J = J + sum(err2(:));</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">J = J / <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">mu</span> = <span class=\"title\">compute_mu</span><span class=\"params\">(X, assignment, K)</span></span></div><div class=\"line\">mu = <span class=\"built_in\">zeros</span>(K, <span class=\"built_in\">size</span>(X, <span class=\"number\">2</span>));</div><div class=\"line\"><span class=\"keyword\">for</span> k = <span class=\"number\">1</span>:K</div><div class=\"line\">    x_k = X(assignment == k, :);</div><div class=\"line\">    mu(k, :) = mean(x_k, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">assignment</span> = <span class=\"title\">assign</span><span class=\"params\">(X, mu)</span></span></div><div class=\"line\"><span class=\"comment\">% assign data points to clusters</span></div><div class=\"line\">N = <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\">assignment = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N</div><div class=\"line\">    x = X(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">    err2 = <span class=\"built_in\">bsxfun</span>(@minus, x, mu).^<span class=\"number\">2</span>;</div><div class=\"line\">    dis = sum(err2, <span class=\"number\">2</span>);</div><div class=\"line\">    [~, idx] = min(dis);</div><div class=\"line\">    assignment(<span class=\"built_in\">i</span>) = idx;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[mu, assignment, J]</span> = <span class=\"title\">my_kmeans</span><span class=\"params\">(X, K)</span></span></div><div class=\"line\">N = <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\">assignment = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">idx = randsample(N, K);</div><div class=\"line\">mu = X(idx, :);</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% for i = 1:K</span></div><div class=\"line\"><span class=\"comment\">%     for j = 1:N</span></div><div class=\"line\"><span class=\"comment\">%         if assignment_gt(j) == i</span></div><div class=\"line\"><span class=\"comment\">%             mu(i,:) = X(j,:);</span></div><div class=\"line\"><span class=\"comment\">%             break;</span></div><div class=\"line\"><span class=\"comment\">%         end</span></div><div class=\"line\"><span class=\"comment\">%     end</span></div><div class=\"line\"><span class=\"comment\">% end</span></div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">color = [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>];</div><div class=\"line\">scatter(mu(:,<span class=\"number\">1</span>), mu(:,<span class=\"number\">2</span>), <span class=\"number\">200</span>, color, <span class=\"string\">'d'</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> iter = <span class=\"number\">1</span>:<span class=\"number\">20</span></div><div class=\"line\">    assignment_prev = assignment;</div><div class=\"line\">    assignment = assign(X, mu);</div><div class=\"line\">    <span class=\"keyword\">if</span> assignment == assignment_prev</div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    mu_prev = mu;</div><div class=\"line\">    mu = compute_mu(X, assignment, K);</div><div class=\"line\">    scatter(mu(:, <span class=\"number\">1</span>), mu(:, <span class=\"number\">2</span>), <span class=\"number\">200</span>, color, <span class=\"string\">'d'</span>);</div><div class=\"line\">    MU = <span class=\"built_in\">zeros</span>(<span class=\"number\">2</span>*K, <span class=\"number\">2</span>);</div><div class=\"line\">    MU(<span class=\"number\">1</span>:<span class=\"number\">2</span>:<span class=\"keyword\">end</span>, :) = mu_prev;</div><div class=\"line\">    MU(<span class=\"number\">2</span>:<span class=\"number\">2</span>:<span class=\"keyword\">end</span>, :) = mu;</div><div class=\"line\">    mu_x = <span class=\"built_in\">reshape</span>(MU(:, <span class=\"number\">1</span>), [], K);</div><div class=\"line\">    mu_y = <span class=\"built_in\">reshape</span>(MU(:, <span class=\"number\">2</span>), [], K);</div><div class=\"line\">    plot(mu_x, mu_y, <span class=\"string\">'k-.'</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:K</div><div class=\"line\">    x = X(assignment == <span class=\"built_in\">i</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    y = X(assignment == <span class=\"built_in\">i</span>, <span class=\"number\">2</span>);</div><div class=\"line\">    scatter(x, y, <span class=\"number\">150</span>, <span class=\"built_in\">repmat</span>(color(<span class=\"built_in\">i</span>,:), [length(x), <span class=\"number\">1</span>]), <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">J = ssd(X, mu, assignment);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>demo$5$cluster<br><img src=\"/img/kmeans_data_demo.png\" alt=\"K-Means\"></p>\n<p>clusterclustercluster</p>\n<p><img src=\"/img/kmeans_success.png\" alt=\"K-Means\"></p>\n<p>~<br><img src=\"/img/kmeans_bigger_demo.png\" alt=\"\"></p>\n<h2 id=\"PS\"><a href=\"#PS\" class=\"headerlink\" title=\"PS\"></a>PS</h2><p>tipMarkdownLaTexMarkdown<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$c_&#123;i&#125;^\\ast$ XXX $\\delta_&#123;ij&#125;^\\ast$</div></pre></td></tr></table></figure></p>\n<p>$c<em>{i}^\\ast$ XXX $\\delta</em>{ij}^\\ast$</p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$c\\_&#123;i&#125;^\\ast$ XXX $\\delta\\_&#123;ij&#125;^\\ast$</div></pre></td></tr></table></figure></p>\n<p>$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$</p>\n<p><a href=\"http://lukang.me/2014/mathjax-for-hexo.html\" target=\"_blank\" rel=\"external\"></a></p>\n","excerpt":"<p><a href=\"https://zh.wikipedia.org/wiki/K-\">K-Means</a>n$k$Sum of Square DistanceSSD</p>\n<script type=\"math/tex; mode=display\">\\text{SSD} = \\sum_{i=1}^{k}\\sum_{x\\in c_i}(x-c_i)^2</script><p><img src=\"/img/kmeans_demo.png\" alt=\"K-Means Demo\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Means$c^\\ast$$\\delta^\\ast$$c_{i}^\\ast$$\\delta_{ij}^\\ast$$\\lbrace 0,1\\rbrace$$x_j$$i$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">c^\\ast, \\delta^\\ast = \\arg\\min_{c,\\delta} \\frac{1}{N}\\sum_{j=1}^{N}\\sum_{i=1}^{k}\\delta_{i,j}(c_i-x_j)^2</script><p>$c_i$$\\delta_{i,j}$K-Means</p>\n<p>K-MeansEM</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Means<br><img src=\"/img/kmeans_algorithm.png\" alt=\"K-Means\"></p>\n<p>$N$$\\lbrace x_1, \\dots, x_N\\rbrace, x_i\\in\\mathbb{R}^D$$k$</p>\n<p>$\\mu_i, i = 1,\\dots, k$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>K-Means$k$</p>\n<ul>\n<li><p>kmeans++spread-out<br>$P = \\omega(x-c_i)^2$$\\omega$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h3 id=\"K\"><a href=\"#K\" class=\"headerlink\" title=\"K\"></a>K</h3><p>$k$$k$</p>\n<p>$k$$k$$1$$4$$k$$k=2$elbow point$k$2<br><img src=\"/img/kmeans_object_fun_vs_k.png\" alt=\"K\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>cluster</p>\n<ul>\n<li></li>\n<li></li>\n<li><a href=\"http://www.public.asu.edu/~jye02/CLASSES/Fall-2005/PAPERS/kdd_spectral_kernelkmeans.pdf\">Kernel K-Means</a></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li></li>\n<li>assign</li>\n<li></li>\n</ul>\n<h2 id=\"K-Means\"><a href=\"#K-Means\" class=\"headerlink\" title=\"K-Means\"></a>K-Means</h2><p>K-MeansFeature SpaceRGB1D3DFeature Space<br><img src=\"/img/kmeans_image_seg_via_intensity.png\" alt=\"1\"></p>\n<p>Spatial CoherentFeature Space</p>\n<p>2012PAMI<a href=\"https://infoscience.epfl.ch/record/177415/files/Superpixel_PAMI2011-2.pdf\">SLIC Superpixels Compared to State-of-the-art Superpixel Methods</a>K-Means</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>K-Meansconditional variancegood represention of data</p>\n<p></p>\n<ul>\n<li>outlieroutlierclusterK-Medians<br><img src=\"/img/kmeans_sensitive_to_outlier.png\" alt=\"outlier\"></li>\n<li>clusterFuzzy K-Meanssoft assignment</li>\n<li>round shapecluster</li>\n<li>Spectral Clusteringkernel K-Means</li>\n</ul>\n<p>K-Means<br><img src=\"/img/kmeans_scaling_up.png\" alt=\"K-Means Scaling Up\"></p>\n<h2 id=\"MATLAB\"><a href=\"#MATLAB\" class=\"headerlink\" title=\"MATLAB\"></a>MATLAB</h2><p>K-Means demo$K = 3$cluster$N$<code>scatter</code></p>\n<p><code>my_kmeans</code>kmeans<code>my</code>$K$assignmentassignment$J$</p>\n<p>debugK-Means</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">K = <span class=\"number\">3</span>;   <span class=\"comment\">% number of clusters</span></div><div class=\"line\">pos = [<span class=\"number\">-5</span>, <span class=\"number\">5</span>; <span class=\"number\">0</span>, <span class=\"number\">1</span>; <span class=\"number\">3</span>, <span class=\"number\">6</span>];  <span class=\"comment\">% position of cluster centers</span></div><div class=\"line\">N = <span class=\"number\">20</span>;    <span class=\"comment\">% number of data points</span></div><div class=\"line\">R = <span class=\"number\">3</span>;     <span class=\"comment\">% radius of clusters</span></div><div class=\"line\">data = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">2</span>);    <span class=\"comment\">% data</span></div><div class=\"line\">class = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);   <span class=\"comment\">% index of cluster</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N</div><div class=\"line\">    idx = randi(<span class=\"number\">3</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    dr = R*<span class=\"built_in\">rand</span>();</div><div class=\"line\">    data(<span class=\"built_in\">i</span>, :) = pos(idx, :) + [dr*cos(rand()*<span class=\"number\">2</span>*pi), dr*sin(rand()*<span class=\"number\">2</span>*pi)];</div><div class=\"line\">    class(<span class=\"built_in\">i</span>) = idx;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% visualization data points</span></div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">color = [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:K</div><div class=\"line\">    x = data(class == <span class=\"built_in\">i</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    y = data(class == <span class=\"built_in\">i</span>, <span class=\"number\">2</span>);</div><div class=\"line\">    scatter(x, y, <span class=\"number\">150</span>, <span class=\"built_in\">repmat</span>(color(<span class=\"built_in\">i</span>,:), [length(x), <span class=\"number\">1</span>]), <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% K-Means</span></div><div class=\"line\">best_J = <span class=\"number\">1E100</span>;</div><div class=\"line\">best_idx = <span class=\"number\">0</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> times = <span class=\"number\">1</span>:<span class=\"number\">5</span>  <span class=\"comment\">% 5 times experiments to choose the best result</span></div><div class=\"line\">    [mu, assignment, J] = my_kmeans(data, K);</div><div class=\"line\">    <span class=\"keyword\">if</span> best_J &gt; J</div><div class=\"line\">        best_idx = times;</div><div class=\"line\">        best_J = J;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    fprintf(<span class=\"string\">'%d experiment: J = %f\\n'</span>, times, J);</div><div class=\"line\">    <span class=\"built_in\">disp</span>(mu);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">fprintf(<span class=\"string\">'best: %d experiment: J = %f\\n'</span>, best_idx, best_J);</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">%% basic functions</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">J</span> = <span class=\"title\">ssd</span><span class=\"params\">(X, mu, assignment)</span></span></div><div class=\"line\"><span class=\"comment\">% sum of square distance</span></div><div class=\"line\"><span class=\"comment\">% X -- data, N*D matrix</span></div><div class=\"line\"><span class=\"comment\">% mu -- centers of clusters, K*D matrix</span></div><div class=\"line\"><span class=\"comment\">% assignment -- current assignment of data to clusters</span></div><div class=\"line\">J = <span class=\"number\">0</span>;</div><div class=\"line\">K = <span class=\"built_in\">size</span>(mu, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> k = <span class=\"number\">1</span>:K</div><div class=\"line\">    x_k = X(assignment == k, :);</div><div class=\"line\">    mu_k = mu(k, :);</div><div class=\"line\">    err2 = <span class=\"built_in\">bsxfun</span>(@minus, x_k, mu_k).^<span class=\"number\">2</span>;</div><div class=\"line\">    J = J + sum(err2(:));</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">J = J / <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">mu</span> = <span class=\"title\">compute_mu</span><span class=\"params\">(X, assignment, K)</span></span></div><div class=\"line\">mu = <span class=\"built_in\">zeros</span>(K, <span class=\"built_in\">size</span>(X, <span class=\"number\">2</span>));</div><div class=\"line\"><span class=\"keyword\">for</span> k = <span class=\"number\">1</span>:K</div><div class=\"line\">    x_k = X(assignment == k, :);</div><div class=\"line\">    mu(k, :) = mean(x_k, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">assignment</span> = <span class=\"title\">assign</span><span class=\"params\">(X, mu)</span></span></div><div class=\"line\"><span class=\"comment\">% assign data points to clusters</span></div><div class=\"line\">N = <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\">assignment = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N</div><div class=\"line\">    x = X(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">    err2 = <span class=\"built_in\">bsxfun</span>(@minus, x, mu).^<span class=\"number\">2</span>;</div><div class=\"line\">    dis = sum(err2, <span class=\"number\">2</span>);</div><div class=\"line\">    [~, idx] = min(dis);</div><div class=\"line\">    assignment(<span class=\"built_in\">i</span>) = idx;</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[mu, assignment, J]</span> = <span class=\"title\">my_kmeans</span><span class=\"params\">(X, K)</span></span></div><div class=\"line\">N = <span class=\"built_in\">size</span>(X, <span class=\"number\">1</span>);</div><div class=\"line\">assignment = <span class=\"built_in\">zeros</span>(N, <span class=\"number\">1</span>);</div><div class=\"line\">idx = randsample(N, K);</div><div class=\"line\">mu = X(idx, :);</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% for i = 1:K</span></div><div class=\"line\"><span class=\"comment\">%     for j = 1:N</span></div><div class=\"line\"><span class=\"comment\">%         if assignment_gt(j) == i</span></div><div class=\"line\"><span class=\"comment\">%             mu(i,:) = X(j,:);</span></div><div class=\"line\"><span class=\"comment\">%             break;</span></div><div class=\"line\"><span class=\"comment\">%         end</span></div><div class=\"line\"><span class=\"comment\">%     end</span></div><div class=\"line\"><span class=\"comment\">% end</span></div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">color = [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>; <span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">1</span>];</div><div class=\"line\">scatter(mu(:,<span class=\"number\">1</span>), mu(:,<span class=\"number\">2</span>), <span class=\"number\">200</span>, color, <span class=\"string\">'d'</span>);</div><div class=\"line\"><span class=\"keyword\">for</span> iter = <span class=\"number\">1</span>:<span class=\"number\">20</span></div><div class=\"line\">    assignment_prev = assignment;</div><div class=\"line\">    assignment = assign(X, mu);</div><div class=\"line\">    <span class=\"keyword\">if</span> assignment == assignment_prev</div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    mu_prev = mu;</div><div class=\"line\">    mu = compute_mu(X, assignment, K);</div><div class=\"line\">    scatter(mu(:, <span class=\"number\">1</span>), mu(:, <span class=\"number\">2</span>), <span class=\"number\">200</span>, color, <span class=\"string\">'d'</span>);</div><div class=\"line\">    MU = <span class=\"built_in\">zeros</span>(<span class=\"number\">2</span>*K, <span class=\"number\">2</span>);</div><div class=\"line\">    MU(<span class=\"number\">1</span>:<span class=\"number\">2</span>:<span class=\"keyword\">end</span>, :) = mu_prev;</div><div class=\"line\">    MU(<span class=\"number\">2</span>:<span class=\"number\">2</span>:<span class=\"keyword\">end</span>, :) = mu;</div><div class=\"line\">    mu_x = <span class=\"built_in\">reshape</span>(MU(:, <span class=\"number\">1</span>), [], K);</div><div class=\"line\">    mu_y = <span class=\"built_in\">reshape</span>(MU(:, <span class=\"number\">2</span>), [], K);</div><div class=\"line\">    plot(mu_x, mu_y, <span class=\"string\">'k-.'</span>);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:K</div><div class=\"line\">    x = X(assignment == <span class=\"built_in\">i</span>, <span class=\"number\">1</span>);</div><div class=\"line\">    y = X(assignment == <span class=\"built_in\">i</span>, <span class=\"number\">2</span>);</div><div class=\"line\">    scatter(x, y, <span class=\"number\">150</span>, <span class=\"built_in\">repmat</span>(color(<span class=\"built_in\">i</span>,:), [length(x), <span class=\"number\">1</span>]), <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">J = ssd(X, mu, assignment);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>demo$5$cluster<br><img src=\"/img/kmeans_data_demo.png\" alt=\"K-Means\"></p>\n<p>clusterclustercluster</p>\n<p><img src=\"/img/kmeans_success.png\" alt=\"K-Means\"></p>\n<p>~<br><img src=\"/img/kmeans_bigger_demo.png\" alt=\"\"></p>\n<h2 id=\"PS\"><a href=\"#PS\" class=\"headerlink\" title=\"PS\"></a>PS</h2><p>tipMarkdownLaTexMarkdown<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$c_&#123;i&#125;^\\ast$ XXX $\\delta_&#123;ij&#125;^\\ast$</div></pre></td></tr></table></figure></p>\n<p>$c<em>{i}^\\ast$ XXX $\\delta</em>{ij}^\\ast$</p>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$c\\_&#123;i&#125;^\\ast$ XXX $\\delta\\_&#123;ij&#125;^\\ast$</div></pre></td></tr></table></figure></p>\n<p>$c_{i}^\\ast$ XXX $\\delta_{ij}^\\ast$</p>\n<p><a href=\"http://lukang.me/2014/mathjax-for-hexo.html\"></a></p>"},{"title":"CS131-","date":"2017-01-22T07:38:01.000Z","_content":"\nCS131(Computer Vision: Foundations and Applications)Li Feifei[](http://vision.stanford.edu/teaching/cs131_fall1617/index.html)2016CS131slide\n\n*2018/03/20 Update: 2017Python[CS131 Computer Vision@Fall 2017](http://vision.stanford.edu/teaching/cs131_fall1718/)*\n\n[](http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf)\n![](/img/cs131_linear_algebra.jpg)\n\n<!-- more -->\n## \n\nslide\n## \n\n\n### scale\n\n$$\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}\n$$\n\n### \n$theta$\n![](/img/rotation.png)\n$$\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}\n$$\n[](https://zh.wikipedia.org/wiki/)\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$\n[](https://zh.wikipedia.org/wiki/)\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$.\n\n### (Homogeneous Transform)\n\n$$\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}\n$$\n\n### SVD\nQRSVD\n$$\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}$$\n$\\mathbf{A}$$m\\times n$$\\mathbf{U}$$m\\times m$$\\mathbf{V}$$n \\times n$$\\mathbf{\\Sigma}$$m \\times n$0.\n\nSVD$\\mathbf{\\Sigma}$$\\mathbf{U}$\n\n10\n\n``` matlab\nim = imread('./superman.png');\nim_gray = rbg2gray(im);\n[u, s, v] = svd(double(im_gray));\nk = 10;\nuk = u(:, 1:k);\nsigma = diag(s);\nsk = diag(sigma(1:k));\nvk = v(:, 1:k);\nim_k = uk*sk*vk';\nimshow(uint8(im_k))\n```\n\n![](/img/original_superman.png)\n![](/img/svd_superman.png)\n","source":"_posts/cs131-linear-alg.md","raw":"---\ntitle: CS131-\ndate: 2017-01-22 15:38:01\ntags:\n    - cs131\n    - \n---\n\nCS131(Computer Vision: Foundations and Applications)Li Feifei[](http://vision.stanford.edu/teaching/cs131_fall1617/index.html)2016CS131slide\n\n*2018/03/20 Update: 2017Python[CS131 Computer Vision@Fall 2017](http://vision.stanford.edu/teaching/cs131_fall1718/)*\n\n[](http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf)\n![](/img/cs131_linear_algebra.jpg)\n\n<!-- more -->\n## \n\nslide\n## \n\n\n### scale\n\n$$\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}\n$$\n\n### \n$theta$\n![](/img/rotation.png)\n$$\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}\n$$\n[](https://zh.wikipedia.org/wiki/)\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$\n[](https://zh.wikipedia.org/wiki/)\n$$\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}\n$$\n$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$.\n\n### (Homogeneous Transform)\n\n$$\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}\n$$\n\n### SVD\nQRSVD\n$$\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}$$\n$\\mathbf{A}$$m\\times n$$\\mathbf{U}$$m\\times m$$\\mathbf{V}$$n \\times n$$\\mathbf{\\Sigma}$$m \\times n$0.\n\nSVD$\\mathbf{\\Sigma}$$\\mathbf{U}$\n\n10\n\n``` matlab\nim = imread('./superman.png');\nim_gray = rbg2gray(im);\n[u, s, v] = svd(double(im_gray));\nk = 10;\nuk = u(:, 1:k);\nsigma = diag(s);\nsk = diag(sigma(1:k));\nvk = v(:, 1:k);\nim_k = uk*sk*vk';\nimshow(uint8(im_k))\n```\n\n![](/img/original_superman.png)\n![](/img/svd_superman.png)\n","slug":"cs131-linear-alg","published":1,"updated":"2018-10-27T07:16:52.383Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8j2000tae7bus1yv9a7","content":"<p>CS131(Computer Vision: Foundations and Applications)Li Feifei<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/index.html\" target=\"_blank\" rel=\"external\"></a>2016CS131slide</p>\n<p><em>2018/03/20 Update: 2017Python<a href=\"http://vision.stanford.edu/teaching/cs131_fall1718/\" target=\"_blank\" rel=\"external\">CS131 Computer Vision@Fall 2017</a></em></p>\n<p><a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf\" target=\"_blank\" rel=\"external\"></a><br><img src=\"/img/cs131_linear_algebra.jpg\" alt=\"\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>slide</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"scale\"><a href=\"#scale\" class=\"headerlink\" title=\"scale\"></a>scale</h3><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$theta$<br><img src=\"/img/rotation.png\" alt=\"\"></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}</script><p><a href=\"https://zh.wikipedia.org/wiki/\" target=\"_blank\" rel=\"external\"></a></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$<br><a href=\"https://zh.wikipedia.org/wiki/\" target=\"_blank\" rel=\"external\"></a></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$.</p>\n<h3 id=\"-Homogeneous-Transform\"><a href=\"#-Homogeneous-Transform\" class=\"headerlink\" title=\"(Homogeneous Transform)\"></a>(Homogeneous Transform)</h3><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}</script><h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>QRSVD</p>\n<script type=\"math/tex; mode=display\">\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}</script><p>$\\mathbf{A}$$m\\times n$$\\mathbf{U}$$m\\times m$$\\mathbf{V}$$n \\times n$$\\mathbf{\\Sigma}$$m \\times n$0.</p>\n<p>SVD$\\mathbf{\\Sigma}$$\\mathbf{U}$</p>\n<p>10</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">im = imread(<span class=\"string\">'./superman.png'</span>);</div><div class=\"line\">im_gray = rbg2gray(im);</div><div class=\"line\">[u, s, v] = svd(double(im_gray));</div><div class=\"line\">k = <span class=\"number\">10</span>;</div><div class=\"line\">uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">sk = <span class=\"built_in\">diag</span>(sigma(<span class=\"number\">1</span>:k));</div><div class=\"line\">vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">im_k = uk*sk*vk';</div><div class=\"line\">imshow(uint8(im_k))</div></pre></td></tr></table></figure>\n<p><img src=\"/img/original_superman.png\" alt=\"\"><br><img src=\"/img/svd_superman.png\" alt=\"\"></p>\n","excerpt":"<p>CS131(Computer Vision: Foundations and Applications)Li Feifei<a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/index.html\"></a>2016CS131slide</p>\n<p><em>2018/03/20 Update: 2017Python<a href=\"http://vision.stanford.edu/teaching/cs131_fall1718/\">CS131 Computer Vision@Fall 2017</a></em></p>\n<p><a href=\"http://vision.stanford.edu/teaching/cs131_fall1617/lectures/lecture2_linalg_review_cs131_2016.pdf\"></a><br><img src=\"/img/cs131_linear_algebra.jpg\" alt=\"\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>slide</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"scale\"><a href=\"#scale\" class=\"headerlink\" title=\"scale\"></a>scale</h3><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{bmatrix}\ns_x & 0\\\\\\\\\n0 & s_y\n\\end{bmatrix}\\begin{bmatrix}\nx\\\\\\\\\ny\n\\end{bmatrix} = \\begin{bmatrix}\ns_xx\\\\\\\\\ns_yy\n\\end{bmatrix}</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$theta$<br><img src=\"/img/rotation.png\" alt=\"\"></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R} = \\begin{bmatrix}\n\\cos\\theta &-\\sin\\theta \\\\\\\\\n\\sin\\theta &\\cos\\theta\n\\end{bmatrix}</script><p><a href=\"https://zh.wikipedia.org/wiki/\"></a></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$<br><a href=\"https://zh.wikipedia.org/wiki/\"></a></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{R}\\mathbf{R^{\\dagger}} = \\mathbf{I}</script><p>$\\det{\\mathbf{R}} = \\det{\\mathbf{R^{\\dagger}}}$$\\det{\\mathbf{R}} = \\pm 1$.</p>\n<h3 id=\"-Homogeneous-Transform\"><a href=\"#-Homogeneous-Transform\" class=\"headerlink\" title=\"(Homogeneous Transform)\"></a>(Homogeneous Transform)</h3><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{H} =\\begin{bmatrix}\na & b & t_x\\\\\\\\\nc & d & t_y\\\\\\\\\n0 & 0 & 1\n\\end{bmatrix},\\mathbf{H}\\begin{bmatrix}\nx\\\\\\\\\ny\\\\\\\\\n1\\\\\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nax+by+t_x\\\\\\\\\ncx+dy+t_y\\\\\\\\\n1\n\\end{bmatrix}</script><h3 id=\"SVD\"><a href=\"#SVD\" class=\"headerlink\" title=\"SVD\"></a>SVD</h3><p>QRSVD</p>\n<script type=\"math/tex; mode=display\">\\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V^\\dagger} = \\mathbf{A}</script><p>$\\mathbf{A}$$m\\times n$$\\mathbf{U}$$m\\times m$$\\mathbf{V}$$n \\times n$$\\mathbf{\\Sigma}$$m \\times n$0.</p>\n<p>SVD$\\mathbf{\\Sigma}$$\\mathbf{U}$</p>\n<p>10</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">im = imread(<span class=\"string\">'./superman.png'</span>);</div><div class=\"line\">im_gray = rbg2gray(im);</div><div class=\"line\">[u, s, v] = svd(double(im_gray));</div><div class=\"line\">k = <span class=\"number\">10</span>;</div><div class=\"line\">uk = u(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">sigma = <span class=\"built_in\">diag</span>(s);</div><div class=\"line\">sk = <span class=\"built_in\">diag</span>(sigma(<span class=\"number\">1</span>:k));</div><div class=\"line\">vk = v(:, <span class=\"number\">1</span>:k);</div><div class=\"line\">im_k = uk*sk*vk';</div><div class=\"line\">imshow(uint8(im_k))</div></pre></td></tr></table></figure>\n<p><img src=\"/img/original_superman.png\" alt=\"\"><br><img src=\"/img/svd_superman.png\" alt=\"\"></p>"},{"title":"CS131-MeanShift","date":"2017-02-12T14:28:15.000Z","_content":"[MeanShift](https://en.wikipedia.org/wiki/Mean_shift)FukunagaHostetler19752000PAMI[Mean Shift: A Robust Approach Toward Feature Space Analysis](http://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf)\n\nMeanShift[](https://en.wikipedia.org/wiki/Mode_(statistics)ModeMeanShift\n![MeanShift](/img/meanshift_basics.jpg)\n\n<!-- more -->\n## \nPAMI[](https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/)[](https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/)\n\n$x$$d$Kernel Function$\\mathbb{R}^n\\rightarrow \\mathbb{R}$\n![kernel](/img/meanshift_kernel_function.png)\n\n\n$$K(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{x^2}{2\\sigma^2})$$\n\n$K$bandwidth$h$$n$\n$$f(x) = \\frac{1}{nh^d}\\sum_{i=1}^{n}K(\\frac{x-x_i}{h})$$\n\n$K(x)$$c_{k,d}$$1$\n$$K(x) = c_{k,d}k(\\Arrowvert x\\Arrowvert ^2)$$\n\n## mean shift\n$f(x)$$0$$f(x)$$g(s) = -k^\\prime(s)$\n![](/img/meanshift_gradient_of_density.png)\n\n$G(x) = c_{k,d}g(\\Arrowvert x\\Arrowvert^2)$$x$$x = x_0$$m_h(x)$mean shift\n$$m_h(x) = \\frac{\\sum_{i=1}^{n}x_i g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}{\\sum_{i=1}^{n}g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}-x$$\n\n$m_h(x)$$f(x)$$m_h(x)$$x$$h$$g(s)$$m_h(x)$$x$\n\n## \n$x_0$$m_h$$x$$m_h$$[1, 2]$mean shift\n\n``` matlab\n%% generate data\nmu = [1 2];\nSigma = [1 0; 0 2]; R = chol(Sigma);\nN = 250;\ndata = repmat(mu, N, 1) + randn(N, 2)*R;\nfigure\nhold on\nscatter(data(:, 1), data(:, 2), 50, 'filled');\n%% meanshift\nmu0 = rand(1,2) * 5;\nmu = mean_shift(mu0, 10, data);\n\nfunction out = gaussian_kernel(x, sigma)\n% gauss kernel, g(x) = \\exp(-x^2/2\\sigma^2)\nout = exp(-x.*x/(2*sigma*sigma));\nend\n\nfunction mu = mean_shift(mu0, h, data)\n% implementation of meanshift algorithm\n% mu_{k+1} = meanshift(mu_{k}) + mu_{k} = \\frac{\\sum_i=1^n xg}{\\sum_i=1^n g}\nmu = mu0;\nsigma = 1;    % parameter for gaussian kernel function\nfor iter = 1:20    \n    fprintf('iter = %d, mu = [%f, %f]\\n', iter, mu(1), mu(2));\n    scatter(mu(1), mu(2), 50, [1,0,0], 'd', 'filled');\n    offset = bsxfun(@minus, mu, data);    % offset = x-x_i\n    dis = sum(offset.^2, 2);              % dis = ||x-x_i||^2\n    x = data(dis < h, :);                 % neighborhood with bandwidth = h\n    g = gaussian_kernel(offset(dis < h), sigma);\n    xg = x.*g;\n    mu_prev = mu;\n    mu = sum(xg, 1) / sum(g, 1);\n    if norm(mu_prev - mu, 2) < 1E-2\n        break;\n    end\n    plot([mu_prev(1) mu(1)], [mu_prev(2), mu(2)], 'b-.', 'linewidth', 2);\nend\nscatter(mu(1), mu(2), 50, [1,0,0], 'd', 'filled');\nend\n```\n![](/img/meanshift_simple_demo.png)\n\nkernellogistaic\n$$K(x) = \\frac{1}{e^x+e^{-x}+2}$$\n\n``` matlab\nfunction out = logistic_kernel(x)\nout = 1./(exp(x) + exp(-x) + 2);\nend\n```\n","source":"_posts/cs131-mean-shift.md","raw":"---\ntitle: CS131-MeanShift\ndate: 2017-02-12 22:28:15\ntags:\n    - cs131\n    - \n---\n[MeanShift](https://en.wikipedia.org/wiki/Mean_shift)FukunagaHostetler19752000PAMI[Mean Shift: A Robust Approach Toward Feature Space Analysis](http://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf)\n\nMeanShift[](https://en.wikipedia.org/wiki/Mode_(statistics)ModeMeanShift\n![MeanShift](/img/meanshift_basics.jpg)\n\n<!-- more -->\n## \nPAMI[](https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/)[](https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/)\n\n$x$$d$Kernel Function$\\mathbb{R}^n\\rightarrow \\mathbb{R}$\n![kernel](/img/meanshift_kernel_function.png)\n\n\n$$K(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{x^2}{2\\sigma^2})$$\n\n$K$bandwidth$h$$n$\n$$f(x) = \\frac{1}{nh^d}\\sum_{i=1}^{n}K(\\frac{x-x_i}{h})$$\n\n$K(x)$$c_{k,d}$$1$\n$$K(x) = c_{k,d}k(\\Arrowvert x\\Arrowvert ^2)$$\n\n## mean shift\n$f(x)$$0$$f(x)$$g(s) = -k^\\prime(s)$\n![](/img/meanshift_gradient_of_density.png)\n\n$G(x) = c_{k,d}g(\\Arrowvert x\\Arrowvert^2)$$x$$x = x_0$$m_h(x)$mean shift\n$$m_h(x) = \\frac{\\sum_{i=1}^{n}x_i g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}{\\sum_{i=1}^{n}g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}-x$$\n\n$m_h(x)$$f(x)$$m_h(x)$$x$$h$$g(s)$$m_h(x)$$x$\n\n## \n$x_0$$m_h$$x$$m_h$$[1, 2]$mean shift\n\n``` matlab\n%% generate data\nmu = [1 2];\nSigma = [1 0; 0 2]; R = chol(Sigma);\nN = 250;\ndata = repmat(mu, N, 1) + randn(N, 2)*R;\nfigure\nhold on\nscatter(data(:, 1), data(:, 2), 50, 'filled');\n%% meanshift\nmu0 = rand(1,2) * 5;\nmu = mean_shift(mu0, 10, data);\n\nfunction out = gaussian_kernel(x, sigma)\n% gauss kernel, g(x) = \\exp(-x^2/2\\sigma^2)\nout = exp(-x.*x/(2*sigma*sigma));\nend\n\nfunction mu = mean_shift(mu0, h, data)\n% implementation of meanshift algorithm\n% mu_{k+1} = meanshift(mu_{k}) + mu_{k} = \\frac{\\sum_i=1^n xg}{\\sum_i=1^n g}\nmu = mu0;\nsigma = 1;    % parameter for gaussian kernel function\nfor iter = 1:20    \n    fprintf('iter = %d, mu = [%f, %f]\\n', iter, mu(1), mu(2));\n    scatter(mu(1), mu(2), 50, [1,0,0], 'd', 'filled');\n    offset = bsxfun(@minus, mu, data);    % offset = x-x_i\n    dis = sum(offset.^2, 2);              % dis = ||x-x_i||^2\n    x = data(dis < h, :);                 % neighborhood with bandwidth = h\n    g = gaussian_kernel(offset(dis < h), sigma);\n    xg = x.*g;\n    mu_prev = mu;\n    mu = sum(xg, 1) / sum(g, 1);\n    if norm(mu_prev - mu, 2) < 1E-2\n        break;\n    end\n    plot([mu_prev(1) mu(1)], [mu_prev(2), mu(2)], 'b-.', 'linewidth', 2);\nend\nscatter(mu(1), mu(2), 50, [1,0,0], 'd', 'filled');\nend\n```\n![](/img/meanshift_simple_demo.png)\n\nkernellogistaic\n$$K(x) = \\frac{1}{e^x+e^{-x}+2}$$\n\n``` matlab\nfunction out = logistic_kernel(x)\nout = 1./(exp(x) + exp(-x) + 2);\nend\n```\n","slug":"cs131-mean-shift","published":1,"updated":"2018-10-27T07:16:52.384Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8j6000vae7bo9r36lss","content":"<p><a href=\"https://en.wikipedia.org/wiki/Mean_shift\" target=\"_blank\" rel=\"external\">MeanShift</a>FukunagaHostetler19752000PAMI<a href=\"http://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf\" target=\"_blank\" rel=\"external\">Mean Shift: A Robust Approach Toward Feature Space Analysis</a></p>\n<p>MeanShift<a href=\"https://en.wikipedia.org/wiki/Mode_(statistics\" target=\"_blank\" rel=\"external\"></a>ModeMeanShift<br><img src=\"/img/meanshift_basics.jpg\" alt=\"MeanShift\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PAMI<a href=\"https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/\" target=\"_blank\" rel=\"external\"></a><a href=\"https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/\" target=\"_blank\" rel=\"external\"></a></p>\n<p>$x$$d$Kernel Function$\\mathbb{R}^n\\rightarrow \\mathbb{R}$<br><img src=\"/img/meanshift_kernel_function.png\" alt=\"kernel\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">K(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{x^2}{2\\sigma^2})</script><p>$K$bandwidth$h$$n$</p>\n<script type=\"math/tex; mode=display\">f(x) = \\frac{1}{nh^d}\\sum_{i=1}^{n}K(\\frac{x-x_i}{h})</script><p>$K(x)$$c_{k,d}$$1$</p>\n<script type=\"math/tex; mode=display\">K(x) = c_{k,d}k(\\Arrowvert x\\Arrowvert ^2)</script><h2 id=\"mean-shift\"><a href=\"#mean-shift\" class=\"headerlink\" title=\"mean shift\"></a>mean shift</h2><p>$f(x)$$0$$f(x)$$g(s) = -k^\\prime(s)$<br><img src=\"/img/meanshift_gradient_of_density.png\" alt=\"\"></p>\n<p>$G(x) = c_{k,d}g(\\Arrowvert x\\Arrowvert^2)$$x$$x = x_0$$m_h(x)$mean shift</p>\n<script type=\"math/tex; mode=display\">m_h(x) = \\frac{\\sum_{i=1}^{n}x_i g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}{\\sum_{i=1}^{n}g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}-x</script><p>$m_h(x)$$f(x)$$m_h(x)$$x$$h$$g(s)$$m_h(x)$$x$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$x_0$$m_h$$x$$m_h$$[1, 2]$mean shift</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">mu = [<span class=\"number\">1</span> <span class=\"number\">2</span>];</div><div class=\"line\">Sigma = [<span class=\"number\">1</span> <span class=\"number\">0</span>; <span class=\"number\">0</span> <span class=\"number\">2</span>]; R = chol(Sigma);</div><div class=\"line\">N = <span class=\"number\">250</span>;</div><div class=\"line\">data = <span class=\"built_in\">repmat</span>(mu, N, <span class=\"number\">1</span>) + <span class=\"built_in\">randn</span>(N, <span class=\"number\">2</span>)*R;</div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">scatter(data(:, <span class=\"number\">1</span>), data(:, <span class=\"number\">2</span>), <span class=\"number\">50</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"comment\">%% meanshift</span></div><div class=\"line\">mu0 = <span class=\"built_in\">rand</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>) * <span class=\"number\">5</span>;</div><div class=\"line\">mu = mean_shift(mu0, <span class=\"number\">10</span>, data);</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">out</span> = <span class=\"title\">gaussian_kernel</span><span class=\"params\">(x, sigma)</span></span></div><div class=\"line\"><span class=\"comment\">% gauss kernel, g(x) = \\exp(-x^2/2\\sigma^2)</span></div><div class=\"line\">out = <span class=\"built_in\">exp</span>(-x.*x/(<span class=\"number\">2</span>*sigma*sigma));</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">mu</span> = <span class=\"title\">mean_shift</span><span class=\"params\">(mu0, h, data)</span></span></div><div class=\"line\"><span class=\"comment\">% implementation of meanshift algorithm</span></div><div class=\"line\"><span class=\"comment\">% mu_&#123;k+1&#125; = meanshift(mu_&#123;k&#125;) + mu_&#123;k&#125; = \\frac&#123;\\sum_i=1^n xg&#125;&#123;\\sum_i=1^n g&#125;</span></div><div class=\"line\">mu = mu0;</div><div class=\"line\">sigma = <span class=\"number\">1</span>;    <span class=\"comment\">% parameter for gaussian kernel function</span></div><div class=\"line\"><span class=\"keyword\">for</span> iter = <span class=\"number\">1</span>:<span class=\"number\">20</span>    </div><div class=\"line\">    fprintf(<span class=\"string\">'iter = %d, mu = [%f, %f]\\n'</span>, iter, mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>));</div><div class=\"line\">    scatter(mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>), <span class=\"number\">50</span>, [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>], <span class=\"string\">'d'</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\">    offset = <span class=\"built_in\">bsxfun</span>(@minus, mu, data);    <span class=\"comment\">% offset = x-x_i</span></div><div class=\"line\">    dis = sum(offset.^<span class=\"number\">2</span>, <span class=\"number\">2</span>);              <span class=\"comment\">% dis = ||x-x_i||^2</span></div><div class=\"line\">    x = data(dis &lt; h, :);                 <span class=\"comment\">% neighborhood with bandwidth = h</span></div><div class=\"line\">    g = gaussian_kernel(offset(dis &lt; h), sigma);</div><div class=\"line\">    xg = x.*g;</div><div class=\"line\">    mu_prev = mu;</div><div class=\"line\">    mu = sum(xg, <span class=\"number\">1</span>) / sum(g, <span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> norm(mu_prev - mu, <span class=\"number\">2</span>) &lt; <span class=\"number\">1E-2</span></div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    plot([mu_prev(<span class=\"number\">1</span>) mu(<span class=\"number\">1</span>)], [mu_prev(<span class=\"number\">2</span>), mu(<span class=\"number\">2</span>)], <span class=\"string\">'b-.'</span>, <span class=\"string\">'linewidth'</span>, <span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">scatter(mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>), <span class=\"number\">50</span>, [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>], <span class=\"string\">'d'</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p><img src=\"/img/meanshift_simple_demo.png\" alt=\"\"></p>\n<p>kernellogistaic</p>\n<script type=\"math/tex; mode=display\">K(x) = \\frac{1}{e^x+e^{-x}+2}</script><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">out</span> = <span class=\"title\">logistic_kernel</span><span class=\"params\">(x)</span></span></div><div class=\"line\">out = <span class=\"number\">1.</span>/(<span class=\"built_in\">exp</span>(x) + <span class=\"built_in\">exp</span>(-x) + <span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n","excerpt":"<p><a href=\"https://en.wikipedia.org/wiki/Mean_shift\">MeanShift</a>FukunagaHostetler19752000PAMI<a href=\"http://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf\">Mean Shift: A Robust Approach Toward Feature Space Analysis</a></p>\n<p>MeanShift<a href=\"https://en.wikipedia.org/wiki/Mode_(statistics\"></a>ModeMeanShift<br><img src=\"/img/meanshift_basics.jpg\" alt=\"MeanShift\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PAMI<a href=\"https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/\"></a><a href=\"https://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/\"></a></p>\n<p>$x$$d$Kernel Function$\\mathbb{R}^n\\rightarrow \\mathbb{R}$<br><img src=\"/img/meanshift_kernel_function.png\" alt=\"kernel\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">K(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp(-\\frac{x^2}{2\\sigma^2})</script><p>$K$bandwidth$h$$n$</p>\n<script type=\"math/tex; mode=display\">f(x) = \\frac{1}{nh^d}\\sum_{i=1}^{n}K(\\frac{x-x_i}{h})</script><p>$K(x)$$c_{k,d}$$1$</p>\n<script type=\"math/tex; mode=display\">K(x) = c_{k,d}k(\\Arrowvert x\\Arrowvert ^2)</script><h2 id=\"mean-shift\"><a href=\"#mean-shift\" class=\"headerlink\" title=\"mean shift\"></a>mean shift</h2><p>$f(x)$$0$$f(x)$$g(s) = -k^\\prime(s)$<br><img src=\"/img/meanshift_gradient_of_density.png\" alt=\"\"></p>\n<p>$G(x) = c_{k,d}g(\\Arrowvert x\\Arrowvert^2)$$x$$x = x_0$$m_h(x)$mean shift</p>\n<script type=\"math/tex; mode=display\">m_h(x) = \\frac{\\sum_{i=1}^{n}x_i g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}{\\sum_{i=1}^{n}g(\\Arrowvert \\frac{x-x_i}{h} \\Arrowvert^2)}-x</script><p>$m_h(x)$$f(x)$$m_h(x)$$x$$h$$g(s)$$m_h(x)$$x$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$x_0$$m_h$$x$$m_h$$[1, 2]$mean shift</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">%% generate data</span></div><div class=\"line\">mu = [<span class=\"number\">1</span> <span class=\"number\">2</span>];</div><div class=\"line\">Sigma = [<span class=\"number\">1</span> <span class=\"number\">0</span>; <span class=\"number\">0</span> <span class=\"number\">2</span>]; R = chol(Sigma);</div><div class=\"line\">N = <span class=\"number\">250</span>;</div><div class=\"line\">data = <span class=\"built_in\">repmat</span>(mu, N, <span class=\"number\">1</span>) + <span class=\"built_in\">randn</span>(N, <span class=\"number\">2</span>)*R;</div><div class=\"line\">figure</div><div class=\"line\">hold on</div><div class=\"line\">scatter(data(:, <span class=\"number\">1</span>), data(:, <span class=\"number\">2</span>), <span class=\"number\">50</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"comment\">%% meanshift</span></div><div class=\"line\">mu0 = <span class=\"built_in\">rand</span>(<span class=\"number\">1</span>,<span class=\"number\">2</span>) * <span class=\"number\">5</span>;</div><div class=\"line\">mu = mean_shift(mu0, <span class=\"number\">10</span>, data);</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">out</span> = <span class=\"title\">gaussian_kernel</span><span class=\"params\">(x, sigma)</span></span></div><div class=\"line\"><span class=\"comment\">% gauss kernel, g(x) = \\exp(-x^2/2\\sigma^2)</span></div><div class=\"line\">out = <span class=\"built_in\">exp</span>(-x.*x/(<span class=\"number\">2</span>*sigma*sigma));</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">mu</span> = <span class=\"title\">mean_shift</span><span class=\"params\">(mu0, h, data)</span></span></div><div class=\"line\"><span class=\"comment\">% implementation of meanshift algorithm</span></div><div class=\"line\"><span class=\"comment\">% mu_&#123;k+1&#125; = meanshift(mu_&#123;k&#125;) + mu_&#123;k&#125; = \\frac&#123;\\sum_i=1^n xg&#125;&#123;\\sum_i=1^n g&#125;</span></div><div class=\"line\">mu = mu0;</div><div class=\"line\">sigma = <span class=\"number\">1</span>;    <span class=\"comment\">% parameter for gaussian kernel function</span></div><div class=\"line\"><span class=\"keyword\">for</span> iter = <span class=\"number\">1</span>:<span class=\"number\">20</span>    </div><div class=\"line\">    fprintf(<span class=\"string\">'iter = %d, mu = [%f, %f]\\n'</span>, iter, mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>));</div><div class=\"line\">    scatter(mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>), <span class=\"number\">50</span>, [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>], <span class=\"string\">'d'</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\">    offset = <span class=\"built_in\">bsxfun</span>(@minus, mu, data);    <span class=\"comment\">% offset = x-x_i</span></div><div class=\"line\">    dis = sum(offset.^<span class=\"number\">2</span>, <span class=\"number\">2</span>);              <span class=\"comment\">% dis = ||x-x_i||^2</span></div><div class=\"line\">    x = data(dis &lt; h, :);                 <span class=\"comment\">% neighborhood with bandwidth = h</span></div><div class=\"line\">    g = gaussian_kernel(offset(dis &lt; h), sigma);</div><div class=\"line\">    xg = x.*g;</div><div class=\"line\">    mu_prev = mu;</div><div class=\"line\">    mu = sum(xg, <span class=\"number\">1</span>) / sum(g, <span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> norm(mu_prev - mu, <span class=\"number\">2</span>) &lt; <span class=\"number\">1E-2</span></div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    plot([mu_prev(<span class=\"number\">1</span>) mu(<span class=\"number\">1</span>)], [mu_prev(<span class=\"number\">2</span>), mu(<span class=\"number\">2</span>)], <span class=\"string\">'b-.'</span>, <span class=\"string\">'linewidth'</span>, <span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div><div class=\"line\">scatter(mu(<span class=\"number\">1</span>), mu(<span class=\"number\">2</span>), <span class=\"number\">50</span>, [<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>], <span class=\"string\">'d'</span>, <span class=\"string\">'filled'</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p><img src=\"/img/meanshift_simple_demo.png\" alt=\"\"></p>\n<p>kernellogistaic</p>\n<script type=\"math/tex; mode=display\">K(x) = \\frac{1}{e^x+e^{-x}+2}</script><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">out</span> = <span class=\"title\">logistic_kernel</span><span class=\"params\">(x)</span></span></div><div class=\"line\">out = <span class=\"number\">1.</span>/(<span class=\"built_in\">exp</span>(x) + <span class=\"built_in\">exp</span>(-x) + <span class=\"number\">2</span>);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>"},{"title":"CS131-","date":"2017-05-03T08:39:18.000Z","_content":"\n\n~~~~  \n![OpticalFlow](/img/cs131_opticalflow_demo.jpg)\n<!-- more -->\n\n## \nOptical Flow\n\n\n\n- \n- \n- \n\n\n![](/img/cs131_opticalflow_brightnessconstancy_assumption.png)\n\n$(x,y)$$(u,v)$\n$$I(x,y,t-1) = I(x+u, y+v, t)$$\n\nTaylor$I_x$, $I_y$, $I_t$Image\n$$I(x+u,y+v,t) = I(x,y,t-1)+I_xu+I_yv+I_t$$\n\n\n$$I_xu+I_yv+I_t=0$$\n\n$I_x$, $I_y$$x$$y$$I_t$$I(x,y,t)-I(x,y,t-1)$$(u,v)$ \n\n$N$$2N$$N$\n\nLucas-Kanade\n\n## L-K\nL-K$5\\times 5$\n![L-K](/img/cs131_opticalflow_lkequation.png)\n\n\n![](/img/cs131_opticalflow_lkleastsquare.png)\n\nL-K$(u,v)$\n\n- $\\mathbf{A}^\\dagger \\mathbf{A}$\n- $\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1$, $\\lambda_2$\n- $\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1/\\lambda_2$\n\nHarris$\\mathbf{A}^\\dagger \\mathbf{A}$\n![Harris](/img/cs131_opticalflow_lkrelationshipwithharris.png)\n\n\n![](/img/cs131_opticalflow_lkharris.png)\n\nL-K\n\n## \nTaylor1.\n\n![](/img/cs131_opticalflow_pyramid.png)\n\n## \n### \n$I_0$$I_1$$t=0$$t=1$$I_t, 0<t<1$2460Hz\n\n### \n\n$$I_t = (1-t)I_0+tI_1$$\n\n\"cross-fading\"\n![](/img/cs131_opticalflow_assignment_crossfade.gif)\n![](/img/cs131_opticalflow_assignment_crossfade.png)\n\n### \n$u_t(x,y)$$v_t(x,y)$$t=0$$t=1$$u_0(x,y)$$v_0(x,y)$$t=0$\n$$I_t(x+tu_0(x,y), y+tv_0(x,y)) = I_0(x,y)$$\n\nMATLAB\n``` matlab\nfor y =1:height\n    for x = 1:width\n        dy = min(max(round(y+v0(y,x)*t), 1), height);\n        dx = min(max(round(x+u0(y,x)*t), 1), width);\n        img(dy,dx,:) = img0(y,x,:);\n    end\nend\n```\n\"ForwardWarpping\"\n![](/img/cs131_opticalflow_assignment_forwardwarped.gif)\n![](/img/cs131_opticalflow_assignment_forwardwarped.png)\n\n\n### \n$t=1$*backward warpping*$t$\n$$I_t(x,y) = I_0(x-tu_t(x,y), y-tv_t(x,y))$$\n\n$t$$u_t$$v_t$\n\n$$u_t(\\hat{x},\\hat{y}) = u_0(x,y)$$\n$$v_t(\\hat{x},\\hat{y}) = v_0(x,y)$$\n\n$x^\\prime = x+u_0t$$y^\\prime = y+v_0t$$\\hat{x}\\in\\lbrace\\text{floor}(x^\\prime), \\text{ceil}(x^\\prime)\\rbrace$$\\hat{y}\\in\\lbrace\\text{floor}(y^\\prime), \\text{ceil}(y^\\prime)\\rbrace$\n\n\n\n$(\\hat{x}, \\hat{y})$$(x, y)$$(x, y)$\n\n$$\\vert I_0(x, y)  I_1(x + u_0(x, y), y + v_0(x, y))\\vert$$\n\n\n\n\n\n![](/img/cs131_opticalflow_assignment_flowwarped.gif)\n![](/img/cs131_opticalflow_assignment_flowwarped.png)","source":"_posts/cs131-opticalflow.md","raw":"---\ntitle: CS131-\ndate: 2017-05-03 16:39:18\ntags:\n    - cs131\n    - \n---\n\n\n~~~~  \n![OpticalFlow](/img/cs131_opticalflow_demo.jpg)\n<!-- more -->\n\n## \nOptical Flow\n\n\n\n- \n- \n- \n\n\n![](/img/cs131_opticalflow_brightnessconstancy_assumption.png)\n\n$(x,y)$$(u,v)$\n$$I(x,y,t-1) = I(x+u, y+v, t)$$\n\nTaylor$I_x$, $I_y$, $I_t$Image\n$$I(x+u,y+v,t) = I(x,y,t-1)+I_xu+I_yv+I_t$$\n\n\n$$I_xu+I_yv+I_t=0$$\n\n$I_x$, $I_y$$x$$y$$I_t$$I(x,y,t)-I(x,y,t-1)$$(u,v)$ \n\n$N$$2N$$N$\n\nLucas-Kanade\n\n## L-K\nL-K$5\\times 5$\n![L-K](/img/cs131_opticalflow_lkequation.png)\n\n\n![](/img/cs131_opticalflow_lkleastsquare.png)\n\nL-K$(u,v)$\n\n- $\\mathbf{A}^\\dagger \\mathbf{A}$\n- $\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1$, $\\lambda_2$\n- $\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1/\\lambda_2$\n\nHarris$\\mathbf{A}^\\dagger \\mathbf{A}$\n![Harris](/img/cs131_opticalflow_lkrelationshipwithharris.png)\n\n\n![](/img/cs131_opticalflow_lkharris.png)\n\nL-K\n\n## \nTaylor1.\n\n![](/img/cs131_opticalflow_pyramid.png)\n\n## \n### \n$I_0$$I_1$$t=0$$t=1$$I_t, 0<t<1$2460Hz\n\n### \n\n$$I_t = (1-t)I_0+tI_1$$\n\n\"cross-fading\"\n![](/img/cs131_opticalflow_assignment_crossfade.gif)\n![](/img/cs131_opticalflow_assignment_crossfade.png)\n\n### \n$u_t(x,y)$$v_t(x,y)$$t=0$$t=1$$u_0(x,y)$$v_0(x,y)$$t=0$\n$$I_t(x+tu_0(x,y), y+tv_0(x,y)) = I_0(x,y)$$\n\nMATLAB\n``` matlab\nfor y =1:height\n    for x = 1:width\n        dy = min(max(round(y+v0(y,x)*t), 1), height);\n        dx = min(max(round(x+u0(y,x)*t), 1), width);\n        img(dy,dx,:) = img0(y,x,:);\n    end\nend\n```\n\"ForwardWarpping\"\n![](/img/cs131_opticalflow_assignment_forwardwarped.gif)\n![](/img/cs131_opticalflow_assignment_forwardwarped.png)\n\n\n### \n$t=1$*backward warpping*$t$\n$$I_t(x,y) = I_0(x-tu_t(x,y), y-tv_t(x,y))$$\n\n$t$$u_t$$v_t$\n\n$$u_t(\\hat{x},\\hat{y}) = u_0(x,y)$$\n$$v_t(\\hat{x},\\hat{y}) = v_0(x,y)$$\n\n$x^\\prime = x+u_0t$$y^\\prime = y+v_0t$$\\hat{x}\\in\\lbrace\\text{floor}(x^\\prime), \\text{ceil}(x^\\prime)\\rbrace$$\\hat{y}\\in\\lbrace\\text{floor}(y^\\prime), \\text{ceil}(y^\\prime)\\rbrace$\n\n\n\n$(\\hat{x}, \\hat{y})$$(x, y)$$(x, y)$\n\n$$\\vert I_0(x, y)  I_1(x + u_0(x, y), y + v_0(x, y))\\vert$$\n\n\n\n\n\n![](/img/cs131_opticalflow_assignment_flowwarped.gif)\n![](/img/cs131_opticalflow_assignment_flowwarped.png)","slug":"cs131-opticalflow","published":1,"updated":"2018-10-27T07:16:52.384Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8je000xae7bjsmgudzv","content":"<p></p>\n<p><del></del>  <br><img src=\"/img/cs131_opticalflow_demo.jpg\" alt=\"OpticalFlow\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Optical Flow</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><br><img src=\"/img/cs131_opticalflow_brightnessconstancy_assumption.png\" alt=\"\"></p>\n<p>$(x,y)$$(u,v)$</p>\n<script type=\"math/tex; mode=display\">I(x,y,t-1) = I(x+u, y+v, t)</script><p>Taylor$I_x$, $I_y$, $I_t$Image</p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v,t) = I(x,y,t-1)+I_xu+I_yv+I_t</script><p></p>\n<script type=\"math/tex; mode=display\">I_xu+I_yv+I_t=0</script><p>$I_x$, $I_y$$x$$y$$I_t$$I(x,y,t)-I(x,y,t-1)$$(u,v)$ </p>\n<p>$N$$2N$$N$</p>\n<p>Lucas-Kanade</p>\n<h2 id=\"L-K\"><a href=\"#L-K\" class=\"headerlink\" title=\"L-K\"></a>L-K</h2><p>L-K$5\\times 5$<br><img src=\"/img/cs131_opticalflow_lkequation.png\" alt=\"L-K\"></p>\n<p><br><img src=\"/img/cs131_opticalflow_lkleastsquare.png\" alt=\"\"></p>\n<p>L-K$(u,v)$</p>\n<ul>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$</li>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1$, $\\lambda_2$</li>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1/\\lambda_2$</li>\n</ul>\n<p>Harris$\\mathbf{A}^\\dagger \\mathbf{A}$<br><img src=\"/img/cs131_opticalflow_lkrelationshipwithharris.png\" alt=\"Harris\"></p>\n<p><br><img src=\"/img/cs131_opticalflow_lkharris.png\" alt=\"\"></p>\n<p>L-K</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Taylor1.</p>\n<p><img src=\"/img/cs131_opticalflow_pyramid.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$I_0$$I_1$$t=0$$t=1$$I_t, 0&lt;t&lt;1$2460Hz</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">I_t = (1-t)I_0+tI_1</script><p>cross-fading<br><img src=\"/img/cs131_opticalflow_assignment_crossfade.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_crossfade.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$u_t(x,y)$$v_t(x,y)$$t=0$$t=1$$u_0(x,y)$$v_0(x,y)$$t=0$</p>\n<script type=\"math/tex; mode=display\">I_t(x+tu_0(x,y), y+tv_0(x,y)) = I_0(x,y)</script><p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> y =<span class=\"number\">1</span>:height</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:width</div><div class=\"line\">        dy = min(max(<span class=\"built_in\">round</span>(y+v0(y,x)*t), <span class=\"number\">1</span>), height);</div><div class=\"line\">        dx = min(max(<span class=\"built_in\">round</span>(x+u0(y,x)*t), <span class=\"number\">1</span>), width);</div><div class=\"line\">        img(dy,dx,:) = img0(y,x,:);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>ForwardWarpping<br><img src=\"/img/cs131_opticalflow_assignment_forwardwarped.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_forwardwarped.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$t=1$<em>backward warpping</em>$t$</p>\n<script type=\"math/tex; mode=display\">I_t(x,y) = I_0(x-tu_t(x,y), y-tv_t(x,y))</script><p>$t$$u_t$$v_t$</p>\n<script type=\"math/tex; mode=display\">u_t(\\hat{x},\\hat{y}) = u_0(x,y)</script><script type=\"math/tex; mode=display\">v_t(\\hat{x},\\hat{y}) = v_0(x,y)</script><p>$x^\\prime = x+u_0t$$y^\\prime = y+v_0t$$\\hat{x}\\in\\lbrace\\text{floor}(x^\\prime), \\text{ceil}(x^\\prime)\\rbrace$$\\hat{y}\\in\\lbrace\\text{floor}(y^\\prime), \\text{ceil}(y^\\prime)\\rbrace$</p>\n<p></p>\n<p>$(\\hat{x}, \\hat{y})$$(x, y)$$(x, y)$</p>\n<script type=\"math/tex; mode=display\">\\vert I_0(x, y)  I_1(x + u_0(x, y), y + v_0(x, y))\\vert</script><p></p>\n<p></p>\n<p><img src=\"/img/cs131_opticalflow_assignment_flowwarped.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_flowwarped.png\" alt=\"\"></p>\n","excerpt":"<p></p>\n<p><del></del>  <br><img src=\"/img/cs131_opticalflow_demo.jpg\" alt=\"OpticalFlow\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Optical Flow</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><br><img src=\"/img/cs131_opticalflow_brightnessconstancy_assumption.png\" alt=\"\"></p>\n<p>$(x,y)$$(u,v)$</p>\n<script type=\"math/tex; mode=display\">I(x,y,t-1) = I(x+u, y+v, t)</script><p>Taylor$I_x$, $I_y$, $I_t$Image</p>\n<script type=\"math/tex; mode=display\">I(x+u,y+v,t) = I(x,y,t-1)+I_xu+I_yv+I_t</script><p></p>\n<script type=\"math/tex; mode=display\">I_xu+I_yv+I_t=0</script><p>$I_x$, $I_y$$x$$y$$I_t$$I(x,y,t)-I(x,y,t-1)$$(u,v)$ </p>\n<p>$N$$2N$$N$</p>\n<p>Lucas-Kanade</p>\n<h2 id=\"L-K\"><a href=\"#L-K\" class=\"headerlink\" title=\"L-K\"></a>L-K</h2><p>L-K$5\\times 5$<br><img src=\"/img/cs131_opticalflow_lkequation.png\" alt=\"L-K\"></p>\n<p><br><img src=\"/img/cs131_opticalflow_lkleastsquare.png\" alt=\"\"></p>\n<p>L-K$(u,v)$</p>\n<ul>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$</li>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1$, $\\lambda_2$</li>\n<li>$\\mathbf{A}^\\dagger \\mathbf{A}$$\\lambda_1/\\lambda_2$</li>\n</ul>\n<p>Harris$\\mathbf{A}^\\dagger \\mathbf{A}$<br><img src=\"/img/cs131_opticalflow_lkrelationshipwithharris.png\" alt=\"Harris\"></p>\n<p><br><img src=\"/img/cs131_opticalflow_lkharris.png\" alt=\"\"></p>\n<p>L-K</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Taylor1.</p>\n<p><img src=\"/img/cs131_opticalflow_pyramid.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$I_0$$I_1$$t=0$$t=1$$I_t, 0&lt;t&lt;1$2460Hz</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">I_t = (1-t)I_0+tI_1</script><p>cross-fading<br><img src=\"/img/cs131_opticalflow_assignment_crossfade.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_crossfade.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$u_t(x,y)$$v_t(x,y)$$t=0$$t=1$$u_0(x,y)$$v_0(x,y)$$t=0$</p>\n<script type=\"math/tex; mode=display\">I_t(x+tu_0(x,y), y+tv_0(x,y)) = I_0(x,y)</script><p>MATLAB<br><figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> y =<span class=\"number\">1</span>:height</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:width</div><div class=\"line\">        dy = min(max(<span class=\"built_in\">round</span>(y+v0(y,x)*t), <span class=\"number\">1</span>), height);</div><div class=\"line\">        dx = min(max(<span class=\"built_in\">round</span>(x+u0(y,x)*t), <span class=\"number\">1</span>), width);</div><div class=\"line\">        img(dy,dx,:) = img0(y,x,:);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure></p>\n<p>ForwardWarpping<br><img src=\"/img/cs131_opticalflow_assignment_forwardwarped.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_forwardwarped.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$t=1$<em>backward warpping</em>$t$</p>\n<script type=\"math/tex; mode=display\">I_t(x,y) = I_0(x-tu_t(x,y), y-tv_t(x,y))</script><p>$t$$u_t$$v_t$</p>\n<script type=\"math/tex; mode=display\">u_t(\\hat{x},\\hat{y}) = u_0(x,y)</script><script type=\"math/tex; mode=display\">v_t(\\hat{x},\\hat{y}) = v_0(x,y)</script><p>$x^\\prime = x+u_0t$$y^\\prime = y+v_0t$$\\hat{x}\\in\\lbrace\\text{floor}(x^\\prime), \\text{ceil}(x^\\prime)\\rbrace$$\\hat{y}\\in\\lbrace\\text{floor}(y^\\prime), \\text{ceil}(y^\\prime)\\rbrace$</p>\n<p></p>\n<p>$(\\hat{x}, \\hat{y})$$(x, y)$$(x, y)$</p>\n<script type=\"math/tex; mode=display\">\\vert I_0(x, y)  I_1(x + u_0(x, y), y + v_0(x, y))\\vert</script><p></p>\n<p></p>\n<p><img src=\"/img/cs131_opticalflow_assignment_flowwarped.gif\" alt=\"\"><br><img src=\"/img/cs131_opticalflow_assignment_flowwarped.png\" alt=\"\"></p>"},{"title":"CS229 ","date":"2018-03-21T03:08:14.000Z","_content":"logistic\n<!-- more -->\n\n## \n\n$$\\hat{y} = h_\\theta(x) = \\sum_{i=1}^{m}\\theta_i x_i = \\theta^T x$$\n\nMean Square Error(MSE)$y$ground truth\n$$J(\\theta) = \\frac{1}{2}(\\hat{y}-y)^2$$\n\n$\\theta^*$\n$$\\theta^* = \\arg\\min J(\\theta)$$\n\n### \n\n$$\\theta_{i+1} = \\theta_{i} - \\alpha \\nabla_\\theta J(\\theta)$$\n\n\n$$\\begin{aligned}\\nabla_\\theta J(\\theta) &= \\frac{1}{2}\\nabla_\\theta (\\theta^T x - y)^2 \\\\\n&= (\\theta^T x - y) x\\end{aligned}$$\n\n\n\n$J(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}J_i(\\theta)$$\\frac{1}{N}$\n\n### \n$x^{(i)}$$X \\in \\mathbb{R}^{N\\times d}$$N$$d$$\\theta\\in\\mathbb{R}^{d\\times 1}$$X\\theta$$i$$i$ground truth$N\\times 1$\n$$J(\\theta) = \\frac{1}{2N} \\Vert X\\theta-y \\Vert_2^2$$\n\n$\\Vert x\\Vert_2^2$$x^T x$\n$$\\begin{aligned}J &= (X\\theta - y)^T (X\\theta - y) \\\\\n&= \\theta^T X^T X\\theta - 2\\theta^T x^T y +y^T y\\end{aligned}$$\n\n\n$$\\nabla_\\theta J = X^T X\\theta - X^T y$$\n\n![](/img/cs229-supervised-learning-least-square-normal-equation.png)\n\n\n![](/img/cs229-supervised-learning-some-useful-matrix-derivatives.png)\n$0$\n$$\\theta^* = (X^TX)^{-1}X^T y$$\n\n### \nlikelihood function\n\n$\\theta$$\\theta$$x$$y$\n$$L(\\theta) = \\prod_{i=1}^{N}P(y^{(i)}|x^{(i)};\\theta)$$\n\nground truthGaussian\n$$y - \\theta^T x  =  \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$$\n\n\n$$L(\\theta) = \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})$$\n\n$\\theta$$\\theta$$(x^{(i)}, y^{(i)})$$L(\\theta)$\n$$\\theta^* = \\arg\\max L(\\theta)$$\n\n$\\log(\\cdot)$$\\log L(\\theta)$\n$$\\begin{aligned} \\mathcal{l} &= \\log L(\\theta) \\\\\n&= \\sum_{i=1}^{N}\\log \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp (\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})\\\\\n&= N\\log\\frac{1}{\\sqrt{2\\pi\\sigma^2}} -\\frac{1}{\\sigma^2}\\frac{1}{2}\\sum_{i=1}^{N}(y^{(i)}-\\theta^T x^{(i)})^2 \\end{aligned}$$\n\n\n\nGaussian\n\n### \n$w^{(i)} = \\exp (-\\frac{(x^{(i)}-x)^2}{2\\tau^2})$\n\n## logistic\nlogistic\n### logistic\nlogistic$\\sigma(x) = \\frac{1}{1+e^{-x}}$sigmoid$(-\\infty, +\\infty)$$(0, 1)$\n![sigmoid](/img/cs229-supervised-learning-sigmoid.png)\n\n$x$\n$$\\frac{d\\sigma(x)} {dx} = \\sigma(x)(1-\\sigma(x))$$\n\nlogistic$x$feature$h_\\theta(x) = \\sigma(\\theta^T x)$\n\n### logistic\nlogistic$(0,1)$$1$\n$$\\begin{aligned}P(y=1|x) &= h_\\theta(x) \\\\\nP(y=0|x) &= 1-h_\\theta(x) \\end{aligned}$$\n\n\n$$P(y|x) = (h_\\theta(x))^y (1-h_\\theta(x))^(1-y)$$\n\n$\\theta$$(i)$\n\n$$\\begin{aligned}L(\\theta) &= \\prod_{i=1}^{N}P(y|x;\\theta) \\\\\n&=\\prod (h_\\theta(x))^y (1-h_\\theta(x))^{(1-y)} \\end{aligned}$$\n\n\n$$\\log L(\\theta) = \\sum_{i=1}^{N}y\\log(h(x)) + (1-y)\\log(1-h(x))$$\n\n$J(\\theta) = - [y\\log(h(x)) + (1-y)\\log(1-h(x))]$$h(x)$$P$\n\nlogistic\n$$\\theta_{i+1} = \\theta_i - \\alpha (h_\\theta(x) - y)x$$\n\n$h_\\theta(x)$\n\n### \nlogistic$\\lbrace 1, -1\\rbrace$$\\sigma(x)$$g(x)$\n$$g(x) = \\begin{cases} 1, \\quad\\text{if}\\quad x \\ge 0\\\\ 0, \\quad\\text{if}\\quad x < 0\\end{cases}$$\n\nperceptron machine","source":"_posts/cs229-supervised-learning.md","raw":"---\ntitle: CS229 \ndate: 2018-03-21 11:08:14\ntags:\n    - \n    - cs229\n---\nlogistic\n<!-- more -->\n\n## \n\n$$\\hat{y} = h_\\theta(x) = \\sum_{i=1}^{m}\\theta_i x_i = \\theta^T x$$\n\nMean Square Error(MSE)$y$ground truth\n$$J(\\theta) = \\frac{1}{2}(\\hat{y}-y)^2$$\n\n$\\theta^*$\n$$\\theta^* = \\arg\\min J(\\theta)$$\n\n### \n\n$$\\theta_{i+1} = \\theta_{i} - \\alpha \\nabla_\\theta J(\\theta)$$\n\n\n$$\\begin{aligned}\\nabla_\\theta J(\\theta) &= \\frac{1}{2}\\nabla_\\theta (\\theta^T x - y)^2 \\\\\n&= (\\theta^T x - y) x\\end{aligned}$$\n\n\n\n$J(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}J_i(\\theta)$$\\frac{1}{N}$\n\n### \n$x^{(i)}$$X \\in \\mathbb{R}^{N\\times d}$$N$$d$$\\theta\\in\\mathbb{R}^{d\\times 1}$$X\\theta$$i$$i$ground truth$N\\times 1$\n$$J(\\theta) = \\frac{1}{2N} \\Vert X\\theta-y \\Vert_2^2$$\n\n$\\Vert x\\Vert_2^2$$x^T x$\n$$\\begin{aligned}J &= (X\\theta - y)^T (X\\theta - y) \\\\\n&= \\theta^T X^T X\\theta - 2\\theta^T x^T y +y^T y\\end{aligned}$$\n\n\n$$\\nabla_\\theta J = X^T X\\theta - X^T y$$\n\n![](/img/cs229-supervised-learning-least-square-normal-equation.png)\n\n\n![](/img/cs229-supervised-learning-some-useful-matrix-derivatives.png)\n$0$\n$$\\theta^* = (X^TX)^{-1}X^T y$$\n\n### \nlikelihood function\n\n$\\theta$$\\theta$$x$$y$\n$$L(\\theta) = \\prod_{i=1}^{N}P(y^{(i)}|x^{(i)};\\theta)$$\n\nground truthGaussian\n$$y - \\theta^T x  =  \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$$\n\n\n$$L(\\theta) = \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})$$\n\n$\\theta$$\\theta$$(x^{(i)}, y^{(i)})$$L(\\theta)$\n$$\\theta^* = \\arg\\max L(\\theta)$$\n\n$\\log(\\cdot)$$\\log L(\\theta)$\n$$\\begin{aligned} \\mathcal{l} &= \\log L(\\theta) \\\\\n&= \\sum_{i=1}^{N}\\log \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp (\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})\\\\\n&= N\\log\\frac{1}{\\sqrt{2\\pi\\sigma^2}} -\\frac{1}{\\sigma^2}\\frac{1}{2}\\sum_{i=1}^{N}(y^{(i)}-\\theta^T x^{(i)})^2 \\end{aligned}$$\n\n\n\nGaussian\n\n### \n$w^{(i)} = \\exp (-\\frac{(x^{(i)}-x)^2}{2\\tau^2})$\n\n## logistic\nlogistic\n### logistic\nlogistic$\\sigma(x) = \\frac{1}{1+e^{-x}}$sigmoid$(-\\infty, +\\infty)$$(0, 1)$\n![sigmoid](/img/cs229-supervised-learning-sigmoid.png)\n\n$x$\n$$\\frac{d\\sigma(x)} {dx} = \\sigma(x)(1-\\sigma(x))$$\n\nlogistic$x$feature$h_\\theta(x) = \\sigma(\\theta^T x)$\n\n### logistic\nlogistic$(0,1)$$1$\n$$\\begin{aligned}P(y=1|x) &= h_\\theta(x) \\\\\nP(y=0|x) &= 1-h_\\theta(x) \\end{aligned}$$\n\n\n$$P(y|x) = (h_\\theta(x))^y (1-h_\\theta(x))^(1-y)$$\n\n$\\theta$$(i)$\n\n$$\\begin{aligned}L(\\theta) &= \\prod_{i=1}^{N}P(y|x;\\theta) \\\\\n&=\\prod (h_\\theta(x))^y (1-h_\\theta(x))^{(1-y)} \\end{aligned}$$\n\n\n$$\\log L(\\theta) = \\sum_{i=1}^{N}y\\log(h(x)) + (1-y)\\log(1-h(x))$$\n\n$J(\\theta) = - [y\\log(h(x)) + (1-y)\\log(1-h(x))]$$h(x)$$P$\n\nlogistic\n$$\\theta_{i+1} = \\theta_i - \\alpha (h_\\theta(x) - y)x$$\n\n$h_\\theta(x)$\n\n### \nlogistic$\\lbrace 1, -1\\rbrace$$\\sigma(x)$$g(x)$\n$$g(x) = \\begin{cases} 1, \\quad\\text{if}\\quad x \\ge 0\\\\ 0, \\quad\\text{if}\\quad x < 0\\end{cases}$$\n\nperceptron machine","slug":"cs229-supervised-learning","published":1,"updated":"2018-10-27T07:16:52.386Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8jg0010ae7by4sfzrak","content":"<p>logistic<br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\hat{y} = h_\\theta(x) = \\sum_{i=1}^{m}\\theta_i x_i = \\theta^T x</script><p>Mean Square Error(MSE)$y$ground truth</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = \\frac{1}{2}(\\hat{y}-y)^2</script><p>$\\theta^*$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = \\arg\\min J(\\theta)</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{i+1} = \\theta_{i} - \\alpha \\nabla_\\theta J(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\nabla_\\theta J(\\theta) &= \\frac{1}{2}\\nabla_\\theta (\\theta^T x - y)^2 \\\\\n&= (\\theta^T x - y) x\\end{aligned}</script><p></p>\n<p>$J(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}J_i(\\theta)$$\\frac{1}{N}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$x^{(i)}$$X \\in \\mathbb{R}^{N\\times d}$$N$$d$$\\theta\\in\\mathbb{R}^{d\\times 1}$$X\\theta$$i$$i$ground truth$N\\times 1$</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = \\frac{1}{2N} \\Vert X\\theta-y \\Vert_2^2</script><p>$\\Vert x\\Vert_2^2$$x^T x$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}J &= (X\\theta - y)^T (X\\theta - y) \\\\\n&= \\theta^T X^T X\\theta - 2\\theta^T x^T y +y^T y\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\nabla_\\theta J = X^T X\\theta - X^T y</script><p><img src=\"/img/cs229-supervised-learning-least-square-normal-equation.png\" alt=\"\"></p>\n<p><br><img src=\"/img/cs229-supervised-learning-some-useful-matrix-derivatives.png\" alt=\"\"><br>$0$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = (X^TX)^{-1}X^T y</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>likelihood function</p>\n<p>$\\theta$$\\theta$$x$$y$</p>\n<script type=\"math/tex; mode=display\">L(\\theta) = \\prod_{i=1}^{N}P(y^{(i)}|x^{(i)};\\theta)</script><p>ground truthGaussian</p>\n<script type=\"math/tex; mode=display\">y - \\theta^T x  =  \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)</script><p></p>\n<script type=\"math/tex; mode=display\">L(\\theta) = \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})</script><p>$\\theta$$\\theta$$(x^{(i)}, y^{(i)})$$L(\\theta)$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = \\arg\\max L(\\theta)</script><p>$\\log(\\cdot)$$\\log L(\\theta)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} \\mathcal{l} &= \\log L(\\theta) \\\\\n&= \\sum_{i=1}^{N}\\log \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp (\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})\\\\\n&= N\\log\\frac{1}{\\sqrt{2\\pi\\sigma^2}} -\\frac{1}{\\sigma^2}\\frac{1}{2}\\sum_{i=1}^{N}(y^{(i)}-\\theta^T x^{(i)})^2 \\end{aligned}</script><p></p>\n<p>Gaussian</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$w^{(i)} = \\exp (-\\frac{(x^{(i)}-x)^2}{2\\tau^2})$</p>\n<h2 id=\"logistic\"><a href=\"#logistic\" class=\"headerlink\" title=\"logistic\"></a>logistic</h2><p>logistic</p>\n<h3 id=\"logistic\"><a href=\"#logistic\" class=\"headerlink\" title=\"logistic\"></a>logistic</h3><p>logistic$\\sigma(x) = \\frac{1}{1+e^{-x}}$sigmoid$(-\\infty, +\\infty)$$(0, 1)$<br><img src=\"/img/cs229-supervised-learning-sigmoid.png\" alt=\"sigmoid\"></p>\n<p>$x$</p>\n<script type=\"math/tex; mode=display\">\\frac{d\\sigma(x)} {dx} = \\sigma(x)(1-\\sigma(x))</script><p>logistic$x$feature$h_\\theta(x) = \\sigma(\\theta^T x)$</p>\n<h3 id=\"logistic-1\"><a href=\"#logistic-1\" class=\"headerlink\" title=\"logistic\"></a>logistic</h3><p>logistic$(0,1)$$1$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}P(y=1|x) &= h_\\theta(x) \\\\\nP(y=0|x) &= 1-h_\\theta(x) \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">P(y|x) = (h_\\theta(x))^y (1-h_\\theta(x))^(1-y)</script><p>$\\theta$$(i)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L(\\theta) &= \\prod_{i=1}^{N}P(y|x;\\theta) \\\\\n&=\\prod (h_\\theta(x))^y (1-h_\\theta(x))^{(1-y)} \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log L(\\theta) = \\sum_{i=1}^{N}y\\log(h(x)) + (1-y)\\log(1-h(x))</script><p>$J(\\theta) = - [y\\log(h(x)) + (1-y)\\log(1-h(x))]$$h(x)$$P$</p>\n<p>logistic</p>\n<script type=\"math/tex; mode=display\">\\theta_{i+1} = \\theta_i - \\alpha (h_\\theta(x) - y)x</script><p>$h_\\theta(x)$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>logistic$\\lbrace 1, -1\\rbrace$$\\sigma(x)$$g(x)$</p>\n<script type=\"math/tex; mode=display\">g(x) = \\begin{cases} 1, \\quad\\text{if}\\quad x \\ge 0\\\\ 0, \\quad\\text{if}\\quad x < 0\\end{cases}</script><p>perceptron machine</p>\n","excerpt":"<p>logistic<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\hat{y} = h_\\theta(x) = \\sum_{i=1}^{m}\\theta_i x_i = \\theta^T x</script><p>Mean Square Error(MSE)$y$ground truth</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = \\frac{1}{2}(\\hat{y}-y)^2</script><p>$\\theta^*$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = \\arg\\min J(\\theta)</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{i+1} = \\theta_{i} - \\alpha \\nabla_\\theta J(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\nabla_\\theta J(\\theta) &= \\frac{1}{2}\\nabla_\\theta (\\theta^T x - y)^2 \\\\\n&= (\\theta^T x - y) x\\end{aligned}</script><p></p>\n<p>$J(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}J_i(\\theta)$$\\frac{1}{N}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$x^{(i)}$$X \\in \\mathbb{R}^{N\\times d}$$N$$d$$\\theta\\in\\mathbb{R}^{d\\times 1}$$X\\theta$$i$$i$ground truth$N\\times 1$</p>\n<script type=\"math/tex; mode=display\">J(\\theta) = \\frac{1}{2N} \\Vert X\\theta-y \\Vert_2^2</script><p>$\\Vert x\\Vert_2^2$$x^T x$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}J &= (X\\theta - y)^T (X\\theta - y) \\\\\n&= \\theta^T X^T X\\theta - 2\\theta^T x^T y +y^T y\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\nabla_\\theta J = X^T X\\theta - X^T y</script><p><img src=\"/img/cs229-supervised-learning-least-square-normal-equation.png\" alt=\"\"></p>\n<p><br><img src=\"/img/cs229-supervised-learning-some-useful-matrix-derivatives.png\" alt=\"\"><br>$0$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = (X^TX)^{-1}X^T y</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>likelihood function</p>\n<p>$\\theta$$\\theta$$x$$y$</p>\n<script type=\"math/tex; mode=display\">L(\\theta) = \\prod_{i=1}^{N}P(y^{(i)}|x^{(i)};\\theta)</script><p>ground truthGaussian</p>\n<script type=\"math/tex; mode=display\">y - \\theta^T x  =  \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)</script><p></p>\n<script type=\"math/tex; mode=display\">L(\\theta) = \\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi\\sigma}}\\exp(\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})</script><p>$\\theta$$\\theta$$(x^{(i)}, y^{(i)})$$L(\\theta)$</p>\n<script type=\"math/tex; mode=display\">\\theta^* = \\arg\\max L(\\theta)</script><p>$\\log(\\cdot)$$\\log L(\\theta)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned} \\mathcal{l} &= \\log L(\\theta) \\\\\n&= \\sum_{i=1}^{N}\\log \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp (\\frac{(y^{(i)}-\\theta^T x^{(i)})^2}{2\\sigma^2})\\\\\n&= N\\log\\frac{1}{\\sqrt{2\\pi\\sigma^2}} -\\frac{1}{\\sigma^2}\\frac{1}{2}\\sum_{i=1}^{N}(y^{(i)}-\\theta^T x^{(i)})^2 \\end{aligned}</script><p></p>\n<p>Gaussian</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$w^{(i)} = \\exp (-\\frac{(x^{(i)}-x)^2}{2\\tau^2})$</p>\n<h2 id=\"logistic\"><a href=\"#logistic\" class=\"headerlink\" title=\"logistic\"></a>logistic</h2><p>logistic</p>\n<h3 id=\"logistic\"><a href=\"#logistic\" class=\"headerlink\" title=\"logistic\"></a>logistic</h3><p>logistic$\\sigma(x) = \\frac{1}{1+e^{-x}}$sigmoid$(-\\infty, +\\infty)$$(0, 1)$<br><img src=\"/img/cs229-supervised-learning-sigmoid.png\" alt=\"sigmoid\"></p>\n<p>$x$</p>\n<script type=\"math/tex; mode=display\">\\frac{d\\sigma(x)} {dx} = \\sigma(x)(1-\\sigma(x))</script><p>logistic$x$feature$h_\\theta(x) = \\sigma(\\theta^T x)$</p>\n<h3 id=\"logistic-1\"><a href=\"#logistic-1\" class=\"headerlink\" title=\"logistic\"></a>logistic</h3><p>logistic$(0,1)$$1$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}P(y=1|x) &= h_\\theta(x) \\\\\nP(y=0|x) &= 1-h_\\theta(x) \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">P(y|x) = (h_\\theta(x))^y (1-h_\\theta(x))^(1-y)</script><p>$\\theta$$(i)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}L(\\theta) &= \\prod_{i=1}^{N}P(y|x;\\theta) \\\\\n&=\\prod (h_\\theta(x))^y (1-h_\\theta(x))^{(1-y)} \\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log L(\\theta) = \\sum_{i=1}^{N}y\\log(h(x)) + (1-y)\\log(1-h(x))</script><p>$J(\\theta) = - [y\\log(h(x)) + (1-y)\\log(1-h(x))]$$h(x)$$P$</p>\n<p>logistic</p>\n<script type=\"math/tex; mode=display\">\\theta_{i+1} = \\theta_i - \\alpha (h_\\theta(x) - y)x</script><p>$h_\\theta(x)$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>logistic$\\lbrace 1, -1\\rbrace$$\\sigma(x)$$g(x)$</p>\n<script type=\"math/tex; mode=display\">g(x) = \\begin{cases} 1, \\quad\\text{if}\\quad x \\ge 0\\\\ 0, \\quad\\text{if}\\quad x < 0\\end{cases}</script><p>perceptron machine</p>"},{"title":"CS131-(SIFT)","date":"2017-01-30T14:16:18.000Z","_content":"\n[SIFT(Scale Invariant Feature Transform)](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform),LoweObject DetectionSIFTSIFT3D\n- scale spaceDoGscaleastimage positioninterest point\n- interest pointlocalizationinterest pointscaleposition\n- key pointfeature operationscaleposition\n- key pointkey pointSIFT\n\n![SIFT](/img/sift_picture.jpg)\n\n<!-- more -->\n## SIFT\nHarris$f$$\\mathcal{T}$$f(I) = f(\\mathcal{T}(I))$Harris\n![harris](/img/harris_non_scale_constant.png)\n\npatchregion size\n![](/img/patch_average_intensity_scale_constant.png)\n\nLowefeaturescaleDoG\n\n[Lowe](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)SIFTSIFTdensekey point500x500~2000SIFTimage matchingrecognitionref imageSIFTSIFT\n\n[Lowe](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)SIFT\n\n## \n$I(x,y)$$G(x,y,\\sigma)$\n$$L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)$$\n\n$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$$\\sigma$\n\nDoG(difference of Gaussian)\n$$D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)$$\n\n$L$octave$L$DoGoctaveoctaveoctaveoctave$s$$s+1$$\\sigma$2$\\sigma$$k = 2^{1/s}$paddingoctave$s+3$$s=2$\n![DoG](/img/sift_dog.png)\n\nDoGDoGscale-normalizedGuassian Laplace$\\sigma^2\\Delta G$$\\sigma^2$$\\sigma \\Delta G$functionfeature\n\n\n$$\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G$$\n\n\n$$\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}$$\n\n\n$$G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G$$\n$k=1$0$s=\\infty$octave$k$$\\sqrt{2}$$s=2$octave$k$$k-1$$k-1$\n\nDoG26\n![](/img/sift_detection_maximum.png)\n\nresize2key point\n\nLoweDoGkey pointkey point\n\n## 128feature\nkey point128CS1312key point`pyramid{scale}(y, x)`key pointkey point128\n\npoint16x16patch4x416cellcell16cell8bincell816cell128SIFT`patch_mag``patch_theta`patch\n\n``` matlab\npatch_mag = sqrt(patch_dx.^2 + patch_dy.^2);\npatch_theta = atan2(patch_dy, patch_dx);  % atan2[-pi, pi]\npatch_theta = mod(patch_theta, 2*pi);   % [0, 2pi]\n```\n\nkey pointslidekey pointpatch\n![](/img/sift_dominant_orientation.png)\n\n`[0, 2pi]``bin`patch`bin`\n\n``` matlab\nfunction [histogram, angles] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles)\n% Compute a gradient histogram using gradient magnitudes and directions.\n% Each point is assigned to one of num_bins depending on its gradient\n% direction; the gradient magnitude of that point is added to its bin.\n%\n% INPUT\n% num_bins: The number of bins to which points should be assigned.\n% gradient_magnitudes, gradient angles:\n%       Two arrays of the same shape where gradient_magnitudes(i) and\n%       gradient_angles(i) give the magnitude and direction of the gradient\n%       for the ith point. gradient_angles ranges from 0 to 2*pi\n%                                      \n% OUTPUT\n% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is\n%       the sum of entries in gradient_magnitudes whose corresponding\n%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for\n%       angles between angle_step and 2*angle_step. Angle_step is calculated as\n%       2*pi/num_bins.\n\n% angles: A 1 x num_bins array which holds the histogram bin lower bounds.\n%       In other words, histogram(i) contains the sum of the\n%       gradient magnitudes of all points whose gradient directions fall\n%       in the range [angles(i), angles(i + 1))\n\n    angle_step = 2 * pi / num_bins;\n    angles = 0 : angle_step : (2*pi-angle_step);\n\n    histogram = zeros(1, num_bins);\n    num = numel(gradient_angles);\n    for n = 1:num\n        index = floor(gradient_angles(n) / angle_step) + 1;\n        histogram(index) = histogram(index) + gradient_magnitudes(n);\n    end    \nend\n\n```\n\nLowe`bin`36\n\n``` matlab\nfunction direction = ComputeDominantDirection(gradient_magnitudes, gradient_angles)\n% Computes the dominant gradient direction for the region around a keypoint\n% given the scale of the keypoint and the gradient magnitudes and gradient\n% angles of the pixels in the region surrounding the keypoint.\n%\n% INPUT\n% gradient_magnitudes, gradient_angles:\n%   Two arrays of the same shape where gradient_magnitudes(i) and\n%   gradient_angles(i) give the magnitude and direction of the gradient for\n%   the ith point.\n\n    % Compute a gradient histogram using the weighted gradient magnitudes.\n    % In David Lowe's paper he suggests using 36 bins for this histogram.\n    num_bins = 36;\n    % Step 1:\n    % compute the 36-bin histogram of angles using ComputeGradientHistogram()\n    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);\n    % Step 2:\n    % Find the maximum value of the gradient histogram, and set \"direction\"\n    % to the angle corresponding to the maximum. (To match our solutions,\n    % just use the lower-bound angle of the max histogram bin. (E.g. return\n    % 0 radians if it's bin 1.)\n    [~, max_index] = max(histogram);\n    direction = angle_bound(max_index);\nend\n```\n\npatch\n\n``` matlab\npatch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;\npatch_theta = mod(patch_theta, 2*pi);\npatch_mag = patch_mag .* fspecial('gaussian', patch_size, patch_size / 2); % patch_size = 16\n```\n\ncellfeature\n\n``` matlab\nfeature = [];\nrow_iter = 1;\nfor y = 1:num_histograms\n    col_iter = 1;\n    for x = 1:num_histograms\n        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);\n        feature = [feature, histogram];\n        col_iter = col_iter + pixelsPerHistogram;\n    end\n    row_iter = row_iter + pixelsPerHistogram;\nend\n```\n\nfeaturenormalizationfeature0.2\n\nSIFTLoweslide\n\n## \nHarrisSIFTSIFTMATLAB`descriptor`SIFT0.7\n\n``` matlab\nfunction match = SIFTSimpleMatcher(descriptor1, descriptor2, thresh)\n% SIFTSimpleMatcher\n%   Match one set of SIFT descriptors (descriptor1) to another set of\n%   descriptors (decriptor2). Each descriptor from descriptor1 can at\n%   most be matched to one member of descriptor2, but descriptors from\n%   descriptor2 can be matched more than once.\n%   \n%   Matches are determined as follows:\n%   For each descriptor vector in descriptor1, find the Euclidean distance\n%   between it and each descriptor vector in descriptor2. If the smallest\n%   distance is less than thresh*(the next smallest distance), we say that\n%   the two vectors are a match, and we add the row [d1 index, d2 index] to\n%   the \"match\" array.\n%   \n% INPUT:\n%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.\n%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.\n%   thresh: a given threshold of ratio. Typically 0.7\n%\n% OUTPUT:\n%   Match: N * 2 matrix, each row is a match.\n%          For example, Match(k, :) = [i, j] means i-th descriptor in\n%          descriptor1 is matched to j-th descriptor in descriptor2.\n    if ~exist('thresh', 'var'),\n        thresh = 0.7;\n    end\n\n    match = [];\n    [N1, ~] = size(descriptor1);\n    for i = 1:N1\n        fea = descriptor1(i, :);\n        err = bsxfun(@minus, fea, descriptor2);\n        dis = sqrt(sum(err.^2, 2));\n        [sorted_dis, ind] = sort(dis, 1);\n        if sorted_dis(1) < thresh * sorted_dis(2)\n            match = [match; [i, ind(1)]];\n        end\n    end\nend\n\n```\n\n$H$$H$\n$$Hp_{\\text{before}} = p_{\\text{after}}$$\n\n\n$$p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}$$\n\n\n$$p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger$$\n\n\n\n``` matlab\nfunction H = ComputeAffineMatrix( Pt1, Pt2 )\n%ComputeAffineMatrix\n%   Computes the transformation matrix that transforms a point from\n%   coordinate frame 1 to coordinate frame 2\n%Input:\n%   Pt1: N * 2 matrix, each row is a point in image 1\n%       (N must be at least 3)\n%   Pt2: N * 2 matrix, each row is the point in image 2 that\n%       matches the same point in image 1 (N should be more than 3)\n%Output:\n%   H: 3 * 3 affine transformation matrix,\n%       such that H*pt1(i,:) = pt2(i,:)\n\n    N = size(Pt1,1);\n    if size(Pt1, 1) ~= size(Pt2, 1),\n        error('Dimensions unmatched.');\n    elseif N<3\n        error('At least 3 points are required.');\n    end\n\n    % Convert the input points to homogeneous coordintes.\n    P1 = [Pt1';ones(1,N)];\n    P2 = [Pt2';ones(1,N)];\n\n    H = P1*P1'\\P1*P2';\n    H = H';\n\n    % Sometimes numerical issues cause least-squares to produce a bottom\n    % row which is not exactly [0 0 1], which confuses some of the later\n    % code. So we'll ensure the bottom row is exactly [0 0 1].\n    H(3,:) = [0 0 1];\nend\n```\n\n~\n![result 1](/img/sift_experiment_1.png)\n![result 2](/img/sift_experiment_2.png)\n","source":"_posts/cs131-sift.md","raw":"---\ntitle: CS131-(SIFT)\ndate: 2017-01-30 22:16:18\ntags:\n     - cs131\n     - \n---\n\n[SIFT(Scale Invariant Feature Transform)](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform),LoweObject DetectionSIFTSIFT3D\n- scale spaceDoGscaleastimage positioninterest point\n- interest pointlocalizationinterest pointscaleposition\n- key pointfeature operationscaleposition\n- key pointkey pointSIFT\n\n![SIFT](/img/sift_picture.jpg)\n\n<!-- more -->\n## SIFT\nHarris$f$$\\mathcal{T}$$f(I) = f(\\mathcal{T}(I))$Harris\n![harris](/img/harris_non_scale_constant.png)\n\npatchregion size\n![](/img/patch_average_intensity_scale_constant.png)\n\nLowefeaturescaleDoG\n\n[Lowe](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)SIFTSIFTdensekey point500x500~2000SIFTimage matchingrecognitionref imageSIFTSIFT\n\n[Lowe](http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)SIFT\n\n## \n$I(x,y)$$G(x,y,\\sigma)$\n$$L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)$$\n\n$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$$\\sigma$\n\nDoG(difference of Gaussian)\n$$D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)$$\n\n$L$octave$L$DoGoctaveoctaveoctaveoctave$s$$s+1$$\\sigma$2$\\sigma$$k = 2^{1/s}$paddingoctave$s+3$$s=2$\n![DoG](/img/sift_dog.png)\n\nDoGDoGscale-normalizedGuassian Laplace$\\sigma^2\\Delta G$$\\sigma^2$$\\sigma \\Delta G$functionfeature\n\n\n$$\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G$$\n\n\n$$\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}$$\n\n\n$$G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G$$\n$k=1$0$s=\\infty$octave$k$$\\sqrt{2}$$s=2$octave$k$$k-1$$k-1$\n\nDoG26\n![](/img/sift_detection_maximum.png)\n\nresize2key point\n\nLoweDoGkey pointkey point\n\n## 128feature\nkey point128CS1312key point`pyramid{scale}(y, x)`key pointkey point128\n\npoint16x16patch4x416cellcell16cell8bincell816cell128SIFT`patch_mag``patch_theta`patch\n\n``` matlab\npatch_mag = sqrt(patch_dx.^2 + patch_dy.^2);\npatch_theta = atan2(patch_dy, patch_dx);  % atan2[-pi, pi]\npatch_theta = mod(patch_theta, 2*pi);   % [0, 2pi]\n```\n\nkey pointslidekey pointpatch\n![](/img/sift_dominant_orientation.png)\n\n`[0, 2pi]``bin`patch`bin`\n\n``` matlab\nfunction [histogram, angles] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles)\n% Compute a gradient histogram using gradient magnitudes and directions.\n% Each point is assigned to one of num_bins depending on its gradient\n% direction; the gradient magnitude of that point is added to its bin.\n%\n% INPUT\n% num_bins: The number of bins to which points should be assigned.\n% gradient_magnitudes, gradient angles:\n%       Two arrays of the same shape where gradient_magnitudes(i) and\n%       gradient_angles(i) give the magnitude and direction of the gradient\n%       for the ith point. gradient_angles ranges from 0 to 2*pi\n%                                      \n% OUTPUT\n% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is\n%       the sum of entries in gradient_magnitudes whose corresponding\n%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for\n%       angles between angle_step and 2*angle_step. Angle_step is calculated as\n%       2*pi/num_bins.\n\n% angles: A 1 x num_bins array which holds the histogram bin lower bounds.\n%       In other words, histogram(i) contains the sum of the\n%       gradient magnitudes of all points whose gradient directions fall\n%       in the range [angles(i), angles(i + 1))\n\n    angle_step = 2 * pi / num_bins;\n    angles = 0 : angle_step : (2*pi-angle_step);\n\n    histogram = zeros(1, num_bins);\n    num = numel(gradient_angles);\n    for n = 1:num\n        index = floor(gradient_angles(n) / angle_step) + 1;\n        histogram(index) = histogram(index) + gradient_magnitudes(n);\n    end    \nend\n\n```\n\nLowe`bin`36\n\n``` matlab\nfunction direction = ComputeDominantDirection(gradient_magnitudes, gradient_angles)\n% Computes the dominant gradient direction for the region around a keypoint\n% given the scale of the keypoint and the gradient magnitudes and gradient\n% angles of the pixels in the region surrounding the keypoint.\n%\n% INPUT\n% gradient_magnitudes, gradient_angles:\n%   Two arrays of the same shape where gradient_magnitudes(i) and\n%   gradient_angles(i) give the magnitude and direction of the gradient for\n%   the ith point.\n\n    % Compute a gradient histogram using the weighted gradient magnitudes.\n    % In David Lowe's paper he suggests using 36 bins for this histogram.\n    num_bins = 36;\n    % Step 1:\n    % compute the 36-bin histogram of angles using ComputeGradientHistogram()\n    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);\n    % Step 2:\n    % Find the maximum value of the gradient histogram, and set \"direction\"\n    % to the angle corresponding to the maximum. (To match our solutions,\n    % just use the lower-bound angle of the max histogram bin. (E.g. return\n    % 0 radians if it's bin 1.)\n    [~, max_index] = max(histogram);\n    direction = angle_bound(max_index);\nend\n```\n\npatch\n\n``` matlab\npatch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;\npatch_theta = mod(patch_theta, 2*pi);\npatch_mag = patch_mag .* fspecial('gaussian', patch_size, patch_size / 2); % patch_size = 16\n```\n\ncellfeature\n\n``` matlab\nfeature = [];\nrow_iter = 1;\nfor y = 1:num_histograms\n    col_iter = 1;\n    for x = 1:num_histograms\n        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - 1, ...\n                             col_iter: col_iter + pixelsPerHistogram - 1);\n        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);\n        feature = [feature, histogram];\n        col_iter = col_iter + pixelsPerHistogram;\n    end\n    row_iter = row_iter + pixelsPerHistogram;\nend\n```\n\nfeaturenormalizationfeature0.2\n\nSIFTLoweslide\n\n## \nHarrisSIFTSIFTMATLAB`descriptor`SIFT0.7\n\n``` matlab\nfunction match = SIFTSimpleMatcher(descriptor1, descriptor2, thresh)\n% SIFTSimpleMatcher\n%   Match one set of SIFT descriptors (descriptor1) to another set of\n%   descriptors (decriptor2). Each descriptor from descriptor1 can at\n%   most be matched to one member of descriptor2, but descriptors from\n%   descriptor2 can be matched more than once.\n%   \n%   Matches are determined as follows:\n%   For each descriptor vector in descriptor1, find the Euclidean distance\n%   between it and each descriptor vector in descriptor2. If the smallest\n%   distance is less than thresh*(the next smallest distance), we say that\n%   the two vectors are a match, and we add the row [d1 index, d2 index] to\n%   the \"match\" array.\n%   \n% INPUT:\n%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.\n%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.\n%   thresh: a given threshold of ratio. Typically 0.7\n%\n% OUTPUT:\n%   Match: N * 2 matrix, each row is a match.\n%          For example, Match(k, :) = [i, j] means i-th descriptor in\n%          descriptor1 is matched to j-th descriptor in descriptor2.\n    if ~exist('thresh', 'var'),\n        thresh = 0.7;\n    end\n\n    match = [];\n    [N1, ~] = size(descriptor1);\n    for i = 1:N1\n        fea = descriptor1(i, :);\n        err = bsxfun(@minus, fea, descriptor2);\n        dis = sqrt(sum(err.^2, 2));\n        [sorted_dis, ind] = sort(dis, 1);\n        if sorted_dis(1) < thresh * sorted_dis(2)\n            match = [match; [i, ind(1)]];\n        end\n    end\nend\n\n```\n\n$H$$H$\n$$Hp_{\\text{before}} = p_{\\text{after}}$$\n\n\n$$p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}$$\n\n\n$$p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger$$\n\n\n\n``` matlab\nfunction H = ComputeAffineMatrix( Pt1, Pt2 )\n%ComputeAffineMatrix\n%   Computes the transformation matrix that transforms a point from\n%   coordinate frame 1 to coordinate frame 2\n%Input:\n%   Pt1: N * 2 matrix, each row is a point in image 1\n%       (N must be at least 3)\n%   Pt2: N * 2 matrix, each row is the point in image 2 that\n%       matches the same point in image 1 (N should be more than 3)\n%Output:\n%   H: 3 * 3 affine transformation matrix,\n%       such that H*pt1(i,:) = pt2(i,:)\n\n    N = size(Pt1,1);\n    if size(Pt1, 1) ~= size(Pt2, 1),\n        error('Dimensions unmatched.');\n    elseif N<3\n        error('At least 3 points are required.');\n    end\n\n    % Convert the input points to homogeneous coordintes.\n    P1 = [Pt1';ones(1,N)];\n    P2 = [Pt2';ones(1,N)];\n\n    H = P1*P1'\\P1*P2';\n    H = H';\n\n    % Sometimes numerical issues cause least-squares to produce a bottom\n    % row which is not exactly [0 0 1], which confuses some of the later\n    % code. So we'll ensure the bottom row is exactly [0 0 1].\n    H(3,:) = [0 0 1];\nend\n```\n\n~\n![result 1](/img/sift_experiment_1.png)\n![result 2](/img/sift_experiment_2.png)\n","slug":"cs131-sift","published":1,"updated":"2018-10-27T07:16:52.385Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8jj0012ae7bos0zf4ez","content":"<p><a href=\"https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\" target=\"_blank\" rel=\"external\">SIFT(Scale Invariant Feature Transform)</a>,LoweObject DetectionSIFTSIFT3D</p>\n<ul>\n<li>scale spaceDoGscaleastimage positioninterest point</li>\n<li>interest pointlocalizationinterest pointscaleposition</li>\n<li>key pointfeature operationscaleposition</li>\n<li>key pointkey pointSIFT</li>\n</ul>\n<p><img src=\"/img/sift_picture.jpg\" alt=\"SIFT\"></p>\n<a id=\"more\"></a>\n<h2 id=\"SIFT\"><a href=\"#SIFT\" class=\"headerlink\" title=\"SIFT\"></a>SIFT</h2><p>Harris$f$$\\mathcal{T}$$f(I) = f(\\mathcal{T}(I))$Harris<br><img src=\"/img/harris_non_scale_constant.png\" alt=\"harris\"></p>\n<p>patchregion size<br><img src=\"/img/patch_average_intensity_scale_constant.png\" alt=\"\"></p>\n<p>LowefeaturescaleDoG</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\" target=\"_blank\" rel=\"external\">Lowe</a>SIFTSIFTdensekey point500x500~2000SIFTimage matchingrecognitionref imageSIFTSIFT</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\" target=\"_blank\" rel=\"external\">Lowe</a>SIFT</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$I(x,y)$$G(x,y,\\sigma)$</p>\n<script type=\"math/tex; mode=display\">L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)</script><p>$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$$\\sigma$</p>\n<p>DoG(difference of Gaussian)</p>\n<script type=\"math/tex; mode=display\">D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)</script><p>$L$octave$L$DoGoctaveoctaveoctaveoctave$s$$s+1$$\\sigma$2$\\sigma$$k = 2^{1/s}$paddingoctave$s+3$$s=2$<br><img src=\"/img/sift_dog.png\" alt=\"DoG\"></p>\n<p>DoGDoGscale-normalizedGuassian Laplace$\\sigma^2\\Delta G$$\\sigma^2$$\\sigma \\Delta G$functionfeature</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G</script><p></p>\n<script type=\"math/tex; mode=display\">\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}</script><p></p>\n<script type=\"math/tex; mode=display\">G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G</script><p>$k=1$0$s=\\infty$octave$k$$\\sqrt{2}$$s=2$octave$k$$k-1$$k-1$</p>\n<p>DoG26<br><img src=\"/img/sift_detection_maximum.png\" alt=\"\"></p>\n<p>resize2key point</p>\n<p>LoweDoGkey pointkey point</p>\n<h2 id=\"128feature\"><a href=\"#128feature\" class=\"headerlink\" title=\"128feature\"></a>128feature</h2><p>key point128CS1312key point<code>pyramid{scale}(y, x)</code>key pointkey point128</p>\n<p>point16x16patch4x416cellcell16cell8bincell816cell128SIFT<code>patch_mag</code><code>patch_theta</code>patch</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_mag = <span class=\"built_in\">sqrt</span>(patch_dx.^<span class=\"number\">2</span> + patch_dy.^<span class=\"number\">2</span>);</div><div class=\"line\">patch_theta = <span class=\"built_in\">atan2</span>(patch_dy, patch_dx);  <span class=\"comment\">% atan2[-pi, pi]</span></div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);   <span class=\"comment\">% [0, 2pi]</span></div></pre></td></tr></table></figure>\n<p>key pointslidekey pointpatch<br><img src=\"/img/sift_dominant_orientation.png\" alt=\"\"></p>\n<p><code>[0, 2pi]</code><code>bin</code>patch<code>bin</code></p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[histogram, angles]</span> = <span class=\"title\">ComputeGradientHistogram</span><span class=\"params\">(num_bins, gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Compute a gradient histogram using gradient magnitudes and directions.</span></div><div class=\"line\"><span class=\"comment\">% Each point is assigned to one of num_bins depending on its gradient</span></div><div class=\"line\"><span class=\"comment\">% direction; the gradient magnitude of that point is added to its bin.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% num_bins: The number of bins to which points should be assigned.</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient angles:</span></div><div class=\"line\"><span class=\"comment\">%       Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles(i) give the magnitude and direction of the gradient</span></div><div class=\"line\"><span class=\"comment\">%       for the ith point. gradient_angles ranges from 0 to 2*pi</span></div><div class=\"line\"><span class=\"comment\">%                                      </span></div><div class=\"line\"><span class=\"comment\">% OUTPUT</span></div><div class=\"line\"><span class=\"comment\">% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is</span></div><div class=\"line\"><span class=\"comment\">%       the sum of entries in gradient_magnitudes whose corresponding</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for</span></div><div class=\"line\"><span class=\"comment\">%       angles between angle_step and 2*angle_step. Angle_step is calculated as</span></div><div class=\"line\"><span class=\"comment\">%       2*pi/num_bins.</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% angles: A 1 x num_bins array which holds the histogram bin lower bounds.</span></div><div class=\"line\"><span class=\"comment\">%       In other words, histogram(i) contains the sum of the</span></div><div class=\"line\"><span class=\"comment\">%       gradient magnitudes of all points whose gradient directions fall</span></div><div class=\"line\"><span class=\"comment\">%       in the range [angles(i), angles(i + 1))</span></div><div class=\"line\"></div><div class=\"line\">    angle_step = <span class=\"number\">2</span> * <span class=\"built_in\">pi</span> / num_bins;</div><div class=\"line\">    angles = <span class=\"number\">0</span> : angle_step : (<span class=\"number\">2</span>*<span class=\"built_in\">pi</span>-angle_step);</div><div class=\"line\"></div><div class=\"line\">    histogram = <span class=\"built_in\">zeros</span>(<span class=\"number\">1</span>, num_bins);</div><div class=\"line\">    num = <span class=\"built_in\">numel</span>(gradient_angles);</div><div class=\"line\">    <span class=\"keyword\">for</span> n = <span class=\"number\">1</span>:num</div><div class=\"line\">        index = <span class=\"built_in\">floor</span>(gradient_angles(n) / angle_step) + <span class=\"number\">1</span>;</div><div class=\"line\">        histogram(index) = histogram(index) + gradient_magnitudes(n);</div><div class=\"line\">    <span class=\"keyword\">end</span>    </div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>Lowe<code>bin</code>36</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">direction</span> = <span class=\"title\">ComputeDominantDirection</span><span class=\"params\">(gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Computes the dominant gradient direction for the region around a keypoint</span></div><div class=\"line\"><span class=\"comment\">% given the scale of the keypoint and the gradient magnitudes and gradient</span></div><div class=\"line\"><span class=\"comment\">% angles of the pixels in the region surrounding the keypoint.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient_angles:</span></div><div class=\"line\"><span class=\"comment\">%   Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%   gradient_angles(i) give the magnitude and direction of the gradient for</span></div><div class=\"line\"><span class=\"comment\">%   the ith point.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Compute a gradient histogram using the weighted gradient magnitudes.</span></div><div class=\"line\">    <span class=\"comment\">% In David Lowe's paper he suggests using 36 bins for this histogram.</span></div><div class=\"line\">    num_bins = <span class=\"number\">36</span>;</div><div class=\"line\">    <span class=\"comment\">% Step 1:</span></div><div class=\"line\">    <span class=\"comment\">% compute the 36-bin histogram of angles using ComputeGradientHistogram()</span></div><div class=\"line\">    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);</div><div class=\"line\">    <span class=\"comment\">% Step 2:</span></div><div class=\"line\">    <span class=\"comment\">% Find the maximum value of the gradient histogram, and set \"direction\"</span></div><div class=\"line\">    <span class=\"comment\">% to the angle corresponding to the maximum. (To match our solutions,</span></div><div class=\"line\">    <span class=\"comment\">% just use the lower-bound angle of the max histogram bin. (E.g. return</span></div><div class=\"line\">    <span class=\"comment\">% 0 radians if it's bin 1.)</span></div><div class=\"line\">    [~, max_index] = max(histogram);</div><div class=\"line\">    direction = angle_bound(max_index);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>patch</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;</div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);</div><div class=\"line\">patch_mag = patch_mag .* fspecial(<span class=\"string\">'gaussian'</span>, patch_size, patch_size / <span class=\"number\">2</span>); <span class=\"comment\">% patch_size = 16</span></div></pre></td></tr></table></figure>\n<p>cellfeature</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">feature = [];</div><div class=\"line\">row_iter = <span class=\"number\">1</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> y = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">    col_iter = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);</div><div class=\"line\">        feature = [feature, histogram];</div><div class=\"line\">        col_iter = col_iter + pixelsPerHistogram;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    row_iter = row_iter + pixelsPerHistogram;</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>featurenormalizationfeature0.2</p>\n<p>SIFTLoweslide</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>HarrisSIFTSIFTMATLAB<code>descriptor</code>SIFT0.7</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">match</span> = <span class=\"title\">SIFTSimpleMatcher</span><span class=\"params\">(descriptor1, descriptor2, thresh)</span></span></div><div class=\"line\"><span class=\"comment\">% SIFTSimpleMatcher</span></div><div class=\"line\"><span class=\"comment\">%   Match one set of SIFT descriptors (descriptor1) to another set of</span></div><div class=\"line\"><span class=\"comment\">%   descriptors (decriptor2). Each descriptor from descriptor1 can at</span></div><div class=\"line\"><span class=\"comment\">%   most be matched to one member of descriptor2, but descriptors from</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2 can be matched more than once.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">%   Matches are determined as follows:</span></div><div class=\"line\"><span class=\"comment\">%   For each descriptor vector in descriptor1, find the Euclidean distance</span></div><div class=\"line\"><span class=\"comment\">%   between it and each descriptor vector in descriptor2. If the smallest</span></div><div class=\"line\"><span class=\"comment\">%   distance is less than thresh*(the next smallest distance), we say that</span></div><div class=\"line\"><span class=\"comment\">%   the two vectors are a match, and we add the row [d1 index, d2 index] to</span></div><div class=\"line\"><span class=\"comment\">%   the \"match\" array.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">% INPUT:</span></div><div class=\"line\"><span class=\"comment\">%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   thresh: a given threshold of ratio. Typically 0.7</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% OUTPUT:</span></div><div class=\"line\"><span class=\"comment\">%   Match: N * 2 matrix, each row is a match.</span></div><div class=\"line\"><span class=\"comment\">%          For example, Match(k, :) = [i, j] means i-th descriptor in</span></div><div class=\"line\"><span class=\"comment\">%          descriptor1 is matched to j-th descriptor in descriptor2.</span></div><div class=\"line\">    <span class=\"keyword\">if</span> ~exist(<span class=\"string\">'thresh'</span>, <span class=\"string\">'var'</span>),</div><div class=\"line\">        thresh = <span class=\"number\">0.7</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    match = [];</div><div class=\"line\">    [N1, ~] = <span class=\"built_in\">size</span>(descriptor1);</div><div class=\"line\">    <span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N1</div><div class=\"line\">        fea = descriptor1(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">        err = <span class=\"built_in\">bsxfun</span>(@minus, fea, descriptor2);</div><div class=\"line\">        dis = <span class=\"built_in\">sqrt</span>(sum(err.^<span class=\"number\">2</span>, <span class=\"number\">2</span>));</div><div class=\"line\">        [sorted_dis, ind] = sort(dis, <span class=\"number\">1</span>);</div><div class=\"line\">        <span class=\"keyword\">if</span> sorted_dis(<span class=\"number\">1</span>) &lt; thresh * sorted_dis(<span class=\"number\">2</span>)</div><div class=\"line\">            match = [match; [i, ind(<span class=\"number\">1</span>)]];</div><div class=\"line\">        <span class=\"keyword\">end</span></div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>$H$$H$</p>\n<script type=\"math/tex; mode=display\">Hp_{\\text{before}} = p_{\\text{after}}</script><p></p>\n<script type=\"math/tex; mode=display\">p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger</script><p></p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">H</span> = <span class=\"title\">ComputeAffineMatrix</span><span class=\"params\">( Pt1, Pt2 )</span></span></div><div class=\"line\"><span class=\"comment\">%ComputeAffineMatrix</span></div><div class=\"line\"><span class=\"comment\">%   Computes the transformation matrix that transforms a point from</span></div><div class=\"line\"><span class=\"comment\">%   coordinate frame 1 to coordinate frame 2</span></div><div class=\"line\"><span class=\"comment\">%Input:</span></div><div class=\"line\"><span class=\"comment\">%   Pt1: N * 2 matrix, each row is a point in image 1</span></div><div class=\"line\"><span class=\"comment\">%       (N must be at least 3)</span></div><div class=\"line\"><span class=\"comment\">%   Pt2: N * 2 matrix, each row is the point in image 2 that</span></div><div class=\"line\"><span class=\"comment\">%       matches the same point in image 1 (N should be more than 3)</span></div><div class=\"line\"><span class=\"comment\">%Output:</span></div><div class=\"line\"><span class=\"comment\">%   H: 3 * 3 affine transformation matrix,</span></div><div class=\"line\"><span class=\"comment\">%       such that H*pt1(i,:) = pt2(i,:)</span></div><div class=\"line\"></div><div class=\"line\">    N = <span class=\"built_in\">size</span>(Pt1,<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">size</span>(Pt1, <span class=\"number\">1</span>) ~= <span class=\"built_in\">size</span>(Pt2, <span class=\"number\">1</span>),</div><div class=\"line\">        error(<span class=\"string\">'Dimensions unmatched.'</span>);</div><div class=\"line\">    <span class=\"keyword\">elseif</span> N&lt;<span class=\"number\">3</span></div><div class=\"line\">        error(<span class=\"string\">'At least 3 points are required.'</span>);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Convert the input points to homogeneous coordintes.</span></div><div class=\"line\">    P1 = [Pt1<span class=\"string\">';ones(1,N)];</span></div><div class=\"line\">    P2 = [Pt2';ones(<span class=\"number\">1</span>,N)];</div><div class=\"line\"></div><div class=\"line\">    H = P1*P1'\\P1*P2';</div><div class=\"line\">    H = H';</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Sometimes numerical issues cause least-squares to produce a bottom</span></div><div class=\"line\">    <span class=\"comment\">% row which is not exactly [0 0 1], which confuses some of the later</span></div><div class=\"line\">    <span class=\"comment\">% code. So we'll ensure the bottom row is exactly [0 0 1].</span></div><div class=\"line\">    H(<span class=\"number\">3</span>,:) = [<span class=\"number\">0</span> <span class=\"number\">0</span> <span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>~<br><img src=\"/img/sift_experiment_1.png\" alt=\"result 1\"><br><img src=\"/img/sift_experiment_2.png\" alt=\"result 2\"></p>\n","excerpt":"<p><a href=\"https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\">SIFT(Scale Invariant Feature Transform)</a>,LoweObject DetectionSIFTSIFT3D</p>\n<ul>\n<li>scale spaceDoGscaleastimage positioninterest point</li>\n<li>interest pointlocalizationinterest pointscaleposition</li>\n<li>key pointfeature operationscaleposition</li>\n<li>key pointkey pointSIFT</li>\n</ul>\n<p><img src=\"/img/sift_picture.jpg\" alt=\"SIFT\"></p>","more":"<h2 id=\"SIFT\"><a href=\"#SIFT\" class=\"headerlink\" title=\"SIFT\"></a>SIFT</h2><p>Harris$f$$\\mathcal{T}$$f(I) = f(\\mathcal{T}(I))$Harris<br><img src=\"/img/harris_non_scale_constant.png\" alt=\"harris\"></p>\n<p>patchregion size<br><img src=\"/img/patch_average_intensity_scale_constant.png\" alt=\"\"></p>\n<p>LowefeaturescaleDoG</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\">Lowe</a>SIFTSIFTdensekey point500x500~2000SIFTimage matchingrecognitionref imageSIFTSIFT</p>\n<p><a href=\"http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\">Lowe</a>SIFT</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$I(x,y)$$G(x,y,\\sigma)$</p>\n<script type=\"math/tex; mode=display\">L(x,y,\\sigma) = G(x,y,\\sigma)\\ast I(x,y)</script><p>$G(x,y, \\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp(-(x^2+y^2)/2\\sigma^2)$$\\sigma$</p>\n<p>DoG(difference of Gaussian)</p>\n<script type=\"math/tex; mode=display\">D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)</script><p>$L$octave$L$DoGoctaveoctaveoctaveoctave$s$$s+1$$\\sigma$2$\\sigma$$k = 2^{1/s}$paddingoctave$s+3$$s=2$<br><img src=\"/img/sift_dog.png\" alt=\"DoG\"></p>\n<p>DoGDoGscale-normalizedGuassian Laplace$\\sigma^2\\Delta G$$\\sigma^2$$\\sigma \\Delta G$functionfeature</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial G}{\\partial \\sigma} = \\sigma \\Delta G</script><p></p>\n<script type=\"math/tex; mode=display\">\\sigma\\Delta G \\approx \\frac{G(x,y,k\\sigma)-G(x,y,\\sigma)}{k\\sigma - \\sigma}</script><p></p>\n<script type=\"math/tex; mode=display\">G(x,y,k\\sigma)-G(x,y,\\sigma) \\approx (k-1)\\sigma^2 \\Delta G</script><p>$k=1$0$s=\\infty$octave$k$$\\sqrt{2}$$s=2$octave$k$$k-1$$k-1$</p>\n<p>DoG26<br><img src=\"/img/sift_detection_maximum.png\" alt=\"\"></p>\n<p>resize2key point</p>\n<p>LoweDoGkey pointkey point</p>\n<h2 id=\"128feature\"><a href=\"#128feature\" class=\"headerlink\" title=\"128feature\"></a>128feature</h2><p>key point128CS1312key point<code>pyramid{scale}(y, x)</code>key pointkey point128</p>\n<p>point16x16patch4x416cellcell16cell8bincell816cell128SIFT<code>patch_mag</code><code>patch_theta</code>patch</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_mag = <span class=\"built_in\">sqrt</span>(patch_dx.^<span class=\"number\">2</span> + patch_dy.^<span class=\"number\">2</span>);</div><div class=\"line\">patch_theta = <span class=\"built_in\">atan2</span>(patch_dy, patch_dx);  <span class=\"comment\">% atan2[-pi, pi]</span></div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);   <span class=\"comment\">% [0, 2pi]</span></div></pre></td></tr></table></figure>\n<p>key pointslidekey pointpatch<br><img src=\"/img/sift_dominant_orientation.png\" alt=\"\"></p>\n<p><code>[0, 2pi]</code><code>bin</code>patch<code>bin</code></p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"params\">[histogram, angles]</span> = <span class=\"title\">ComputeGradientHistogram</span><span class=\"params\">(num_bins, gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Compute a gradient histogram using gradient magnitudes and directions.</span></div><div class=\"line\"><span class=\"comment\">% Each point is assigned to one of num_bins depending on its gradient</span></div><div class=\"line\"><span class=\"comment\">% direction; the gradient magnitude of that point is added to its bin.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% num_bins: The number of bins to which points should be assigned.</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient angles:</span></div><div class=\"line\"><span class=\"comment\">%       Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles(i) give the magnitude and direction of the gradient</span></div><div class=\"line\"><span class=\"comment\">%       for the ith point. gradient_angles ranges from 0 to 2*pi</span></div><div class=\"line\"><span class=\"comment\">%                                      </span></div><div class=\"line\"><span class=\"comment\">% OUTPUT</span></div><div class=\"line\"><span class=\"comment\">% histogram: A 1 x num_bins array containing the gradient histogram. Entry 1 is</span></div><div class=\"line\"><span class=\"comment\">%       the sum of entries in gradient_magnitudes whose corresponding</span></div><div class=\"line\"><span class=\"comment\">%       gradient_angles lie between 0 and angle_step. Similarly, entry 2 is for</span></div><div class=\"line\"><span class=\"comment\">%       angles between angle_step and 2*angle_step. Angle_step is calculated as</span></div><div class=\"line\"><span class=\"comment\">%       2*pi/num_bins.</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">% angles: A 1 x num_bins array which holds the histogram bin lower bounds.</span></div><div class=\"line\"><span class=\"comment\">%       In other words, histogram(i) contains the sum of the</span></div><div class=\"line\"><span class=\"comment\">%       gradient magnitudes of all points whose gradient directions fall</span></div><div class=\"line\"><span class=\"comment\">%       in the range [angles(i), angles(i + 1))</span></div><div class=\"line\"></div><div class=\"line\">    angle_step = <span class=\"number\">2</span> * <span class=\"built_in\">pi</span> / num_bins;</div><div class=\"line\">    angles = <span class=\"number\">0</span> : angle_step : (<span class=\"number\">2</span>*<span class=\"built_in\">pi</span>-angle_step);</div><div class=\"line\"></div><div class=\"line\">    histogram = <span class=\"built_in\">zeros</span>(<span class=\"number\">1</span>, num_bins);</div><div class=\"line\">    num = <span class=\"built_in\">numel</span>(gradient_angles);</div><div class=\"line\">    <span class=\"keyword\">for</span> n = <span class=\"number\">1</span>:num</div><div class=\"line\">        index = <span class=\"built_in\">floor</span>(gradient_angles(n) / angle_step) + <span class=\"number\">1</span>;</div><div class=\"line\">        histogram(index) = histogram(index) + gradient_magnitudes(n);</div><div class=\"line\">    <span class=\"keyword\">end</span>    </div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>Lowe<code>bin</code>36</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">direction</span> = <span class=\"title\">ComputeDominantDirection</span><span class=\"params\">(gradient_magnitudes, gradient_angles)</span></span></div><div class=\"line\"><span class=\"comment\">% Computes the dominant gradient direction for the region around a keypoint</span></div><div class=\"line\"><span class=\"comment\">% given the scale of the keypoint and the gradient magnitudes and gradient</span></div><div class=\"line\"><span class=\"comment\">% angles of the pixels in the region surrounding the keypoint.</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% INPUT</span></div><div class=\"line\"><span class=\"comment\">% gradient_magnitudes, gradient_angles:</span></div><div class=\"line\"><span class=\"comment\">%   Two arrays of the same shape where gradient_magnitudes(i) and</span></div><div class=\"line\"><span class=\"comment\">%   gradient_angles(i) give the magnitude and direction of the gradient for</span></div><div class=\"line\"><span class=\"comment\">%   the ith point.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Compute a gradient histogram using the weighted gradient magnitudes.</span></div><div class=\"line\">    <span class=\"comment\">% In David Lowe's paper he suggests using 36 bins for this histogram.</span></div><div class=\"line\">    num_bins = <span class=\"number\">36</span>;</div><div class=\"line\">    <span class=\"comment\">% Step 1:</span></div><div class=\"line\">    <span class=\"comment\">% compute the 36-bin histogram of angles using ComputeGradientHistogram()</span></div><div class=\"line\">    [histogram, angle_bound] = ComputeGradientHistogram(num_bins, gradient_magnitudes, gradient_angles);</div><div class=\"line\">    <span class=\"comment\">% Step 2:</span></div><div class=\"line\">    <span class=\"comment\">% Find the maximum value of the gradient histogram, and set \"direction\"</span></div><div class=\"line\">    <span class=\"comment\">% to the angle corresponding to the maximum. (To match our solutions,</span></div><div class=\"line\">    <span class=\"comment\">% just use the lower-bound angle of the max histogram bin. (E.g. return</span></div><div class=\"line\">    <span class=\"comment\">% 0 radians if it's bin 1.)</span></div><div class=\"line\">    [~, max_index] = max(histogram);</div><div class=\"line\">    direction = angle_bound(max_index);</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>patch</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">patch_theta = patch_theta - ComputeDominantDirection(patch_mag, patch_theta);;</div><div class=\"line\">patch_theta = <span class=\"built_in\">mod</span>(patch_theta, <span class=\"number\">2</span>*<span class=\"built_in\">pi</span>);</div><div class=\"line\">patch_mag = patch_mag .* fspecial(<span class=\"string\">'gaussian'</span>, patch_size, patch_size / <span class=\"number\">2</span>); <span class=\"comment\">% patch_size = 16</span></div></pre></td></tr></table></figure>\n<p>cellfeature</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">feature = [];</div><div class=\"line\">row_iter = <span class=\"number\">1</span>;</div><div class=\"line\"><span class=\"keyword\">for</span> y = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">    col_iter = <span class=\"number\">1</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span> x = <span class=\"number\">1</span>:num_histograms</div><div class=\"line\">        cell_mag = patch_mag(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        cell_theta = patch_theta(row_iter: row_iter + pixelsPerHistogram - <span class=\"number\">1</span>, ...</div><div class=\"line\">                             col_iter: col_iter + pixelsPerHistogram - <span class=\"number\">1</span>);</div><div class=\"line\">        [histogram, ~] = ComputeGradientHistogram(num_angles, cell_mag, cell_theta);</div><div class=\"line\">        feature = [feature, histogram];</div><div class=\"line\">        col_iter = col_iter + pixelsPerHistogram;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\">    row_iter = row_iter + pixelsPerHistogram;</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>featurenormalizationfeature0.2</p>\n<p>SIFTLoweslide</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>HarrisSIFTSIFTMATLAB<code>descriptor</code>SIFT0.7</p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">match</span> = <span class=\"title\">SIFTSimpleMatcher</span><span class=\"params\">(descriptor1, descriptor2, thresh)</span></span></div><div class=\"line\"><span class=\"comment\">% SIFTSimpleMatcher</span></div><div class=\"line\"><span class=\"comment\">%   Match one set of SIFT descriptors (descriptor1) to another set of</span></div><div class=\"line\"><span class=\"comment\">%   descriptors (decriptor2). Each descriptor from descriptor1 can at</span></div><div class=\"line\"><span class=\"comment\">%   most be matched to one member of descriptor2, but descriptors from</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2 can be matched more than once.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">%   Matches are determined as follows:</span></div><div class=\"line\"><span class=\"comment\">%   For each descriptor vector in descriptor1, find the Euclidean distance</span></div><div class=\"line\"><span class=\"comment\">%   between it and each descriptor vector in descriptor2. If the smallest</span></div><div class=\"line\"><span class=\"comment\">%   distance is less than thresh*(the next smallest distance), we say that</span></div><div class=\"line\"><span class=\"comment\">%   the two vectors are a match, and we add the row [d1 index, d2 index] to</span></div><div class=\"line\"><span class=\"comment\">%   the \"match\" array.</span></div><div class=\"line\"><span class=\"comment\">%   </span></div><div class=\"line\"><span class=\"comment\">% INPUT:</span></div><div class=\"line\"><span class=\"comment\">%   descriptor1: N1 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   descriptor2: N2 * 128 matrix, each row is a SIFT descriptor.</span></div><div class=\"line\"><span class=\"comment\">%   thresh: a given threshold of ratio. Typically 0.7</span></div><div class=\"line\"><span class=\"comment\">%</span></div><div class=\"line\"><span class=\"comment\">% OUTPUT:</span></div><div class=\"line\"><span class=\"comment\">%   Match: N * 2 matrix, each row is a match.</span></div><div class=\"line\"><span class=\"comment\">%          For example, Match(k, :) = [i, j] means i-th descriptor in</span></div><div class=\"line\"><span class=\"comment\">%          descriptor1 is matched to j-th descriptor in descriptor2.</span></div><div class=\"line\">    <span class=\"keyword\">if</span> ~exist(<span class=\"string\">'thresh'</span>, <span class=\"string\">'var'</span>),</div><div class=\"line\">        thresh = <span class=\"number\">0.7</span>;</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    match = [];</div><div class=\"line\">    [N1, ~] = <span class=\"built_in\">size</span>(descriptor1);</div><div class=\"line\">    <span class=\"keyword\">for</span> <span class=\"built_in\">i</span> = <span class=\"number\">1</span>:N1</div><div class=\"line\">        fea = descriptor1(<span class=\"built_in\">i</span>, :);</div><div class=\"line\">        err = <span class=\"built_in\">bsxfun</span>(@minus, fea, descriptor2);</div><div class=\"line\">        dis = <span class=\"built_in\">sqrt</span>(sum(err.^<span class=\"number\">2</span>, <span class=\"number\">2</span>));</div><div class=\"line\">        [sorted_dis, ind] = sort(dis, <span class=\"number\">1</span>);</div><div class=\"line\">        <span class=\"keyword\">if</span> sorted_dis(<span class=\"number\">1</span>) &lt; thresh * sorted_dis(<span class=\"number\">2</span>)</div><div class=\"line\">            match = [match; [i, ind(<span class=\"number\">1</span>)]];</div><div class=\"line\">        <span class=\"keyword\">end</span></div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>$H$$H$</p>\n<script type=\"math/tex; mode=display\">Hp_{\\text{before}} = p_{\\text{after}}</script><p></p>\n<script type=\"math/tex; mode=display\">p = \\begin{bmatrix}x \\\\\\\\ y \\\\\\\\ 1\\end{bmatrix}</script><p></p>\n<script type=\"math/tex; mode=display\">p_{\\text{before}}^\\dagger H^\\dagger = p_{\\text{after}}\\dagger</script><p></p>\n<figure class=\"highlight matlab\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">H</span> = <span class=\"title\">ComputeAffineMatrix</span><span class=\"params\">( Pt1, Pt2 )</span></span></div><div class=\"line\"><span class=\"comment\">%ComputeAffineMatrix</span></div><div class=\"line\"><span class=\"comment\">%   Computes the transformation matrix that transforms a point from</span></div><div class=\"line\"><span class=\"comment\">%   coordinate frame 1 to coordinate frame 2</span></div><div class=\"line\"><span class=\"comment\">%Input:</span></div><div class=\"line\"><span class=\"comment\">%   Pt1: N * 2 matrix, each row is a point in image 1</span></div><div class=\"line\"><span class=\"comment\">%       (N must be at least 3)</span></div><div class=\"line\"><span class=\"comment\">%   Pt2: N * 2 matrix, each row is the point in image 2 that</span></div><div class=\"line\"><span class=\"comment\">%       matches the same point in image 1 (N should be more than 3)</span></div><div class=\"line\"><span class=\"comment\">%Output:</span></div><div class=\"line\"><span class=\"comment\">%   H: 3 * 3 affine transformation matrix,</span></div><div class=\"line\"><span class=\"comment\">%       such that H*pt1(i,:) = pt2(i,:)</span></div><div class=\"line\"></div><div class=\"line\">    N = <span class=\"built_in\">size</span>(Pt1,<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">size</span>(Pt1, <span class=\"number\">1</span>) ~= <span class=\"built_in\">size</span>(Pt2, <span class=\"number\">1</span>),</div><div class=\"line\">        error(<span class=\"string\">'Dimensions unmatched.'</span>);</div><div class=\"line\">    <span class=\"keyword\">elseif</span> N&lt;<span class=\"number\">3</span></div><div class=\"line\">        error(<span class=\"string\">'At least 3 points are required.'</span>);</div><div class=\"line\">    <span class=\"keyword\">end</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Convert the input points to homogeneous coordintes.</span></div><div class=\"line\">    P1 = [Pt1<span class=\"string\">';ones(1,N)];</div><div class=\"line\">    P2 = [Pt2'</span>;ones(<span class=\"number\">1</span>,N)];</div><div class=\"line\"></div><div class=\"line\">    H = P1*P1'\\P1*P2';</div><div class=\"line\">    H = H';</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">% Sometimes numerical issues cause least-squares to produce a bottom</span></div><div class=\"line\">    <span class=\"comment\">% row which is not exactly [0 0 1], which confuses some of the later</span></div><div class=\"line\">    <span class=\"comment\">% code. So we'll ensure the bottom row is exactly [0 0 1].</span></div><div class=\"line\">    H(<span class=\"number\">3</span>,:) = [<span class=\"number\">0</span> <span class=\"number\">0</span> <span class=\"number\">1</span>];</div><div class=\"line\"><span class=\"keyword\">end</span></div></pre></td></tr></table></figure>\n<p>~<br><img src=\"/img/sift_experiment_1.png\" alt=\"result 1\"><br><img src=\"/img/sift_experiment_2.png\" alt=\"result 2\"></p>"},{"title":"IPDBPython","date":"2017-08-21T07:53:16.000Z","_content":"IPDBIPDBIpython DebuggerGDBIpythonPythonPDBIPDBGoogle\n<!-- more -->\n## \nIPDBPython`pip install ipdb`\n\n\n\n### \n\n``` py\nimport ipdb\n# some code\nx = 10\nipdb.set_trace()\ny = 20\n# other code\n```\n`x = 10`Ipython\n\n### \nIPDB\n``` sh\npython -m ipdb your_code.py\n```\n\n## \nIPDB\n### \nTMTM\n\n`h`IPDB`help command`\n\n### \n`n`(next)\n### \n`s`(step into)\n### \n`b line_number`(break)`b file_name:line_number`\n\n\n### \n`c`(continue)\n### \n`r`(return)\n### \n`j line_number`(jump)\n### \nIPDB`l first[, second]`(list)\n\n`first``second``second``first``second``first`vs\n\n[SO](https://stackoverflow.com/questions/6240887/how-can-i-make-ipdb-show-more-lines-of-context-while-debugging)IPDB\n### \n`w``where`\n\n### \n`whatis variable_name``type`\n### \n`a`(argument)\n### \n`p`(print)`pp`(pretty print)\n\n### \n`cl``clear file:line_number`\n### \n`restart``restart``run``run args`\n### \n`q`\n\nIPDB\n","source":"_posts/debugging-with-ipdb.md","raw":"---\ntitle: IPDBPython\ndate: 2017-08-21 15:53:16\ntags:\n    - python\n    - debug\n---\nIPDBIPDBIpython DebuggerGDBIpythonPythonPDBIPDBGoogle\n<!-- more -->\n## \nIPDBPython`pip install ipdb`\n\n\n\n### \n\n``` py\nimport ipdb\n# some code\nx = 10\nipdb.set_trace()\ny = 20\n# other code\n```\n`x = 10`Ipython\n\n### \nIPDB\n``` sh\npython -m ipdb your_code.py\n```\n\n## \nIPDB\n### \nTMTM\n\n`h`IPDB`help command`\n\n### \n`n`(next)\n### \n`s`(step into)\n### \n`b line_number`(break)`b file_name:line_number`\n\n\n### \n`c`(continue)\n### \n`r`(return)\n### \n`j line_number`(jump)\n### \nIPDB`l first[, second]`(list)\n\n`first``second``second``first``second``first`vs\n\n[SO](https://stackoverflow.com/questions/6240887/how-can-i-make-ipdb-show-more-lines-of-context-while-debugging)IPDB\n### \n`w``where`\n\n### \n`whatis variable_name``type`\n### \n`a`(argument)\n### \n`p`(print)`pp`(pretty print)\n\n### \n`cl``clear file:line_number`\n### \n`restart``restart``run``run args`\n### \n`q`\n\nIPDB\n","slug":"debugging-with-ipdb","published":1,"updated":"2018-10-27T07:16:52.387Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8jl0014ae7b3byiaz48","content":"<p>IPDBIPDBIpython DebuggerGDBIpythonPythonPDBIPDBGoogle<br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>IPDBPython<code>pip install ipdb</code></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> ipdb</div><div class=\"line\"><span class=\"comment\"># some code</span></div><div class=\"line\">x = <span class=\"number\">10</span></div><div class=\"line\">ipdb.set_trace()</div><div class=\"line\">y = <span class=\"number\">20</span></div><div class=\"line\"><span class=\"comment\"># other code</span></div></pre></td></tr></table></figure></p>\n<p><code>x = 10</code>Ipython</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IPDB<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">python -m ipdb your_code.py</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>IPDB</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>TMTM</p>\n<p><code>h</code>IPDB<code>help command</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>n</code>(next)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>s</code>(step into)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>b line_number</code>(break)<code>b file_name:line_number</code></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>c</code>(continue)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>r</code>(return)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>j line_number</code>(jump)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IPDB<code>l first[, second]</code>(list)</p>\n<p><code>first</code><code>second</code><code>second</code><code>first</code><code>second</code><code>first</code>vs</p>\n<p><a href=\"https://stackoverflow.com/questions/6240887/how-can-i-make-ipdb-show-more-lines-of-context-while-debugging\" target=\"_blank\" rel=\"external\">SO</a>IPDB</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>w</code><code>where</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>whatis variable_name</code><code>type</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>a</code>(argument)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>p</code>(print)<code>pp</code>(pretty print)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>cl</code><code>clear file:line_number</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>restart</code><code>restart</code><code>run</code><code>run args</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>q</code></p>\n<p>IPDB</p>\n","excerpt":"<p>IPDBIPDBIpython DebuggerGDBIpythonPythonPDBIPDBGoogle<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>IPDBPython<code>pip install ipdb</code></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> ipdb</div><div class=\"line\"><span class=\"comment\"># some code</span></div><div class=\"line\">x = <span class=\"number\">10</span></div><div class=\"line\">ipdb.set_trace()</div><div class=\"line\">y = <span class=\"number\">20</span></div><div class=\"line\"><span class=\"comment\"># other code</span></div></pre></td></tr></table></figure></p>\n<p><code>x = 10</code>Ipython</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IPDB<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">python -m ipdb your_code.py</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>IPDB</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>TMTM</p>\n<p><code>h</code>IPDB<code>help command</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>n</code>(next)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>s</code>(step into)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>b line_number</code>(break)<code>b file_name:line_number</code></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>c</code>(continue)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>r</code>(return)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>j line_number</code>(jump)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IPDB<code>l first[, second]</code>(list)</p>\n<p><code>first</code><code>second</code><code>second</code><code>first</code><code>second</code><code>first</code>vs</p>\n<p><a href=\"https://stackoverflow.com/questions/6240887/how-can-i-make-ipdb-show-more-lines-of-context-while-debugging\">SO</a>IPDB</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>w</code><code>where</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>whatis variable_name</code><code>type</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>a</code>(argument)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>p</code>(print)<code>pp</code>(pretty print)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>cl</code><code>clear file:line_number</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>restart</code><code>restart</code><code>run</code><code>run args</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>q</code></p>\n<p>IPDB</p>"},{"title":"DigitalOceanShadowsocksIPV4/IPV6","date":"2017-02-08T09:31:35.000Z","_content":"GoAgentFQSSDigitalOceanDOGitHub\n\nDOshadowsocksiPadFQNYss\n![](/img/god_use_vpn.png)\n\n<!-- more -->\n## \nGitHubDOPayPalDO50\n\nUbuntu 16.04IPV6 Enable\n\n## ss\nss\n``` bash\napt-get install python-pip\npip install shadowsocks\n```\n`unsupported locale setting`[](http://www.linfuyan.com/locale_error_unsupported_locale_setting/)\n``` bash\nexport LC_ALL=C\n```\n\n## \n`/etc``shadowsocks.json`\n```\n{\n\"server\":\"::\",  \n\"server_port\":8388,\n\"local_address\": \"127.0.0.1\",\n\"local_port\": 1080,\n\"password\":\"your_password\",\n\"timeout\":600,\n\"method\":\"aes-256-cfb\"\n}\n```\n`::`IPV6\n\n## \nss\n\n`/etc/rc.local``exit 0`\n```\nssserver -c /etc/shadowsocks.json -d start  # json\n```\n\n`reboot`\n\n## \nssjson\n\n## IOS\nPadGitHub\n\n- [IPsec VPN ](https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md)\n- [ IPsec/L2TP VPN ](https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md)\n\nVPNIPsec\n\n```\nwget https://git.io/vpnsetup -O vpnsetup.sh && sudo sh vpnsetup.sh\n```\n\nIOS\n![](/img/ipsec_ios_vpn_setting.png)\n","source":"_posts/digitalocean-shadowsocks.md","raw":"---\ntitle: DigitalOceanShadowsocksIPV4/IPV6\ndate: 2017-02-08 17:31:35\ntags:\n    - tool\n---\nGoAgentFQSSDigitalOceanDOGitHub\n\nDOshadowsocksiPadFQNYss\n![](/img/god_use_vpn.png)\n\n<!-- more -->\n## \nGitHubDOPayPalDO50\n\nUbuntu 16.04IPV6 Enable\n\n## ss\nss\n``` bash\napt-get install python-pip\npip install shadowsocks\n```\n`unsupported locale setting`[](http://www.linfuyan.com/locale_error_unsupported_locale_setting/)\n``` bash\nexport LC_ALL=C\n```\n\n## \n`/etc``shadowsocks.json`\n```\n{\n\"server\":\"::\",  \n\"server_port\":8388,\n\"local_address\": \"127.0.0.1\",\n\"local_port\": 1080,\n\"password\":\"your_password\",\n\"timeout\":600,\n\"method\":\"aes-256-cfb\"\n}\n```\n`::`IPV6\n\n## \nss\n\n`/etc/rc.local``exit 0`\n```\nssserver -c /etc/shadowsocks.json -d start  # json\n```\n\n`reboot`\n\n## \nssjson\n\n## IOS\nPadGitHub\n\n- [IPsec VPN ](https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md)\n- [ IPsec/L2TP VPN ](https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md)\n\nVPNIPsec\n\n```\nwget https://git.io/vpnsetup -O vpnsetup.sh && sudo sh vpnsetup.sh\n```\n\nIOS\n![](/img/ipsec_ios_vpn_setting.png)\n","slug":"digitalocean-shadowsocks","published":1,"updated":"2018-10-27T07:16:52.388Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8jp0016ae7bw9moem88","content":"<p>GoAgentFQSSDigitalOceanDOGitHub</p>\n<p>DOshadowsocksiPadFQNYss<br><img src=\"/img/god_use_vpn.png\" alt=\"\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>GitHubDOPayPalDO50</p>\n<p>Ubuntu 16.04IPV6 Enable</p>\n<h2 id=\"ss\"><a href=\"#ss\" class=\"headerlink\" title=\"ss\"></a>ss</h2><p>ss<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">apt-get install python-pip</div><div class=\"line\">pip install shadowsocks</div></pre></td></tr></table></figure></p>\n<p><code>unsupported locale setting</code><a href=\"http://www.linfuyan.com/locale_error_unsupported_locale_setting/\" target=\"_blank\" rel=\"external\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> LC_ALL=C</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>/etc</code><code>shadowsocks.json</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">&quot;server&quot;:&quot;::&quot;,  </div><div class=\"line\">&quot;server_port&quot;:8388,</div><div class=\"line\">&quot;local_address&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">&quot;local_port&quot;: 1080,</div><div class=\"line\">&quot;password&quot;:&quot;your_password&quot;,</div><div class=\"line\">&quot;timeout&quot;:600,</div><div class=\"line\">&quot;method&quot;:&quot;aes-256-cfb&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>::</code>IPV6</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ss</p>\n<p><code>/etc/rc.local</code><code>exit 0</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssserver -c /etc/shadowsocks.json -d start  # json</div></pre></td></tr></table></figure></p>\n<p><code>reboot</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ssjson</p>\n<h2 id=\"IOS\"><a href=\"#IOS\" class=\"headerlink\" title=\"IOS\"></a>IOS</h2><p>PadGitHub</p>\n<ul>\n<li><a href=\"https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md\" target=\"_blank\" rel=\"external\">IPsec VPN </a></li>\n<li><a href=\"https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md\" target=\"_blank\" rel=\"external\"> IPsec/L2TP VPN </a></li>\n</ul>\n<p>VPNIPsec</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget https://git.io/vpnsetup -O vpnsetup.sh &amp;&amp; sudo sh vpnsetup.sh</div></pre></td></tr></table></figure>\n<p>IOS<br><img src=\"/img/ipsec_ios_vpn_setting.png\" alt=\"\"></p>\n","excerpt":"<p>GoAgentFQSSDigitalOceanDOGitHub</p>\n<p>DOshadowsocksiPadFQNYss<br><img src=\"/img/god_use_vpn.png\" alt=\"\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>GitHubDOPayPalDO50</p>\n<p>Ubuntu 16.04IPV6 Enable</p>\n<h2 id=\"ss\"><a href=\"#ss\" class=\"headerlink\" title=\"ss\"></a>ss</h2><p>ss<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">apt-get install python-pip</div><div class=\"line\">pip install shadowsocks</div></pre></td></tr></table></figure></p>\n<p><code>unsupported locale setting</code><a href=\"http://www.linfuyan.com/locale_error_unsupported_locale_setting/\"></a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> LC_ALL=C</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>/etc</code><code>shadowsocks.json</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">&quot;server&quot;:&quot;::&quot;,  </div><div class=\"line\">&quot;server_port&quot;:8388,</div><div class=\"line\">&quot;local_address&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">&quot;local_port&quot;: 1080,</div><div class=\"line\">&quot;password&quot;:&quot;your_password&quot;,</div><div class=\"line\">&quot;timeout&quot;:600,</div><div class=\"line\">&quot;method&quot;:&quot;aes-256-cfb&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>::</code>IPV6</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ss</p>\n<p><code>/etc/rc.local</code><code>exit 0</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ssserver -c /etc/shadowsocks.json -d start  # json</div></pre></td></tr></table></figure></p>\n<p><code>reboot</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ssjson</p>\n<h2 id=\"IOS\"><a href=\"#IOS\" class=\"headerlink\" title=\"IOS\"></a>IOS</h2><p>PadGitHub</p>\n<ul>\n<li><a href=\"https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md\">IPsec VPN </a></li>\n<li><a href=\"https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md\"> IPsec/L2TP VPN </a></li>\n</ul>\n<p>VPNIPsec</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">wget https://git.io/vpnsetup -O vpnsetup.sh &amp;&amp; sudo sh vpnsetup.sh</div></pre></td></tr></table></figure>\n<p>IOS<br><img src=\"/img/ipsec_ios_vpn_setting.png\" alt=\"\"></p>"},{"title":"doc2dashdash","date":"2017-08-26T11:32:00.000Z","_content":"DashMacC/C++/PythonOpenCV/VimAppDownload DocsetsDashDashUbuntu/WindowsDash[zeal](https://zealdocs.org)Windows/LinuxDash\n\n[doc2dash](https://doc2dash.readthedocs.io/en/stable/)DashdocsetPyTorchdocsetDash/zeal\n\ndoc2dash\n![Demo](/img/doc2dash_pytorch_example.jpg)\n\n<!-- more -->\n## doc2dash\ndoc2dashPythonPythonAnaconda`conda create`doc2dash\n``` sh\nconda create -n doc2dash\n```\n`pip install`\n``` sh\nsource activate doc2dash\npip install doc2dash\n```\n\ndoc2dashsphinxpydoctorPyTorchdoc2dash\n## PyTorch\ndoc2dashsphinxdoc2dashsphinxrst\n\n```\npip install sphinx_rtd_theme\n```\nPyTorch`docs/`PyTorchMakefilesphinx`make html`HTML`build/html`\n\n```\n# in directory $PYTORCH/docs, run\nmake html\n```\n\ndoc2dashsphinxDash~`-n`source\n\n``` sh\n# $PYTORCH/docs/build/htmlHTML\ndoc2dash -n pytorch $PYTORCH/docs/build/html\n```\n\n`pytorch.docset`Dash+\n![docset](/img/doc2dash_how_to_add_docset.jpg)\n\n## Ubuntuzeal\nzealDashMacUbuntu[](https://zealdocs.org/download.html#linux)\n\n``` sh\nsudo add-apt-repository ppa:zeal-developers/ppa\nsudo apt-get update\nsudo apt-get install zeal\n```\n\n`Tool/Docsets`docset`$HOME/.local/share/Zeal/Zeal/docsets`\n","source":"_posts/doc2dash-usage.md","raw":"---\ntitle: doc2dashdash\ndate: 2017-08-26 19:32:00\ntags:\n    - tool\n---\nDashMacC/C++/PythonOpenCV/VimAppDownload DocsetsDashDashUbuntu/WindowsDash[zeal](https://zealdocs.org)Windows/LinuxDash\n\n[doc2dash](https://doc2dash.readthedocs.io/en/stable/)DashdocsetPyTorchdocsetDash/zeal\n\ndoc2dash\n![Demo](/img/doc2dash_pytorch_example.jpg)\n\n<!-- more -->\n## doc2dash\ndoc2dashPythonPythonAnaconda`conda create`doc2dash\n``` sh\nconda create -n doc2dash\n```\n`pip install`\n``` sh\nsource activate doc2dash\npip install doc2dash\n```\n\ndoc2dashsphinxpydoctorPyTorchdoc2dash\n## PyTorch\ndoc2dashsphinxdoc2dashsphinxrst\n\n```\npip install sphinx_rtd_theme\n```\nPyTorch`docs/`PyTorchMakefilesphinx`make html`HTML`build/html`\n\n```\n# in directory $PYTORCH/docs, run\nmake html\n```\n\ndoc2dashsphinxDash~`-n`source\n\n``` sh\n# $PYTORCH/docs/build/htmlHTML\ndoc2dash -n pytorch $PYTORCH/docs/build/html\n```\n\n`pytorch.docset`Dash+\n![docset](/img/doc2dash_how_to_add_docset.jpg)\n\n## Ubuntuzeal\nzealDashMacUbuntu[](https://zealdocs.org/download.html#linux)\n\n``` sh\nsudo add-apt-repository ppa:zeal-developers/ppa\nsudo apt-get update\nsudo apt-get install zeal\n```\n\n`Tool/Docsets`docset`$HOME/.local/share/Zeal/Zeal/docsets`\n","slug":"doc2dash-usage","published":1,"updated":"2018-10-27T07:16:52.388Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8jt0019ae7bw19ucwsv","content":"<p>DashMacC/C++/PythonOpenCV/VimAppDownload DocsetsDashDashUbuntu/WindowsDash<a href=\"https://zealdocs.org\" target=\"_blank\" rel=\"external\">zeal</a>Windows/LinuxDash</p>\n<p><a href=\"https://doc2dash.readthedocs.io/en/stable/\" target=\"_blank\" rel=\"external\">doc2dash</a>DashdocsetPyTorchdocsetDash/zeal</p>\n<p>doc2dash<br><img src=\"/img/doc2dash_pytorch_example.jpg\" alt=\"Demo\"></p>\n<a id=\"more\"></a>\n<h2 id=\"doc2dash\"><a href=\"#doc2dash\" class=\"headerlink\" title=\"doc2dash\"></a>doc2dash</h2><p>doc2dashPythonPythonAnaconda<code>conda create</code>doc2dash<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">conda create -n doc2dash</div></pre></td></tr></table></figure></p>\n<p><code>pip install</code><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">source</span> activate doc2dash</div><div class=\"line\">pip install doc2dash</div></pre></td></tr></table></figure></p>\n<p>doc2dashsphinxpydoctorPyTorchdoc2dash</p>\n<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><p>doc2dashsphinxdoc2dashsphinxrst</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install sphinx_rtd_theme</div></pre></td></tr></table></figure>\n<p>PyTorch<code>docs/</code>PyTorchMakefilesphinx<code>make html</code>HTML<code>build/html</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># in directory $PYTORCH/docs, run</div><div class=\"line\">make html</div></pre></td></tr></table></figure>\n<p>doc2dashsphinxDash~<code>-n</code>source</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># $PYTORCH/docs/build/htmlHTML</span></div><div class=\"line\">doc2dash -n pytorch <span class=\"variable\">$PYTORCH</span>/docs/build/html</div></pre></td></tr></table></figure>\n<p><code>pytorch.docset</code>Dash+<br><img src=\"/img/doc2dash_how_to_add_docset.jpg\" alt=\"docset\"></p>\n<h2 id=\"Ubuntuzeal\"><a href=\"#Ubuntuzeal\" class=\"headerlink\" title=\"Ubuntuzeal\"></a>Ubuntuzeal</h2><p>zealDashMacUbuntu<a href=\"https://zealdocs.org/download.html#linux\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo add-apt-repository ppa:zeal-developers/ppa</div><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get install zeal</div></pre></td></tr></table></figure>\n<p><code>Tool/Docsets</code>docset<code>$HOME/.local/share/Zeal/Zeal/docsets</code></p>\n","excerpt":"<p>DashMacC/C++/PythonOpenCV/VimAppDownload DocsetsDashDashUbuntu/WindowsDash<a href=\"https://zealdocs.org\">zeal</a>Windows/LinuxDash</p>\n<p><a href=\"https://doc2dash.readthedocs.io/en/stable/\">doc2dash</a>DashdocsetPyTorchdocsetDash/zeal</p>\n<p>doc2dash<br><img src=\"/img/doc2dash_pytorch_example.jpg\" alt=\"Demo\"></p>","more":"<h2 id=\"doc2dash\"><a href=\"#doc2dash\" class=\"headerlink\" title=\"doc2dash\"></a>doc2dash</h2><p>doc2dashPythonPythonAnaconda<code>conda create</code>doc2dash<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">conda create -n doc2dash</div></pre></td></tr></table></figure></p>\n<p><code>pip install</code><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">source</span> activate doc2dash</div><div class=\"line\">pip install doc2dash</div></pre></td></tr></table></figure></p>\n<p>doc2dashsphinxpydoctorPyTorchdoc2dash</p>\n<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><p>doc2dashsphinxdoc2dashsphinxrst</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install sphinx_rtd_theme</div></pre></td></tr></table></figure>\n<p>PyTorch<code>docs/</code>PyTorchMakefilesphinx<code>make html</code>HTML<code>build/html</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># in directory $PYTORCH/docs, run</div><div class=\"line\">make html</div></pre></td></tr></table></figure>\n<p>doc2dashsphinxDash~<code>-n</code>source</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># $PYTORCH/docs/build/htmlHTML</span></div><div class=\"line\">doc2dash -n pytorch <span class=\"variable\">$PYTORCH</span>/docs/build/html</div></pre></td></tr></table></figure>\n<p><code>pytorch.docset</code>Dash+<br><img src=\"/img/doc2dash_how_to_add_docset.jpg\" alt=\"docset\"></p>\n<h2 id=\"Ubuntuzeal\"><a href=\"#Ubuntuzeal\" class=\"headerlink\" title=\"Ubuntuzeal\"></a>Ubuntuzeal</h2><p>zealDashMacUbuntu<a href=\"https://zealdocs.org/download.html#linux\"></a></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo add-apt-repository ppa:zeal-developers/ppa</div><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get install zeal</div></pre></td></tr></table></figure>\n<p><code>Tool/Docsets</code>docset<code>$HOME/.local/share/Zeal/Zeal/docsets</code></p>"},{"title":"Effective CPP  - Chapter 2 ","date":"2017-04-24T12:50:10.000Z","_content":"C++OOPcopying function\n<!-- more-->\n\n## 05 C++\n\nC++\n\n\n\nnon-static\n\n## 06 \n\n`private`\n\n## 07 \n\nOOPC++base classderivedbase classbase class\n\nbase class`virtual`C\n\nbase class\n\n> \n\nSTLSTL`vector``string`\n\n\n\n``` cpp\nclass ABC {\npublic:\n    virtual ~ABC() = 0;    \n};\nABC::~ABC() {}\n```\n\n`~ABC()`\n\n## 08 \n\n\n\n\n## 09 \n\n\n\n\n\n\n\n\n## 10 `operator=``*this`\n\n\n\n\n``` cpp\na = b = c;\n```\n\n`+=`\n\n``` cpp\nclass A {\npublic:\n    A& operator=(const A& rhs) {\n        // ...\n        return *this;\n    }\n};\n```\n\n## 11 `operator=`\n\n\n``` cpp\nWidget w;\n// ...\nw = w;\n```\n\n\n\n\n\n``` cpp\nA& operator=(const A& rhs) {\n    if(&rhs == this) return *this; //\n    // ...\n}\n```\n\n\ncopy-swap`rhs``*this`\n\n\n\n## 12 \ncopyingbase class\n\n``` cpp\nclass Derived: public Base{\nprivate:\n    int a;\npublic:\n    Derived(const Derived& rhs):a(rhs.a) {}\n    Derived& operator=(const Derived& rhs) {\n        a = rhs.a;\n        return *this;\n    }\n};\n```\n\n`a`\n>copying`private`\n\n``` cpp\nDerived(const Derived& rhs):Base(rhs), a(rhs.a) {}\nDerived& operator=(const Derived& rhs) {\n    Base::operator=(rhs);\n    a = rhs.a;\n    return *this;\n}\n```\n\ncopying`init()`\n","source":"_posts/effective-cpp-02.md","raw":"---\ntitle: Effective CPP  - Chapter 2 \ndate: 2017-04-24 20:50:10\ntags:\n     - cpp\n---\nC++OOPcopying function\n<!-- more-->\n\n## 05 C++\n\nC++\n\n\n\nnon-static\n\n## 06 \n\n`private`\n\n## 07 \n\nOOPC++base classderivedbase classbase class\n\nbase class`virtual`C\n\nbase class\n\n> \n\nSTLSTL`vector``string`\n\n\n\n``` cpp\nclass ABC {\npublic:\n    virtual ~ABC() = 0;    \n};\nABC::~ABC() {}\n```\n\n`~ABC()`\n\n## 08 \n\n\n\n\n## 09 \n\n\n\n\n\n\n\n\n## 10 `operator=``*this`\n\n\n\n\n``` cpp\na = b = c;\n```\n\n`+=`\n\n``` cpp\nclass A {\npublic:\n    A& operator=(const A& rhs) {\n        // ...\n        return *this;\n    }\n};\n```\n\n## 11 `operator=`\n\n\n``` cpp\nWidget w;\n// ...\nw = w;\n```\n\n\n\n\n\n``` cpp\nA& operator=(const A& rhs) {\n    if(&rhs == this) return *this; //\n    // ...\n}\n```\n\n\ncopy-swap`rhs``*this`\n\n\n\n## 12 \ncopyingbase class\n\n``` cpp\nclass Derived: public Base{\nprivate:\n    int a;\npublic:\n    Derived(const Derived& rhs):a(rhs.a) {}\n    Derived& operator=(const Derived& rhs) {\n        a = rhs.a;\n        return *this;\n    }\n};\n```\n\n`a`\n>copying`private`\n\n``` cpp\nDerived(const Derived& rhs):Base(rhs), a(rhs.a) {}\nDerived& operator=(const Derived& rhs) {\n    Base::operator=(rhs);\n    a = rhs.a;\n    return *this;\n}\n```\n\ncopying`init()`\n","slug":"effective-cpp-02","published":1,"updated":"2018-10-27T07:16:52.389Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8k1001bae7bwfpk3s4z","content":"<p>C++OOPcopying function<br><a id=\"more\"></a></p>\n<h2 id=\"05-C-\"><a href=\"#05-C-\" class=\"headerlink\" title=\"05 C++\"></a>05 C++</h2><p>C++</p>\n<p></p>\n<p>non-static</p>\n<h2 id=\"06-\"><a href=\"#06-\" class=\"headerlink\" title=\"06 \"></a>06 </h2><p><code>private</code></p>\n<h2 id=\"07-\"><a href=\"#07-\" class=\"headerlink\" title=\"07 \"></a>07 </h2><p>OOPC++base classderivedbase classbase class</p>\n<p>base class<code>virtual</code>C</p>\n<p>base class</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p>STLSTL<code>vector</code><code>string</code></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> ABC &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~ABC() = <span class=\"number\">0</span>;    </div><div class=\"line\">&#125;;</div><div class=\"line\">ABC::~ABC() &#123;&#125;</div></pre></td></tr></table></figure>\n<p><code>~ABC()</code></p>\n<h2 id=\"08-\"><a href=\"#08-\" class=\"headerlink\" title=\"08 \"></a>08 </h2><p></p>\n<p></p>\n<h2 id=\"09-\"><a href=\"#09-\" class=\"headerlink\" title=\"09 \"></a>09 </h2><p></p>\n<p></p>\n<p></p>\n<p></p>\n<h2 id=\"10-operator--this\"><a href=\"#10-operator--this\" class=\"headerlink\" title=\"10 operator=*this\"></a>10 <code>operator=</code><code>*this</code></h2><p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = b = c;</div></pre></td></tr></table></figure>\n<p><code>+=</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    A&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> A&amp; rhs) &#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"11-operator-\"><a href=\"#11-operator-\" class=\"headerlink\" title=\"11 operator=\"></a>11 <code>operator=</code></h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Widget w;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">w = w;</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">A&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> A&amp; rhs) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(&amp;rhs == <span class=\"keyword\">this</span>) <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; <span class=\"comment\">//</span></div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>\n<p>copy-swap<code>rhs</code><code>*this</code></p>\n<p></p>\n<h2 id=\"12-\"><a href=\"#12-\" class=\"headerlink\" title=\"12 \"></a>12 </h2><p>copyingbase class</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base&#123;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">int</span> a;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Derived(<span class=\"keyword\">const</span> Derived&amp; rhs):a(rhs.a) &#123;&#125;</div><div class=\"line\">    Derived&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> Derived&amp; rhs) &#123;</div><div class=\"line\">        a = rhs.a;</div><div class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>a</code></p>\n<blockquote>\n<p>copying<code>private</code></p>\n</blockquote>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Derived(<span class=\"keyword\">const</span> Derived&amp; rhs):Base(rhs), a(rhs.a) &#123;&#125;</div><div class=\"line\">Derived&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> Derived&amp; rhs) &#123;</div><div class=\"line\">    Base::<span class=\"keyword\">operator</span>=(rhs);</div><div class=\"line\">    a = rhs.a;</div><div class=\"line\">    <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>copying<code>init()</code></p>\n","excerpt":"<p>C++OOPcopying function<br>","more":"</p>\n<h2 id=\"05-C-\"><a href=\"#05-C-\" class=\"headerlink\" title=\"05 C++\"></a>05 C++</h2><p>C++</p>\n<p></p>\n<p>non-static</p>\n<h2 id=\"06-\"><a href=\"#06-\" class=\"headerlink\" title=\"06 \"></a>06 </h2><p><code>private</code></p>\n<h2 id=\"07-\"><a href=\"#07-\" class=\"headerlink\" title=\"07 \"></a>07 </h2><p>OOPC++base classderivedbase classbase class</p>\n<p>base class<code>virtual</code>C</p>\n<p>base class</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p>STLSTL<code>vector</code><code>string</code></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> ABC &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~ABC() = <span class=\"number\">0</span>;    </div><div class=\"line\">&#125;;</div><div class=\"line\">ABC::~ABC() &#123;&#125;</div></pre></td></tr></table></figure>\n<p><code>~ABC()</code></p>\n<h2 id=\"08-\"><a href=\"#08-\" class=\"headerlink\" title=\"08 \"></a>08 </h2><p></p>\n<p></p>\n<h2 id=\"09-\"><a href=\"#09-\" class=\"headerlink\" title=\"09 \"></a>09 </h2><p></p>\n<p></p>\n<p></p>\n<p></p>\n<h2 id=\"10-operator--this\"><a href=\"#10-operator--this\" class=\"headerlink\" title=\"10 operator=*this\"></a>10 <code>operator=</code><code>*this</code></h2><p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">a = b = c;</div></pre></td></tr></table></figure>\n<p><code>+=</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    A&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> A&amp; rhs) &#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"11-operator-\"><a href=\"#11-operator-\" class=\"headerlink\" title=\"11 operator=\"></a>11 <code>operator=</code></h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">Widget w;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">w = w;</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">A&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> A&amp; rhs) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(&amp;rhs == <span class=\"keyword\">this</span>) <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>; <span class=\"comment\">//</span></div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>\n<p>copy-swap<code>rhs</code><code>*this</code></p>\n<p></p>\n<h2 id=\"12-\"><a href=\"#12-\" class=\"headerlink\" title=\"12 \"></a>12 </h2><p>copyingbase class</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base&#123;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">int</span> a;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Derived(<span class=\"keyword\">const</span> Derived&amp; rhs):a(rhs.a) &#123;&#125;</div><div class=\"line\">    Derived&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> Derived&amp; rhs) &#123;</div><div class=\"line\">        a = rhs.a;</div><div class=\"line\">        <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>a</code></p>\n<blockquote>\n<p>copying<code>private</code></p>\n</blockquote>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Derived(<span class=\"keyword\">const</span> Derived&amp; rhs):Base(rhs), a(rhs.a) &#123;&#125;</div><div class=\"line\">Derived&amp; <span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> Derived&amp; rhs) &#123;</div><div class=\"line\">    Base::<span class=\"keyword\">operator</span>=(rhs);</div><div class=\"line\">    a = rhs.a;</div><div class=\"line\">    <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>copying<code>init()</code></p>"},{"title":"Effective CPP  - Chapter 1 C++","date":"2017-04-20T05:49:42.000Z","_content":"Effective C++\n![C++](/img/effectivecpp_01_cpp_rely_on_renpin.jpg)\n<!-- more-->\n\n### 01 C++\nC++CC++C++\n\nC++\n- CC++\n- OOPC\n- Template\n- STLSTL\n\nC++\n\n### 02 `const`, `enum`, `inline` `#define`\n\n`#define`C\n\n`#define``const`\n\n``` cpp\n#define PI 3.14\nconst double PI = 3.14;\n```\n`int`, `char`, `bool``enum`\n\n``` cpp\nenum {K = 1};\n```\n`const``enum``enum``#define`\n\n`#define``inline`\n\n`#define`\n\n### 03 `const`\n`const`error\n\n`const``const`\n\n`const``const``const`\n\n``` cpp\nconst int* p = &a;\n*p = 5;   // \np = &b;   // \nint* const p = &a;\np = &b;    // \n*p = 5;    // \n```\n\nSTL`const``const_iterator`\n\n`const`\n\n- \n\n``` cpp\nif (fun(a, b) = c)  //  ==  =\n```\n\n-  pass-by-const-reference \n- \n\n`const`\n\n``` cpp\nclass my_string{\n  const char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n  char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n};\n```\n\n`const`\n\n\n\n``` cpp\nclass my_string{\n  const char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n  char& operator[](size_t pos) {\n\t  return const_cast<char&>(\n\t         static_cast<const my_string&>(*this)[pos]);\n  }\n};\n```\n\n`non-const reference``const reference``static_cast``const char&``const``const_cast`\n\n`const``mutable`\n\n### 04 \n\nbug\n\n\n\n\n\n``` cpp\npublic A(name, age) {\n  this->name = name; // \n  this->age = age;\n}\n```\n\n`A``copy-construct`\n\n\n\n`non-local static`scope`static`\n","source":"_posts/effective-cpp-01.md","raw":"---\ntitle: Effective CPP  - Chapter 1 C++\ndate: 2017-04-20 13:49:42\ntags:\n     - cpp\n---\nEffective C++\n![C++](/img/effectivecpp_01_cpp_rely_on_renpin.jpg)\n<!-- more-->\n\n### 01 C++\nC++CC++C++\n\nC++\n- CC++\n- OOPC\n- Template\n- STLSTL\n\nC++\n\n### 02 `const`, `enum`, `inline` `#define`\n\n`#define`C\n\n`#define``const`\n\n``` cpp\n#define PI 3.14\nconst double PI = 3.14;\n```\n`int`, `char`, `bool``enum`\n\n``` cpp\nenum {K = 1};\n```\n`const``enum``enum``#define`\n\n`#define``inline`\n\n`#define`\n\n### 03 `const`\n`const`error\n\n`const``const`\n\n`const``const``const`\n\n``` cpp\nconst int* p = &a;\n*p = 5;   // \np = &b;   // \nint* const p = &a;\np = &b;    // \n*p = 5;    // \n```\n\nSTL`const``const_iterator`\n\n`const`\n\n- \n\n``` cpp\nif (fun(a, b) = c)  //  ==  =\n```\n\n-  pass-by-const-reference \n- \n\n`const`\n\n``` cpp\nclass my_string{\n  const char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n  char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n};\n```\n\n`const`\n\n\n\n``` cpp\nclass my_string{\n  const char& operator[](size_t pos) {\n\t  return this->ptr[pos];\n  }\n  char& operator[](size_t pos) {\n\t  return const_cast<char&>(\n\t         static_cast<const my_string&>(*this)[pos]);\n  }\n};\n```\n\n`non-const reference``const reference``static_cast``const char&``const``const_cast`\n\n`const``mutable`\n\n### 04 \n\nbug\n\n\n\n\n\n``` cpp\npublic A(name, age) {\n  this->name = name; // \n  this->age = age;\n}\n```\n\n`A``copy-construct`\n\n\n\n`non-local static`scope`static`\n","slug":"effective-cpp-01","published":1,"updated":"2018-10-27T07:16:52.389Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8k4001dae7bsu05nz7d","content":"<p>Effective C++<br><img src=\"/img/effectivecpp_01_cpp_rely_on_renpin.jpg\" alt=\"C++\"><br><a id=\"more\"></a></p>\n<h3 id=\"01-C-\"><a href=\"#01-C-\" class=\"headerlink\" title=\"01 C++\"></a>01 C++</h3><p>C++CC++C++</p>\n<p>C++</p>\n<ul>\n<li>CC++</li>\n<li>OOPC</li>\n<li>Template</li>\n<li>STLSTL</li>\n</ul>\n<p>C++</p>\n<h3 id=\"02-const-enum-inline-define\"><a href=\"#02-const-enum-inline-define\" class=\"headerlink\" title=\"02 const, enum, inline #define\"></a>02 <code>const</code>, <code>enum</code>, <code>inline</code> <code>#define</code></h3><p><code>#define</code>C</p>\n<p><code>#define</code><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PI 3.14</span></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> PI = <span class=\"number\">3.14</span>;</div></pre></td></tr></table></figure>\n<p><code>int</code>, <code>char</code>, <code>bool</code><code>enum</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> &#123;K = <span class=\"number\">1</span>&#125;;</div></pre></td></tr></table></figure>\n<p><code>const</code><code>enum</code><code>enum</code><code>#define</code></p>\n<p><code>#define</code><code>inline</code></p>\n<p><code>#define</code></p>\n<h3 id=\"03-const\"><a href=\"#03-const\" class=\"headerlink\" title=\"03 const\"></a>03 <code>const</code></h3><p><code>const</code>error</p>\n<p><code>const</code><code>const</code></p>\n<p><code>const</code><code>const</code><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* p = &amp;a;</div><div class=\"line\">*p = <span class=\"number\">5</span>;   <span class=\"comment\">// </span></div><div class=\"line\">p = &amp;b;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> p = &amp;a;</div><div class=\"line\">p = &amp;b;    <span class=\"comment\">// </span></div><div class=\"line\">*p = <span class=\"number\">5</span>;    <span class=\"comment\">// </span></div></pre></td></tr></table></figure>\n<p>STL<code>const</code><code>const_iterator</code></p>\n<p><code>const</code></p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (fun(a, b) = c)  <span class=\"comment\">//  ==  =</span></div></pre></td></tr></table></figure>\n<ul>\n<li> pass-by-const-reference </li>\n<li></li>\n</ul>\n<p><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> my_string&#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>const</code></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> my_string&#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">const_cast</span>&lt;<span class=\"keyword\">char</span>&amp;&gt;(</div><div class=\"line\">\t         <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">const</span> my_string&amp;&gt;(*<span class=\"keyword\">this</span>)[pos]);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>non-const reference</code><code>const reference</code><code>static_cast</code><code>const char&amp;</code><code>const</code><code>const_cast</code></p>\n<p><code>const</code><code>mutable</code></p>\n<h3 id=\"04-\"><a href=\"#04-\" class=\"headerlink\" title=\"04 \"></a>04 </h3><p>bug</p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">A</span><span class=\"params\">(name, age)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;name = name; <span class=\"comment\">// </span></div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;age = age;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>A</code><code>copy-construct</code></p>\n<p></p>\n<p><code>non-local static</code>scope<code>static</code></p>\n","excerpt":"<p>Effective C++<br><img src=\"/img/effectivecpp_01_cpp_rely_on_renpin.jpg\" alt=\"C++\"><br>","more":"</p>\n<h3 id=\"01-C-\"><a href=\"#01-C-\" class=\"headerlink\" title=\"01 C++\"></a>01 C++</h3><p>C++CC++C++</p>\n<p>C++</p>\n<ul>\n<li>CC++</li>\n<li>OOPC</li>\n<li>Template</li>\n<li>STLSTL</li>\n</ul>\n<p>C++</p>\n<h3 id=\"02-const-enum-inline-define\"><a href=\"#02-const-enum-inline-define\" class=\"headerlink\" title=\"02 const, enum, inline #define\"></a>02 <code>const</code>, <code>enum</code>, <code>inline</code> <code>#define</code></h3><p><code>#define</code>C</p>\n<p><code>#define</code><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> PI 3.14</span></div><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">double</span> PI = <span class=\"number\">3.14</span>;</div></pre></td></tr></table></figure>\n<p><code>int</code>, <code>char</code>, <code>bool</code><code>enum</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">enum</span> &#123;K = <span class=\"number\">1</span>&#125;;</div></pre></td></tr></table></figure>\n<p><code>const</code><code>enum</code><code>enum</code><code>#define</code></p>\n<p><code>#define</code><code>inline</code></p>\n<p><code>#define</code></p>\n<h3 id=\"03-const\"><a href=\"#03-const\" class=\"headerlink\" title=\"03 const\"></a>03 <code>const</code></h3><p><code>const</code>error</p>\n<p><code>const</code><code>const</code></p>\n<p><code>const</code><code>const</code><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span>* p = &amp;a;</div><div class=\"line\">*p = <span class=\"number\">5</span>;   <span class=\"comment\">// </span></div><div class=\"line\">p = &amp;b;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">int</span>* <span class=\"keyword\">const</span> p = &amp;a;</div><div class=\"line\">p = &amp;b;    <span class=\"comment\">// </span></div><div class=\"line\">*p = <span class=\"number\">5</span>;    <span class=\"comment\">// </span></div></pre></td></tr></table></figure>\n<p>STL<code>const</code><code>const_iterator</code></p>\n<p><code>const</code></p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> (fun(a, b) = c)  <span class=\"comment\">//  ==  =</span></div></pre></td></tr></table></figure>\n<ul>\n<li> pass-by-const-reference </li>\n<li></li>\n</ul>\n<p><code>const</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> my_string&#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>const</code></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> my_string&#123;</div><div class=\"line\">  <span class=\"keyword\">const</span> <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;ptr[pos];</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">char</span>&amp; <span class=\"keyword\">operator</span>[](<span class=\"keyword\">size_t</span> pos) &#123;</div><div class=\"line\">\t  <span class=\"keyword\">return</span> <span class=\"keyword\">const_cast</span>&lt;<span class=\"keyword\">char</span>&amp;&gt;(</div><div class=\"line\">\t         <span class=\"keyword\">static_cast</span>&lt;<span class=\"keyword\">const</span> my_string&amp;&gt;(*<span class=\"keyword\">this</span>)[pos]);</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>non-const reference</code><code>const reference</code><code>static_cast</code><code>const char&amp;</code><code>const</code><code>const_cast</code></p>\n<p><code>const</code><code>mutable</code></p>\n<h3 id=\"04-\"><a href=\"#04-\" class=\"headerlink\" title=\"04 \"></a>04 </h3><p>bug</p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">A</span><span class=\"params\">(name, age)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;name = name; <span class=\"comment\">// </span></div><div class=\"line\">  <span class=\"keyword\">this</span>-&gt;age = age;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>A</code><code>copy-construct</code></p>\n<p></p>\n<p><code>non-local static</code>scope<code>static</code></p>"},{"title":"Effective CPP - Chapter 3 ","date":"2017-04-25T05:35:43.000Z","_content":"C++C++\n![Pointer](/img/effectivecpp_02_pointers.png)\n<!-- more -->\n\n## 13 \n\n\n\n> \n\n\n\nC++11`weak_ptr``shared_ptr`C++11boost\n\n\n- RAII(Resource Acquisition Is Initialization)\n- \n\n## 14 coping\n\n\n\n\n``` cpp\n// Lock\nclass Lock {\npublic:\n    explicit Lock(Mutex* pm):mutexPtr(pm) { // \n        lock(mutexPtr);\n    }\n    ~Lock() {unlock(mutexPtr); } //\nprivate:\n    Mutex* mutexPtr;\n};\n```\n`Lock`\n\n``` cpp\nMutex m;   // \n// ...\n{\nLock ml(&m);\n// ...\n}    // ml\n```\n\n`Lock`\n\n- 6trickcopying\n- `shared_ptr``shared_ptr`\n- \n- \n\n## 15 \nAPICAPI\n\n`get()``->``*`\n\n`T``operator T()`\n\n## 16 `new``delete`\n`new T()``delete``new T[]``delete []`\n\nSTL`vector``string`\n\n## 17 newed\nnewed\n\n\n\n\n\n``` cpp\nint priority() { /*some code*/}\nvoid process(shared_ptr<Widget> pw, int priority) { /*some code*/}\n```\n`process`\n\n``` cpp\nprocess(new Widget(), priority());\n```\n`shared_ptr``explicit``shared_ptr`\n\n``` cpp\nprocess(shared_ptr<Widget>(new Widget()), priority());\n```\n\nC++\n\n- newWidget\n- `priority()`Widget\n- `shared_ptr`\n\n\n\n``` cpp\nauto pw = shared_ptr<Widget>(new Widget());\nprocess(pw, priority());\n```\n","source":"_posts/effective-cpp-03.md","raw":"---\ntitle: Effective CPP - Chapter 3 \ndate: 2017-04-25 13:35:43\ntags:\n    - cpp\n---\nC++C++\n![Pointer](/img/effectivecpp_02_pointers.png)\n<!-- more -->\n\n## 13 \n\n\n\n> \n\n\n\nC++11`weak_ptr``shared_ptr`C++11boost\n\n\n- RAII(Resource Acquisition Is Initialization)\n- \n\n## 14 coping\n\n\n\n\n``` cpp\n// Lock\nclass Lock {\npublic:\n    explicit Lock(Mutex* pm):mutexPtr(pm) { // \n        lock(mutexPtr);\n    }\n    ~Lock() {unlock(mutexPtr); } //\nprivate:\n    Mutex* mutexPtr;\n};\n```\n`Lock`\n\n``` cpp\nMutex m;   // \n// ...\n{\nLock ml(&m);\n// ...\n}    // ml\n```\n\n`Lock`\n\n- 6trickcopying\n- `shared_ptr``shared_ptr`\n- \n- \n\n## 15 \nAPICAPI\n\n`get()``->``*`\n\n`T``operator T()`\n\n## 16 `new``delete`\n`new T()``delete``new T[]``delete []`\n\nSTL`vector``string`\n\n## 17 newed\nnewed\n\n\n\n\n\n``` cpp\nint priority() { /*some code*/}\nvoid process(shared_ptr<Widget> pw, int priority) { /*some code*/}\n```\n`process`\n\n``` cpp\nprocess(new Widget(), priority());\n```\n`shared_ptr``explicit``shared_ptr`\n\n``` cpp\nprocess(shared_ptr<Widget>(new Widget()), priority());\n```\n\nC++\n\n- newWidget\n- `priority()`Widget\n- `shared_ptr`\n\n\n\n``` cpp\nauto pw = shared_ptr<Widget>(new Widget());\nprocess(pw, priority());\n```\n","slug":"effective-cpp-03","published":1,"updated":"2018-10-27T07:16:52.389Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8k6001gae7bd3ipqbws","content":"<p>C++C++<br><img src=\"/img/effectivecpp_02_pointers.png\" alt=\"Pointer\"><br><a id=\"more\"></a></p>\n<h2 id=\"13-\"><a href=\"#13-\" class=\"headerlink\" title=\"13 \"></a>13 </h2><p></p>\n<p></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p>C++11<code>weak_ptr</code><code>shared_ptr</code>C++11boost</p>\n<p></p>\n<ul>\n<li>RAII(Resource Acquisition Is Initialization)</li>\n<li></li>\n</ul>\n<h2 id=\"14-coping\"><a href=\"#14-coping\" class=\"headerlink\" title=\"14 coping\"></a>14 coping</h2><p></p>\n<p></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Lock</div><div class=\"line\">class Lock &#123;</div><div class=\"line\">public:</div><div class=\"line\">    explicit Lock(Mutex* pm):mutexPtr(pm) &#123; // </div><div class=\"line\">        lock(mutexPtr);</div><div class=\"line\">    &#125;</div><div class=\"line\">    ~Lock() &#123;unlock(mutexPtr); &#125; //</div><div class=\"line\">private:</div><div class=\"line\">    Mutex* mutexPtr;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>Lock</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Mutex m;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">&#123;</div><div class=\"line\"><span class=\"function\">Lock <span class=\"title\">ml</span><span class=\"params\">(&amp;m)</span></span>;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">&#125;    <span class=\"comment\">// ml</span></div></pre></td></tr></table></figure>\n<p><code>Lock</code></p>\n<ul>\n<li>6trickcopying</li>\n<li><code>shared_ptr</code><code>shared_ptr</code></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"15-\"><a href=\"#15-\" class=\"headerlink\" title=\"15 \"></a>15 </h2><p>APICAPI</p>\n<p><code>get()</code><code>-&gt;</code><code>*</code></p>\n<p><code>T</code><code>operator T()</code></p>\n<h2 id=\"16-newdelete\"><a href=\"#16-newdelete\" class=\"headerlink\" title=\"16 newdelete\"></a>16 <code>new</code><code>delete</code></h2><p><code>new T()</code><code>delete</code><code>new T[]</code><code>delete []</code></p>\n<p>STL<code>vector</code><code>string</code></p>\n<h2 id=\"17-newed\"><a href=\"#17-newed\" class=\"headerlink\" title=\"17 newed\"></a>17 newed</h2><p>newed</p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">priority</span><span class=\"params\">()</span> </span>&#123; <span class=\"comment\">/*some code*/</span>&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">(<span class=\"built_in\">shared_ptr</span>&lt;Widget&gt; pw, <span class=\"keyword\">int</span> priority)</span> </span>&#123; <span class=\"comment\">/*some code*/</span>&#125;</div></pre></td></tr></table></figure>\n<p><code>process</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">process(<span class=\"keyword\">new</span> Widget(), priority());</div></pre></td></tr></table></figure>\n<p><code>shared_ptr</code><code>explicit</code><code>shared_ptr</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">process(<span class=\"built_in\">shared_ptr</span>&lt;Widget&gt;(<span class=\"keyword\">new</span> Widget()), priority());</div></pre></td></tr></table></figure>\n<p>C++</p>\n<ul>\n<li>newWidget</li>\n<li><code>priority()</code>Widget</li>\n<li><code>shared_ptr</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">auto</span> pw = <span class=\"built_in\">shared_ptr</span>&lt;Widget&gt;(<span class=\"keyword\">new</span> Widget());</div><div class=\"line\">process(pw, priority());</div></pre></td></tr></table></figure>\n","excerpt":"<p>C++C++<br><img src=\"/img/effectivecpp_02_pointers.png\" alt=\"Pointer\"><br>","more":"</p>\n<h2 id=\"13-\"><a href=\"#13-\" class=\"headerlink\" title=\"13 \"></a>13 </h2><p></p>\n<p></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p>C++11<code>weak_ptr</code><code>shared_ptr</code>C++11boost</p>\n<p></p>\n<ul>\n<li>RAII(Resource Acquisition Is Initialization)</li>\n<li></li>\n</ul>\n<h2 id=\"14-coping\"><a href=\"#14-coping\" class=\"headerlink\" title=\"14 coping\"></a>14 coping</h2><p></p>\n<p></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Lock</div><div class=\"line\">class Lock &#123;</div><div class=\"line\">public:</div><div class=\"line\">    explicit Lock(Mutex* pm):mutexPtr(pm) &#123; // </div><div class=\"line\">        lock(mutexPtr);</div><div class=\"line\">    &#125;</div><div class=\"line\">    ~Lock() &#123;unlock(mutexPtr); &#125; //</div><div class=\"line\">private:</div><div class=\"line\">    Mutex* mutexPtr;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>Lock</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Mutex m;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">&#123;</div><div class=\"line\"><span class=\"function\">Lock <span class=\"title\">ml</span><span class=\"params\">(&amp;m)</span></span>;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\">&#125;    <span class=\"comment\">// ml</span></div></pre></td></tr></table></figure>\n<p><code>Lock</code></p>\n<ul>\n<li>6trickcopying</li>\n<li><code>shared_ptr</code><code>shared_ptr</code></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"15-\"><a href=\"#15-\" class=\"headerlink\" title=\"15 \"></a>15 </h2><p>APICAPI</p>\n<p><code>get()</code><code>-&gt;</code><code>*</code></p>\n<p><code>T</code><code>operator T()</code></p>\n<h2 id=\"16-newdelete\"><a href=\"#16-newdelete\" class=\"headerlink\" title=\"16 newdelete\"></a>16 <code>new</code><code>delete</code></h2><p><code>new T()</code><code>delete</code><code>new T[]</code><code>delete []</code></p>\n<p>STL<code>vector</code><code>string</code></p>\n<h2 id=\"17-newed\"><a href=\"#17-newed\" class=\"headerlink\" title=\"17 newed\"></a>17 newed</h2><p>newed</p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">priority</span><span class=\"params\">()</span> </span>&#123; <span class=\"comment\">/*some code*/</span>&#125;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">(<span class=\"built_in\">shared_ptr</span>&lt;Widget&gt; pw, <span class=\"keyword\">int</span> priority)</span> </span>&#123; <span class=\"comment\">/*some code*/</span>&#125;</div></pre></td></tr></table></figure>\n<p><code>process</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">process(<span class=\"keyword\">new</span> Widget(), priority());</div></pre></td></tr></table></figure>\n<p><code>shared_ptr</code><code>explicit</code><code>shared_ptr</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">process(<span class=\"built_in\">shared_ptr</span>&lt;Widget&gt;(<span class=\"keyword\">new</span> Widget()), priority());</div></pre></td></tr></table></figure>\n<p>C++</p>\n<ul>\n<li>newWidget</li>\n<li><code>priority()</code>Widget</li>\n<li><code>shared_ptr</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">auto</span> pw = <span class=\"built_in\">shared_ptr</span>&lt;Widget&gt;(<span class=\"keyword\">new</span> Widget());</div><div class=\"line\">process(pw, priority());</div></pre></td></tr></table></figure>"},{"title":"Effective CPP  - Chapter 4 ","date":"2017-04-29T09:29:33.000Z","_content":"OOPC++\n![C?](/img/effectivecpp_04_cwithclass.jpg)\n<!-- more -->\n\n## 18 \n`const`\n\nSTL`size()`\n\n\n\n## 19 `class``type`\n`class`\n\n- \n- \n- pass-by-valuecopying\n- `setter()`\n- \n- \n- \n- \n- `friend`\n- \n- `template class`\n- non-member\n\n## 20 pass-by-reference-to-constpass-by-value\npass-by-value\n\nSTL\n\n## 21 reference\nnon-static\n\nC++11\n\n## 22 `private`\n\n\n`private``protected`\n\n## 23 non-membernon-friendmember\nnon-member\n\n- \n- C++hppcppC++\n- non-member\n\n## 24 non-member\n`explicit`\n\n\n``` cpp\nclass Rational {\n// ...\npublic:\n    Rational(int numerator=0, int denominator=1);\n    const Rational operator*(const Rational& rhs) const;\n};\n```\n\n`auto res = 2*Rational(4,5)``int``operator*(const Rational&)`\n\nnon-member\n```cpp\nconst Rational operator*(const Rational& lhs, const Rational& rhs) {\n    //...\n}\n```\n\n## 25 `swap()`\n\n\nSTL`swap()`\n```cpp\nnamespace std {\ntemplate <typename T>\nvoid swap(T& a, T&b) {\n    T tmp(a);\n    a = b;\n    b = tmp;\n}\n}\n```\npImplpointer to implementation\n\n`Widget`\n\n`Widget`\n``` cpp\nnamespace std {\ntemplate <>\nvoid swap<Widget>(Widget& a, Widget& b) {\n    swap(pImpl, b.pImpl);\n}\n}\n```\n`swap()``Widget``swap()`STLSTL`vector``std``swap()`\n\n`Widget`\n``` cpp\nnamespace std {\ntemplate <typename T>\nvoid swap(Widget<T>& a, Widget<T>& b) {\n    a.swap(b);\n}\n}\n```\n\n`std``std`\n\n`Widget``swap()``std`C++\n\n- `swap()`\n- `public``swap()`\n- non-member`swap()``swap()`\n- `std::swap()``swap()`\n- `swap()``using``std::swap()``swap()`\n","source":"_posts/effective-cpp-04.md","raw":"---\ntitle: Effective CPP  - Chapter 4 \ndate: 2017-04-29 17:29:33\ntags:\n     - cpp\n---\nOOPC++\n![C?](/img/effectivecpp_04_cwithclass.jpg)\n<!-- more -->\n\n## 18 \n`const`\n\nSTL`size()`\n\n\n\n## 19 `class``type`\n`class`\n\n- \n- \n- pass-by-valuecopying\n- `setter()`\n- \n- \n- \n- \n- `friend`\n- \n- `template class`\n- non-member\n\n## 20 pass-by-reference-to-constpass-by-value\npass-by-value\n\nSTL\n\n## 21 reference\nnon-static\n\nC++11\n\n## 22 `private`\n\n\n`private``protected`\n\n## 23 non-membernon-friendmember\nnon-member\n\n- \n- C++hppcppC++\n- non-member\n\n## 24 non-member\n`explicit`\n\n\n``` cpp\nclass Rational {\n// ...\npublic:\n    Rational(int numerator=0, int denominator=1);\n    const Rational operator*(const Rational& rhs) const;\n};\n```\n\n`auto res = 2*Rational(4,5)``int``operator*(const Rational&)`\n\nnon-member\n```cpp\nconst Rational operator*(const Rational& lhs, const Rational& rhs) {\n    //...\n}\n```\n\n## 25 `swap()`\n\n\nSTL`swap()`\n```cpp\nnamespace std {\ntemplate <typename T>\nvoid swap(T& a, T&b) {\n    T tmp(a);\n    a = b;\n    b = tmp;\n}\n}\n```\npImplpointer to implementation\n\n`Widget`\n\n`Widget`\n``` cpp\nnamespace std {\ntemplate <>\nvoid swap<Widget>(Widget& a, Widget& b) {\n    swap(pImpl, b.pImpl);\n}\n}\n```\n`swap()``Widget``swap()`STLSTL`vector``std``swap()`\n\n`Widget`\n``` cpp\nnamespace std {\ntemplate <typename T>\nvoid swap(Widget<T>& a, Widget<T>& b) {\n    a.swap(b);\n}\n}\n```\n\n`std``std`\n\n`Widget``swap()``std`C++\n\n- `swap()`\n- `public``swap()`\n- non-member`swap()``swap()`\n- `std::swap()``swap()`\n- `swap()``using``std::swap()``swap()`\n","slug":"effective-cpp-04","published":1,"updated":"2018-10-27T07:16:52.390Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8k7001iae7b3rnetups","content":"<p>OOPC++<br><img src=\"/img/effectivecpp_04_cwithclass.jpg\" alt=\"C?\"><br><a id=\"more\"></a></p>\n<h2 id=\"18-\"><a href=\"#18-\" class=\"headerlink\" title=\"18 \"></a>18 </h2><p><code>const</code></p>\n<p>STL<code>size()</code></p>\n<p></p>\n<h2 id=\"19-classtype\"><a href=\"#19-classtype\" class=\"headerlink\" title=\"19 classtype\"></a>19 <code>class</code><code>type</code></h2><p><code>class</code></p>\n<ul>\n<li></li>\n<li></li>\n<li>pass-by-valuecopying</li>\n<li><code>setter()</code></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><code>friend</code></li>\n<li></li>\n<li><code>template class</code></li>\n<li>non-member</li>\n</ul>\n<h2 id=\"20-pass-by-reference-to-constpass-by-value\"><a href=\"#20-pass-by-reference-to-constpass-by-value\" class=\"headerlink\" title=\"20 pass-by-reference-to-constpass-by-value\"></a>20 pass-by-reference-to-constpass-by-value</h2><p>pass-by-value</p>\n<p>STL</p>\n<h2 id=\"21-reference\"><a href=\"#21-reference\" class=\"headerlink\" title=\"21 reference\"></a>21 reference</h2><p>non-static</p>\n<p>C++11</p>\n<h2 id=\"22-private\"><a href=\"#22-private\" class=\"headerlink\" title=\"22 private\"></a>22 <code>private</code></h2><p></p>\n<p><code>private</code><code>protected</code></p>\n<h2 id=\"23-non-membernon-friendmember\"><a href=\"#23-non-membernon-friendmember\" class=\"headerlink\" title=\"23 non-membernon-friendmember\"></a>23 non-membernon-friendmember</h2><p>non-member</p>\n<ul>\n<li></li>\n<li>C++hppcppC++</li>\n<li>non-member</li>\n</ul>\n<h2 id=\"24-non-member\"><a href=\"#24-non-member\" class=\"headerlink\" title=\"24 non-member\"></a>24 non-member</h2><p><code>explicit</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">int</span> numerator=<span class=\"number\">0</span>, <span class=\"keyword\">int</span> denominator=<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">const</span> Rational <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; rhs) <span class=\"keyword\">const</span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>auto res = 2*Rational(4,5)</code><code>int</code><code>operator*(const Rational&amp;)</code></p>\n<p>non-member<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> Rational <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; lhs, <span class=\"keyword\">const</span> Rational&amp; rhs) &#123;</div><div class=\"line\">    <span class=\"comment\">//...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"25-swap-\"><a href=\"#25-swap-\" class=\"headerlink\" title=\"25 swap()\"></a>25 <code>swap()</code></h2><p></p>\n<p>STL<code>swap()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(T&amp; a, T&amp;b)</span> </span>&#123;</div><div class=\"line\">    <span class=\"function\">T <span class=\"title\">tmp</span><span class=\"params\">(a)</span></span>;</div><div class=\"line\">    a = b;</div><div class=\"line\">    b = tmp;</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>pImplpointer to implementation</p>\n<p><code>Widget</code></p>\n<p><code>Widget</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> swap&lt;Widget&gt;(Widget&amp; a, Widget&amp; b) &#123;</div><div class=\"line\">    swap(pImpl, b.pImpl);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>swap()</code><code>Widget</code><code>swap()</code>STLSTL<code>vector</code><code>std</code><code>swap()</code></p>\n<p><code>Widget</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(Widget&lt;T&gt;&amp; a, Widget&lt;T&gt;&amp; b)</span> </span>&#123;</div><div class=\"line\">    a.swap(b);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>std</code><code>std</code></p>\n<p><code>Widget</code><code>swap()</code><code>std</code>C++</p>\n<ul>\n<li><code>swap()</code></li>\n<li><code>public</code><code>swap()</code></li>\n<li>non-member<code>swap()</code><code>swap()</code></li>\n<li><code>std::swap()</code><code>swap()</code></li>\n<li><code>swap()</code><code>using</code><code>std::swap()</code><code>swap()</code></li>\n</ul>\n","excerpt":"<p>OOPC++<br><img src=\"/img/effectivecpp_04_cwithclass.jpg\" alt=\"C?\"><br>","more":"</p>\n<h2 id=\"18-\"><a href=\"#18-\" class=\"headerlink\" title=\"18 \"></a>18 </h2><p><code>const</code></p>\n<p>STL<code>size()</code></p>\n<p></p>\n<h2 id=\"19-classtype\"><a href=\"#19-classtype\" class=\"headerlink\" title=\"19 classtype\"></a>19 <code>class</code><code>type</code></h2><p><code>class</code></p>\n<ul>\n<li></li>\n<li></li>\n<li>pass-by-valuecopying</li>\n<li><code>setter()</code></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><code>friend</code></li>\n<li></li>\n<li><code>template class</code></li>\n<li>non-member</li>\n</ul>\n<h2 id=\"20-pass-by-reference-to-constpass-by-value\"><a href=\"#20-pass-by-reference-to-constpass-by-value\" class=\"headerlink\" title=\"20 pass-by-reference-to-constpass-by-value\"></a>20 pass-by-reference-to-constpass-by-value</h2><p>pass-by-value</p>\n<p>STL</p>\n<h2 id=\"21-reference\"><a href=\"#21-reference\" class=\"headerlink\" title=\"21 reference\"></a>21 reference</h2><p>non-static</p>\n<p>C++11</p>\n<h2 id=\"22-private\"><a href=\"#22-private\" class=\"headerlink\" title=\"22 private\"></a>22 <code>private</code></h2><p></p>\n<p><code>private</code><code>protected</code></p>\n<h2 id=\"23-non-membernon-friendmember\"><a href=\"#23-non-membernon-friendmember\" class=\"headerlink\" title=\"23 non-membernon-friendmember\"></a>23 non-membernon-friendmember</h2><p>non-member</p>\n<ul>\n<li></li>\n<li>C++hppcppC++</li>\n<li>non-member</li>\n</ul>\n<h2 id=\"24-non-member\"><a href=\"#24-non-member\" class=\"headerlink\" title=\"24 non-member\"></a>24 non-member</h2><p><code>explicit</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"comment\">// ...</span></div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">int</span> numerator=<span class=\"number\">0</span>, <span class=\"keyword\">int</span> denominator=<span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">const</span> Rational <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; rhs) <span class=\"keyword\">const</span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>auto res = 2*Rational(4,5)</code><code>int</code><code>operator*(const Rational&amp;)</code></p>\n<p>non-member<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">const</span> Rational <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; lhs, <span class=\"keyword\">const</span> Rational&amp; rhs) &#123;</div><div class=\"line\">    <span class=\"comment\">//...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"25-swap-\"><a href=\"#25-swap-\" class=\"headerlink\" title=\"25 swap()\"></a>25 <code>swap()</code></h2><p></p>\n<p>STL<code>swap()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(T&amp; a, T&amp;b)</span> </span>&#123;</div><div class=\"line\">    <span class=\"function\">T <span class=\"title\">tmp</span><span class=\"params\">(a)</span></span>;</div><div class=\"line\">    a = b;</div><div class=\"line\">    b = tmp;</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>pImplpointer to implementation</p>\n<p><code>Widget</code></p>\n<p><code>Widget</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> swap&lt;Widget&gt;(Widget&amp; a, Widget&amp; b) &#123;</div><div class=\"line\">    swap(pImpl, b.pImpl);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>swap()</code><code>Widget</code><code>swap()</code>STLSTL<code>vector</code><code>std</code><code>swap()</code></p>\n<p><code>Widget</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">swap</span><span class=\"params\">(Widget&lt;T&gt;&amp; a, Widget&lt;T&gt;&amp; b)</span> </span>&#123;</div><div class=\"line\">    a.swap(b);</div><div class=\"line\">&#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>std</code><code>std</code></p>\n<p><code>Widget</code><code>swap()</code><code>std</code>C++</p>\n<ul>\n<li><code>swap()</code></li>\n<li><code>public</code><code>swap()</code></li>\n<li>non-member<code>swap()</code><code>swap()</code></li>\n<li><code>std::swap()</code><code>swap()</code></li>\n<li><code>swap()</code><code>using</code><code>std::swap()</code><code>swap()</code></li>\n</ul>"},{"title":"Effective CPP  - Chapter 7 ","date":"2017-06-23T12:19:07.000Z","_content":"C++STLC++\n\n![~](/img/effective_cpp_07_joke.jpg)\n<!-- more -->\n\n## 41 \nOOP\n\n`T``<`\n\ninstantiated\n``` cpp\ntemplate <typename T>\nbool fun(const T& a, const T& b) {return a < b;}\n```\n\n## 42 `typename`\n`typename``class`\n``` cpp\ntemplate <typename/class T>\nvoid fun(T& a) {...}\n```\n\n`typename`\n``` cpp\n// \ntemplate <typename C>\nvoid print_2nd_element(const C& container) {\n    // \n    typename C::const_iterator it(container.begin());\n    cout << *++it;\n}\n```\n\n\n\n``` cpp\ntemplate <typename T>\nclass Derived: public Base<T>::Nested { //Nesttypename\npublic:\n    explicit Derived(int x)\n     :Base<T>::Nested(x) { // \n        typename Base<T>::Nested tmp; //\n     }\n};\n```\n\n## 43 \n\n\n``` cpp\nclass TypeA {\npublic:\n    void fun();\n};\n\nclass TypeB {\npublic:\n    void fun();\n};\n\ntemplate <typename Type>\nclass Base {\npublic:\n    void do_something() {\n        Type x;\n        x.fun();\n    }\n};\n\ntemplate <typename Type>\nclass Derived: public Base<Type> {\npublic:\n    void do_something_too() {\n        // ...\n        do_something();  // \n    }\n};\n```\n\n`Base<Tyep>``Type`\n``` cpp\ntemplate <>\nclass Base<TypeC> {\npublic:\n    //  dom_somthing \n};\n```\n\n`class Derived<TypeC>: public Base<TypeC>``do_something`\n\n\n\n- `this->`\n``` cpp\nvoid do_something_too() {\n    // ...\n    this->do_something();  // \n}\n```\n\n- `using`3333\n\n``` cpp\nusing Base<Type>::do_something;\nvoid do_something_too() {\n    // ...\n    this->do_something();  // \n}\n```\n\n- \n\n``` cpp\nvoid do_something_too() {\n    // ...\n    Base<Type>::do_something();  // \n}\n```\n\n## 44 \n\n\n$N$`n`\n\n``` cpp\ntemplate <typename T, size_t n>\nclass Matrix {\npublic:\n    void invert();\n};\n```\n\n\n\n``` cpp\ntemplate <typename T>\nclass MatrixBase {\nprotected:\n    MatrixBase(size_t n, T* pMem) // \n     :size(n), pData(pMem) {}\n    void setDataPtr(T* ptr) {pData = ptr;} // \n    void invert();   // \nprivate:\n    size_t size;\n    T* pData;\n};\n```\n\n`private`Is-a\n``` cpp\ntemplate <typename T, size_t n>\nclass Matrix: private MatrixBase<T> {\npublic:\n    Matrix(): MatrixBase<T>(n, 0), pData(new T[n*n]) {\n        this->setDataPtr(pData.get()); // \n    }\nprivate:\n    boost::scoped_array<T> pData;\n};\n```\n\n`n`profile\n\n`int``long``vector<int>``vector<long>`\n\n`vector<int*>, list<const int*>``T*``void*`\n\n## 45 \n\n``` cpp\nBase* p = new Base;\nBase* p = new Derived;\n```\n\n``` cpp\n// \ntemplate <typename T>\nclass SmartPointer {\npublic:\n    //  U\n    template <typename U>\n    SmartPointer(const SmartPointer<U>& other)\n        // \n       :ptr(other.get())  {...}\n    T* get() const { return ptr; }\nprivate:\n    T* ptr;\n};\n```\n\n\n``` cpp\ntemplate <typename T>\nclass shared_ptr {\npublic:\n    ...\n    // shared_ptr\n    template <typename Y>\n    shared_ptr& operator = (shared_ptr<Y> const& r);\n    // auto_ptr\n    template <typename Y>\n    shared_ptr& operator = (auto_ptr<Y> const& r);\n};\n```\n\n\n``` cpp\nshared_ptr& operator = (shared_ptr const& r);\n```\n## 46 friend\n24`Rational`\n\n``` cpp\ntemplate <typename T>\nclass Rational {\npublic:\n    Rational(const T& numerator=0, const T& denominator=1);\n};\n\ntemplate <typename T>\nconst Rational<T> operator*(const Rational<T>& lhs,\n                            const Rational<T>& rhs)\n{...}\n\nRational<int> onehalf(1, 2);\nRational<int> res = onehalf * 2;  // \n```\n\n`2`\n\n`Rational<T>``onehalf``Rational<int>`\n\n\n``` cpp\ntemplate <typename T> class Rational;   // \ntemplate <typename T>\nconst Rational<T> doMultiply(const Rational<T>& lhs,\n                             const Rational<T>& rhs) {};\n\ntemplate <typename T>\nclass Rational {\npublic:\n    Rational(const T& numerator=0, const T& denominator=1) {\n    }\n    // ...\n    friend const Rational<T> operator*(const Rational& lhs,\n                                       const Rational& rhs)\n    {return doMultiply(lhs, rhs); }\n};\n```\n\n## 47 `trait`\nSTL`advance`\n- `istream_iterator`\n- `ostream_iterator`\n- \n- \n- `vector`\n\nC++tag\n``` cpp\nstruct input_iterator_tag {};\nstruct output_iterator_tag {};\nstruct forward_iterator_tag: public input_iterator_tag {};\nstruct bidirectional_iterator_tag: public forward_iterator_tag {};\nstruct random_access_iterator_tag: public bidirectional_iterator_tag {};\n```\n\n`advance``trait`\n\n`trait`STLSTL`trait`C++11`iterator_traits`\n\n`typedef`\n``` cpp\ntemplate <typename T>\nclass deque {\npublic:\n    class iterator {\n    public:\n        typedef random_access_iterator_tag iterator_category;\n        // ...\n    }\n};\n```\n\n`iterator_traits``iterator_category`~`iterator_traits``IterT`\n\n``` cpp\ntemplate <typename IterT>\nstruct iterator_traits {\n    typedef typename IterT::iterator_category iterator_category;\n};\n```\n\n~\n\n``` cpp\ntemplate <typename T>\nstruct iterator_traits<T*> {\n    typedef random_access_iterator_tag iterator_category;\n};\n```\n\n`traits`\n\n- category\n- `iterator_category`\n- \n\n`advance`\n``` cpp\ntemplate <typename IterT, typename DistT>\nvoid advance(IterT& iter, DistT d) {\n    if(typeid(typename std::iterator_traits<IterT>::iterator_category\n        == typeid(std::random_access_iterator_tag) {\n        // ...\n    }\n    // ...\n}\n```\n\n`if-else`\n\n\n``` cpp\ntemplate <typename IterT, typename DistT>\nvoid doAdvance(IterT& iter, Dist d, std::random_access_iterator_tag) {\n    iter += d;\n}\n\n// ... doadvance\n\n// advance\ntemplate <typename Iter, typename DistT>\nvoid advance(IterT& iter, Dist d) {\n    doAdvance(iter, d, typename std::iterator_traits<IterT>::iterator_category());\n    //  typename\n    //  iterator_category()\n}\n```\n\n- `trait`\n- `trait`\n\n## 48 \nTemplate Metaprogram TMPMXNet\n\n47`trait`\n\n`n`\n\n``` cpp\ntemplate <unsigned n>\nstruct F {\n    enum {value = n * F<n-1>::value };\n};\n\ntemplate <>\nstruct F<0> {\n    enum {value = 1 };\n};\n```\n\nTMP\n","source":"_posts/effective-cpp-07.md","raw":"---\ntitle: Effective CPP  - Chapter 7 \ndate: 2017-06-23 20:19:07\ntags:\n    - cpp\n---\nC++STLC++\n\n![~](/img/effective_cpp_07_joke.jpg)\n<!-- more -->\n\n## 41 \nOOP\n\n`T``<`\n\ninstantiated\n``` cpp\ntemplate <typename T>\nbool fun(const T& a, const T& b) {return a < b;}\n```\n\n## 42 `typename`\n`typename``class`\n``` cpp\ntemplate <typename/class T>\nvoid fun(T& a) {...}\n```\n\n`typename`\n``` cpp\n// \ntemplate <typename C>\nvoid print_2nd_element(const C& container) {\n    // \n    typename C::const_iterator it(container.begin());\n    cout << *++it;\n}\n```\n\n\n\n``` cpp\ntemplate <typename T>\nclass Derived: public Base<T>::Nested { //Nesttypename\npublic:\n    explicit Derived(int x)\n     :Base<T>::Nested(x) { // \n        typename Base<T>::Nested tmp; //\n     }\n};\n```\n\n## 43 \n\n\n``` cpp\nclass TypeA {\npublic:\n    void fun();\n};\n\nclass TypeB {\npublic:\n    void fun();\n};\n\ntemplate <typename Type>\nclass Base {\npublic:\n    void do_something() {\n        Type x;\n        x.fun();\n    }\n};\n\ntemplate <typename Type>\nclass Derived: public Base<Type> {\npublic:\n    void do_something_too() {\n        // ...\n        do_something();  // \n    }\n};\n```\n\n`Base<Tyep>``Type`\n``` cpp\ntemplate <>\nclass Base<TypeC> {\npublic:\n    //  dom_somthing \n};\n```\n\n`class Derived<TypeC>: public Base<TypeC>``do_something`\n\n\n\n- `this->`\n``` cpp\nvoid do_something_too() {\n    // ...\n    this->do_something();  // \n}\n```\n\n- `using`3333\n\n``` cpp\nusing Base<Type>::do_something;\nvoid do_something_too() {\n    // ...\n    this->do_something();  // \n}\n```\n\n- \n\n``` cpp\nvoid do_something_too() {\n    // ...\n    Base<Type>::do_something();  // \n}\n```\n\n## 44 \n\n\n$N$`n`\n\n``` cpp\ntemplate <typename T, size_t n>\nclass Matrix {\npublic:\n    void invert();\n};\n```\n\n\n\n``` cpp\ntemplate <typename T>\nclass MatrixBase {\nprotected:\n    MatrixBase(size_t n, T* pMem) // \n     :size(n), pData(pMem) {}\n    void setDataPtr(T* ptr) {pData = ptr;} // \n    void invert();   // \nprivate:\n    size_t size;\n    T* pData;\n};\n```\n\n`private`Is-a\n``` cpp\ntemplate <typename T, size_t n>\nclass Matrix: private MatrixBase<T> {\npublic:\n    Matrix(): MatrixBase<T>(n, 0), pData(new T[n*n]) {\n        this->setDataPtr(pData.get()); // \n    }\nprivate:\n    boost::scoped_array<T> pData;\n};\n```\n\n`n`profile\n\n`int``long``vector<int>``vector<long>`\n\n`vector<int*>, list<const int*>``T*``void*`\n\n## 45 \n\n``` cpp\nBase* p = new Base;\nBase* p = new Derived;\n```\n\n``` cpp\n// \ntemplate <typename T>\nclass SmartPointer {\npublic:\n    //  U\n    template <typename U>\n    SmartPointer(const SmartPointer<U>& other)\n        // \n       :ptr(other.get())  {...}\n    T* get() const { return ptr; }\nprivate:\n    T* ptr;\n};\n```\n\n\n``` cpp\ntemplate <typename T>\nclass shared_ptr {\npublic:\n    ...\n    // shared_ptr\n    template <typename Y>\n    shared_ptr& operator = (shared_ptr<Y> const& r);\n    // auto_ptr\n    template <typename Y>\n    shared_ptr& operator = (auto_ptr<Y> const& r);\n};\n```\n\n\n``` cpp\nshared_ptr& operator = (shared_ptr const& r);\n```\n## 46 friend\n24`Rational`\n\n``` cpp\ntemplate <typename T>\nclass Rational {\npublic:\n    Rational(const T& numerator=0, const T& denominator=1);\n};\n\ntemplate <typename T>\nconst Rational<T> operator*(const Rational<T>& lhs,\n                            const Rational<T>& rhs)\n{...}\n\nRational<int> onehalf(1, 2);\nRational<int> res = onehalf * 2;  // \n```\n\n`2`\n\n`Rational<T>``onehalf``Rational<int>`\n\n\n``` cpp\ntemplate <typename T> class Rational;   // \ntemplate <typename T>\nconst Rational<T> doMultiply(const Rational<T>& lhs,\n                             const Rational<T>& rhs) {};\n\ntemplate <typename T>\nclass Rational {\npublic:\n    Rational(const T& numerator=0, const T& denominator=1) {\n    }\n    // ...\n    friend const Rational<T> operator*(const Rational& lhs,\n                                       const Rational& rhs)\n    {return doMultiply(lhs, rhs); }\n};\n```\n\n## 47 `trait`\nSTL`advance`\n- `istream_iterator`\n- `ostream_iterator`\n- \n- \n- `vector`\n\nC++tag\n``` cpp\nstruct input_iterator_tag {};\nstruct output_iterator_tag {};\nstruct forward_iterator_tag: public input_iterator_tag {};\nstruct bidirectional_iterator_tag: public forward_iterator_tag {};\nstruct random_access_iterator_tag: public bidirectional_iterator_tag {};\n```\n\n`advance``trait`\n\n`trait`STLSTL`trait`C++11`iterator_traits`\n\n`typedef`\n``` cpp\ntemplate <typename T>\nclass deque {\npublic:\n    class iterator {\n    public:\n        typedef random_access_iterator_tag iterator_category;\n        // ...\n    }\n};\n```\n\n`iterator_traits``iterator_category`~`iterator_traits``IterT`\n\n``` cpp\ntemplate <typename IterT>\nstruct iterator_traits {\n    typedef typename IterT::iterator_category iterator_category;\n};\n```\n\n~\n\n``` cpp\ntemplate <typename T>\nstruct iterator_traits<T*> {\n    typedef random_access_iterator_tag iterator_category;\n};\n```\n\n`traits`\n\n- category\n- `iterator_category`\n- \n\n`advance`\n``` cpp\ntemplate <typename IterT, typename DistT>\nvoid advance(IterT& iter, DistT d) {\n    if(typeid(typename std::iterator_traits<IterT>::iterator_category\n        == typeid(std::random_access_iterator_tag) {\n        // ...\n    }\n    // ...\n}\n```\n\n`if-else`\n\n\n``` cpp\ntemplate <typename IterT, typename DistT>\nvoid doAdvance(IterT& iter, Dist d, std::random_access_iterator_tag) {\n    iter += d;\n}\n\n// ... doadvance\n\n// advance\ntemplate <typename Iter, typename DistT>\nvoid advance(IterT& iter, Dist d) {\n    doAdvance(iter, d, typename std::iterator_traits<IterT>::iterator_category());\n    //  typename\n    //  iterator_category()\n}\n```\n\n- `trait`\n- `trait`\n\n## 48 \nTemplate Metaprogram TMPMXNet\n\n47`trait`\n\n`n`\n\n``` cpp\ntemplate <unsigned n>\nstruct F {\n    enum {value = n * F<n-1>::value };\n};\n\ntemplate <>\nstruct F<0> {\n    enum {value = 1 };\n};\n```\n\nTMP\n","slug":"effective-cpp-07","published":1,"updated":"2018-10-27T07:16:52.392Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ka001lae7bk7j8zfo3","content":"<p>C++STLC++</p>\n<p><img src=\"/img/effective_cpp_07_joke.jpg\" alt=\"~\"><br><a id=\"more\"></a></p>\n<h2 id=\"41-\"><a href=\"#41-\" class=\"headerlink\" title=\"41 \"></a>41 </h2><p>OOP</p>\n<p><code>T</code><code>&lt;</code></p>\n<p>instantiated<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">fun</span><span class=\"params\">(<span class=\"keyword\">const</span> T&amp; a, <span class=\"keyword\">const</span> T&amp; b)</span> </span>&#123;<span class=\"keyword\">return</span> a &lt; b;&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"42-typename\"><a href=\"#42-typename\" class=\"headerlink\" title=\"42 typename\"></a>42 <code>typename</code></h2><p><code>typename</code><code>class</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span>/<span class=\"keyword\">class</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">(T&amp; a)</span> </span>&#123;...&#125;</div></pre></td></tr></table></figure></p>\n<p><code>typename</code><br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// </div><div class=\"line\">template &lt;typename C&gt;</div><div class=\"line\">void print_2nd_element(const C&amp; container) &#123;</div><div class=\"line\">    // </div><div class=\"line\">    typename C::const_iterator it(container.begin());</div><div class=\"line\">    cout &lt;&lt; *++it;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">template &lt;typename T&gt;</div><div class=\"line\">class Derived: public Base&lt;T&gt;::Nested &#123; //Nesttypename</div><div class=\"line\">public:</div><div class=\"line\">    explicit Derived(int x)</div><div class=\"line\">     :Base&lt;T&gt;::Nested(x) &#123; // </div><div class=\"line\">        typename Base&lt;T&gt;::Nested tmp; //</div><div class=\"line\">     &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"43-\"><a href=\"#43-\" class=\"headerlink\" title=\"43 \"></a>43 </h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> TypeA &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> TypeB &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Type&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        Type x;</div><div class=\"line\">        x.fun();</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Type&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base&lt;Type&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">        do_something();  <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>Base&lt;Tyep&gt;</code><code>Type</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Base&lt;TypeC&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">//  dom_somthing </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>class Derived&lt;TypeC&gt;: public Base&lt;TypeC&gt;</code><code>do_something</code></p>\n<p></p>\n<ul>\n<li><p><code>this-&gt;</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p><code>using</code>3333</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">using</span> Base&lt;Type&gt;::do_something;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    Base&lt;Type&gt;::do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"44-\"><a href=\"#44-\" class=\"headerlink\" title=\"44 \"></a>44 </h2><p></p>\n<p>$N$<code>n</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T, <span class=\"keyword\">size_t</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Matrix &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">invert</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> MatrixBase &#123;</div><div class=\"line\"><span class=\"keyword\">protected</span>:</div><div class=\"line\">    MatrixBase(<span class=\"keyword\">size_t</span> n, T* pMem) <span class=\"comment\">// </span></div><div class=\"line\">     :size(n), pData(pMem) &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setDataPtr</span><span class=\"params\">(T* ptr)</span> </span>&#123;pData = ptr;&#125; <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">invert</span><span class=\"params\">()</span></span>;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">size_t</span> size;</div><div class=\"line\">    T* pData;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>private</code>Is-a<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T, <span class=\"keyword\">size_t</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Matrix: <span class=\"keyword\">private</span> MatrixBase&lt;T&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Matrix(): MatrixBase&lt;T&gt;(n, <span class=\"number\">0</span>), pData(<span class=\"keyword\">new</span> T[n*n]) &#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;setDataPtr(pData.get()); <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    boost::scoped_array&lt;T&gt; pData;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>n</code>profile</p>\n<p><code>int</code><code>long</code><code>vector&lt;int&gt;</code><code>vector&lt;long&gt;</code></p>\n<p><code>vector&lt;int*&gt;, list&lt;const int*&gt;</code><code>T*</code><code>void*</code></p>\n<h2 id=\"45-\"><a href=\"#45-\" class=\"headerlink\" title=\"45 \"></a>45 </h2><p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Base* p = <span class=\"keyword\">new</span> Base;</div><div class=\"line\">Base* p = <span class=\"keyword\">new</span> Derived;</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> SmartPointer &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">//  U</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> U&gt;</div><div class=\"line\">    SmartPointer(<span class=\"keyword\">const</span> SmartPointer&lt;U&gt;&amp; other)</div><div class=\"line\">        <span class=\"comment\">// </span></div><div class=\"line\">       :ptr(other.get())  &#123;...&#125;</div><div class=\"line\">    <span class=\"function\">T* <span class=\"title\">get</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> ptr; &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    T* ptr;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> <span class=\"built_in\">shared_ptr</span> &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    ...</div><div class=\"line\">    <span class=\"comment\">// shared_ptr</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Y&gt;</div><div class=\"line\">    <span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">shared_ptr</span>&lt;Y&gt; <span class=\"keyword\">const</span>&amp; r);</div><div class=\"line\">    <span class=\"comment\">// auto_ptr</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Y&gt;</div><div class=\"line\">    <span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">auto_ptr</span>&lt;Y&gt; <span class=\"keyword\">const</span>&amp; r);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">shared_ptr</span> <span class=\"keyword\">const</span>&amp; r);</div></pre></td></tr></table></figure></p>\n<h2 id=\"46-friend\"><a href=\"#46-friend\" class=\"headerlink\" title=\"46 friend\"></a>46 friend</h2><p>24<code>Rational</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">const</span> T&amp; numerator=<span class=\"number\">0</span>, <span class=\"keyword\">const</span> T&amp; denominator=<span class=\"number\">1</span>);</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">const</span> Rational&lt;T&gt; <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; lhs,</div><div class=\"line\">                            <span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; rhs)</div><div class=\"line\">&#123;...&#125;</div><div class=\"line\"></div><div class=\"line\">Rational&lt;<span class=\"keyword\">int</span>&gt; onehalf(<span class=\"number\">1</span>, <span class=\"number\">2</span>);</div><div class=\"line\">Rational&lt;<span class=\"keyword\">int</span>&gt; res = onehalf * <span class=\"number\">2</span>;  <span class=\"comment\">// </span></div></pre></td></tr></table></figure>\n<p><code>2</code></p>\n<p><code>Rational&lt;T&gt;</code><code>onehalf</code><code>Rational&lt;int&gt;</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt; <span class=\"keyword\">class</span> Rational;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">const</span> Rational&lt;T&gt; doMultiply(<span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; lhs,</div><div class=\"line\">                             <span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; rhs) &#123;&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">const</span> T&amp; numerator=<span class=\"number\">0</span>, <span class=\"keyword\">const</span> T&amp; denominator=<span class=\"number\">1</span>) &#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">friend</span> <span class=\"keyword\">const</span> Rational&lt;T&gt; <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; lhs,</div><div class=\"line\">                                       <span class=\"keyword\">const</span> Rational&amp; rhs)</div><div class=\"line\">    &#123;<span class=\"keyword\">return</span> doMultiply(lhs, rhs); &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<h2 id=\"47-trait\"><a href=\"#47-trait\" class=\"headerlink\" title=\"47 trait\"></a>47 <code>trait</code></h2><p>STL<code>advance</code></p>\n<ul>\n<li><code>istream_iterator</code></li>\n<li><code>ostream_iterator</code></li>\n<li></li>\n<li></li>\n<li><code>vector</code></li>\n</ul>\n<p>C++tag<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> input_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> output_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> forward_iterator_tag: <span class=\"keyword\">public</span> input_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> bidirectional_iterator_tag: <span class=\"keyword\">public</span> forward_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> random_access_iterator_tag: <span class=\"keyword\">public</span> bidirectional_iterator_tag &#123;&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>advance</code><code>trait</code></p>\n<p><code>trait</code>STLSTL<code>trait</code>C++11<code>iterator_traits</code></p>\n<p><code>typedef</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> <span class=\"built_in\">deque</span> &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">class</span> iterator &#123;</div><div class=\"line\">    <span class=\"keyword\">public</span>:</div><div class=\"line\">        <span class=\"keyword\">typedef</span> random_access_iterator_tag iterator_category;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>iterator_traits</code><code>iterator_category</code>~<code>iterator_traits</code><code>IterT</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> iterator_traits &#123;</div><div class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> IterT::iterator_category iterator_category;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>~</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> iterator_traits&lt;T*&gt; &#123;</div><div class=\"line\">    <span class=\"keyword\">typedef</span> random_access_iterator_tag iterator_category;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>traits</code></p>\n<ul>\n<li>category</li>\n<li><code>iterator_category</code></li>\n<li></li>\n</ul>\n<p><code>advance</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(IterT&amp; iter, DistT d)</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"keyword\">typeid</span>(<span class=\"keyword\">typename</span> <span class=\"built_in\">std</span>::iterator_traits&lt;IterT&gt;::iterator_category</div><div class=\"line\">        == <span class=\"keyword\">typeid</span>(<span class=\"built_in\">std</span>::random_access_iterator_tag) &#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>if-else</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doAdvance</span><span class=\"params\">(IterT&amp; iter, Dist d, <span class=\"built_in\">std</span>::random_access_iterator_tag)</span> </span>&#123;</div><div class=\"line\">    iter += d;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// ... doadvance</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// advance</span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Iter, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(IterT&amp; iter, Dist d)</span> </span>&#123;</div><div class=\"line\">    doAdvance(iter, d, <span class=\"keyword\">typename</span> <span class=\"built_in\">std</span>::iterator_traits&lt;IterT&gt;::iterator_category());</div><div class=\"line\">    <span class=\"comment\">//  typename</span></div><div class=\"line\">    <span class=\"comment\">//  iterator_category()</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li><code>trait</code></li>\n<li><code>trait</code></li>\n</ul>\n<h2 id=\"48-\"><a href=\"#48-\" class=\"headerlink\" title=\"48 \"></a>48 </h2><p>Template Metaprogram TMPMXNet</p>\n<p>47<code>trait</code></p>\n<p><code>n</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">unsigned</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> F &#123;</div><div class=\"line\">    <span class=\"keyword\">enum</span> &#123;value = n * F&lt;n<span class=\"number\">-1</span>&gt;::value &#125;;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> F&lt;<span class=\"number\">0</span>&gt; &#123;</div><div class=\"line\">    <span class=\"keyword\">enum</span> &#123;value = <span class=\"number\">1</span> &#125;;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>TMP</p>\n","excerpt":"<p>C++STLC++</p>\n<p><img src=\"/img/effective_cpp_07_joke.jpg\" alt=\"~\"><br>","more":"</p>\n<h2 id=\"41-\"><a href=\"#41-\" class=\"headerlink\" title=\"41 \"></a>41 </h2><p>OOP</p>\n<p><code>T</code><code>&lt;</code></p>\n<p>instantiated<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">fun</span><span class=\"params\">(<span class=\"keyword\">const</span> T&amp; a, <span class=\"keyword\">const</span> T&amp; b)</span> </span>&#123;<span class=\"keyword\">return</span> a &lt; b;&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"42-typename\"><a href=\"#42-typename\" class=\"headerlink\" title=\"42 typename\"></a>42 <code>typename</code></h2><p><code>typename</code><code>class</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span>/<span class=\"keyword\">class</span> T&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">(T&amp; a)</span> </span>&#123;...&#125;</div></pre></td></tr></table></figure></p>\n<p><code>typename</code><br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// </div><div class=\"line\">template &lt;typename C&gt;</div><div class=\"line\">void print_2nd_element(const C&amp; container) &#123;</div><div class=\"line\">    // </div><div class=\"line\">    typename C::const_iterator it(container.begin());</div><div class=\"line\">    cout &lt;&lt; *++it;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">template &lt;typename T&gt;</div><div class=\"line\">class Derived: public Base&lt;T&gt;::Nested &#123; //Nesttypename</div><div class=\"line\">public:</div><div class=\"line\">    explicit Derived(int x)</div><div class=\"line\">     :Base&lt;T&gt;::Nested(x) &#123; // </div><div class=\"line\">        typename Base&lt;T&gt;::Nested tmp; //</div><div class=\"line\">     &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"43-\"><a href=\"#43-\" class=\"headerlink\" title=\"43 \"></a>43 </h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> TypeA &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> TypeB &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Type&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        Type x;</div><div class=\"line\">        x.fun();</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Type&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base&lt;Type&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">        do_something();  <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>Base&lt;Tyep&gt;</code><code>Type</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Base&lt;TypeC&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">//  dom_somthing </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>class Derived&lt;TypeC&gt;: public Base&lt;TypeC&gt;</code><code>do_something</code></p>\n<p></p>\n<ul>\n<li><p><code>this-&gt;</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p><code>using</code>3333</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">using</span> Base&lt;Type&gt;::do_something;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">this</span>-&gt;do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">do_something_too</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    Base&lt;Type&gt;::do_something();  <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"44-\"><a href=\"#44-\" class=\"headerlink\" title=\"44 \"></a>44 </h2><p></p>\n<p>$N$<code>n</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T, <span class=\"keyword\">size_t</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Matrix &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">invert</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> MatrixBase &#123;</div><div class=\"line\"><span class=\"keyword\">protected</span>:</div><div class=\"line\">    MatrixBase(<span class=\"keyword\">size_t</span> n, T* pMem) <span class=\"comment\">// </span></div><div class=\"line\">     :size(n), pData(pMem) &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">setDataPtr</span><span class=\"params\">(T* ptr)</span> </span>&#123;pData = ptr;&#125; <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">invert</span><span class=\"params\">()</span></span>;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">size_t</span> size;</div><div class=\"line\">    T* pData;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>private</code>Is-a<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T, <span class=\"keyword\">size_t</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Matrix: <span class=\"keyword\">private</span> MatrixBase&lt;T&gt; &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Matrix(): MatrixBase&lt;T&gt;(n, <span class=\"number\">0</span>), pData(<span class=\"keyword\">new</span> T[n*n]) &#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>-&gt;setDataPtr(pData.get()); <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    boost::scoped_array&lt;T&gt; pData;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>n</code>profile</p>\n<p><code>int</code><code>long</code><code>vector&lt;int&gt;</code><code>vector&lt;long&gt;</code></p>\n<p><code>vector&lt;int*&gt;, list&lt;const int*&gt;</code><code>T*</code><code>void*</code></p>\n<h2 id=\"45-\"><a href=\"#45-\" class=\"headerlink\" title=\"45 \"></a>45 </h2><p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">Base* p = <span class=\"keyword\">new</span> Base;</div><div class=\"line\">Base* p = <span class=\"keyword\">new</span> Derived;</div></pre></td></tr></table></figure></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> SmartPointer &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">//  U</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> U&gt;</div><div class=\"line\">    SmartPointer(<span class=\"keyword\">const</span> SmartPointer&lt;U&gt;&amp; other)</div><div class=\"line\">        <span class=\"comment\">// </span></div><div class=\"line\">       :ptr(other.get())  &#123;...&#125;</div><div class=\"line\">    <span class=\"function\">T* <span class=\"title\">get</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> ptr; &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    T* ptr;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> <span class=\"built_in\">shared_ptr</span> &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    ...</div><div class=\"line\">    <span class=\"comment\">// shared_ptr</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Y&gt;</div><div class=\"line\">    <span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">shared_ptr</span>&lt;Y&gt; <span class=\"keyword\">const</span>&amp; r);</div><div class=\"line\">    <span class=\"comment\">// auto_ptr</span></div><div class=\"line\">    <span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Y&gt;</div><div class=\"line\">    <span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">auto_ptr</span>&lt;Y&gt; <span class=\"keyword\">const</span>&amp; r);</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">shared_ptr</span>&amp; <span class=\"keyword\">operator</span> = (<span class=\"built_in\">shared_ptr</span> <span class=\"keyword\">const</span>&amp; r);</div></pre></td></tr></table></figure></p>\n<h2 id=\"46-friend\"><a href=\"#46-friend\" class=\"headerlink\" title=\"46 friend\"></a>46 friend</h2><p>24<code>Rational</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">const</span> T&amp; numerator=<span class=\"number\">0</span>, <span class=\"keyword\">const</span> T&amp; denominator=<span class=\"number\">1</span>);</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">const</span> Rational&lt;T&gt; <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; lhs,</div><div class=\"line\">                            <span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; rhs)</div><div class=\"line\">&#123;...&#125;</div><div class=\"line\"></div><div class=\"line\">Rational&lt;<span class=\"keyword\">int</span>&gt; onehalf(<span class=\"number\">1</span>, <span class=\"number\">2</span>);</div><div class=\"line\">Rational&lt;<span class=\"keyword\">int</span>&gt; res = onehalf * <span class=\"number\">2</span>;  <span class=\"comment\">// </span></div></pre></td></tr></table></figure>\n<p><code>2</code></p>\n<p><code>Rational&lt;T&gt;</code><code>onehalf</code><code>Rational&lt;int&gt;</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt; <span class=\"keyword\">class</span> Rational;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">const</span> Rational&lt;T&gt; doMultiply(<span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; lhs,</div><div class=\"line\">                             <span class=\"keyword\">const</span> Rational&lt;T&gt;&amp; rhs) &#123;&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> Rational &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Rational(<span class=\"keyword\">const</span> T&amp; numerator=<span class=\"number\">0</span>, <span class=\"keyword\">const</span> T&amp; denominator=<span class=\"number\">1</span>) &#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">    <span class=\"keyword\">friend</span> <span class=\"keyword\">const</span> Rational&lt;T&gt; <span class=\"keyword\">operator</span>*(<span class=\"keyword\">const</span> Rational&amp; lhs,</div><div class=\"line\">                                       <span class=\"keyword\">const</span> Rational&amp; rhs)</div><div class=\"line\">    &#123;<span class=\"keyword\">return</span> doMultiply(lhs, rhs); &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<h2 id=\"47-trait\"><a href=\"#47-trait\" class=\"headerlink\" title=\"47 trait\"></a>47 <code>trait</code></h2><p>STL<code>advance</code></p>\n<ul>\n<li><code>istream_iterator</code></li>\n<li><code>ostream_iterator</code></li>\n<li></li>\n<li></li>\n<li><code>vector</code></li>\n</ul>\n<p>C++tag<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">struct</span> input_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> output_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> forward_iterator_tag: <span class=\"keyword\">public</span> input_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> bidirectional_iterator_tag: <span class=\"keyword\">public</span> forward_iterator_tag &#123;&#125;;</div><div class=\"line\"><span class=\"keyword\">struct</span> random_access_iterator_tag: <span class=\"keyword\">public</span> bidirectional_iterator_tag &#123;&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>advance</code><code>trait</code></p>\n<p><code>trait</code>STLSTL<code>trait</code>C++11<code>iterator_traits</code></p>\n<p><code>typedef</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> <span class=\"built_in\">deque</span> &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">class</span> iterator &#123;</div><div class=\"line\">    <span class=\"keyword\">public</span>:</div><div class=\"line\">        <span class=\"keyword\">typedef</span> random_access_iterator_tag iterator_category;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p><code>iterator_traits</code><code>iterator_category</code>~<code>iterator_traits</code><code>IterT</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> iterator_traits &#123;</div><div class=\"line\">    <span class=\"keyword\">typedef</span> <span class=\"keyword\">typename</span> IterT::iterator_category iterator_category;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>~</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> iterator_traits&lt;T*&gt; &#123;</div><div class=\"line\">    <span class=\"keyword\">typedef</span> random_access_iterator_tag iterator_category;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>traits</code></p>\n<ul>\n<li>category</li>\n<li><code>iterator_category</code></li>\n<li></li>\n</ul>\n<p><code>advance</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(IterT&amp; iter, DistT d)</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"keyword\">typeid</span>(<span class=\"keyword\">typename</span> <span class=\"built_in\">std</span>::iterator_traits&lt;IterT&gt;::iterator_category</div><div class=\"line\">        == <span class=\"keyword\">typeid</span>(<span class=\"built_in\">std</span>::random_access_iterator_tag) &#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>if-else</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> IterT, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doAdvance</span><span class=\"params\">(IterT&amp; iter, Dist d, <span class=\"built_in\">std</span>::random_access_iterator_tag)</span> </span>&#123;</div><div class=\"line\">    iter += d;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// ... doadvance</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// advance</span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Iter, <span class=\"keyword\">typename</span> DistT&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">advance</span><span class=\"params\">(IterT&amp; iter, Dist d)</span> </span>&#123;</div><div class=\"line\">    doAdvance(iter, d, <span class=\"keyword\">typename</span> <span class=\"built_in\">std</span>::iterator_traits&lt;IterT&gt;::iterator_category());</div><div class=\"line\">    <span class=\"comment\">//  typename</span></div><div class=\"line\">    <span class=\"comment\">//  iterator_category()</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li><code>trait</code></li>\n<li><code>trait</code></li>\n</ul>\n<h2 id=\"48-\"><a href=\"#48-\" class=\"headerlink\" title=\"48 \"></a>48 </h2><p>Template Metaprogram TMPMXNet</p>\n<p>47<code>trait</code></p>\n<p><code>n</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">unsigned</span> n&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> F &#123;</div><div class=\"line\">    <span class=\"keyword\">enum</span> &#123;value = n * F&lt;n<span class=\"number\">-1</span>&gt;::value &#125;;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">struct</span> F&lt;<span class=\"number\">0</span>&gt; &#123;</div><div class=\"line\">    <span class=\"keyword\">enum</span> &#123;value = <span class=\"number\">1</span> &#125;;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>TMP</p>"},{"title":"Effective CPP  - Chapter 5 ","date":"2017-05-01T06:56:54.000Z","_content":"\n\n<!-- more -->\n\n## 26 \n\n\n## 27 \nC++\n\n\n\nC++\n\n- `(T)expression`C\n- `T(expression)`\n- `static_cast`,`const_cast`,`dynamic_cast``reinterpret_cast`\n\n\n\n `const_cast``const`\n\n`static_cast`non-constconst`double``int`\n\n`dynamic_cast``dynamic_cast`\n\n`dynamic_cast`base\n\n`reinterpret_cast``int`bit[cpp reference](http://en.cppreference.com/w/cpp/language/reinterpret_cast)\n\n`reinterpret_cast``const_cast``static_cast`CPU`dynamic_cast`\n\n## 28 handle\n`const`\n\n`string``const`\n\n`const handle&`\n\n\n\n## 29 \n`delete`\n\n\n``` cpp\n// `Menu`\nvoid Menu::changeBg(std::istream& imgSrc) {\n    lock(&this->mutex);  //  1\n    delete this->bg;     // bg2\n    ++this->imgChangeCnt;      //   3\n    bg = new Image(imgSrc);    //   4\n    unlock(&this->mutex);      //   5\n}\n```\n\n\n\n- 4\n- `bg`\n\n13\n\n\n\n- `bg`\n- copy-and-swapswap\n\npImplswap\n\n- `int`nothrow\n\n## 30 \n`inline``inline`\n\n`inline``inline`\n\n`inline`\n\n`inline``inline`\n\n\n\nprofile2880%20%\n\n## 31 \nC++\n\ncpp\n\nC++C++JavaJavaC++\n\nJavahandlehandlepImpl\n\n`Date``Person`\n\n``` cpp\n#include <string>   // for string\n#include <memory>   // for shared_ptr\n\nclass PersonImpl;   // Person\nclass Date;         // Person\n\nclass Person {\npublic:\n    Person(const std::string& name, const Date& birthday);\n    std::string name() const;\nprivate:\n    std::shared_ptr<PersonImpl> pImpl;   // \n};\n\n/*********************************/\n#include \"Person.h\"\n#include \"PersonImpl.h\"\nPerson::Person(const std::string& name, const Date& birthday):\n    pImpl(new PersonImpl(name, birthday)) {}\n\nstd::string Person::name() const {\n    return pImpl->name();\n}\n```\n\nhandle`PersonImpl``Person``Date``date.hpp``Date``Person``Date``PersonImpl``Person``Person``Person``PersonImpl`\n\n\n\n- object pointerobject referenceobjectpointerreferenceobject\n-  pass-by-value\n- `Person``PersonImpl`\n\n`Person`Caffe`Layer``Person`7\n\n``` cpp\nclass Person {\npublic:\n    virtual ~Person();\n    virtual string name() const = 0;\n};\n```\n\n`static`\n\n``` cpp\nclass Person {\npublic:\n    static shared_ptr<Person> create(const string& name, const Date& birthday);\n// ... \n};\n```\n\n\n\n``` cpp\nclass RealPerson: public Person {\npublic:\n    RealPerson(const string& name, const Date& birthday): name(name), birthDate(birthday) {}\n    virtual ~RealPerson() {}\n    string name() const { return this->name; }\nprivate:\n    string name;\n    Date birthDate;\n};\n```\n\n`create()`\n\n``` cpp\nshared_ptr<Person> Person::create(const string& name, const Date& date) {\n    return shared_ptr<Person>(new RealPerson(name, date));\n}\n```\n\n\n\n\n","source":"_posts/effective-cpp-05.md","raw":"---\ntitle: Effective CPP  - Chapter 5 \ndate: 2017-05-01 14:56:54\ntags:\n    - cpp\n---\n\n\n<!-- more -->\n\n## 26 \n\n\n## 27 \nC++\n\n\n\nC++\n\n- `(T)expression`C\n- `T(expression)`\n- `static_cast`,`const_cast`,`dynamic_cast``reinterpret_cast`\n\n\n\n `const_cast``const`\n\n`static_cast`non-constconst`double``int`\n\n`dynamic_cast``dynamic_cast`\n\n`dynamic_cast`base\n\n`reinterpret_cast``int`bit[cpp reference](http://en.cppreference.com/w/cpp/language/reinterpret_cast)\n\n`reinterpret_cast``const_cast``static_cast`CPU`dynamic_cast`\n\n## 28 handle\n`const`\n\n`string``const`\n\n`const handle&`\n\n\n\n## 29 \n`delete`\n\n\n``` cpp\n// `Menu`\nvoid Menu::changeBg(std::istream& imgSrc) {\n    lock(&this->mutex);  //  1\n    delete this->bg;     // bg2\n    ++this->imgChangeCnt;      //   3\n    bg = new Image(imgSrc);    //   4\n    unlock(&this->mutex);      //   5\n}\n```\n\n\n\n- 4\n- `bg`\n\n13\n\n\n\n- `bg`\n- copy-and-swapswap\n\npImplswap\n\n- `int`nothrow\n\n## 30 \n`inline``inline`\n\n`inline``inline`\n\n`inline`\n\n`inline``inline`\n\n\n\nprofile2880%20%\n\n## 31 \nC++\n\ncpp\n\nC++C++JavaJavaC++\n\nJavahandlehandlepImpl\n\n`Date``Person`\n\n``` cpp\n#include <string>   // for string\n#include <memory>   // for shared_ptr\n\nclass PersonImpl;   // Person\nclass Date;         // Person\n\nclass Person {\npublic:\n    Person(const std::string& name, const Date& birthday);\n    std::string name() const;\nprivate:\n    std::shared_ptr<PersonImpl> pImpl;   // \n};\n\n/*********************************/\n#include \"Person.h\"\n#include \"PersonImpl.h\"\nPerson::Person(const std::string& name, const Date& birthday):\n    pImpl(new PersonImpl(name, birthday)) {}\n\nstd::string Person::name() const {\n    return pImpl->name();\n}\n```\n\nhandle`PersonImpl``Person``Date``date.hpp``Date``Person``Date``PersonImpl``Person``Person``Person``PersonImpl`\n\n\n\n- object pointerobject referenceobjectpointerreferenceobject\n-  pass-by-value\n- `Person``PersonImpl`\n\n`Person`Caffe`Layer``Person`7\n\n``` cpp\nclass Person {\npublic:\n    virtual ~Person();\n    virtual string name() const = 0;\n};\n```\n\n`static`\n\n``` cpp\nclass Person {\npublic:\n    static shared_ptr<Person> create(const string& name, const Date& birthday);\n// ... \n};\n```\n\n\n\n``` cpp\nclass RealPerson: public Person {\npublic:\n    RealPerson(const string& name, const Date& birthday): name(name), birthDate(birthday) {}\n    virtual ~RealPerson() {}\n    string name() const { return this->name; }\nprivate:\n    string name;\n    Date birthDate;\n};\n```\n\n`create()`\n\n``` cpp\nshared_ptr<Person> Person::create(const string& name, const Date& date) {\n    return shared_ptr<Person>(new RealPerson(name, date));\n}\n```\n\n\n\n\n","slug":"effective-cpp-05","published":1,"updated":"2018-10-27T07:16:52.391Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ke001nae7by09pojvd","content":"<p></p>\n<a id=\"more\"></a>\n<h2 id=\"26-\"><a href=\"#26-\" class=\"headerlink\" title=\"26 \"></a>26 </h2><p></p>\n<h2 id=\"27-\"><a href=\"#27-\" class=\"headerlink\" title=\"27 \"></a>27 </h2><p>C++</p>\n<p></p>\n<p>C++</p>\n<ul>\n<li><code>(T)expression</code>C</li>\n<li><code>T(expression)</code></li>\n<li><code>static_cast</code>,<code>const_cast</code>,<code>dynamic_cast</code><code>reinterpret_cast</code></li>\n</ul>\n<p></p>\n<p> <code>const_cast</code><code>const</code></p>\n<p><code>static_cast</code>non-constconst<code>double</code><code>int</code></p>\n<p><code>dynamic_cast</code><code>dynamic_cast</code></p>\n<p><code>dynamic_cast</code>base</p>\n<p><code>reinterpret_cast</code><code>int</code>bit<a href=\"http://en.cppreference.com/w/cpp/language/reinterpret_cast\" target=\"_blank\" rel=\"external\">cpp reference</a></p>\n<p><code>reinterpret_cast</code><code>const_cast</code><code>static_cast</code>CPU<code>dynamic_cast</code></p>\n<h2 id=\"28-handle\"><a href=\"#28-handle\" class=\"headerlink\" title=\"28 handle\"></a>28 handle</h2><p><code>const</code></p>\n<p><code>string</code><code>const</code></p>\n<p><code>const handle&amp;</code></p>\n<p></p>\n<h2 id=\"29-\"><a href=\"#29-\" class=\"headerlink\" title=\"29 \"></a>29 </h2><p><code>delete</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// `Menu`</span></div><div class=\"line\"><span class=\"keyword\">void</span> Menu::changeBg(<span class=\"built_in\">std</span>::istream&amp; imgSrc) &#123;</div><div class=\"line\">    lock(&amp;<span class=\"keyword\">this</span>-&gt;mutex);  <span class=\"comment\">//  1</span></div><div class=\"line\">    <span class=\"keyword\">delete</span> <span class=\"keyword\">this</span>-&gt;bg;     <span class=\"comment\">// bg2</span></div><div class=\"line\">    ++<span class=\"keyword\">this</span>-&gt;imgChangeCnt;      <span class=\"comment\">//   3</span></div><div class=\"line\">    bg = <span class=\"keyword\">new</span> Image(imgSrc);    <span class=\"comment\">//   4</span></div><div class=\"line\">    unlock(&amp;<span class=\"keyword\">this</span>-&gt;mutex);      <span class=\"comment\">//   5</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li>4</li>\n<li><code>bg</code></li>\n</ul>\n<p>13</p>\n<p></p>\n<ul>\n<li><code>bg</code></li>\n<li>copy-and-swapswap</li>\n</ul>\n<p>pImplswap</p>\n<ul>\n<li><code>int</code>nothrow</li>\n</ul>\n<h2 id=\"30-\"><a href=\"#30-\" class=\"headerlink\" title=\"30 \"></a>30 </h2><p><code>inline</code><code>inline</code></p>\n<p><code>inline</code><code>inline</code></p>\n<p><code>inline</code></p>\n<p><code>inline</code><code>inline</code></p>\n<p></p>\n<p>profile2880%20%</p>\n<h2 id=\"31-\"><a href=\"#31-\" class=\"headerlink\" title=\"31 \"></a>31 </h2><p>C++</p>\n<p>cpp</p>\n<p>C++C++JavaJavaC++</p>\n<p>JavahandlehandlepImpl</p>\n<p><code>Date</code><code>Person</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span>   <span class=\"comment\">// for string</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;memory&gt;</span>   <span class=\"comment\">// for shared_ptr</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> PersonImpl;   <span class=\"comment\">// Person</span></div><div class=\"line\"><span class=\"keyword\">class</span> Date;         <span class=\"comment\">// Person</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Person(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday);</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">shared_ptr</span>&lt;PersonImpl&gt; pImpl;   <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*********************************/</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"Person.h\"</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"PersonImpl.h\"</span></span></div><div class=\"line\">Person::Person(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday):</div><div class=\"line\">    pImpl(<span class=\"keyword\">new</span> PersonImpl(name, birthday)) &#123;&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> Person::name() <span class=\"keyword\">const</span> &#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> pImpl-&gt;name();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>handle<code>PersonImpl</code><code>Person</code><code>Date</code><code>date.hpp</code><code>Date</code><code>Person</code><code>Date</code><code>PersonImpl</code><code>Person</code><code>Person</code><code>Person</code><code>PersonImpl</code></p>\n<p></p>\n<ul>\n<li>object pointerobject referenceobjectpointerreferenceobject</li>\n<li> pass-by-value</li>\n<li><code>Person</code><code>PersonImpl</code></li>\n</ul>\n<p><code>Person</code>Caffe<code>Layer</code><code>Person</code>7</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~Person();</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>static</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">shared_ptr</span>&lt;Person&gt; create(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday);</div><div class=\"line\"><span class=\"comment\">// ... </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> RealPerson: <span class=\"keyword\">public</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    RealPerson(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday): name(name), birthDate(birthday) &#123;&#125;</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~RealPerson() &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;name; &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"built_in\">string</span> name;</div><div class=\"line\">    Date birthDate;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>create()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">shared_ptr</span>&lt;Person&gt; Person::create(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; date) &#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">shared_ptr</span>&lt;Person&gt;(<span class=\"keyword\">new</span> RealPerson(name, date));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n","excerpt":"<p></p>","more":"<h2 id=\"26-\"><a href=\"#26-\" class=\"headerlink\" title=\"26 \"></a>26 </h2><p></p>\n<h2 id=\"27-\"><a href=\"#27-\" class=\"headerlink\" title=\"27 \"></a>27 </h2><p>C++</p>\n<p></p>\n<p>C++</p>\n<ul>\n<li><code>(T)expression</code>C</li>\n<li><code>T(expression)</code></li>\n<li><code>static_cast</code>,<code>const_cast</code>,<code>dynamic_cast</code><code>reinterpret_cast</code></li>\n</ul>\n<p></p>\n<p> <code>const_cast</code><code>const</code></p>\n<p><code>static_cast</code>non-constconst<code>double</code><code>int</code></p>\n<p><code>dynamic_cast</code><code>dynamic_cast</code></p>\n<p><code>dynamic_cast</code>base</p>\n<p><code>reinterpret_cast</code><code>int</code>bit<a href=\"http://en.cppreference.com/w/cpp/language/reinterpret_cast\">cpp reference</a></p>\n<p><code>reinterpret_cast</code><code>const_cast</code><code>static_cast</code>CPU<code>dynamic_cast</code></p>\n<h2 id=\"28-handle\"><a href=\"#28-handle\" class=\"headerlink\" title=\"28 handle\"></a>28 handle</h2><p><code>const</code></p>\n<p><code>string</code><code>const</code></p>\n<p><code>const handle&amp;</code></p>\n<p></p>\n<h2 id=\"29-\"><a href=\"#29-\" class=\"headerlink\" title=\"29 \"></a>29 </h2><p><code>delete</code></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// `Menu`</span></div><div class=\"line\"><span class=\"keyword\">void</span> Menu::changeBg(<span class=\"built_in\">std</span>::istream&amp; imgSrc) &#123;</div><div class=\"line\">    lock(&amp;<span class=\"keyword\">this</span>-&gt;mutex);  <span class=\"comment\">//  1</span></div><div class=\"line\">    <span class=\"keyword\">delete</span> <span class=\"keyword\">this</span>-&gt;bg;     <span class=\"comment\">// bg2</span></div><div class=\"line\">    ++<span class=\"keyword\">this</span>-&gt;imgChangeCnt;      <span class=\"comment\">//   3</span></div><div class=\"line\">    bg = <span class=\"keyword\">new</span> Image(imgSrc);    <span class=\"comment\">//   4</span></div><div class=\"line\">    unlock(&amp;<span class=\"keyword\">this</span>-&gt;mutex);      <span class=\"comment\">//   5</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li>4</li>\n<li><code>bg</code></li>\n</ul>\n<p>13</p>\n<p></p>\n<ul>\n<li><code>bg</code></li>\n<li>copy-and-swapswap</li>\n</ul>\n<p>pImplswap</p>\n<ul>\n<li><code>int</code>nothrow</li>\n</ul>\n<h2 id=\"30-\"><a href=\"#30-\" class=\"headerlink\" title=\"30 \"></a>30 </h2><p><code>inline</code><code>inline</code></p>\n<p><code>inline</code><code>inline</code></p>\n<p><code>inline</code></p>\n<p><code>inline</code><code>inline</code></p>\n<p></p>\n<p>profile2880%20%</p>\n<h2 id=\"31-\"><a href=\"#31-\" class=\"headerlink\" title=\"31 \"></a>31 </h2><p>C++</p>\n<p>cpp</p>\n<p>C++C++JavaJavaC++</p>\n<p>JavahandlehandlepImpl</p>\n<p><code>Date</code><code>Person</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string&gt;</span>   <span class=\"comment\">// for string</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;memory&gt;</span>   <span class=\"comment\">// for shared_ptr</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> PersonImpl;   <span class=\"comment\">// Person</span></div><div class=\"line\"><span class=\"keyword\">class</span> Date;         <span class=\"comment\">// Person</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    Person(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday);</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">shared_ptr</span>&lt;PersonImpl&gt; pImpl;   <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/*********************************/</span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"Person.h\"</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"PersonImpl.h\"</span></span></div><div class=\"line\">Person::Person(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday):</div><div class=\"line\">    pImpl(<span class=\"keyword\">new</span> PersonImpl(name, birthday)) &#123;&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> Person::name() <span class=\"keyword\">const</span> &#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> pImpl-&gt;name();</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>handle<code>PersonImpl</code><code>Person</code><code>Date</code><code>date.hpp</code><code>Date</code><code>Person</code><code>Date</code><code>PersonImpl</code><code>Person</code><code>Person</code><code>Person</code><code>PersonImpl</code></p>\n<p></p>\n<ul>\n<li>object pointerobject referenceobjectpointerreferenceobject</li>\n<li> pass-by-value</li>\n<li><code>Person</code><code>PersonImpl</code></li>\n</ul>\n<p><code>Person</code>Caffe<code>Layer</code><code>Person</code>7</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~Person();</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>static</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">shared_ptr</span>&lt;Person&gt; create(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday);</div><div class=\"line\"><span class=\"comment\">// ... </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> RealPerson: <span class=\"keyword\">public</span> Person &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    RealPerson(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; birthday): name(name), birthDate(birthday) &#123;&#125;</div><div class=\"line\">    <span class=\"keyword\">virtual</span> ~RealPerson() &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"built_in\">string</span> <span class=\"title\">name</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;name; &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"built_in\">string</span> name;</div><div class=\"line\">    Date birthDate;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>create()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">shared_ptr</span>&lt;Person&gt; Person::create(<span class=\"keyword\">const</span> <span class=\"built_in\">string</span>&amp; name, <span class=\"keyword\">const</span> Date&amp; date) &#123;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"built_in\">shared_ptr</span>&lt;Person&gt;(<span class=\"keyword\">new</span> RealPerson(name, date));</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>"},{"title":"Effective CPP  - Chapter 8 newdelete","date":"2017-07-03T11:47:43.000Z","_content":"C++C++`operator new``operator delete`new_handler`operator new`\n\n`operator new``operator delete``operator new[]``operator delete[]``operator new``operator new[]`\n\nSTLallocator objects\n![memory_leak_everywhere](/img/effectivecpp_08_memory_leak_everywherre.jpg)\n<!-- more -->\n\n## 49 new-handler\nnew-handler`operator new`new-handler\n\nnew-handler`<new>``set_new_handler`\n``` cpp\nnamespace std {\n    typedef void (*new_handler) ();\n    new_handler set_new_handler(new_handler p) throw();\n}\n```\n\n`p``throw()`\n\n`operator new``set_new_handler()`51.\n\nnew_handler\n\n- `operator new`\n- new_handler`set_new_handler`\n- new_handler`NULL``set_new_handler()``operator new`\n- `bad_alloc`\n- exitabort\n\n`set_new_handler()``operator new`\n\n``` cpp\nclass A {\npublic:\n    static std::new_handler set_new_handler(std::new_handler p) throw();\n    static void* operator new(std::size_t size) throw(std::bad_alloc);\n\nprivate:\n    static std::new_handler current_handler;\n};\n\n// \nstd::new_handler A::set_new_handler(std::new_handler p) throw() {\n    std::new_hanlder old = current_handler;\n    current_handler = p;\n    return old;\n}\n```\n`const`\n``` cpp\n// \nstd::new_handler A::current_handler = 0;\n```\n\n`operator new``set_new_handler()`global`operator new`scope\n\n``` cpp\n// new_handler\nclass Helper {\npublic:\n    explicit Helper(std::new_handler p): handler(p) {}\n    ~Helper() {std::set_new_handler(handler); }\nprivate:\n    std::new_handler handler;\n    // \n    Helper(const Helper&);\n    Helper& operator= (const Helper&);\n};\n// Aoperator new\nvoid* A::operator new(std::size_t size) throw(std::bad_alloc) {\n    //  new_handler\n    Helper h(std::set_new_handler(current_handler));\n    return ::operator new(size);\n}\n```\n\nmixinnew_handler`current_handler`\n\n``` cpp\ntemplate <typename T>\nclass HandlerHelper {\npublic:\n    static std::new_handler set_new_handler(std::new_handler p) throw();\n    static void* operator new(std::size_t size) throw(std::bad_alloc);\n    ... // new52\nprivate:\n    static std::new_handler current_handler;\n};\n// HelperA\n```\n\n`A``HandlerHelper<A>`\n``` cpp\nclass A: public HandlerHelper<A> {\n    ...\n};\n```\n\n## 50 `new``delete`\n\n- `delete`\n- `operator new`\n- `operator new``delete`\n\n`new`Boost`Pool`\n\n## 51 `new``delete`\n`operator new`\n- 49\n- new_handlingnew_handling`NULL``bad_alloc`\n- C++0\n- `operator new`\n\n`operator new`\n``` cpp\nvoid* operator new(size_t size) throw(bad_alloc) {\n    // operator new\n    using namespace std;\n    if(size == 0) {\n        size = 1; // 0byte\n    }\n    while(true) {\n        // ... try to alloc memory\n        if(success) {\n            return the pointer;\n        }\n        // handler\n        // get_new_handler()new_handler\n        // set_new_handler\n        new_handler globalHandler = set_new_handler(0);\n        set_new_handler(globalHandler);\n\n        if(globalHandler) {\n            (*globalHandler)();\n        } else {\n            throw bad_alloc();\n        }\n    }\n}\n```\n\n`operator delete`C++delete NULL pointer\n``` cpp\nvoid operator delete(void* memory) throw() {\n    if(memory == 0) return;\n    // ...\n}\n```\n\n## 52 placement newplacement delete\n`operator new``size_t`placement newplacement new\n``` cpp\nvoid* operator new(size_t size, void* memory) throw();\n\n```\n\nplacement newC++`<new>``vector`placementnewplacement new\n\nplacement new\n`new`\n- `operator new`\n- \n\n`operator new`delete\n\n`operator new delete`placement newplacement newlogging\n``` cpp\n// Wedgetplacement new\nstatic void* operator new(size_t size, ostream& logStream) throw (bad_alloc);\n\nWidget* pw = new (std::cerr) Widget;\n```\nplacement deleteplacement deleteloggingplacement new\n``` cpp\nstatic void operator delete(void* memory, ostream& logStream) throw();\n// \nWidget* pw = new (std::cerr) Widget;\n```\n\n\n``` cpp\ndelete pw;\n```\ndeleteplacement deletedelete\n\nnewdelete\n``` cpp\nclass StdNewDeleteForms {\npublic:\n    // newdelete\n    static void* operator new(std::size_t size) throw std::bad_alloc) {\n        return ::operator new(size);\n    }\n\n    static void operator delete(void* memory) throw() {\n        ::operator delete(memory);\n    }\n    // placement new  delete\n    static void* operator new(std::size_t size, void* p) throw() {\n        ::operator new(size, p);\n    }\n    static void operator delete(void* memory, void* p) throw() {\n        ::operator delete(memory, p);\n    }\n    // nothrow new  delete\n    static void* operator new(std::size_t size, const std::nothrow_t& nt) throw() {\n        return ::operator new(size, nt);\n    }\n    static void operator delete(void* memory, const std::nothrow_t&) throw() {\n        ::operator delete(mempry);\n    }\n};\n```\n\nC++newdelete`using`39\n``` cpp\nclass Widget: public StdNewDeleteForms {\npublic:\n    // new  delete\n    using StdNewDeleteForms::operator new;\n    using StdNetDeleteForms::operator delete;\n    // placement new  delete\n    static void* operator new(std::size_t size,\n        std::ostream& logStream) throw(std::bad_alloc);\n    static void operator delete(void* memory, std::ostream& logStream) throw();\n};\n```\n","source":"_posts/effective-cpp-08.md","raw":"---\ntitle: Effective CPP  - Chapter 8 newdelete\ndate: 2017-07-03 19:47:43\ntags:\n    - cpp\n---\nC++C++`operator new``operator delete`new_handler`operator new`\n\n`operator new``operator delete``operator new[]``operator delete[]``operator new``operator new[]`\n\nSTLallocator objects\n![memory_leak_everywhere](/img/effectivecpp_08_memory_leak_everywherre.jpg)\n<!-- more -->\n\n## 49 new-handler\nnew-handler`operator new`new-handler\n\nnew-handler`<new>``set_new_handler`\n``` cpp\nnamespace std {\n    typedef void (*new_handler) ();\n    new_handler set_new_handler(new_handler p) throw();\n}\n```\n\n`p``throw()`\n\n`operator new``set_new_handler()`51.\n\nnew_handler\n\n- `operator new`\n- new_handler`set_new_handler`\n- new_handler`NULL``set_new_handler()``operator new`\n- `bad_alloc`\n- exitabort\n\n`set_new_handler()``operator new`\n\n``` cpp\nclass A {\npublic:\n    static std::new_handler set_new_handler(std::new_handler p) throw();\n    static void* operator new(std::size_t size) throw(std::bad_alloc);\n\nprivate:\n    static std::new_handler current_handler;\n};\n\n// \nstd::new_handler A::set_new_handler(std::new_handler p) throw() {\n    std::new_hanlder old = current_handler;\n    current_handler = p;\n    return old;\n}\n```\n`const`\n``` cpp\n// \nstd::new_handler A::current_handler = 0;\n```\n\n`operator new``set_new_handler()`global`operator new`scope\n\n``` cpp\n// new_handler\nclass Helper {\npublic:\n    explicit Helper(std::new_handler p): handler(p) {}\n    ~Helper() {std::set_new_handler(handler); }\nprivate:\n    std::new_handler handler;\n    // \n    Helper(const Helper&);\n    Helper& operator= (const Helper&);\n};\n// Aoperator new\nvoid* A::operator new(std::size_t size) throw(std::bad_alloc) {\n    //  new_handler\n    Helper h(std::set_new_handler(current_handler));\n    return ::operator new(size);\n}\n```\n\nmixinnew_handler`current_handler`\n\n``` cpp\ntemplate <typename T>\nclass HandlerHelper {\npublic:\n    static std::new_handler set_new_handler(std::new_handler p) throw();\n    static void* operator new(std::size_t size) throw(std::bad_alloc);\n    ... // new52\nprivate:\n    static std::new_handler current_handler;\n};\n// HelperA\n```\n\n`A``HandlerHelper<A>`\n``` cpp\nclass A: public HandlerHelper<A> {\n    ...\n};\n```\n\n## 50 `new``delete`\n\n- `delete`\n- `operator new`\n- `operator new``delete`\n\n`new`Boost`Pool`\n\n## 51 `new``delete`\n`operator new`\n- 49\n- new_handlingnew_handling`NULL``bad_alloc`\n- C++0\n- `operator new`\n\n`operator new`\n``` cpp\nvoid* operator new(size_t size) throw(bad_alloc) {\n    // operator new\n    using namespace std;\n    if(size == 0) {\n        size = 1; // 0byte\n    }\n    while(true) {\n        // ... try to alloc memory\n        if(success) {\n            return the pointer;\n        }\n        // handler\n        // get_new_handler()new_handler\n        // set_new_handler\n        new_handler globalHandler = set_new_handler(0);\n        set_new_handler(globalHandler);\n\n        if(globalHandler) {\n            (*globalHandler)();\n        } else {\n            throw bad_alloc();\n        }\n    }\n}\n```\n\n`operator delete`C++delete NULL pointer\n``` cpp\nvoid operator delete(void* memory) throw() {\n    if(memory == 0) return;\n    // ...\n}\n```\n\n## 52 placement newplacement delete\n`operator new``size_t`placement newplacement new\n``` cpp\nvoid* operator new(size_t size, void* memory) throw();\n\n```\n\nplacement newC++`<new>``vector`placementnewplacement new\n\nplacement new\n`new`\n- `operator new`\n- \n\n`operator new`delete\n\n`operator new delete`placement newplacement newlogging\n``` cpp\n// Wedgetplacement new\nstatic void* operator new(size_t size, ostream& logStream) throw (bad_alloc);\n\nWidget* pw = new (std::cerr) Widget;\n```\nplacement deleteplacement deleteloggingplacement new\n``` cpp\nstatic void operator delete(void* memory, ostream& logStream) throw();\n// \nWidget* pw = new (std::cerr) Widget;\n```\n\n\n``` cpp\ndelete pw;\n```\ndeleteplacement deletedelete\n\nnewdelete\n``` cpp\nclass StdNewDeleteForms {\npublic:\n    // newdelete\n    static void* operator new(std::size_t size) throw std::bad_alloc) {\n        return ::operator new(size);\n    }\n\n    static void operator delete(void* memory) throw() {\n        ::operator delete(memory);\n    }\n    // placement new  delete\n    static void* operator new(std::size_t size, void* p) throw() {\n        ::operator new(size, p);\n    }\n    static void operator delete(void* memory, void* p) throw() {\n        ::operator delete(memory, p);\n    }\n    // nothrow new  delete\n    static void* operator new(std::size_t size, const std::nothrow_t& nt) throw() {\n        return ::operator new(size, nt);\n    }\n    static void operator delete(void* memory, const std::nothrow_t&) throw() {\n        ::operator delete(mempry);\n    }\n};\n```\n\nC++newdelete`using`39\n``` cpp\nclass Widget: public StdNewDeleteForms {\npublic:\n    // new  delete\n    using StdNewDeleteForms::operator new;\n    using StdNetDeleteForms::operator delete;\n    // placement new  delete\n    static void* operator new(std::size_t size,\n        std::ostream& logStream) throw(std::bad_alloc);\n    static void operator delete(void* memory, std::ostream& logStream) throw();\n};\n```\n","slug":"effective-cpp-08","published":1,"updated":"2018-10-27T07:16:52.393Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8kh001qae7bwsgprn9f","content":"<p>C++C++<code>operator new</code><code>operator delete</code>new_handler<code>operator new</code></p>\n<p><code>operator new</code><code>operator delete</code><code>operator new[]</code><code>operator delete[]</code><code>operator new</code><code>operator new[]</code></p>\n<p>STLallocator objects<br><img src=\"/img/effectivecpp_08_memory_leak_everywherre.jpg\" alt=\"memory_leak_everywhere\"><br><a id=\"more\"></a></p>\n<h2 id=\"49-new-handler\"><a href=\"#49-new-handler\" class=\"headerlink\" title=\"49 new-handler\"></a>49 new-handler</h2><p>new-handler<code>operator new</code>new-handler</p>\n<p>new-handler<code>&lt;new&gt;</code><code>set_new_handler</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">typedef</span> <span class=\"title\">void</span> <span class=\"params\">(*new_handler)</span> <span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>p</code><code>throw()</code></p>\n<p><code>operator new</code><code>set_new_handler()</code>51.</p>\n<p>new_handler</p>\n<ul>\n<li><code>operator new</code></li>\n<li>new_handler<code>set_new_handler</code></li>\n<li>new_handler<code>NULL</code><code>set_new_handler()</code><code>operator new</code></li>\n<li><code>bad_alloc</code></li>\n<li>exitabort</li>\n</ul>\n<p><code>set_new_handler()</code><code>operator new</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::<span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(<span class=\"built_in\">std</span>::new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span></span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::new_handler current_handler;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"built_in\">std</span>::new_handler A::set_new_handler(<span class=\"built_in\">std</span>::new_handler p) <span class=\"keyword\">throw</span>() &#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::new_hanlder old = current_handler;</div><div class=\"line\">    current_handler = p;</div><div class=\"line\">    <span class=\"keyword\">return</span> old;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>const</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"built_in\">std</span>::new_handler A::current_handler = <span class=\"number\">0</span>;</div></pre></td></tr></table></figure></p>\n<p><code>operator new</code><code>set_new_handler()</code>global<code>operator new</code>scope</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">// new_handler</div><div class=\"line\">class Helper &#123;</div><div class=\"line\">public:</div><div class=\"line\">    explicit Helper(std::new_handler p): handler(p) &#123;&#125;</div><div class=\"line\">    ~Helper() &#123;std::set_new_handler(handler); &#125;</div><div class=\"line\">private:</div><div class=\"line\">    std::new_handler handler;</div><div class=\"line\">    // </div><div class=\"line\">    Helper(const Helper&amp;);</div><div class=\"line\">    Helper&amp; operator= (const Helper&amp;);</div><div class=\"line\">&#125;;</div><div class=\"line\">// Aoperator new</div><div class=\"line\">void* A::operator new(std::size_t size) throw(std::bad_alloc) &#123;</div><div class=\"line\">    //  new_handler</div><div class=\"line\">    Helper h(std::set_new_handler(current_handler));</div><div class=\"line\">    return ::operator new(size);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>mixinnew_handler<code>current_handler</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> HandlerHelper &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::<span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(<span class=\"built_in\">std</span>::new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span></span>;</div><div class=\"line\">    ... <span class=\"comment\">// new52</span></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::new_handler current_handler;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// HelperA</span></div></pre></td></tr></table></figure>\n<p><code>A</code><code>HandlerHelper&lt;A&gt;</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A: <span class=\"keyword\">public</span> HandlerHelper&lt;A&gt; &#123;</div><div class=\"line\">    ...</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<h2 id=\"50-newdelete\"><a href=\"#50-newdelete\" class=\"headerlink\" title=\"50 newdelete\"></a>50 <code>new</code><code>delete</code></h2><p></p>\n<ul>\n<li><code>delete</code></li>\n<li><code>operator new</code></li>\n<li><code>operator new</code><code>delete</code></li>\n</ul>\n<p><code>new</code>Boost<code>Pool</code></p>\n<h2 id=\"51-newdelete\"><a href=\"#51-newdelete\" class=\"headerlink\" title=\"51 newdelete\"></a>51 <code>new</code><code>delete</code></h2><p><code>operator new</code></p>\n<ul>\n<li>49</li>\n<li>new_handlingnew_handling<code>NULL</code><code>bad_alloc</code></li>\n<li>C++0</li>\n<li><code>operator new</code></li>\n</ul>\n<p><code>operator new</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(bad_alloc)</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// operator new</span></div><div class=\"line\">    <span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\">    <span class=\"keyword\">if</span>(size == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">        size = <span class=\"number\">1</span>; <span class=\"comment\">// 0byte</span></div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"literal\">true</span>) &#123;</div><div class=\"line\">        <span class=\"comment\">// ... try to alloc memory</span></div><div class=\"line\">        <span class=\"keyword\">if</span>(success) &#123;</div><div class=\"line\">            <span class=\"keyword\">return</span> the pointer;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"comment\">// handler</span></div><div class=\"line\">        <span class=\"comment\">// get_new_handler()new_handler</span></div><div class=\"line\">        <span class=\"comment\">// set_new_handler</span></div><div class=\"line\">        new_handler globalHandler = set_new_handler(<span class=\"number\">0</span>);</div><div class=\"line\">        set_new_handler(globalHandler);</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">if</span>(globalHandler) &#123;</div><div class=\"line\">            (*globalHandler)();</div><div class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">            <span class=\"keyword\">throw</span> bad_alloc();</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>operator delete</code>C++delete NULL pointer<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory)</span> <span class=\"title\">throw</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(memory == <span class=\"number\">0</span>) <span class=\"keyword\">return</span>;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"52-placement-newplacement-delete\"><a href=\"#52-placement-newplacement-delete\" class=\"headerlink\" title=\"52 placement newplacement delete\"></a>52 placement newplacement delete</h2><p><code>operator new</code><code>size_t</code>placement newplacement new<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size, <span class=\"keyword\">void</span>* memory)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div></pre></td></tr></table></figure></p>\n<p>placement newC++<code>&lt;new&gt;</code><code>vector</code>placementnewplacement new</p>\n<p>placement new<br><code>new</code></p>\n<ul>\n<li><code>operator new</code></li>\n<li></li>\n</ul>\n<p><code>operator new</code>delete</p>\n<p><code>operator new delete</code>placement newplacement newlogging<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Wedgetplacement new</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size, ostream&amp; logStream)</span> <span class=\"title\">throw</span> <span class=\"params\">(bad_alloc)</span></span>;</div><div class=\"line\"></div><div class=\"line\">Widget* pw = <span class=\"keyword\">new</span> (<span class=\"built_in\">std</span>::<span class=\"built_in\">cerr</span>) Widget;</div></pre></td></tr></table></figure></p>\n<p>placement deleteplacement deleteloggingplacement new<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory, ostream&amp; logStream)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">Widget* pw = <span class=\"keyword\">new</span> (<span class=\"built_in\">std</span>::<span class=\"built_in\">cerr</span>) Widget;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">delete</span> pw;</div></pre></td></tr></table></figure></p>\n<p>deleteplacement deletedelete</p>\n<p>newdelete<br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">class StdNewDeleteForms &#123;</div><div class=\"line\">public:</div><div class=\"line\">    // newdelete</div><div class=\"line\">    static void* operator new(std::size_t size) throw std::bad_alloc) &#123;</div><div class=\"line\">        return ::operator new(size);</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    static void operator delete(void* memory) throw() &#123;</div><div class=\"line\">        ::operator delete(memory);</div><div class=\"line\">    &#125;</div><div class=\"line\">    // placement new  delete</div><div class=\"line\">    static void* operator new(std::size_t size, void* p) throw() &#123;</div><div class=\"line\">        ::operator new(size, p);</div><div class=\"line\">    &#125;</div><div class=\"line\">    static void operator delete(void* memory, void* p) throw() &#123;</div><div class=\"line\">        ::operator delete(memory, p);</div><div class=\"line\">    &#125;</div><div class=\"line\">    // nothrow new  delete</div><div class=\"line\">    static void* operator new(std::size_t size, const std::nothrow_t&amp; nt) throw() &#123;</div><div class=\"line\">        return ::operator new(size, nt);</div><div class=\"line\">    &#125;</div><div class=\"line\">    static void operator delete(void* memory, const std::nothrow_t&amp;) throw() &#123;</div><div class=\"line\">        ::operator delete(mempry);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>C++newdelete<code>using</code>39<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Widget: <span class=\"keyword\">public</span> StdNewDeleteForms &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// new  delete</span></div><div class=\"line\">    <span class=\"keyword\">using</span> StdNewDeleteForms::<span class=\"keyword\">operator</span> <span class=\"keyword\">new</span>;</div><div class=\"line\">    <span class=\"keyword\">using</span> StdNetDeleteForms::<span class=\"keyword\">operator</span> <span class=\"keyword\">delete</span>;</div><div class=\"line\">    <span class=\"comment\">// placement new  delete</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size,</span></span></div><div class=\"line\">        <span class=\"built_in\">std</span>::ostream&amp; logStream) <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory, <span class=\"built_in\">std</span>::ostream&amp; logStream)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n","excerpt":"<p>C++C++<code>operator new</code><code>operator delete</code>new_handler<code>operator new</code></p>\n<p><code>operator new</code><code>operator delete</code><code>operator new[]</code><code>operator delete[]</code><code>operator new</code><code>operator new[]</code></p>\n<p>STLallocator objects<br><img src=\"/img/effectivecpp_08_memory_leak_everywherre.jpg\" alt=\"memory_leak_everywhere\"><br>","more":"</p>\n<h2 id=\"49-new-handler\"><a href=\"#49-new-handler\" class=\"headerlink\" title=\"49 new-handler\"></a>49 new-handler</h2><p>new-handler<code>operator new</code>new-handler</p>\n<p>new-handler<code>&lt;new&gt;</code><code>set_new_handler</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span> &#123;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">typedef</span> <span class=\"title\">void</span> <span class=\"params\">(*new_handler)</span> <span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>p</code><code>throw()</code></p>\n<p><code>operator new</code><code>set_new_handler()</code>51.</p>\n<p>new_handler</p>\n<ul>\n<li><code>operator new</code></li>\n<li>new_handler<code>set_new_handler</code></li>\n<li>new_handler<code>NULL</code><code>set_new_handler()</code><code>operator new</code></li>\n<li><code>bad_alloc</code></li>\n<li>exitabort</li>\n</ul>\n<p><code>set_new_handler()</code><code>operator new</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::<span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(<span class=\"built_in\">std</span>::new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span></span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::new_handler current_handler;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"built_in\">std</span>::new_handler A::set_new_handler(<span class=\"built_in\">std</span>::new_handler p) <span class=\"keyword\">throw</span>() &#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::new_hanlder old = current_handler;</div><div class=\"line\">    current_handler = p;</div><div class=\"line\">    <span class=\"keyword\">return</span> old;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>const</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"built_in\">std</span>::new_handler A::current_handler = <span class=\"number\">0</span>;</div></pre></td></tr></table></figure></p>\n<p><code>operator new</code><code>set_new_handler()</code>global<code>operator new</code>scope</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\">// new_handler</div><div class=\"line\">class Helper &#123;</div><div class=\"line\">public:</div><div class=\"line\">    explicit Helper(std::new_handler p): handler(p) &#123;&#125;</div><div class=\"line\">    ~Helper() &#123;std::set_new_handler(handler); &#125;</div><div class=\"line\">private:</div><div class=\"line\">    std::new_handler handler;</div><div class=\"line\">    // </div><div class=\"line\">    Helper(const Helper&amp;);</div><div class=\"line\">    Helper&amp; operator= (const Helper&amp;);</div><div class=\"line\">&#125;;</div><div class=\"line\">// Aoperator new</div><div class=\"line\">void* A::operator new(std::size_t size) throw(std::bad_alloc) &#123;</div><div class=\"line\">    //  new_handler</div><div class=\"line\">    Helper h(std::set_new_handler(current_handler));</div><div class=\"line\">    return ::operator new(size);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>mixinnew_handler<code>current_handler</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> T&gt;</div><div class=\"line\"><span class=\"keyword\">class</span> HandlerHelper &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::<span class=\"function\">new_handler <span class=\"title\">set_new_handler</span><span class=\"params\">(<span class=\"built_in\">std</span>::new_handler p)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span></span>;</div><div class=\"line\">    ... <span class=\"comment\">// new52</span></div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">static</span> <span class=\"built_in\">std</span>::new_handler current_handler;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// HelperA</span></div></pre></td></tr></table></figure>\n<p><code>A</code><code>HandlerHelper&lt;A&gt;</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> A: <span class=\"keyword\">public</span> HandlerHelper&lt;A&gt; &#123;</div><div class=\"line\">    ...</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<h2 id=\"50-newdelete\"><a href=\"#50-newdelete\" class=\"headerlink\" title=\"50 newdelete\"></a>50 <code>new</code><code>delete</code></h2><p></p>\n<ul>\n<li><code>delete</code></li>\n<li><code>operator new</code></li>\n<li><code>operator new</code><code>delete</code></li>\n</ul>\n<p><code>new</code>Boost<code>Pool</code></p>\n<h2 id=\"51-newdelete\"><a href=\"#51-newdelete\" class=\"headerlink\" title=\"51 newdelete\"></a>51 <code>new</code><code>delete</code></h2><p><code>operator new</code></p>\n<ul>\n<li>49</li>\n<li>new_handlingnew_handling<code>NULL</code><code>bad_alloc</code></li>\n<li>C++0</li>\n<li><code>operator new</code></li>\n</ul>\n<p><code>operator new</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size)</span> <span class=\"title\">throw</span><span class=\"params\">(bad_alloc)</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// operator new</span></div><div class=\"line\">    <span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</div><div class=\"line\">    <span class=\"keyword\">if</span>(size == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">        size = <span class=\"number\">1</span>; <span class=\"comment\">// 0byte</span></div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">while</span>(<span class=\"literal\">true</span>) &#123;</div><div class=\"line\">        <span class=\"comment\">// ... try to alloc memory</span></div><div class=\"line\">        <span class=\"keyword\">if</span>(success) &#123;</div><div class=\"line\">            <span class=\"keyword\">return</span> the pointer;</div><div class=\"line\">        &#125;</div><div class=\"line\">        <span class=\"comment\">// handler</span></div><div class=\"line\">        <span class=\"comment\">// get_new_handler()new_handler</span></div><div class=\"line\">        <span class=\"comment\">// set_new_handler</span></div><div class=\"line\">        new_handler globalHandler = set_new_handler(<span class=\"number\">0</span>);</div><div class=\"line\">        set_new_handler(globalHandler);</div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">if</span>(globalHandler) &#123;</div><div class=\"line\">            (*globalHandler)();</div><div class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">            <span class=\"keyword\">throw</span> bad_alloc();</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><code>operator delete</code>C++delete NULL pointer<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory)</span> <span class=\"title\">throw</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(memory == <span class=\"number\">0</span>) <span class=\"keyword\">return</span>;</div><div class=\"line\">    <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"52-placement-newplacement-delete\"><a href=\"#52-placement-newplacement-delete\" class=\"headerlink\" title=\"52 placement newplacement delete\"></a>52 placement newplacement delete</h2><p><code>operator new</code><code>size_t</code>placement newplacement new<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size, <span class=\"keyword\">void</span>* memory)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div></pre></td></tr></table></figure></p>\n<p>placement newC++<code>&lt;new&gt;</code><code>vector</code>placementnewplacement new</p>\n<p>placement new<br><code>new</code></p>\n<ul>\n<li><code>operator new</code></li>\n<li></li>\n</ul>\n<p><code>operator new</code>delete</p>\n<p><code>operator new delete</code>placement newplacement newlogging<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Wedgetplacement new</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"keyword\">size_t</span> size, ostream&amp; logStream)</span> <span class=\"title\">throw</span> <span class=\"params\">(bad_alloc)</span></span>;</div><div class=\"line\"></div><div class=\"line\">Widget* pw = <span class=\"keyword\">new</span> (<span class=\"built_in\">std</span>::<span class=\"built_in\">cerr</span>) Widget;</div></pre></td></tr></table></figure></p>\n<p>placement deleteplacement deleteloggingplacement new<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory, ostream&amp; logStream)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">Widget* pw = <span class=\"keyword\">new</span> (<span class=\"built_in\">std</span>::<span class=\"built_in\">cerr</span>) Widget;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">delete</span> pw;</div></pre></td></tr></table></figure></p>\n<p>deleteplacement deletedelete</p>\n<p>newdelete<br><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">class StdNewDeleteForms &#123;</div><div class=\"line\">public:</div><div class=\"line\">    // newdelete</div><div class=\"line\">    static void* operator new(std::size_t size) throw std::bad_alloc) &#123;</div><div class=\"line\">        return ::operator new(size);</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    static void operator delete(void* memory) throw() &#123;</div><div class=\"line\">        ::operator delete(memory);</div><div class=\"line\">    &#125;</div><div class=\"line\">    // placement new  delete</div><div class=\"line\">    static void* operator new(std::size_t size, void* p) throw() &#123;</div><div class=\"line\">        ::operator new(size, p);</div><div class=\"line\">    &#125;</div><div class=\"line\">    static void operator delete(void* memory, void* p) throw() &#123;</div><div class=\"line\">        ::operator delete(memory, p);</div><div class=\"line\">    &#125;</div><div class=\"line\">    // nothrow new  delete</div><div class=\"line\">    static void* operator new(std::size_t size, const std::nothrow_t&amp; nt) throw() &#123;</div><div class=\"line\">        return ::operator new(size, nt);</div><div class=\"line\">    &#125;</div><div class=\"line\">    static void operator delete(void* memory, const std::nothrow_t&amp;) throw() &#123;</div><div class=\"line\">        ::operator delete(mempry);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<p>C++newdelete<code>using</code>39<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Widget: <span class=\"keyword\">public</span> StdNewDeleteForms &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// new  delete</span></div><div class=\"line\">    <span class=\"keyword\">using</span> StdNewDeleteForms::<span class=\"keyword\">operator</span> <span class=\"keyword\">new</span>;</div><div class=\"line\">    <span class=\"keyword\">using</span> StdNetDeleteForms::<span class=\"keyword\">operator</span> <span class=\"keyword\">delete</span>;</div><div class=\"line\">    <span class=\"comment\">// placement new  delete</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span>* <span class=\"keyword\">operator</span> <span class=\"title\">new</span><span class=\"params\">(<span class=\"built_in\">std</span>::<span class=\"keyword\">size_t</span> size,</div><div class=\"line\">        <span class=\"built_in\">std</span>::ostream&amp; logStream)</span> <span class=\"title\">throw</span><span class=\"params\">(<span class=\"built_in\">std</span>::bad_alloc)</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"keyword\">operator</span> <span class=\"title\">delete</span><span class=\"params\">(<span class=\"keyword\">void</span>* memory, <span class=\"built_in\">std</span>::ostream&amp; logStream)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>"},{"title":"Effective CPP  - Chapter 6 ","date":"2017-06-17T02:40:19.000Z","_content":"C++public or privateOOPC++\n\n\n![](/img/effectivecpp_06_joke.jpg)\n<!-- more -->\n\n## 32 `public`Is-a\n`public`Is-aXXXbase classderived classderived classbase class\n\n`fly()`\n\n## 33 \nC++localderived classbase class\n\n`using`\n``` cpp\nclass Base {\npublic:\n    virtual void f1() = 0;\n    void f3();\n    void f3(double);\n};\n\nclass Derived: public Base {\npublic:\n    using Base::f3;\n    virtual void f1();\n    void f3();\n};\n\nDerived d;\nd.f1();  // Derivedf1\nd.f3();  // Derivedf3\ndouble x;\nd.f3(x);  // Basef3\n// usingBase::f3\n```\n\n## 34 \n`public`\n\n``` cpp\nclass Shape {\npublic:\n    virtual void draw() const = 0;\n    virtual void error(const std::string& msg);\n    int getID() const;\n};\nclass Rect: public Shape {...};\nclass Circle: public Shape {...};\n```\n\n- \n`draw()`derived class\n\n\n- \n`error()`derived classXX\nderived classbase class\n\n``` cpp\nclass Base {\npublic:\n    virtual void fun() = 0;   // \nprotected:\n    void default_fun() {...};   // \n};\n// \nclass Derived: public Base {\npublic:\n    virtual void fun() {\n        default_fun();\n    }\n};\n```\n`default_fun()`\n\n``` cpp\nclass Base {\npublic:\n    virtual void fun() = 0;\n};\n// \nvoid Base::fun() {\n    // \n}\n\nclass Derived: public Base {\npublic:\n    // \n    virtual void fun() {Base::fun(); }\n};\nclass Derived2: public Base {\npublic:\n    // \n    virtual void fun() {\n        // ...\n    }\n};\n```\n\n- \nderived class\n\n## 35 `virtual`\n\n\n\n``` cpp\nclass GameCharacter {\npublic:\n    virtual int healthValue() const;\n};\n```\n\n- non-virtual interfacetemplate method\n`virtual``healthValue()`\n\n``` cpp\nclass GameCharacter {\npublic:\n    int healthValue() const {\n        // ... \n        int ret_val = doHealthValue();\n        // ... \n        return ret_val\n    }\nprivate:\n    virtual int doHealthValue() const {...}\n};\n```\n`doHealthValue()`\n\n- \n\n\n``` cpp\nclass GameCharacter;   // \n// \nint defaultHealthValue(const GameCharacter&);\n\nclass GameCharacter {\npublic:\n    typedef int (*HealthCalcFun) (const GameCharacter&);\n\n    explicit GameCharacter(HealthCalcFun f=defaultHealthValue\n        :healthFunc(f){\n        // ...\n    }\nprivate:\n    HealthCalcFun healthFunc;\n};\n```\n\nboss\n`healthFunc`\n\n- `std::function`\n`std::function`C++11`std::function`[](http://en.cppreference.com/w/cpp/utility/functional/function)\n\n`typedef``std::function`\n\n``` cpp\ntypedef std::function<int(const GameCharacter&)> HealthCalcFun;\n```\n\n- \n`GameCharacter``HealthCalcFun`\n\n![UML](/img/effectivecpp_strategy_pattern.png)\n\n``` cpp\n//HealthCalcFunc\nclass GameCharacter;    // \nclass HealthCalcFunc {\npublic:\n    virtual int calc(const GameCharacter& gc) const {...}\n};\n\nHealthCalcFunc defaultCalcFunc;\n\nclass GameCharacter {\nprivate:\n    HealthCalcFunc* pfun;\npublic:\n    explicit GameCharacter(HealthCalcFunc* p=&defaultCalcFunc):\n        pfun(p) {}\n    int healthValue() const {\n        return pfun->calc(*this);\n    }\n};\n```\n\n\n\n## 36 \n34\n\n\n``` cpp\nclass B {\npublic:\n    void mf() {...}\n};\nclass D: public B {\npublic:\n    void mf() {...}\n};\n\nD d;\nB* pb = &d;\nD* pd = &d;\n\npb->mf();   // B::mf()\npd->mf();   // D::mf()\n```\n\n`pb``B``B``mf()`\n\n\n\n## 37 \n36\n\n\n``` cpp\n// CircleShape\nShape* ps;\nShape* pc = new Circle;   // Shape\n```\n\n`pc``Circle*``ps`\n``` cpp\nps = new Circle;   // psCircle*\n```\n\n\n\n\n\n``` cpp\nclass Shape {\npublic:\n    enum ShapeColor {RED, GREEN};\n    virtual void draw(ShapeColor c=RED) const=0;\n};\n\nclass Circle: public Shape {\npublic:\n    virtual void draw(ShapeColor c=RED) const;\n};\n```\n\n`GREEN`\n\n35NVIpublicpublic\n\n``` cpp\nclass Shape {\npublic:\n    void draw(ShapeColor c=RED) const {\n        doDraw(c);  // \n    }\nprivate:\n    //\n    virtual void doDraw(ShapeColor c) const = 0;  \n};\n\nclass Circle: public Shape {\nprivate:\n    virtual void doDraw(ShapeColor c) const;  // \n};\n```\n\n## 38 has-a\nhas-ais-implemented-in-terms-of\n\n## 39 `private`\n38`D``B``D``B``B``D``B``D`\n\n~`D``B`\n\n## 40 \n`C``A``B``mf()``d.mf()`,`d.A::mf()`\n\n`File`\n![](/img/effectivecpp_diamond.png)\n\n``` cpp\nclass File {...};\nclass InputFile: virtual public File {...};\nclass OutputFile: virtual public File {...};\nclass IOFile: public InputFile, public OutputFile {...};\n```\n\npublicvirtual\n\nJavaC#Interface\n\n##  `std::function`\n`std::function`lambda`std::function`\n\n\n``` cpp\n#include <functional>\n#include <iostream>\n\nstruct Foo {\n    Foo(int num) : num_(num) {}\n    void print_add(int i) const { std::cout << num_+i << '\\n'; }\n    int num_;\n};\n\nvoid print_num(int i)\n{\n    std::cout << i << '\\n';\n}\n\nstruct PrintNum {\n    void operator()(int i) const\n    {\n        std::cout << i << '\\n';\n    }\n};\n\nint main()\n{\n    // store a free function\n    // \n    std::function<void(int)> f_display = print_num;\n    f_display(-9);\n\n    // lambda\n    // store a lambda\n    std::function<void()> f_display_42 = []() { print_num(42); };\n    f_display_42();\n\n    // store the result of a call to std::bind\n    // \n    std::function<void()> f_display_31337 = std::bind(print_num, 31337);\n    f_display_31337();\n\n    // store a call to a member function\n    // const reference\n    std::function<void(const Foo&, int)> f_add_display = &Foo::print_add;\n    const Foo foo(314159);\n    f_add_display(foo, 1);\n    f_add_display(314159, 1);\n\n    // store a call to a data member accessor\n    std::function<int(Foo const&)> f_num = &Foo::num_;\n    std::cout << \"num_: \" << f_num(foo) << '\\n';\n\n    // store a call to a member function and object\n    using std::placeholders::_1;\n    std::function<void(int)> f_add_display2 = std::bind( &Foo::print_add, foo, _1 );\n    f_add_display2(2);\n\n    // store a call to a member function and object ptr\n    std::function<void(int)> f_add_display3 = std::bind( &Foo::print_add, &foo, _1 );\n    f_add_display3(3);\n\n    // store a call to a function object\n    std::function<void(int)> f_display_obj = PrintNum();\n    f_display_obj(18);\n}\n```\n","source":"_posts/effective-cpp-06.md","raw":"---\ntitle: Effective CPP  - Chapter 6 \ndate: 2017-06-17 10:40:19\ntags:\n    - cpp\n---\nC++public or privateOOPC++\n\n\n![](/img/effectivecpp_06_joke.jpg)\n<!-- more -->\n\n## 32 `public`Is-a\n`public`Is-aXXXbase classderived classderived classbase class\n\n`fly()`\n\n## 33 \nC++localderived classbase class\n\n`using`\n``` cpp\nclass Base {\npublic:\n    virtual void f1() = 0;\n    void f3();\n    void f3(double);\n};\n\nclass Derived: public Base {\npublic:\n    using Base::f3;\n    virtual void f1();\n    void f3();\n};\n\nDerived d;\nd.f1();  // Derivedf1\nd.f3();  // Derivedf3\ndouble x;\nd.f3(x);  // Basef3\n// usingBase::f3\n```\n\n## 34 \n`public`\n\n``` cpp\nclass Shape {\npublic:\n    virtual void draw() const = 0;\n    virtual void error(const std::string& msg);\n    int getID() const;\n};\nclass Rect: public Shape {...};\nclass Circle: public Shape {...};\n```\n\n- \n`draw()`derived class\n\n\n- \n`error()`derived classXX\nderived classbase class\n\n``` cpp\nclass Base {\npublic:\n    virtual void fun() = 0;   // \nprotected:\n    void default_fun() {...};   // \n};\n// \nclass Derived: public Base {\npublic:\n    virtual void fun() {\n        default_fun();\n    }\n};\n```\n`default_fun()`\n\n``` cpp\nclass Base {\npublic:\n    virtual void fun() = 0;\n};\n// \nvoid Base::fun() {\n    // \n}\n\nclass Derived: public Base {\npublic:\n    // \n    virtual void fun() {Base::fun(); }\n};\nclass Derived2: public Base {\npublic:\n    // \n    virtual void fun() {\n        // ...\n    }\n};\n```\n\n- \nderived class\n\n## 35 `virtual`\n\n\n\n``` cpp\nclass GameCharacter {\npublic:\n    virtual int healthValue() const;\n};\n```\n\n- non-virtual interfacetemplate method\n`virtual``healthValue()`\n\n``` cpp\nclass GameCharacter {\npublic:\n    int healthValue() const {\n        // ... \n        int ret_val = doHealthValue();\n        // ... \n        return ret_val\n    }\nprivate:\n    virtual int doHealthValue() const {...}\n};\n```\n`doHealthValue()`\n\n- \n\n\n``` cpp\nclass GameCharacter;   // \n// \nint defaultHealthValue(const GameCharacter&);\n\nclass GameCharacter {\npublic:\n    typedef int (*HealthCalcFun) (const GameCharacter&);\n\n    explicit GameCharacter(HealthCalcFun f=defaultHealthValue\n        :healthFunc(f){\n        // ...\n    }\nprivate:\n    HealthCalcFun healthFunc;\n};\n```\n\nboss\n`healthFunc`\n\n- `std::function`\n`std::function`C++11`std::function`[](http://en.cppreference.com/w/cpp/utility/functional/function)\n\n`typedef``std::function`\n\n``` cpp\ntypedef std::function<int(const GameCharacter&)> HealthCalcFun;\n```\n\n- \n`GameCharacter``HealthCalcFun`\n\n![UML](/img/effectivecpp_strategy_pattern.png)\n\n``` cpp\n//HealthCalcFunc\nclass GameCharacter;    // \nclass HealthCalcFunc {\npublic:\n    virtual int calc(const GameCharacter& gc) const {...}\n};\n\nHealthCalcFunc defaultCalcFunc;\n\nclass GameCharacter {\nprivate:\n    HealthCalcFunc* pfun;\npublic:\n    explicit GameCharacter(HealthCalcFunc* p=&defaultCalcFunc):\n        pfun(p) {}\n    int healthValue() const {\n        return pfun->calc(*this);\n    }\n};\n```\n\n\n\n## 36 \n34\n\n\n``` cpp\nclass B {\npublic:\n    void mf() {...}\n};\nclass D: public B {\npublic:\n    void mf() {...}\n};\n\nD d;\nB* pb = &d;\nD* pd = &d;\n\npb->mf();   // B::mf()\npd->mf();   // D::mf()\n```\n\n`pb``B``B``mf()`\n\n\n\n## 37 \n36\n\n\n``` cpp\n// CircleShape\nShape* ps;\nShape* pc = new Circle;   // Shape\n```\n\n`pc``Circle*``ps`\n``` cpp\nps = new Circle;   // psCircle*\n```\n\n\n\n\n\n``` cpp\nclass Shape {\npublic:\n    enum ShapeColor {RED, GREEN};\n    virtual void draw(ShapeColor c=RED) const=0;\n};\n\nclass Circle: public Shape {\npublic:\n    virtual void draw(ShapeColor c=RED) const;\n};\n```\n\n`GREEN`\n\n35NVIpublicpublic\n\n``` cpp\nclass Shape {\npublic:\n    void draw(ShapeColor c=RED) const {\n        doDraw(c);  // \n    }\nprivate:\n    //\n    virtual void doDraw(ShapeColor c) const = 0;  \n};\n\nclass Circle: public Shape {\nprivate:\n    virtual void doDraw(ShapeColor c) const;  // \n};\n```\n\n## 38 has-a\nhas-ais-implemented-in-terms-of\n\n## 39 `private`\n38`D``B``D``B``B``D``B``D`\n\n~`D``B`\n\n## 40 \n`C``A``B``mf()``d.mf()`,`d.A::mf()`\n\n`File`\n![](/img/effectivecpp_diamond.png)\n\n``` cpp\nclass File {...};\nclass InputFile: virtual public File {...};\nclass OutputFile: virtual public File {...};\nclass IOFile: public InputFile, public OutputFile {...};\n```\n\npublicvirtual\n\nJavaC#Interface\n\n##  `std::function`\n`std::function`lambda`std::function`\n\n\n``` cpp\n#include <functional>\n#include <iostream>\n\nstruct Foo {\n    Foo(int num) : num_(num) {}\n    void print_add(int i) const { std::cout << num_+i << '\\n'; }\n    int num_;\n};\n\nvoid print_num(int i)\n{\n    std::cout << i << '\\n';\n}\n\nstruct PrintNum {\n    void operator()(int i) const\n    {\n        std::cout << i << '\\n';\n    }\n};\n\nint main()\n{\n    // store a free function\n    // \n    std::function<void(int)> f_display = print_num;\n    f_display(-9);\n\n    // lambda\n    // store a lambda\n    std::function<void()> f_display_42 = []() { print_num(42); };\n    f_display_42();\n\n    // store the result of a call to std::bind\n    // \n    std::function<void()> f_display_31337 = std::bind(print_num, 31337);\n    f_display_31337();\n\n    // store a call to a member function\n    // const reference\n    std::function<void(const Foo&, int)> f_add_display = &Foo::print_add;\n    const Foo foo(314159);\n    f_add_display(foo, 1);\n    f_add_display(314159, 1);\n\n    // store a call to a data member accessor\n    std::function<int(Foo const&)> f_num = &Foo::num_;\n    std::cout << \"num_: \" << f_num(foo) << '\\n';\n\n    // store a call to a member function and object\n    using std::placeholders::_1;\n    std::function<void(int)> f_add_display2 = std::bind( &Foo::print_add, foo, _1 );\n    f_add_display2(2);\n\n    // store a call to a member function and object ptr\n    std::function<void(int)> f_add_display3 = std::bind( &Foo::print_add, &foo, _1 );\n    f_add_display3(3);\n\n    // store a call to a function object\n    std::function<void(int)> f_display_obj = PrintNum();\n    f_display_obj(18);\n}\n```\n","slug":"effective-cpp-06","published":1,"updated":"2018-10-27T07:16:52.392Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8km001sae7b6m37llp2","content":"<p>C++public or privateOOPC++</p>\n<p><br><img src=\"/img/effectivecpp_06_joke.jpg\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"32-publicIs-a\"><a href=\"#32-publicIs-a\" class=\"headerlink\" title=\"32 publicIs-a\"></a>32 <code>public</code>Is-a</h2><p><code>public</code>Is-aXXXbase classderived classderived classbase class</p>\n<p><code>fly()</code></p>\n<h2 id=\"33-\"><a href=\"#33-\" class=\"headerlink\" title=\"33 \"></a>33 </h2><p>C++localderived classbase class</p>\n<p><code>using</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">f1</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">(<span class=\"keyword\">double</span>)</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">using</span> Base::f3;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">f1</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">Derived d;</div><div class=\"line\">d.f1();  <span class=\"comment\">// Derivedf1</span></div><div class=\"line\">d.f3();  <span class=\"comment\">// Derivedf3</span></div><div class=\"line\"><span class=\"keyword\">double</span> x;</div><div class=\"line\">d.f3(x);  <span class=\"comment\">// Basef3</span></div><div class=\"line\"><span class=\"comment\">// usingBase::f3</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"34-\"><a href=\"#34-\" class=\"headerlink\" title=\"34 \"></a>34 </h2><p><code>public</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">error</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; msg)</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getID</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Rect: <span class=\"keyword\">public</span> Shape &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;...&#125;;</div></pre></td></tr></table></figure>\n<ul>\n<li><p><br><code>draw()</code>derived class<br></p>\n</li>\n<li><p><br><code>error()</code>derived classXX<br>derived classbase class</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">protected</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">default_fun</span><span class=\"params\">()</span> </span>&#123;...&#125;;   <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        default_fun();</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>default_fun()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">void</span> Base::fun() &#123;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;Base::fun(); &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Derived2: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<ul>\n<li><br>derived class</li>\n</ul>\n<h2 id=\"35-virtual\"><a href=\"#35-virtual\" class=\"headerlink\" title=\"35 virtual\"></a>35 <code>virtual</code></h2><p></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">int</span> <span class=\"title\">healthValue</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<ul>\n<li>non-virtual interfacetemplate method<br><code>virtual</code><code>healthValue()</code></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">healthValue</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ... </span></div><div class=\"line\">        <span class=\"keyword\">int</span> ret_val = doHealthValue();</div><div class=\"line\">        <span class=\"comment\">// ... </span></div><div class=\"line\">        <span class=\"keyword\">return</span> ret_val</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> <span class=\"keyword\">int</span> doHealthValue() <span class=\"keyword\">const</span> &#123;...&#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>doHealthValue()</code></p>\n<ul>\n<li><br></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">defaultHealthValue</span><span class=\"params\">(<span class=\"keyword\">const</span> GameCharacter&amp;)</span></span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">typedef</span> <span class=\"title\">int</span> <span class=\"params\">(*HealthCalcFun)</span> <span class=\"params\">(<span class=\"keyword\">const</span> GameCharacter&amp;)</span></span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">GameCharacter</span><span class=\"params\">(HealthCalcFun f=defaultHealthValue</span></span></div><div class=\"line\">        :healthFunc(f)&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    HealthCalcFun healthFunc;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>boss<br><code>healthFunc</code></p>\n<ul>\n<li><code>std::function</code><br><code>std::function</code>C++11<code>std::function</code><a href=\"http://en.cppreference.com/w/cpp/utility/functional/function\" target=\"_blank\" rel=\"external\"></a></li>\n</ul>\n<p><code>typedef</code><code>std::function</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">int</span>(<span class=\"keyword\">const</span> GameCharacter&amp;)&gt; HealthCalcFun;</div></pre></td></tr></table></figure>\n<ul>\n<li><br><code>GameCharacter</code><code>HealthCalcFun</code></li>\n</ul>\n<p><img src=\"/img/effectivecpp_strategy_pattern.png\" alt=\"UML\"></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">//HealthCalcFunc</div><div class=\"line\">class GameCharacter;    // </div><div class=\"line\">class HealthCalcFunc &#123;</div><div class=\"line\">public:</div><div class=\"line\">    virtual int calc(const GameCharacter&amp; gc) const &#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">HealthCalcFunc defaultCalcFunc;</div><div class=\"line\"></div><div class=\"line\">class GameCharacter &#123;</div><div class=\"line\">private:</div><div class=\"line\">    HealthCalcFunc* pfun;</div><div class=\"line\">public:</div><div class=\"line\">    explicit GameCharacter(HealthCalcFunc* p=&amp;defaultCalcFunc):</div><div class=\"line\">        pfun(p) &#123;&#125;</div><div class=\"line\">    int healthValue() const &#123;</div><div class=\"line\">        return pfun-&gt;calc(*this);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"36-\"><a href=\"#36-\" class=\"headerlink\" title=\"36 \"></a>36 </h2><p>34</p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> B &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mf</span><span class=\"params\">()</span> </span>&#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> D: <span class=\"keyword\">public</span> B &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mf</span><span class=\"params\">()</span> </span>&#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">D d;</div><div class=\"line\">B* pb = &amp;d;</div><div class=\"line\">D* pd = &amp;d;</div><div class=\"line\"></div><div class=\"line\">pb-&gt;mf();   <span class=\"comment\">// B::mf()</span></div><div class=\"line\">pd-&gt;mf();   <span class=\"comment\">// D::mf()</span></div></pre></td></tr></table></figure></p>\n<p><code>pb</code><code>B</code><code>B</code><code>mf()</code></p>\n<p></p>\n<h2 id=\"37-\"><a href=\"#37-\" class=\"headerlink\" title=\"37 \"></a>37 </h2><p>36</p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// CircleShape</span></div><div class=\"line\">Shape* ps;</div><div class=\"line\">Shape* pc = <span class=\"keyword\">new</span> Circle;   <span class=\"comment\">// Shape</span></div></pre></td></tr></table></figure></p>\n<p><code>pc</code><code>Circle*</code><code>ps</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ps = <span class=\"keyword\">new</span> Circle;   <span class=\"comment\">// psCircle*</span></div></pre></td></tr></table></figure></p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">enum</span> ShapeColor &#123;RED, GREEN&#125;;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span></span>=<span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>GREEN</code></p>\n<p>35NVIpublicpublic</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span> </span>&#123;</div><div class=\"line\">        doDraw(c);  <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"comment\">//</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">doDraw</span><span class=\"params\">(ShapeColor c)</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;  </div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">doDraw</span><span class=\"params\">(ShapeColor c)</span> <span class=\"keyword\">const</span></span>;  <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"38-has-a\"><a href=\"#38-has-a\" class=\"headerlink\" title=\"38 has-a\"></a>38 has-a</h2><p>has-ais-implemented-in-terms-of</p>\n<h2 id=\"39-private\"><a href=\"#39-private\" class=\"headerlink\" title=\"39 private\"></a>39 <code>private</code></h2><p>38<code>D</code><code>B</code><code>D</code><code>B</code><code>B</code><code>D</code><code>B</code><code>D</code></p>\n<p>~<code>D</code><code>B</code></p>\n<h2 id=\"40-\"><a href=\"#40-\" class=\"headerlink\" title=\"40 \"></a>40 </h2><p><code>C</code><code>A</code><code>B</code><code>mf()</code><code>d.mf()</code>,<code>d.A::mf()</code></p>\n<p><code>File</code><br><img src=\"/img/effectivecpp_diamond.png\" alt=\"\"></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> InputFile: <span class=\"keyword\">virtual</span> <span class=\"keyword\">public</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> OutputFile: <span class=\"keyword\">virtual</span> <span class=\"keyword\">public</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> IOFile: <span class=\"keyword\">public</span> InputFile, <span class=\"keyword\">public</span> OutputFile &#123;...&#125;;</div></pre></td></tr></table></figure>\n<p>publicvirtual</p>\n<p>JavaC#Interface</p>\n<h2 id=\"-std-function\"><a href=\"#-std-function\" class=\"headerlink\" title=\" std::function\"></a> <code>std::function</code></h2><p><code>std::function</code>lambda<code>std::function</code><br></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;functional&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> Foo &#123;</div><div class=\"line\">    Foo(<span class=\"keyword\">int</span> num) : num_(num) &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_add</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; num_+i &lt;&lt; <span class=\"string\">'\\n'</span>; &#125;</div><div class=\"line\">    <span class=\"keyword\">int</span> num_;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_num</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; i &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> PrintNum &#123;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">operator</span><span class=\"params\">()</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> <span class=\"keyword\">const</span></span></div><div class=\"line\">    &#123;</div><div class=\"line\">        <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; i &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"comment\">// store a free function</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_display = print_num;</div><div class=\"line\">    f_display(<span class=\"number\">-9</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// lambda</span></div><div class=\"line\">    <span class=\"comment\">// store a lambda</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>()&gt; f_display_42 = []() &#123; print_num(<span class=\"number\">42</span>); &#125;;</div><div class=\"line\">    f_display_42();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store the result of a call to std::bind</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>()&gt; f_display_31337 = <span class=\"built_in\">std</span>::bind(print_num, <span class=\"number\">31337</span>);</div><div class=\"line\">    f_display_31337();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function</span></div><div class=\"line\">    <span class=\"comment\">// const reference</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">const</span> Foo&amp;, <span class=\"keyword\">int</span>)&gt; f_add_display = &amp;Foo::print_add;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">const</span> Foo <span class=\"title\">foo</span><span class=\"params\">(<span class=\"number\">314159</span>)</span></span>;</div><div class=\"line\">    f_add_display(foo, <span class=\"number\">1</span>);</div><div class=\"line\">    f_add_display(<span class=\"number\">314159</span>, <span class=\"number\">1</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a data member accessor</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">int</span>(Foo <span class=\"keyword\">const</span>&amp;)&gt; f_num = &amp;Foo::num_;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"num_: \"</span> &lt;&lt; f_num(foo) &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function and object</span></div><div class=\"line\">    <span class=\"keyword\">using</span> <span class=\"built_in\">std</span>::placeholders::_1;</div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_add_display2 = <span class=\"built_in\">std</span>::bind( &amp;Foo::print_add, foo, _1 );</div><div class=\"line\">    f_add_display2(<span class=\"number\">2</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function and object ptr</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_add_display3 = <span class=\"built_in\">std</span>::bind( &amp;Foo::print_add, &amp;foo, _1 );</div><div class=\"line\">    f_add_display3(<span class=\"number\">3</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a function object</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_display_obj = PrintNum();</div><div class=\"line\">    f_display_obj(<span class=\"number\">18</span>);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"<p>C++public or privateOOPC++</p>\n<p><br><img src=\"/img/effectivecpp_06_joke.jpg\" alt=\"\"><br>","more":"</p>\n<h2 id=\"32-publicIs-a\"><a href=\"#32-publicIs-a\" class=\"headerlink\" title=\"32 publicIs-a\"></a>32 <code>public</code>Is-a</h2><p><code>public</code>Is-aXXXbase classderived classderived classbase class</p>\n<p><code>fly()</code></p>\n<h2 id=\"33-\"><a href=\"#33-\" class=\"headerlink\" title=\"33 \"></a>33 </h2><p>C++localderived classbase class</p>\n<p><code>using</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">f1</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">(<span class=\"keyword\">double</span>)</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">using</span> Base::f3;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">f1</span><span class=\"params\">()</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">f3</span><span class=\"params\">()</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">Derived d;</div><div class=\"line\">d.f1();  <span class=\"comment\">// Derivedf1</span></div><div class=\"line\">d.f3();  <span class=\"comment\">// Derivedf3</span></div><div class=\"line\"><span class=\"keyword\">double</span> x;</div><div class=\"line\">d.f3(x);  <span class=\"comment\">// Basef3</span></div><div class=\"line\"><span class=\"comment\">// usingBase::f3</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"34-\"><a href=\"#34-\" class=\"headerlink\" title=\"34 \"></a>34 </h2><p><code>public</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">error</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"built_in\">std</span>::<span class=\"built_in\">string</span>&amp; msg)</span></span>;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">getID</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Rect: <span class=\"keyword\">public</span> Shape &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;...&#125;;</div></pre></td></tr></table></figure>\n<ul>\n<li><p><br><code>draw()</code>derived class<br></p>\n</li>\n<li><p><br><code>error()</code>derived classXX<br>derived classbase class</p>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">protected</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">default_fun</span><span class=\"params\">()</span> </span>&#123;...&#125;;   <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        default_fun();</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>default_fun()</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>= <span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">void</span> Base::fun() &#123;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Derived: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;Base::fun(); &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> Derived2: <span class=\"keyword\">public</span> Base &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">fun</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<ul>\n<li><br>derived class</li>\n</ul>\n<h2 id=\"35-virtual\"><a href=\"#35-virtual\" class=\"headerlink\" title=\"35 virtual\"></a>35 <code>virtual</code></h2><p></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">int</span> <span class=\"title\">healthValue</span><span class=\"params\">()</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure></p>\n<ul>\n<li>non-virtual interfacetemplate method<br><code>virtual</code><code>healthValue()</code></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">healthValue</span><span class=\"params\">()</span> <span class=\"keyword\">const</span> </span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ... </span></div><div class=\"line\">        <span class=\"keyword\">int</span> ret_val = doHealthValue();</div><div class=\"line\">        <span class=\"comment\">// ... </span></div><div class=\"line\">        <span class=\"keyword\">return</span> ret_val</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"keyword\">virtual</span> <span class=\"keyword\">int</span> doHealthValue() <span class=\"keyword\">const</span> &#123;...&#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>doHealthValue()</code></p>\n<ul>\n<li><br></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter;   <span class=\"comment\">// </span></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">defaultHealthValue</span><span class=\"params\">(<span class=\"keyword\">const</span> GameCharacter&amp;)</span></span>;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> GameCharacter &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">typedef</span> <span class=\"title\">int</span> <span class=\"params\">(*HealthCalcFun)</span> <span class=\"params\">(<span class=\"keyword\">const</span> GameCharacter&amp;)</span></span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">explicit</span> <span class=\"title\">GameCharacter</span><span class=\"params\">(HealthCalcFun f=defaultHealthValue</div><div class=\"line\">        :healthFunc(f)</span></span>&#123;</div><div class=\"line\">        <span class=\"comment\">// ...</span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    HealthCalcFun healthFunc;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>boss<br><code>healthFunc</code></p>\n<ul>\n<li><code>std::function</code><br><code>std::function</code>C++11<code>std::function</code><a href=\"http://en.cppreference.com/w/cpp/utility/functional/function\"></a></li>\n</ul>\n<p><code>typedef</code><code>std::function</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">int</span>(<span class=\"keyword\">const</span> GameCharacter&amp;)&gt; HealthCalcFun;</div></pre></td></tr></table></figure>\n<ul>\n<li><br><code>GameCharacter</code><code>HealthCalcFun</code></li>\n</ul>\n<p><img src=\"/img/effectivecpp_strategy_pattern.png\" alt=\"UML\"></p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">//HealthCalcFunc</div><div class=\"line\">class GameCharacter;    // </div><div class=\"line\">class HealthCalcFunc &#123;</div><div class=\"line\">public:</div><div class=\"line\">    virtual int calc(const GameCharacter&amp; gc) const &#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">HealthCalcFunc defaultCalcFunc;</div><div class=\"line\"></div><div class=\"line\">class GameCharacter &#123;</div><div class=\"line\">private:</div><div class=\"line\">    HealthCalcFunc* pfun;</div><div class=\"line\">public:</div><div class=\"line\">    explicit GameCharacter(HealthCalcFunc* p=&amp;defaultCalcFunc):</div><div class=\"line\">        pfun(p) &#123;&#125;</div><div class=\"line\">    int healthValue() const &#123;</div><div class=\"line\">        return pfun-&gt;calc(*this);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"36-\"><a href=\"#36-\" class=\"headerlink\" title=\"36 \"></a>36 </h2><p>34</p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> B &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mf</span><span class=\"params\">()</span> </span>&#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> D: <span class=\"keyword\">public</span> B &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">mf</span><span class=\"params\">()</span> </span>&#123;...&#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\">D d;</div><div class=\"line\">B* pb = &amp;d;</div><div class=\"line\">D* pd = &amp;d;</div><div class=\"line\"></div><div class=\"line\">pb-&gt;mf();   <span class=\"comment\">// B::mf()</span></div><div class=\"line\">pd-&gt;mf();   <span class=\"comment\">// D::mf()</span></div></pre></td></tr></table></figure></p>\n<p><code>pb</code><code>B</code><code>B</code><code>mf()</code></p>\n<p></p>\n<h2 id=\"37-\"><a href=\"#37-\" class=\"headerlink\" title=\"37 \"></a>37 </h2><p>36</p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// CircleShape</span></div><div class=\"line\">Shape* ps;</div><div class=\"line\">Shape* pc = <span class=\"keyword\">new</span> Circle;   <span class=\"comment\">// Shape</span></div></pre></td></tr></table></figure></p>\n<p><code>pc</code><code>Circle*</code><code>ps</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">ps = <span class=\"keyword\">new</span> Circle;   <span class=\"comment\">// psCircle*</span></div></pre></td></tr></table></figure></p>\n<p></p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"keyword\">enum</span> ShapeColor &#123;RED, GREEN&#125;;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span></span>=<span class=\"number\">0</span>;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span></span>;</div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p><code>GREEN</code></p>\n<p>35NVIpublicpublic</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">public</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">draw</span><span class=\"params\">(ShapeColor c=RED)</span> <span class=\"keyword\">const</span> </span>&#123;</div><div class=\"line\">        doDraw(c);  <span class=\"comment\">// </span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"comment\">//</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">doDraw</span><span class=\"params\">(ShapeColor c)</span> <span class=\"keyword\">const</span> </span>= <span class=\"number\">0</span>;  </div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">class</span> Circle: <span class=\"keyword\">public</span> Shape &#123;</div><div class=\"line\"><span class=\"keyword\">private</span>:</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">virtual</span> <span class=\"keyword\">void</span> <span class=\"title\">doDraw</span><span class=\"params\">(ShapeColor c)</span> <span class=\"keyword\">const</span></span>;  <span class=\"comment\">// </span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"38-has-a\"><a href=\"#38-has-a\" class=\"headerlink\" title=\"38 has-a\"></a>38 has-a</h2><p>has-ais-implemented-in-terms-of</p>\n<h2 id=\"39-private\"><a href=\"#39-private\" class=\"headerlink\" title=\"39 private\"></a>39 <code>private</code></h2><p>38<code>D</code><code>B</code><code>D</code><code>B</code><code>B</code><code>D</code><code>B</code><code>D</code></p>\n<p>~<code>D</code><code>B</code></p>\n<h2 id=\"40-\"><a href=\"#40-\" class=\"headerlink\" title=\"40 \"></a>40 </h2><p><code>C</code><code>A</code><code>B</code><code>mf()</code><code>d.mf()</code>,<code>d.A::mf()</code></p>\n<p><code>File</code><br><img src=\"/img/effectivecpp_diamond.png\" alt=\"\"></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">class</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> InputFile: <span class=\"keyword\">virtual</span> <span class=\"keyword\">public</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> OutputFile: <span class=\"keyword\">virtual</span> <span class=\"keyword\">public</span> File &#123;...&#125;;</div><div class=\"line\"><span class=\"keyword\">class</span> IOFile: <span class=\"keyword\">public</span> InputFile, <span class=\"keyword\">public</span> OutputFile &#123;...&#125;;</div></pre></td></tr></table></figure>\n<p>publicvirtual</p>\n<p>JavaC#Interface</p>\n<h2 id=\"-std-function\"><a href=\"#-std-function\" class=\"headerlink\" title=\" std::function\"></a> <code>std::function</code></h2><p><code>std::function</code>lambda<code>std::function</code><br></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;functional&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> Foo &#123;</div><div class=\"line\">    Foo(<span class=\"keyword\">int</span> num) : num_(num) &#123;&#125;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_add</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> <span class=\"keyword\">const</span> </span>&#123; <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; num_+i &lt;&lt; <span class=\"string\">'\\n'</span>; &#125;</div><div class=\"line\">    <span class=\"keyword\">int</span> num_;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">print_num</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; i &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">struct</span> PrintNum &#123;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">operator</span><span class=\"params\">()</span><span class=\"params\">(<span class=\"keyword\">int</span> i)</span> <span class=\"keyword\">const</span></div><div class=\"line\">    </span>&#123;</div><div class=\"line\">        <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; i &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;;</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"comment\">// store a free function</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_display = print_num;</div><div class=\"line\">    f_display(<span class=\"number\">-9</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// lambda</span></div><div class=\"line\">    <span class=\"comment\">// store a lambda</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>()&gt; f_display_42 = []() &#123; print_num(<span class=\"number\">42</span>); &#125;;</div><div class=\"line\">    f_display_42();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store the result of a call to std::bind</span></div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>()&gt; f_display_31337 = <span class=\"built_in\">std</span>::bind(print_num, <span class=\"number\">31337</span>);</div><div class=\"line\">    f_display_31337();</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function</span></div><div class=\"line\">    <span class=\"comment\">// const reference</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">const</span> Foo&amp;, <span class=\"keyword\">int</span>)&gt; f_add_display = &amp;Foo::print_add;</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">const</span> Foo <span class=\"title\">foo</span><span class=\"params\">(<span class=\"number\">314159</span>)</span></span>;</div><div class=\"line\">    f_add_display(foo, <span class=\"number\">1</span>);</div><div class=\"line\">    f_add_display(<span class=\"number\">314159</span>, <span class=\"number\">1</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a data member accessor</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">int</span>(Foo <span class=\"keyword\">const</span>&amp;)&gt; f_num = &amp;Foo::num_;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"num_: \"</span> &lt;&lt; f_num(foo) &lt;&lt; <span class=\"string\">'\\n'</span>;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function and object</span></div><div class=\"line\">    <span class=\"keyword\">using</span> <span class=\"built_in\">std</span>::placeholders::_1;</div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_add_display2 = <span class=\"built_in\">std</span>::bind( &amp;Foo::print_add, foo, _1 );</div><div class=\"line\">    f_add_display2(<span class=\"number\">2</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a member function and object ptr</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_add_display3 = <span class=\"built_in\">std</span>::bind( &amp;Foo::print_add, &amp;foo, _1 );</div><div class=\"line\">    f_add_display3(<span class=\"number\">3</span>);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">// store a call to a function object</span></div><div class=\"line\">    <span class=\"built_in\">std</span>::function&lt;<span class=\"keyword\">void</span>(<span class=\"keyword\">int</span>)&gt; f_display_obj = PrintNum();</div><div class=\"line\">    f_display_obj(<span class=\"number\">18</span>);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>"},{"title":"","date":"2017-10-27T01:56:00.000Z","_content":"\n![just a joke](/img/just-a-joke.png)\n\n<!-- more -->\n \n\n \n\n\n\n \n\n\n","source":"_posts/fuck-gfw.md","raw":"---\ntitle: \ndate: 2017-10-27 09:56:00\ntags:\n    - \n---\n\n![just a joke](/img/just-a-joke.png)\n\n<!-- more -->\n \n\n \n\n\n\n \n\n\n","slug":"fuck-gfw","published":1,"updated":"2018-10-27T07:16:52.394Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8l4001vae7bcj5hxdco","content":"<p><br><img src=\"/img/just-a-joke.png\" alt=\"just a joke\"></p>\n<a id=\"more\"></a>\n<p> </p>\n<p> </p>\n<p></p>\n<p> </p>\n<p></p>\n","excerpt":"<p><br><img src=\"/img/just-a-joke.png\" alt=\"just a joke\"></p>","more":"<p> </p>\n<p> </p>\n<p></p>\n<p> </p>\n<p></p>"},{"title":"Focal Loss - Focal Loss for Dense Object Detection","date":"2017-08-14T14:43:55.000Z","_content":"Focal LossHe KaimingRBGICCV2017[](https://www.zhihu.com/question/63581984)\n\nRetinaNetYOLOYOLO\n\n![](/img/focal_loss_different_model_comparison.jpg)\n\nUpdate@2018.03.26 YOLOv3[](https://pjreddie.com/darknet/yolo/)Focal LossRetina Net\n![YOLO v3](/img/yolov3-comparision-with-retina.png)\n<!-- more -->\n\n## Focal Loss\none-statetwo-stageYOLOSSDRCNNproposalSeletive SearchRPNproposal\n\ncentral issusproposalYOLOPASCAL VOCYOLO V2$13 \\times 13 \\times 5$$845$lossloss\n\none-stageRetinaNettrade-off\n\n$$\\text{FL}(p_t) = -(1-p_t)^\\gamma \\log(p_t)$$\n\n## \nHoGDPM\n\nR-CNNR-CNNproposalEdgeBoxesSelective SearchDeepMaskRPNproposal1-2K\n\nYOLOSSDfeature mapproposal100Kproposalfeature map\n- \n- \n\nFaster-RCNNHuber Lossoutliererrorclipping$1$FocalLossinnerloss\n\n## Focal Loss\nFocal Loss\n\n$$\\text{CE}(p, y) = \\begin{cases}-\\log(p) \\quad &\\text{if}\\quad y = 1\\\\ -\\log(1-p) &\\text{otherwise}\\end{cases}$$\n\n\n$$\\text{CE}(p, y) = -\\log(p_y)$$\n\n$p_t$($p_t$ground truth)$.5$\n![FL vs CELoss](/img/focal_loss_vs_ce_loss.jpg)\n\n$\\alpha_t$baseline\n$$\\text{CE}(p) = -\\alpha_t\\log(p_t)$$\n\nFocal Loss$\\gamma$$\\gamma=2$\n$$\\text{FL}(p_t) = -(1-p_t)^\\gamma\\log(p_t)$$\n\nFocal Loss\n\n## \nPyTorch[Focal Loss](https://github.com/DingKe/pytorch_workplace/blob/master/focalloss/loss.py)`one-hot``classes``index`one-hotFocal Lossonehot$\\odot$element-wise\n\n$$L = -\\sum_{i}^{C}\\text{onehot}\\odot (1-P_i)^\\gamma \\log P_i$$\n\n``` py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n\ndef one_hot(index, classes):\n    size = index.size() + (classes,)\n    view = index.size() + (1,)\n\n    mask = torch.Tensor(*size).fill_(0)\n    index = index.view(*view)\n    ones = 1.\n\n    if isinstance(index, Variable):\n        ones = Variable(torch.Tensor(index.size()).fill_(1))\n        mask = Variable(mask, volatile=index.volatile)\n\n    return mask.scatter_(1, index, ones)\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, eps=1e-7):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.eps = eps\n\n    def forward(self, input, target):\n        y = one_hot(target, input.size(-1))\n        logit = F.softmax(input)\n        logit = logit.clamp(self.eps, 1. - self.eps)\n\n        loss = -1 * y * torch.log(logit) # cross entropy\n        loss = loss * (1 - logit) ** self.gamma # focal loss\n\n        return loss.sum()\n```\n\n## \n$0.01$Focal Loss\n\nimagenetbase net$\\sigma=0.01$$0$$b=-\\log((1-\\pi)/\\pi)$$\\pi$anchor$0.01$\n\nFalse Positive\n\n## RetinaNet\nResNetFeature Pyramid NetFPNone-stageRetinaNet\n","source":"_posts/focal-loss-paper.md","raw":"---\ntitle: Focal Loss - Focal Loss for Dense Object Detection\ndate: 2017-08-14 22:43:55\ntags:\n    - paper\n    - deep learning\n---\nFocal LossHe KaimingRBGICCV2017[](https://www.zhihu.com/question/63581984)\n\nRetinaNetYOLOYOLO\n\n![](/img/focal_loss_different_model_comparison.jpg)\n\nUpdate@2018.03.26 YOLOv3[](https://pjreddie.com/darknet/yolo/)Focal LossRetina Net\n![YOLO v3](/img/yolov3-comparision-with-retina.png)\n<!-- more -->\n\n## Focal Loss\none-statetwo-stageYOLOSSDRCNNproposalSeletive SearchRPNproposal\n\ncentral issusproposalYOLOPASCAL VOCYOLO V2$13 \\times 13 \\times 5$$845$lossloss\n\none-stageRetinaNettrade-off\n\n$$\\text{FL}(p_t) = -(1-p_t)^\\gamma \\log(p_t)$$\n\n## \nHoGDPM\n\nR-CNNR-CNNproposalEdgeBoxesSelective SearchDeepMaskRPNproposal1-2K\n\nYOLOSSDfeature mapproposal100Kproposalfeature map\n- \n- \n\nFaster-RCNNHuber Lossoutliererrorclipping$1$FocalLossinnerloss\n\n## Focal Loss\nFocal Loss\n\n$$\\text{CE}(p, y) = \\begin{cases}-\\log(p) \\quad &\\text{if}\\quad y = 1\\\\ -\\log(1-p) &\\text{otherwise}\\end{cases}$$\n\n\n$$\\text{CE}(p, y) = -\\log(p_y)$$\n\n$p_t$($p_t$ground truth)$.5$\n![FL vs CELoss](/img/focal_loss_vs_ce_loss.jpg)\n\n$\\alpha_t$baseline\n$$\\text{CE}(p) = -\\alpha_t\\log(p_t)$$\n\nFocal Loss$\\gamma$$\\gamma=2$\n$$\\text{FL}(p_t) = -(1-p_t)^\\gamma\\log(p_t)$$\n\nFocal Loss\n\n## \nPyTorch[Focal Loss](https://github.com/DingKe/pytorch_workplace/blob/master/focalloss/loss.py)`one-hot``classes``index`one-hotFocal Lossonehot$\\odot$element-wise\n\n$$L = -\\sum_{i}^{C}\\text{onehot}\\odot (1-P_i)^\\gamma \\log P_i$$\n\n``` py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n\ndef one_hot(index, classes):\n    size = index.size() + (classes,)\n    view = index.size() + (1,)\n\n    mask = torch.Tensor(*size).fill_(0)\n    index = index.view(*view)\n    ones = 1.\n\n    if isinstance(index, Variable):\n        ones = Variable(torch.Tensor(index.size()).fill_(1))\n        mask = Variable(mask, volatile=index.volatile)\n\n    return mask.scatter_(1, index, ones)\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=0, eps=1e-7):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.eps = eps\n\n    def forward(self, input, target):\n        y = one_hot(target, input.size(-1))\n        logit = F.softmax(input)\n        logit = logit.clamp(self.eps, 1. - self.eps)\n\n        loss = -1 * y * torch.log(logit) # cross entropy\n        loss = loss * (1 - logit) ** self.gamma # focal loss\n\n        return loss.sum()\n```\n\n## \n$0.01$Focal Loss\n\nimagenetbase net$\\sigma=0.01$$0$$b=-\\log((1-\\pi)/\\pi)$$\\pi$anchor$0.01$\n\nFalse Positive\n\n## RetinaNet\nResNetFeature Pyramid NetFPNone-stageRetinaNet\n","slug":"focal-loss-paper","published":1,"updated":"2018-10-27T07:16:52.393Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8l9001wae7bgag91bkt","content":"<p>Focal LossHe KaimingRBGICCV2017<a href=\"https://www.zhihu.com/question/63581984\" target=\"_blank\" rel=\"external\"></a></p>\n<p>RetinaNetYOLOYOLO</p>\n<p><img src=\"/img/focal_loss_different_model_comparison.jpg\" alt=\"\"></p>\n<p>Update@2018.03.26 YOLOv3<a href=\"https://pjreddie.com/darknet/yolo/\" target=\"_blank\" rel=\"external\"></a>Focal LossRetina Net<br><img src=\"/img/yolov3-comparision-with-retina.png\" alt=\"YOLO v3\"><br><a id=\"more\"></a></p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p>one-statetwo-stageYOLOSSDRCNNproposalSeletive SearchRPNproposal</p>\n<p>central issusproposalYOLOPASCAL VOCYOLO V2$13 \\times 13 \\times 5$$845$lossloss</p>\n<p>one-stageRetinaNettrade-off</p>\n<script type=\"math/tex; mode=display\">\\text{FL}(p_t) = -(1-p_t)^\\gamma \\log(p_t)</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>HoGDPM</p>\n<p>R-CNNR-CNNproposalEdgeBoxesSelective SearchDeepMaskRPNproposal1-2K</p>\n<p>YOLOSSDfeature mapproposal100Kproposalfeature map</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>Faster-RCNNHuber Lossoutliererrorclipping$1$FocalLossinnerloss</p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p>Focal Loss</p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p, y) = \\begin{cases}-\\log(p) \\quad &\\text{if}\\quad y = 1\\\\ -\\log(1-p) &\\text{otherwise}\\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p, y) = -\\log(p_y)</script><p>$p_t$($p_t$ground truth)$.5$<br><img src=\"/img/focal_loss_vs_ce_loss.jpg\" alt=\"FL vs CELoss\"></p>\n<p>$\\alpha_t$baseline</p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p) = -\\alpha_t\\log(p_t)</script><p>Focal Loss$\\gamma$$\\gamma=2$</p>\n<script type=\"math/tex; mode=display\">\\text{FL}(p_t) = -(1-p_t)^\\gamma\\log(p_t)</script><p>Focal Loss</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorch<a href=\"https://github.com/DingKe/pytorch_workplace/blob/master/focalloss/loss.py\" target=\"_blank\" rel=\"external\">Focal Loss</a><code>one-hot</code><code>classes</code><code>index</code>one-hotFocal Lossonehot$\\odot$element-wise</p>\n<script type=\"math/tex; mode=display\">L = -\\sum_{i}^{C}\\text{onehot}\\odot (1-P_i)^\\gamma \\log P_i</script><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</div><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">one_hot</span><span class=\"params\">(index, classes)</span>:</span></div><div class=\"line\">    size = index.size() + (classes,)</div><div class=\"line\">    view = index.size() + (<span class=\"number\">1</span>,)</div><div class=\"line\"></div><div class=\"line\">    mask = torch.Tensor(*size).fill_(<span class=\"number\">0</span>)</div><div class=\"line\">    index = index.view(*view)</div><div class=\"line\">    ones = <span class=\"number\">1.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> isinstance(index, Variable):</div><div class=\"line\">        ones = Variable(torch.Tensor(index.size()).fill_(<span class=\"number\">1</span>))</div><div class=\"line\">        mask = Variable(mask, volatile=index.volatile)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">return</span> mask.scatter_(<span class=\"number\">1</span>, index, ones)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FocalLoss</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, gamma=<span class=\"number\">0</span>, eps=<span class=\"number\">1e-7</span>)</span>:</span></div><div class=\"line\">        super(FocalLoss, self).__init__()</div><div class=\"line\">        self.gamma = gamma</div><div class=\"line\">        self.eps = eps</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, input, target)</span>:</span></div><div class=\"line\">        y = one_hot(target, input.size(<span class=\"number\">-1</span>))</div><div class=\"line\">        logit = F.softmax(input)</div><div class=\"line\">        logit = logit.clamp(self.eps, <span class=\"number\">1.</span> - self.eps)</div><div class=\"line\"></div><div class=\"line\">        loss = <span class=\"number\">-1</span> * y * torch.log(logit) <span class=\"comment\"># cross entropy</span></div><div class=\"line\">        loss = loss * (<span class=\"number\">1</span> - logit) ** self.gamma <span class=\"comment\"># focal loss</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> loss.sum()</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$0.01$Focal Loss</p>\n<p>imagenetbase net$\\sigma=0.01$$0$$b=-\\log((1-\\pi)/\\pi)$$\\pi$anchor$0.01$</p>\n<p>False Positive</p>\n<h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p>ResNetFeature Pyramid NetFPNone-stageRetinaNet</p>\n","excerpt":"<p>Focal LossHe KaimingRBGICCV2017<a href=\"https://www.zhihu.com/question/63581984\"></a></p>\n<p>RetinaNetYOLOYOLO</p>\n<p><img src=\"/img/focal_loss_different_model_comparison.jpg\" alt=\"\"></p>\n<p>Update@2018.03.26 YOLOv3<a href=\"https://pjreddie.com/darknet/yolo/\"></a>Focal LossRetina Net<br><img src=\"/img/yolov3-comparision-with-retina.png\" alt=\"YOLO v3\"><br>","more":"</p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p>one-statetwo-stageYOLOSSDRCNNproposalSeletive SearchRPNproposal</p>\n<p>central issusproposalYOLOPASCAL VOCYOLO V2$13 \\times 13 \\times 5$$845$lossloss</p>\n<p>one-stageRetinaNettrade-off</p>\n<script type=\"math/tex; mode=display\">\\text{FL}(p_t) = -(1-p_t)^\\gamma \\log(p_t)</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>HoGDPM</p>\n<p>R-CNNR-CNNproposalEdgeBoxesSelective SearchDeepMaskRPNproposal1-2K</p>\n<p>YOLOSSDfeature mapproposal100Kproposalfeature map</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>Faster-RCNNHuber Lossoutliererrorclipping$1$FocalLossinnerloss</p>\n<h2 id=\"Focal-Loss\"><a href=\"#Focal-Loss\" class=\"headerlink\" title=\"Focal Loss\"></a>Focal Loss</h2><p>Focal Loss</p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p, y) = \\begin{cases}-\\log(p) \\quad &\\text{if}\\quad y = 1\\\\ -\\log(1-p) &\\text{otherwise}\\end{cases}</script><p></p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p, y) = -\\log(p_y)</script><p>$p_t$($p_t$ground truth)$.5$<br><img src=\"/img/focal_loss_vs_ce_loss.jpg\" alt=\"FL vs CELoss\"></p>\n<p>$\\alpha_t$baseline</p>\n<script type=\"math/tex; mode=display\">\\text{CE}(p) = -\\alpha_t\\log(p_t)</script><p>Focal Loss$\\gamma$$\\gamma=2$</p>\n<script type=\"math/tex; mode=display\">\\text{FL}(p_t) = -(1-p_t)^\\gamma\\log(p_t)</script><p>Focal Loss</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorch<a href=\"https://github.com/DingKe/pytorch_workplace/blob/master/focalloss/loss.py\">Focal Loss</a><code>one-hot</code><code>classes</code><code>index</code>one-hotFocal Lossonehot$\\odot$element-wise</p>\n<script type=\"math/tex; mode=display\">L = -\\sum_{i}^{C}\\text{onehot}\\odot (1-P_i)^\\gamma \\log P_i</script><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</div><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">one_hot</span><span class=\"params\">(index, classes)</span>:</span></div><div class=\"line\">    size = index.size() + (classes,)</div><div class=\"line\">    view = index.size() + (<span class=\"number\">1</span>,)</div><div class=\"line\"></div><div class=\"line\">    mask = torch.Tensor(*size).fill_(<span class=\"number\">0</span>)</div><div class=\"line\">    index = index.view(*view)</div><div class=\"line\">    ones = <span class=\"number\">1.</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> isinstance(index, Variable):</div><div class=\"line\">        ones = Variable(torch.Tensor(index.size()).fill_(<span class=\"number\">1</span>))</div><div class=\"line\">        mask = Variable(mask, volatile=index.volatile)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">return</span> mask.scatter_(<span class=\"number\">1</span>, index, ones)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FocalLoss</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, gamma=<span class=\"number\">0</span>, eps=<span class=\"number\">1e-7</span>)</span>:</span></div><div class=\"line\">        super(FocalLoss, self).__init__()</div><div class=\"line\">        self.gamma = gamma</div><div class=\"line\">        self.eps = eps</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, input, target)</span>:</span></div><div class=\"line\">        y = one_hot(target, input.size(<span class=\"number\">-1</span>))</div><div class=\"line\">        logit = F.softmax(input)</div><div class=\"line\">        logit = logit.clamp(self.eps, <span class=\"number\">1.</span> - self.eps)</div><div class=\"line\"></div><div class=\"line\">        loss = <span class=\"number\">-1</span> * y * torch.log(logit) <span class=\"comment\"># cross entropy</span></div><div class=\"line\">        loss = loss * (<span class=\"number\">1</span> - logit) ** self.gamma <span class=\"comment\"># focal loss</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"keyword\">return</span> loss.sum()</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$0.01$Focal Loss</p>\n<p>imagenetbase net$\\sigma=0.01$$0$$b=-\\log((1-\\pi)/\\pi)$$\\pi$anchor$0.01$</p>\n<p>False Positive</p>\n<h2 id=\"RetinaNet\"><a href=\"#RetinaNet\" class=\"headerlink\" title=\"RetinaNet\"></a>RetinaNet</h2><p>ResNetFeature Pyramid NetFPNone-stageRetinaNet</p>"},{"title":"Hello World","date":"2016-12-16T11:00:00.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n![Hexo](/img/helloworld_hexo.png)\n<!-- more -->\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n### Code highlight\n\nHello World!\n\n``` cpp\n#include <iostream>\nint main() {\n    std::cout << \"HelloWorld\\n\";\n}\n```\n\n``` py\nprint 'HelloWorld'\n```\n\n### Latex Support by Mathjax\n\nMass-energy equation by Einstein: $E = mc^2$\n\na linear equation:\n\n$$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2016-12-16 19:00:00\ntags:\n    - \n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n![Hexo](/img/helloworld_hexo.png)\n<!-- more -->\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n### Code highlight\n\nHello World!\n\n``` cpp\n#include <iostream>\nint main() {\n    std::cout << \"HelloWorld\\n\";\n}\n```\n\n``` py\nprint 'HelloWorld'\n```\n\n### Latex Support by Mathjax\n\nMass-energy equation by Einstein: $E = mc^2$\n\na linear equation:\n\n$$\\mathbf{A}\\mathbf{v} = \\mathbf{y}$$\n","slug":"hello-world","published":1,"updated":"2018-10-27T07:16:52.396Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8lb001yae7bvzheawrk","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<p><img src=\"/img/helloworld_hexo.png\" alt=\"Hexo\"><br><a id=\"more\"></a></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n<h3 id=\"Code-highlight\"><a href=\"#Code-highlight\" class=\"headerlink\" title=\"Code highlight\"></a>Code highlight</h3><p>Hello World!</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"HelloWorld\\n\"</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">'HelloWorld'</span></div></pre></td></tr></table></figure>\n<h3 id=\"Latex-Support-by-Mathjax\"><a href=\"#Latex-Support-by-Mathjax\" class=\"headerlink\" title=\"Latex Support by Mathjax\"></a>Latex Support by Mathjax</h3><p>Mass-energy equation by Einstein: $E = mc^2$</p>\n<p>a linear equation:</p>\n<script type=\"math/tex; mode=display\">\\mathbf{A}\\mathbf{v} = \\mathbf{y}</script>","excerpt":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<p><img src=\"/img/helloworld_hexo.png\" alt=\"Hexo\"><br>","more":"</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n<h3 id=\"Code-highlight\"><a href=\"#Code-highlight\" class=\"headerlink\" title=\"Code highlight\"></a>Code highlight</h3><p>Hello World!</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">    <span class=\"built_in\">std</span>::<span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"HelloWorld\\n\"</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">print</span> <span class=\"string\">'HelloWorld'</span></div></pre></td></tr></table></figure>\n<h3 id=\"Latex-Support-by-Mathjax\"><a href=\"#Latex-Support-by-Mathjax\" class=\"headerlink\" title=\"Latex Support by Mathjax\"></a>Latex Support by Mathjax</h3><p>Mass-energy equation by Einstein: $E = mc^2$</p>\n<p>a linear equation:</p>\n<script type=\"math/tex; mode=display\">\\mathbf{A}\\mathbf{v} = \\mathbf{y}</script>"},{"title":" Visual Studio  GSL ","date":"2016-12-16T11:00:00.000Z","_content":"\nGSLGNUGSLWindowsVisualStudio\n\n![GSL is GNU Sentific Library](/img/gsl_picture.jpg)\n<!-- more -->\n[GSL ](http://www.gnu.org/software/gsl/)GSL\n\n\nHTML[No-Cruft Excel to HTML Table Converter](http://pressbin.com/tools/excel_to_html_table/index.html)\n{% raw %}\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n{% endraw %}\n\nGSLLinuxINSTALLCMAKEHAO!\n\n``` bash\n./configure\nmake\nmake install\nmake clean\n```\n\nGSLWindowsWindows Visual Studio  CMakeGUI GSL\n\n## CMAKE.SLN\n\nCMAKEGUIGSL ConfigureVisual Studio2013FinishConfigureGenerateGSL.sln\n\n## Visual Studio\n\n Visual Studio .SLNDebugRelease\n\n\\bin\\gsl\\Debug\\Release\n\n\n## \n\nPath\\GSL_Build_Path\\bin\\Debug\\Debuggsl.dll\n\nDLLPath\n\n## Visual Studio\n\nVisual StudioOpenCVYuanbo She [Opencv  2014 (Win8.1 + Opencv 2.4.8 + VS 2013)](http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html)\n\nLIBGSLOpenCV\n\n``` html\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Project ToolsVersion=\"4.0\" xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\">\n  <ImportGroup Label=\"PropertySheets\" />\n  <PropertyGroup Label=\"UserMacros\" />\n  <PropertyGroup>\n        <IncludePath>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)</IncludePath>\n        <LibraryPath Condition=\"'$(Platform)'=='Win32'\">$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n        <LibraryPath Condition=\"'$(Platform)'=='X64'\">$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n  </PropertyGroup>\n  <ItemDefinitionGroup>\n        <Link Condition=\"'$(Configuration)'=='Debug'\">\n          <AdditionalDependencies>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n        <Link Condition=\"'$(Configuration)'=='Release'\">\n          <AdditionalDependencies>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n  </ItemDefinitionGroup>\n  <ItemGroup />\n</Project>\n```\n\nVisual Studio\n\n## \n\n\n\n\n``` cpp\n#include <stdio.h>\n#include <gsl/gsl_sf_bessel.h>\nint main(void)\n{\n\tdouble x = 5.0;\n\tdouble y = gsl_sf_bessel_J0(x);\n\tprintf(\"J0(%g) = %.18e\\n\", x, y);\n\treturn 0;\n}\n```\n\n\n{% raw %}\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n{% endraw %}\n","source":"_posts/gsl-with-vs.md","raw":"---\ntitle:  Visual Studio  GSL \ndate: 2016-12-16 19:00:00\ntags:\n    - tool\n---\n\nGSLGNUGSLWindowsVisualStudio\n\n![GSL is GNU Sentific Library](/img/gsl_picture.jpg)\n<!-- more -->\n[GSL ](http://www.gnu.org/software/gsl/)GSL\n\n\nHTML[No-Cruft Excel to HTML Table Converter](http://pressbin.com/tools/excel_to_html_table/index.html)\n{% raw %}\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n{% endraw %}\n\nGSLLinuxINSTALLCMAKEHAO!\n\n``` bash\n./configure\nmake\nmake install\nmake clean\n```\n\nGSLWindowsWindows Visual Studio  CMakeGUI GSL\n\n## CMAKE.SLN\n\nCMAKEGUIGSL ConfigureVisual Studio2013FinishConfigureGenerateGSL.sln\n\n## Visual Studio\n\n Visual Studio .SLNDebugRelease\n\n\\bin\\gsl\\Debug\\Release\n\n\n## \n\nPath\\GSL_Build_Path\\bin\\Debug\\Debuggsl.dll\n\nDLLPath\n\n## Visual Studio\n\nVisual StudioOpenCVYuanbo She [Opencv  2014 (Win8.1 + Opencv 2.4.8 + VS 2013)](http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html)\n\nLIBGSLOpenCV\n\n``` html\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<Project ToolsVersion=\"4.0\" xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\">\n  <ImportGroup Label=\"PropertySheets\" />\n  <PropertyGroup Label=\"UserMacros\" />\n  <PropertyGroup>\n        <IncludePath>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)</IncludePath>\n        <LibraryPath Condition=\"'$(Platform)'=='Win32'\">$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n        <LibraryPath Condition=\"'$(Platform)'=='X64'\">$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)</LibraryPath>\n  </PropertyGroup>\n  <ItemDefinitionGroup>\n        <Link Condition=\"'$(Configuration)'=='Debug'\">\n          <AdditionalDependencies>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n        <Link Condition=\"'$(Configuration)'=='Release'\">\n          <AdditionalDependencies>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)</AdditionalDependencies>\n        </Link>\n  </ItemDefinitionGroup>\n  <ItemGroup />\n</Project>\n```\n\nVisual Studio\n\n## \n\n\n\n\n``` cpp\n#include <stdio.h>\n#include <gsl/gsl_sf_bessel.h>\nint main(void)\n{\n\tdouble x = 5.0;\n\tdouble y = gsl_sf_bessel_J0(x);\n\tprintf(\"J0(%g) = %.18e\\n\", x, y);\n\treturn 0;\n}\n```\n\n\n{% raw %}\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n{% endraw %}\n","slug":"gsl-with-vs","published":1,"updated":"2018-10-27T07:16:52.395Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8lc0020ae7ble161rjq","content":"<p>GSLGNUGSLWindowsVisualStudio</p>\n<p><img src=\"/img/gsl_picture.jpg\" alt=\"GSL is GNU Sentific Library\"><br><a id=\"more\"></a><br><a href=\"http://www.gnu.org/software/gsl/\" target=\"_blank\" rel=\"external\">GSL </a>GSL</p>\n<p>HTML<a href=\"http://pressbin.com/tools/excel_to_html_table/index.html\" target=\"_blank\" rel=\"external\">No-Cruft Excel to HTML Table Converter</a><br>\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n</p>\n<p>GSLLinuxINSTALLCMAKEHAO!</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">make install</div><div class=\"line\">make clean</div></pre></td></tr></table></figure>\n<p>GSLWindowsWindows Visual Studio  CMakeGUI GSL</p>\n<h2 id=\"CMAKE-SLN\"><a href=\"#CMAKE-SLN\" class=\"headerlink\" title=\"CMAKE.SLN\"></a>CMAKE.SLN</h2><p>CMAKEGUIGSL ConfigureVisual Studio2013FinishConfigureGenerateGSL.sln</p>\n<h2 id=\"Visual-Studio\"><a href=\"#Visual-Studio\" class=\"headerlink\" title=\"Visual Studio\"></a>Visual Studio</h2><p> Visual Studio .SLNDebugRelease</p>\n<p>\\bin\\gsl\\Debug\\Release</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Path\\GSL_Build_Path\\bin\\Debug\\Debuggsl.dll</p>\n<p>DLLPath</p>\n<h2 id=\"Visual-Studio\"><a href=\"#Visual-Studio\" class=\"headerlink\" title=\"Visual Studio\"></a>Visual Studio</h2><p>Visual StudioOpenCVYuanbo She <a href=\"http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html\" target=\"_blank\" rel=\"external\">Opencv  2014 (Win8.1 + Opencv 2.4.8 + VS 2013)</a></p>\n<p>LIBGSLOpenCV</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;</div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Project</span> <span class=\"attr\">ToolsVersion</span>=<span class=\"string\">\"4.0\"</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://schemas.microsoft.com/developer/msbuild/2003\"</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ImportGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"PropertySheets\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"UserMacros\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">IncludePath</span>&gt;</span>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)<span class=\"tag\">&lt;/<span class=\"name\">IncludePath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='Win32'\"</span>&gt;</span>$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='X64'\"</span>&gt;</span>$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Debug'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Release'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemGroup</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Project</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>Visual Studio</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;gsl/gsl_sf_bessel.h&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">\t<span class=\"keyword\">double</span> x = <span class=\"number\">5.0</span>;</div><div class=\"line\">\t<span class=\"keyword\">double</span> y = gsl_sf_bessel_J0(x);</div><div class=\"line\">\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"J0(%g) = %.18e\\n\"</span>, x, y);</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><br>\n</p><p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n<p></p>\n","excerpt":"<p>GSLGNUGSLWindowsVisualStudio</p>\n<p><img src=\"/img/gsl_picture.jpg\" alt=\"GSL is GNU Sentific Library\"><br>","more":"<br><a href=\"http://www.gnu.org/software/gsl/\">GSL </a>GSL</p>\n<p>HTML<a href=\"http://pressbin.com/tools/excel_to_html_table/index.html\">No-Cruft Excel to HTML Table Converter</a><br>\n<table>\n   <tr>\n      <td>Complex Numbers </td>\n      <td>Roots of Polynomials</td>\n   </tr>\n   <tr>\n      <td>Special Functions </td>\n      <td>Vectors and Matrices</td>\n   </tr>\n   <tr>\n      <td>Permutations </td>\n      <td>Sorting</td>\n   </tr>\n   <tr>\n      <td>BLAS Support </td>\n      <td>Linear Algebra</td>\n   </tr>\n   <tr>\n      <td>Eigensystems </td>\n      <td>Fast Fourier Transforms</td>\n   </tr>\n   <tr>\n      <td>Quadrature </td>\n      <td>Random Numbers</td>\n   </tr>\n   <tr>\n      <td>Quasi-Random Sequences </td>\n      <td>Random Distributions</td>\n   </tr>\n   <tr>\n      <td>Statistics </td>\n      <td>Histograms</td>\n   </tr>\n   <tr>\n      <td>N-Tuples </td>\n      <td>Monte Carlo Integration</td>\n   </tr>\n   <tr>\n      <td>Simulated Annealing </td>\n      <td>Differential Equations</td>\n   </tr>\n   <tr>\n      <td>Interpolation </td>\n      <td>Numerical Differentiation</td>\n   </tr>\n   <tr>\n      <td>Chebyshev Approximation </td>\n      <td>Series Acceleration</td>\n   </tr>\n   <tr>\n      <td>Discrete Hankel Transforms </td>\n      <td>Root-Finding</td>\n   </tr>\n   <tr>\n      <td>Minimization </td>\n      <td>Least-Squares Fitting</td>\n   </tr>\n   <tr>\n      <td>Physical Constants </td>\n      <td>IEEE Floating-Point</td>\n   </tr>\n   <tr>\n      <td>Discrete Wavelet Transforms </td>\n      <td>Basis splines</td>\n   </tr>\n</table>\n</p>\n<p>GSLLinuxINSTALLCMAKEHAO!</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure</div><div class=\"line\">make</div><div class=\"line\">make install</div><div class=\"line\">make clean</div></pre></td></tr></table></figure>\n<p>GSLWindowsWindows Visual Studio  CMakeGUI GSL</p>\n<h2 id=\"CMAKE-SLN\"><a href=\"#CMAKE-SLN\" class=\"headerlink\" title=\"CMAKE.SLN\"></a>CMAKE.SLN</h2><p>CMAKEGUIGSL ConfigureVisual Studio2013FinishConfigureGenerateGSL.sln</p>\n<h2 id=\"Visual-Studio\"><a href=\"#Visual-Studio\" class=\"headerlink\" title=\"Visual Studio\"></a>Visual Studio</h2><p> Visual Studio .SLNDebugRelease</p>\n<p>\\bin\\gsl\\Debug\\Release</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Path\\GSL_Build_Path\\bin\\Debug\\Debuggsl.dll</p>\n<p>DLLPath</p>\n<h2 id=\"Visual-Studio\"><a href=\"#Visual-Studio\" class=\"headerlink\" title=\"Visual Studio\"></a>Visual Studio</h2><p>Visual StudioOpenCVYuanbo She <a href=\"http://my.phirobot.com/blog/2014-02-opencv_configuration_in_vs.html\">Opencv  2014 (Win8.1 + Opencv 2.4.8 + VS 2013)</a></p>\n<p>LIBGSLOpenCV</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;</div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">Project</span> <span class=\"attr\">ToolsVersion</span>=<span class=\"string\">\"4.0\"</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://schemas.microsoft.com/developer/msbuild/2003\"</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ImportGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"PropertySheets\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span> <span class=\"attr\">Label</span>=<span class=\"string\">\"UserMacros\"</span> /&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">IncludePath</span>&gt;</span>$(OPENCV249)\\include;E:\\GSLCode\\gsl-build\\;$(IncludePath)<span class=\"tag\">&lt;/<span class=\"name\">IncludePath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='Win32'\"</span>&gt;</span>$(OPENCV249)\\x86\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">LibraryPath</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Platform)'=='X64'\"</span>&gt;</span>$(OPENCV249)\\x64\\vc12\\lib;E:\\GSLCode\\gsl-build\\Debug;$(LibraryPath)<span class=\"tag\">&lt;/<span class=\"name\">LibraryPath</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">PropertyGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Debug'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249d.lib;opencv_contrib249d.lib;opencv_core249d.lib;opencv_features2d249d.lib;opencv_flann249d.lib;opencv_gpu249d.lib;opencv_highgui249d.lib;opencv_imgproc249d.lib;opencv_legacy249d.lib;opencv_ml249d.lib;opencv_nonfree249d.lib;opencv_objdetect249d.lib;opencv_ocl249d.lib;opencv_photo249d.lib;opencv_stitching249d.lib;opencv_superres249d.lib;opencv_ts249d.lib;opencv_video249d.lib;opencv_videostab249d.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">Link</span> <span class=\"attr\">Condition</span>=<span class=\"string\">\"'$(Configuration)'=='Release'\"</span>&gt;</span></div><div class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">AdditionalDependencies</span>&gt;</span>opencv_calib3d249.lib;opencv_contrib249.lib;opencv_core249.lib;opencv_features2d249.lib;opencv_flann249.lib;opencv_gpu249.lib;opencv_highgui249.lib;opencv_imgproc249.lib;opencv_legacy249.lib;opencv_ml249.lib;opencv_nonfree249.lib;opencv_objdetect249.lib;opencv_ocl249.lib;opencv_photo249.lib;opencv_stitching249.lib;opencv_superres249.lib;opencv_ts249.lib;opencv_video249.lib;opencv_videostab249.lib;gsl.lib;gslcblas.lib;%(AdditionalDependencies)<span class=\"tag\">&lt;/<span class=\"name\">AdditionalDependencies</span>&gt;</span></div><div class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">Link</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">ItemDefinitionGroup</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">ItemGroup</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">Project</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>Visual Studio</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;gsl/gsl_sf_bessel.h&gt;</span></span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">void</span>)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">\t<span class=\"keyword\">double</span> x = <span class=\"number\">5.0</span>;</div><div class=\"line\">\t<span class=\"keyword\">double</span> y = gsl_sf_bessel_J0(x);</div><div class=\"line\">\t<span class=\"built_in\">printf</span>(<span class=\"string\">\"J0(%g) = %.18e\\n\"</span>, x, y);</div><div class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><br>\n<p><img src=\"http://i.imgur.com/uXhVvwS.jpg\" width=\"600\" height=\"200\"></p>\n</p>"},{"title":"Neural Network for Machine Learning - Lecture 01","date":"2017-05-03T12:56:36.000Z","_content":"Hinton  Coursera Neural Network for Machine LearningDL\n![](/img/hinton_brainsimulator.jpg)\n<!-- more -->\n\n## Why do we need ML?\nMLMNIST22\n![MNIST Digit 2](/img/hinton_01_mnist_example.png)\n\n## What are neural network?\n\n\n- \n- \n- \n\n\ndendritic treeaxonsynapsecommunication\n![](/img/hinton_01_neuron_structure.png)\n\n$10^{11}$$10^4$\n![](/img/hinton_01_neuron_commucation.png)\n\n\n\n\n\n## Simple models of different neurons\n\n\n### Linear neuron\n\n$$y = b+\\sum_{i=1}^{n}w_ix_i$$\n\n### Binary threshold neuron\n\n\n$$y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge \\theta\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n$z$$z=\\sum_{i}w_ix_i$\n\n\n\n$$y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n$z$$z = b+\\sum_{i}w_ix_i$\n\n### Rectified linear neuron\n\n$$y = \\begin{cases}z \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n### Sigmoid neuron\nlogisticshrink$(0, 1)$\n$$y = \\frac{1}{1+\\exp(-z)}$$\n![Logistic](/img/hinton_01_sigmoid_function.png)\n\nLogistic$(-\\infty, +\\infty)$SSigmoid\n\n### Stochastic binary neuron\nLogistic$1$\n$$P(y=1) = \\frac{1}{1+\\exp(-z)}$$\n\nRectified linear neuron\n\n## Three types of learning\n\n\n- \n- good internal representation of input\n- \n\n### \nmodel($f$$W$)$x$\n\n$W$$x$ \n\n### \noccasional\n\n\n- delayedAlphaGo\n- \n\n### \n\n","source":"_posts/hinton-nnml-01.md","raw":"---\ntitle: Neural Network for Machine Learning - Lecture 01\ndate: 2017-05-03 20:56:36\ntags:\n    - deep learning\n    - \n---\nHinton  Coursera Neural Network for Machine LearningDL\n![](/img/hinton_brainsimulator.jpg)\n<!-- more -->\n\n## Why do we need ML?\nMLMNIST22\n![MNIST Digit 2](/img/hinton_01_mnist_example.png)\n\n## What are neural network?\n\n\n- \n- \n- \n\n\ndendritic treeaxonsynapsecommunication\n![](/img/hinton_01_neuron_structure.png)\n\n$10^{11}$$10^4$\n![](/img/hinton_01_neuron_commucation.png)\n\n\n\n\n\n## Simple models of different neurons\n\n\n### Linear neuron\n\n$$y = b+\\sum_{i=1}^{n}w_ix_i$$\n\n### Binary threshold neuron\n\n\n$$y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge \\theta\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n$z$$z=\\sum_{i}w_ix_i$\n\n\n\n$$y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n$z$$z = b+\\sum_{i}w_ix_i$\n\n### Rectified linear neuron\n\n$$y = \\begin{cases}z \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}$$\n\n### Sigmoid neuron\nlogisticshrink$(0, 1)$\n$$y = \\frac{1}{1+\\exp(-z)}$$\n![Logistic](/img/hinton_01_sigmoid_function.png)\n\nLogistic$(-\\infty, +\\infty)$SSigmoid\n\n### Stochastic binary neuron\nLogistic$1$\n$$P(y=1) = \\frac{1}{1+\\exp(-z)}$$\n\nRectified linear neuron\n\n## Three types of learning\n\n\n- \n- good internal representation of input\n- \n\n### \nmodel($f$$W$)$x$\n\n$W$$x$ \n\n### \noccasional\n\n\n- delayedAlphaGo\n- \n\n### \n\n","slug":"hinton-nnml-01","published":1,"updated":"2018-10-27T07:16:52.396Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ld0023ae7bre5rq59h","content":"<p>Hinton  Coursera Neural Network for Machine LearningDL<br><img src=\"/img/hinton_brainsimulator.jpg\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"Why-do-we-need-ML\"><a href=\"#Why-do-we-need-ML\" class=\"headerlink\" title=\"Why do we need ML?\"></a>Why do we need ML?</h2><p>MLMNIST22<br><img src=\"/img/hinton_01_mnist_example.png\" alt=\"MNIST Digit 2\"></p>\n<h2 id=\"What-are-neural-network\"><a href=\"#What-are-neural-network\" class=\"headerlink\" title=\"What are neural network?\"></a>What are neural network?</h2><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><br>dendritic treeaxonsynapsecommunication<br><img src=\"/img/hinton_01_neuron_structure.png\" alt=\"\"></p>\n<p>$10^{11}$$10^4$<br><img src=\"/img/hinton_01_neuron_commucation.png\" alt=\"\"></p>\n<p></p>\n<p></p>\n<h2 id=\"Simple-models-of-different-neurons\"><a href=\"#Simple-models-of-different-neurons\" class=\"headerlink\" title=\"Simple models of different neurons\"></a>Simple models of different neurons</h2><p></p>\n<h3 id=\"Linear-neuron\"><a href=\"#Linear-neuron\" class=\"headerlink\" title=\"Linear neuron\"></a>Linear neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = b+\\sum_{i=1}^{n}w_ix_i</script><h3 id=\"Binary-threshold-neuron\"><a href=\"#Binary-threshold-neuron\" class=\"headerlink\" title=\"Binary threshold neuron\"></a>Binary threshold neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge \\theta\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><p>$z$$z=\\sum_{i}w_ix_i$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><p>$z$$z = b+\\sum_{i}w_ix_i$</p>\n<h3 id=\"Rectified-linear-neuron\"><a href=\"#Rectified-linear-neuron\" class=\"headerlink\" title=\"Rectified linear neuron\"></a>Rectified linear neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}z \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><h3 id=\"Sigmoid-neuron\"><a href=\"#Sigmoid-neuron\" class=\"headerlink\" title=\"Sigmoid neuron\"></a>Sigmoid neuron</h3><p>logisticshrink$(0, 1)$</p>\n<script type=\"math/tex; mode=display\">y = \\frac{1}{1+\\exp(-z)}</script><p><img src=\"/img/hinton_01_sigmoid_function.png\" alt=\"Logistic\"></p>\n<p>Logistic$(-\\infty, +\\infty)$SSigmoid</p>\n<h3 id=\"Stochastic-binary-neuron\"><a href=\"#Stochastic-binary-neuron\" class=\"headerlink\" title=\"Stochastic binary neuron\"></a>Stochastic binary neuron</h3><p>Logistic$1$</p>\n<script type=\"math/tex; mode=display\">P(y=1) = \\frac{1}{1+\\exp(-z)}</script><p>Rectified linear neuron</p>\n<h2 id=\"Three-types-of-learning\"><a href=\"#Three-types-of-learning\" class=\"headerlink\" title=\"Three types of learning\"></a>Three types of learning</h2><p></p>\n<ul>\n<li></li>\n<li>good internal representation of input</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>model($f$$W$)$x$</p>\n<p>$W$$x$ </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>occasional</p>\n<p></p>\n<ul>\n<li>delayedAlphaGo</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n","excerpt":"<p>Hinton  Coursera Neural Network for Machine LearningDL<br><img src=\"/img/hinton_brainsimulator.jpg\" alt=\"\"><br>","more":"</p>\n<h2 id=\"Why-do-we-need-ML\"><a href=\"#Why-do-we-need-ML\" class=\"headerlink\" title=\"Why do we need ML?\"></a>Why do we need ML?</h2><p>MLMNIST22<br><img src=\"/img/hinton_01_mnist_example.png\" alt=\"MNIST Digit 2\"></p>\n<h2 id=\"What-are-neural-network\"><a href=\"#What-are-neural-network\" class=\"headerlink\" title=\"What are neural network?\"></a>What are neural network?</h2><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><br>dendritic treeaxonsynapsecommunication<br><img src=\"/img/hinton_01_neuron_structure.png\" alt=\"\"></p>\n<p>$10^{11}$$10^4$<br><img src=\"/img/hinton_01_neuron_commucation.png\" alt=\"\"></p>\n<p></p>\n<p></p>\n<h2 id=\"Simple-models-of-different-neurons\"><a href=\"#Simple-models-of-different-neurons\" class=\"headerlink\" title=\"Simple models of different neurons\"></a>Simple models of different neurons</h2><p></p>\n<h3 id=\"Linear-neuron\"><a href=\"#Linear-neuron\" class=\"headerlink\" title=\"Linear neuron\"></a>Linear neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = b+\\sum_{i=1}^{n}w_ix_i</script><h3 id=\"Binary-threshold-neuron\"><a href=\"#Binary-threshold-neuron\" class=\"headerlink\" title=\"Binary threshold neuron\"></a>Binary threshold neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge \\theta\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><p>$z$$z=\\sum_{i}w_ix_i$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}1 \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><p>$z$$z = b+\\sum_{i}w_ix_i$</p>\n<h3 id=\"Rectified-linear-neuron\"><a href=\"#Rectified-linear-neuron\" class=\"headerlink\" title=\"Rectified linear neuron\"></a>Rectified linear neuron</h3><p></p>\n<script type=\"math/tex; mode=display\">y = \\begin{cases}z \\quad \\text{if} \\quad z\\ge 0\\\\ 0\\quad \\text{otherwise}\\end{cases}</script><h3 id=\"Sigmoid-neuron\"><a href=\"#Sigmoid-neuron\" class=\"headerlink\" title=\"Sigmoid neuron\"></a>Sigmoid neuron</h3><p>logisticshrink$(0, 1)$</p>\n<script type=\"math/tex; mode=display\">y = \\frac{1}{1+\\exp(-z)}</script><p><img src=\"/img/hinton_01_sigmoid_function.png\" alt=\"Logistic\"></p>\n<p>Logistic$(-\\infty, +\\infty)$SSigmoid</p>\n<h3 id=\"Stochastic-binary-neuron\"><a href=\"#Stochastic-binary-neuron\" class=\"headerlink\" title=\"Stochastic binary neuron\"></a>Stochastic binary neuron</h3><p>Logistic$1$</p>\n<script type=\"math/tex; mode=display\">P(y=1) = \\frac{1}{1+\\exp(-z)}</script><p>Rectified linear neuron</p>\n<h2 id=\"Three-types-of-learning\"><a href=\"#Three-types-of-learning\" class=\"headerlink\" title=\"Three types of learning\"></a>Three types of learning</h2><p></p>\n<ul>\n<li></li>\n<li>good internal representation of input</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>model($f$$W$)$x$</p>\n<p>$W$$x$ </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>occasional</p>\n<p></p>\n<ul>\n<li>delayedAlphaGo</li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>"},{"title":"Neural Network for Machine Learning - Lecture 02","date":"2017-05-25T05:26:33.000Z","_content":"\n\n![Perceptron](/img/hinton_02_perceptron_gragh.png)\n\n<!-- more -->\n## Different neural network archs\n### Feed-forward neural network \n$1$deep\n![](/img/hinton_02_feed_forward_nn.png)\n\n### Recurrent network\nRNNRNN\n![RNN](/img/hinton_02_recurrent_nn.png)\n\nRNNmodeling squence[](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n![RNN modeling squences](/img/hinton_02_rnn_app.png)\n\n### Symmetrically connected network\nRNN\n\n## Percetron\n### \n\n- feature activation\n- feature\n- \n\n![](/img/hinton_02_perceptron_paradigm_for_pattern_recong.png)\n\nBinary threshold neuron${0,1}$$0$\n\n\n\n$$y=\\begin{cases}1, \\quad \\text{if} \\quad \\sum w_ix_i+b>0 \\\\ 0 \\quad \\text{otherwise}\\end{cases}$$\n\n\n- \n- $0$$x$$w$\n- 1$w$$x$\n\n\n\n### \n\n\nWeight Space\n\n$x^\\dagger w = 0$$x$$x$$0$\n\n![](/img/hinton_02_weight_space_hyperplane.png)\n\n\n\n\n\n\n\n$d_a^2+d_b^2$\n![why training works](/img/hinton_02_why_training_works_1.png)\n\n\n\nmarginmargin\n![margin](/img/hinton_02_margin.png)\n\ninput vector\n\n## \n\n![](/img/hinton_02_perceptron_xor.png)\n","source":"_posts/hinton-nnml-02.md","raw":"---\ntitle: Neural Network for Machine Learning - Lecture 02\ndate: 2017-05-25 13:26:33\ntags:\n    - \n    - deep learning\n---\n\n\n![Perceptron](/img/hinton_02_perceptron_gragh.png)\n\n<!-- more -->\n## Different neural network archs\n### Feed-forward neural network \n$1$deep\n![](/img/hinton_02_feed_forward_nn.png)\n\n### Recurrent network\nRNNRNN\n![RNN](/img/hinton_02_recurrent_nn.png)\n\nRNNmodeling squence[](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n![RNN modeling squences](/img/hinton_02_rnn_app.png)\n\n### Symmetrically connected network\nRNN\n\n## Percetron\n### \n\n- feature activation\n- feature\n- \n\n![](/img/hinton_02_perceptron_paradigm_for_pattern_recong.png)\n\nBinary threshold neuron${0,1}$$0$\n\n\n\n$$y=\\begin{cases}1, \\quad \\text{if} \\quad \\sum w_ix_i+b>0 \\\\ 0 \\quad \\text{otherwise}\\end{cases}$$\n\n\n- \n- $0$$x$$w$\n- 1$w$$x$\n\n\n\n### \n\n\nWeight Space\n\n$x^\\dagger w = 0$$x$$x$$0$\n\n![](/img/hinton_02_weight_space_hyperplane.png)\n\n\n\n\n\n\n\n$d_a^2+d_b^2$\n![why training works](/img/hinton_02_why_training_works_1.png)\n\n\n\nmarginmargin\n![margin](/img/hinton_02_margin.png)\n\ninput vector\n\n## \n\n![](/img/hinton_02_perceptron_xor.png)\n","slug":"hinton-nnml-02","published":1,"updated":"2018-10-27T07:16:52.397Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ly0025ae7bxo5xuz5p","content":"<p></p>\n<p><img src=\"/img/hinton_02_perceptron_gragh.png\" alt=\"Perceptron\"></p>\n<a id=\"more\"></a>\n<h2 id=\"Different-neural-network-archs\"><a href=\"#Different-neural-network-archs\" class=\"headerlink\" title=\"Different neural network archs\"></a>Different neural network archs</h2><h3 id=\"Feed-forward-neural-network-\"><a href=\"#Feed-forward-neural-network-\" class=\"headerlink\" title=\"Feed-forward neural network \"></a>Feed-forward neural network </h3><p>$1$deep<br><img src=\"/img/hinton_02_feed_forward_nn.png\" alt=\"\"></p>\n<h3 id=\"Recurrent-network\"><a href=\"#Recurrent-network\" class=\"headerlink\" title=\"Recurrent network\"></a>Recurrent network</h3><p>RNNRNN<br><img src=\"/img/hinton_02_recurrent_nn.png\" alt=\"RNN\"></p>\n<p>RNNmodeling squence<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" target=\"_blank\" rel=\"external\"></a><br><img src=\"/img/hinton_02_rnn_app.png\" alt=\"RNN modeling squences\"></p>\n<h3 id=\"Symmetrically-connected-network\"><a href=\"#Symmetrically-connected-network\" class=\"headerlink\" title=\"Symmetrically connected network\"></a>Symmetrically connected network</h3><p>RNN</p>\n<h2 id=\"Percetron\"><a href=\"#Percetron\" class=\"headerlink\" title=\"Percetron\"></a>Percetron</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>feature activation</li>\n<li>feature</li>\n<li></li>\n</ul>\n<p><img src=\"/img/hinton_02_perceptron_paradigm_for_pattern_recong.png\" alt=\"\"></p>\n<p>Binary threshold neuron${0,1}$$0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">y=\\begin{cases}1, \\quad \\text{if} \\quad \\sum w_ix_i+b>0 \\\\ 0 \\quad \\text{otherwise}\\end{cases}</script><p></p>\n<ul>\n<li></li>\n<li>$0$$x$$w$</li>\n<li>1$w$$x$</li>\n</ul>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>Weight Space</p>\n<p>$x^\\dagger w = 0$$x$$x$$0$</p>\n<p><img src=\"/img/hinton_02_weight_space_hyperplane.png\" alt=\"\"></p>\n<p></p>\n<p></p>\n<p></p>\n<p>$d_a^2+d_b^2$<br><img src=\"/img/hinton_02_why_training_works_1.png\" alt=\"why training works\"></p>\n<p></p>\n<p>marginmargin<br><img src=\"/img/hinton_02_margin.png\" alt=\"margin\"></p>\n<p>input vector</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><img src=\"/img/hinton_02_perceptron_xor.png\" alt=\"\"></p>\n","excerpt":"<p></p>\n<p><img src=\"/img/hinton_02_perceptron_gragh.png\" alt=\"Perceptron\"></p>","more":"<h2 id=\"Different-neural-network-archs\"><a href=\"#Different-neural-network-archs\" class=\"headerlink\" title=\"Different neural network archs\"></a>Different neural network archs</h2><h3 id=\"Feed-forward-neural-network-\"><a href=\"#Feed-forward-neural-network-\" class=\"headerlink\" title=\"Feed-forward neural network \"></a>Feed-forward neural network </h3><p>$1$deep<br><img src=\"/img/hinton_02_feed_forward_nn.png\" alt=\"\"></p>\n<h3 id=\"Recurrent-network\"><a href=\"#Recurrent-network\" class=\"headerlink\" title=\"Recurrent network\"></a>Recurrent network</h3><p>RNNRNN<br><img src=\"/img/hinton_02_recurrent_nn.png\" alt=\"RNN\"></p>\n<p>RNNmodeling squence<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\"></a><br><img src=\"/img/hinton_02_rnn_app.png\" alt=\"RNN modeling squences\"></p>\n<h3 id=\"Symmetrically-connected-network\"><a href=\"#Symmetrically-connected-network\" class=\"headerlink\" title=\"Symmetrically connected network\"></a>Symmetrically connected network</h3><p>RNN</p>\n<h2 id=\"Percetron\"><a href=\"#Percetron\" class=\"headerlink\" title=\"Percetron\"></a>Percetron</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>feature activation</li>\n<li>feature</li>\n<li></li>\n</ul>\n<p><img src=\"/img/hinton_02_perceptron_paradigm_for_pattern_recong.png\" alt=\"\"></p>\n<p>Binary threshold neuron${0,1}$$0$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">y=\\begin{cases}1, \\quad \\text{if} \\quad \\sum w_ix_i+b>0 \\\\ 0 \\quad \\text{otherwise}\\end{cases}</script><p></p>\n<ul>\n<li></li>\n<li>$0$$x$$w$</li>\n<li>1$w$$x$</li>\n</ul>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>Weight Space</p>\n<p>$x^\\dagger w = 0$$x$$x$$0$</p>\n<p><img src=\"/img/hinton_02_weight_space_hyperplane.png\" alt=\"\"></p>\n<p></p>\n<p></p>\n<p></p>\n<p>$d_a^2+d_b^2$<br><img src=\"/img/hinton_02_why_training_works_1.png\" alt=\"why training works\"></p>\n<p></p>\n<p>marginmargin<br><img src=\"/img/hinton_02_margin.png\" alt=\"margin\"></p>\n<p>input vector</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br><img src=\"/img/hinton_02_perceptron_xor.png\" alt=\"\"></p>"},{"title":"Neural Network for Machine Learning - Lecture 06 ","date":"2017-06-25T05:48:31.000Z","_content":"SGDfull batch GDmini batch SGDtrickPCAXavierGDHinton[](http://sebastianruder.com/optimizing-gradient-descent/index.html)[](https://arxiv.org/abs/1609.04747)PyTorch\n\n\n\n![](/img/contours_evaluation_optimizers.gif)\n<!-- more -->\n\n## Momentum\nGDmomentumGD\n\n$\\epsilon$$\\alpha$momentum\n$$\\Delta w_t = v_t = \\alpha v_{t-1} - \\epsilon g_t = \\Delta w_t - \\epsilon g_t$$\n\nmomentum$g$\n$$v_t = \\alpha(v_{t-1} + \\frac{\\epsilon g}{1-\\alpha}) - \\frac{\\epsilon g}{1-\\alpha}$$\n\n$\\alpha < 0$$t = \\infty$\n$$v_\\infty = -\\frac{\\epsilon}{1-\\alpha}g$$\n\n$\\frac{1}{1-\\alpha}$$\\alpha=0.99$$100$\n\nHintonmomentum$0.5$\n\nNesterovNesterov\n\n![Nesterov](/img/hinton_06_nesterov_momentum.png)\n\n## Adaptive Learning Rate\nlayerlayer\n\n$w_{ij}$$0.95$$0.05$$1$$1$\n![Different learning rate gain](/img/hinton_06_learningrate.png)\n\ntrickbatch sizemomentum\n\n![Tricks for adaptive lr](/img/hinton_06_tricks_for_adaptive_lr.png)\n\n## RMSProp\nrpropstep sizefull batch GDRMSPropmini batch SGDrprop\n\nmean squareRMSMS\n\n$$\\text{MeanSquare}(w, t) = 0.9 \\text{MeanSquare}(w, t-1) + 0.1g_t^2$$\n\nMean Square\n\nRMSProp\n![Otehr RMSProp](/img/hinton_06_rmsprop_improvement.png)\n\n## \n- full batch GDLBFGSadaptive learning raterprop\n- mini batch SGDmomentmumRMSProp\n\n\n![](/img/hinton_06_summary.png)\n\n## Modern SGD\n\nHintonModern C++Modern SGD\n\n- loss\n- loss\n- Hinton\n- \n\n![](/img/hinton_06_maanmian.jpg)\n\n### Adagrad\n[Adagrad](http://jmlr.org/papers/v12/duchi11a.html)AdaAdaptive$t$$i$$g_{i}$\n$$g_{i} = \\bigtriangledown_{\\theta_i} J(\\theta)$$\n\nAdagrad\n$$\\hat{g_i} = \\frac{1}{\\sqrt{G_i+\\epsilon}}g_i$$\n\n$G_i$$t$$\\theta_i$$g_i$\n\n$\\odot$element-wise product$G_t = g_t \\odot g_t$\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t+\\epsilon}}\\odot g_t$$\n\nPyTorch\n\n``` py\n# for each gradient of parameters:\n# addcmul(t, alpha, t1, t2): t = t1*t2*alpha + t\n# let epsilon = 1E-10\nstate['sum'].addcmul_(1, grad, grad)   #  G\nstd = state['sum'].sqrt().add_(1e-10)  #  \\sqrt(G)\np.data.addcdiv_(-clr, grad, std)       # \n```\n\nAdagrad$0.01$AdagradPyTorch\n\nAdagrad$G_t$Adadelta\n\n### Adadelta\n[Adadelta](https://arxiv.org/abs/1212.5701)$g$$w$$\\gamma$$0.9$$E[g_t^2]$\n\n$$E[g_t^2] = \\gamma E[g_{t-1}^2] + (1-\\gamma)g_t^2$$\n\n$\\sqrt{E[g_t^2]}$$g$RMSHintonRMSprop\n\n$$\\hat{g}_t = \\frac{1}{\\text{RMS}[g]}g_t$$\n\n$\\theta$$\\Delta \\theta$$\\Delta \\theta$$\\text{RMS}[\\Delta \\theta]$$\\eta$\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\text{RMS}[\\Delta \\theta]}{\\text{RMS}[g]}g_t$$\n\nPyTorch`lr`$1.0$`MS`$E[x^2]$$\\text{RMS}[x] = \\sqrt{\\text{MS}[x]+\\epsilon}$\n``` py\n# update: MS[g] = MS[g]*\\rho + g*g*(1-\\rho)\nsquare_avg.mul_(rho).addcmul_(1 - rho, grad, grad)\n# current RMS[g] = sqrt(MS[g] + \\epsilon)\nstd = square_avg.add(eps).sqrt_()\n# \\Delta \\theta = RMS[\\Delta \\theta] / RMS[g]) * g\ndelta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n# update parameter: \\theta -= lr * \\Delta \\theta\np.data.add_(-group['lr'], delta)\n# update MS[\\Delta \\theta] = MS[\\Delta \\theta] * \\rho + \\Delta \\theta^2 * (1-\\rho)\nacc_delta.mul_(rho).addcmul_(1 - rho, delta, delta)\n```\n\n### Adam\n[Adaptive momen EstimationAdam](https://arxiv.org/abs/1412.6980)Adam\n$$\\begin{aligned}m_t&=\\beta_1 m_{t-1}+(1-\\beta_1)g_t\\\\v_t&=\\beta_2 v_{t-1}+(1-\\beta_2)g_t^2\\end{aligned}$$\n\nbiase towards $0$\n$$\\begin{aligned}\\hat{m} &= \\frac{m}{1-\\beta_1}\\\\ \\hat{v}&=\\frac{v}{1-\\beta_2}\\end{aligned}$$\n\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t} + \\epsilon}}\\hat{m_t}$$\n\n$\\beta_1 = 0.9$$\\beta_2=0.999$$\\epsilon=10^{-8}$\n\nPyTorch\n$$\\Delta \\theta = \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta \\frac{m_t}{\\sqrt{v_t}}$$\n\n$\\text{step_size} =  \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta$$\\beta$$\\beta_t = \\beta_0^t$\n\n``` py\n# exp_avg is `m`: expected average of g\nexp_avg.mul_(beta1).add_(1 - beta1, grad)\n# exp_avg_sq is `v`: expected average of g's square\nexp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n# \\sqrt{v_t + \\epsilon}\ndenom = exp_avg_sq.sqrt().add_(group['eps'])\n\n# 1 - \\beta_1^t\nbias_correction1 = 1 - beta1 ** state['step']\n# 1 - \\beta_2^t\nbias_correction2 = 1 - beta2 ** state['step']\n# get step_size\nstep_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n# delta = -step_size * m / sqrt(v)\np.data.addcdiv_(-step_size, exp_avg, denom)\n```\n\n### AdaMax\nAdam$g$$2$$\\sqrt{\\hat{v_t}}$$g$Normalization$p$$1$$2$$p$\n\n[AdaMax](https://arxiv.org/abs/1412.6980)$\\hat{v_t}$$u_t$\n$$u_t = \\beta_2^\\infty u_{t-1} + (1-\\beta_2^\\infty) g_t^\\infty$$\n\n$u\\_t$$u\\_t$$u\\_{t-1}$\n\n![Adamaxut](/img/hinton_06_adamax.png)\n\n\n$$\\theta_{t+1} = \\theta_t -\\frac{\\eta}{u_t}\\hat{m}_t$$\n\nPyTorch\n``` py\n# Update biased first moment estimate, which is \\hat{m}_t\nexp_avg.mul_(beta1).add_(1 - beta1, grad)\n#  max(A, B) \n# Update the exponentially weighted infinity norm.\nnorm_buf = torch.cat([\n    exp_inf.mul_(beta2).unsqueeze(0),\n    grad.abs().add_(eps).unsqueeze_(0)\n], 0)\n##  exp_inf  g~\ntorch.max(norm_buf, 0, keepdim=False, out=(exp_inf, exp_inf.new().long()))\n\n## beta1 correction\nbias_correction = 1 - beta1 ** state['step']\nclr = group['lr'] / bias_correction\n\np.data.addcdiv_(-clr, exp_avg, exp_inf)\n```\n","source":"_posts/hinton-nnml-06.md","raw":"---\ntitle: Neural Network for Machine Learning - Lecture 06 \ndate: 2017-06-25 13:48:31\ntags:\n    - \n    - deep learning\n    - pytorch\n---\nSGDfull batch GDmini batch SGDtrickPCAXavierGDHinton[](http://sebastianruder.com/optimizing-gradient-descent/index.html)[](https://arxiv.org/abs/1609.04747)PyTorch\n\n\n\n![](/img/contours_evaluation_optimizers.gif)\n<!-- more -->\n\n## Momentum\nGDmomentumGD\n\n$\\epsilon$$\\alpha$momentum\n$$\\Delta w_t = v_t = \\alpha v_{t-1} - \\epsilon g_t = \\Delta w_t - \\epsilon g_t$$\n\nmomentum$g$\n$$v_t = \\alpha(v_{t-1} + \\frac{\\epsilon g}{1-\\alpha}) - \\frac{\\epsilon g}{1-\\alpha}$$\n\n$\\alpha < 0$$t = \\infty$\n$$v_\\infty = -\\frac{\\epsilon}{1-\\alpha}g$$\n\n$\\frac{1}{1-\\alpha}$$\\alpha=0.99$$100$\n\nHintonmomentum$0.5$\n\nNesterovNesterov\n\n![Nesterov](/img/hinton_06_nesterov_momentum.png)\n\n## Adaptive Learning Rate\nlayerlayer\n\n$w_{ij}$$0.95$$0.05$$1$$1$\n![Different learning rate gain](/img/hinton_06_learningrate.png)\n\ntrickbatch sizemomentum\n\n![Tricks for adaptive lr](/img/hinton_06_tricks_for_adaptive_lr.png)\n\n## RMSProp\nrpropstep sizefull batch GDRMSPropmini batch SGDrprop\n\nmean squareRMSMS\n\n$$\\text{MeanSquare}(w, t) = 0.9 \\text{MeanSquare}(w, t-1) + 0.1g_t^2$$\n\nMean Square\n\nRMSProp\n![Otehr RMSProp](/img/hinton_06_rmsprop_improvement.png)\n\n## \n- full batch GDLBFGSadaptive learning raterprop\n- mini batch SGDmomentmumRMSProp\n\n\n![](/img/hinton_06_summary.png)\n\n## Modern SGD\n\nHintonModern C++Modern SGD\n\n- loss\n- loss\n- Hinton\n- \n\n![](/img/hinton_06_maanmian.jpg)\n\n### Adagrad\n[Adagrad](http://jmlr.org/papers/v12/duchi11a.html)AdaAdaptive$t$$i$$g_{i}$\n$$g_{i} = \\bigtriangledown_{\\theta_i} J(\\theta)$$\n\nAdagrad\n$$\\hat{g_i} = \\frac{1}{\\sqrt{G_i+\\epsilon}}g_i$$\n\n$G_i$$t$$\\theta_i$$g_i$\n\n$\\odot$element-wise product$G_t = g_t \\odot g_t$\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t+\\epsilon}}\\odot g_t$$\n\nPyTorch\n\n``` py\n# for each gradient of parameters:\n# addcmul(t, alpha, t1, t2): t = t1*t2*alpha + t\n# let epsilon = 1E-10\nstate['sum'].addcmul_(1, grad, grad)   #  G\nstd = state['sum'].sqrt().add_(1e-10)  #  \\sqrt(G)\np.data.addcdiv_(-clr, grad, std)       # \n```\n\nAdagrad$0.01$AdagradPyTorch\n\nAdagrad$G_t$Adadelta\n\n### Adadelta\n[Adadelta](https://arxiv.org/abs/1212.5701)$g$$w$$\\gamma$$0.9$$E[g_t^2]$\n\n$$E[g_t^2] = \\gamma E[g_{t-1}^2] + (1-\\gamma)g_t^2$$\n\n$\\sqrt{E[g_t^2]}$$g$RMSHintonRMSprop\n\n$$\\hat{g}_t = \\frac{1}{\\text{RMS}[g]}g_t$$\n\n$\\theta$$\\Delta \\theta$$\\Delta \\theta$$\\text{RMS}[\\Delta \\theta]$$\\eta$\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\text{RMS}[\\Delta \\theta]}{\\text{RMS}[g]}g_t$$\n\nPyTorch`lr`$1.0$`MS`$E[x^2]$$\\text{RMS}[x] = \\sqrt{\\text{MS}[x]+\\epsilon}$\n``` py\n# update: MS[g] = MS[g]*\\rho + g*g*(1-\\rho)\nsquare_avg.mul_(rho).addcmul_(1 - rho, grad, grad)\n# current RMS[g] = sqrt(MS[g] + \\epsilon)\nstd = square_avg.add(eps).sqrt_()\n# \\Delta \\theta = RMS[\\Delta \\theta] / RMS[g]) * g\ndelta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)\n# update parameter: \\theta -= lr * \\Delta \\theta\np.data.add_(-group['lr'], delta)\n# update MS[\\Delta \\theta] = MS[\\Delta \\theta] * \\rho + \\Delta \\theta^2 * (1-\\rho)\nacc_delta.mul_(rho).addcmul_(1 - rho, delta, delta)\n```\n\n### Adam\n[Adaptive momen EstimationAdam](https://arxiv.org/abs/1412.6980)Adam\n$$\\begin{aligned}m_t&=\\beta_1 m_{t-1}+(1-\\beta_1)g_t\\\\v_t&=\\beta_2 v_{t-1}+(1-\\beta_2)g_t^2\\end{aligned}$$\n\nbiase towards $0$\n$$\\begin{aligned}\\hat{m} &= \\frac{m}{1-\\beta_1}\\\\ \\hat{v}&=\\frac{v}{1-\\beta_2}\\end{aligned}$$\n\n\n$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t} + \\epsilon}}\\hat{m_t}$$\n\n$\\beta_1 = 0.9$$\\beta_2=0.999$$\\epsilon=10^{-8}$\n\nPyTorch\n$$\\Delta \\theta = \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta \\frac{m_t}{\\sqrt{v_t}}$$\n\n$\\text{step_size} =  \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta$$\\beta$$\\beta_t = \\beta_0^t$\n\n``` py\n# exp_avg is `m`: expected average of g\nexp_avg.mul_(beta1).add_(1 - beta1, grad)\n# exp_avg_sq is `v`: expected average of g's square\nexp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n\n# \\sqrt{v_t + \\epsilon}\ndenom = exp_avg_sq.sqrt().add_(group['eps'])\n\n# 1 - \\beta_1^t\nbias_correction1 = 1 - beta1 ** state['step']\n# 1 - \\beta_2^t\nbias_correction2 = 1 - beta2 ** state['step']\n# get step_size\nstep_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n# delta = -step_size * m / sqrt(v)\np.data.addcdiv_(-step_size, exp_avg, denom)\n```\n\n### AdaMax\nAdam$g$$2$$\\sqrt{\\hat{v_t}}$$g$Normalization$p$$1$$2$$p$\n\n[AdaMax](https://arxiv.org/abs/1412.6980)$\\hat{v_t}$$u_t$\n$$u_t = \\beta_2^\\infty u_{t-1} + (1-\\beta_2^\\infty) g_t^\\infty$$\n\n$u\\_t$$u\\_t$$u\\_{t-1}$\n\n![Adamaxut](/img/hinton_06_adamax.png)\n\n\n$$\\theta_{t+1} = \\theta_t -\\frac{\\eta}{u_t}\\hat{m}_t$$\n\nPyTorch\n``` py\n# Update biased first moment estimate, which is \\hat{m}_t\nexp_avg.mul_(beta1).add_(1 - beta1, grad)\n#  max(A, B) \n# Update the exponentially weighted infinity norm.\nnorm_buf = torch.cat([\n    exp_inf.mul_(beta2).unsqueeze(0),\n    grad.abs().add_(eps).unsqueeze_(0)\n], 0)\n##  exp_inf  g~\ntorch.max(norm_buf, 0, keepdim=False, out=(exp_inf, exp_inf.new().long()))\n\n## beta1 correction\nbias_correction = 1 - beta1 ** state['step']\nclr = group['lr'] / bias_correction\n\np.data.addcdiv_(-clr, exp_avg, exp_inf)\n```\n","slug":"hinton-nnml-06","published":1,"updated":"2018-10-27T07:16:52.398Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8m00027ae7bav66cqr4","content":"<p>SGDfull batch GDmini batch SGDtrickPCAXavierGDHinton<a href=\"http://sebastianruder.com/optimizing-gradient-descent/index.html\" target=\"_blank\" rel=\"external\"></a><a href=\"https://arxiv.org/abs/1609.04747\" target=\"_blank\" rel=\"external\"></a>PyTorch</p>\n<p></p>\n<p><img src=\"/img/contours_evaluation_optimizers.gif\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h2><p>GDmomentumGD</p>\n<p>$\\epsilon$$\\alpha$momentum</p>\n<script type=\"math/tex; mode=display\">\\Delta w_t = v_t = \\alpha v_{t-1} - \\epsilon g_t = \\Delta w_t - \\epsilon g_t</script><p>momentum$g$</p>\n<script type=\"math/tex; mode=display\">v_t = \\alpha(v_{t-1} + \\frac{\\epsilon g}{1-\\alpha}) - \\frac{\\epsilon g}{1-\\alpha}</script><p>$\\alpha &lt; 0$$t = \\infty$</p>\n<script type=\"math/tex; mode=display\">v_\\infty = -\\frac{\\epsilon}{1-\\alpha}g</script><p>$\\frac{1}{1-\\alpha}$$\\alpha=0.99$$100$</p>\n<p>Hintonmomentum$0.5$</p>\n<p>NesterovNesterov</p>\n<p><img src=\"/img/hinton_06_nesterov_momentum.png\" alt=\"Nesterov\"></p>\n<h2 id=\"Adaptive-Learning-Rate\"><a href=\"#Adaptive-Learning-Rate\" class=\"headerlink\" title=\"Adaptive Learning Rate\"></a>Adaptive Learning Rate</h2><p>layerlayer</p>\n<p>$w_{ij}$$0.95$$0.05$$1$$1$<br><img src=\"/img/hinton_06_learningrate.png\" alt=\"Different learning rate gain\"></p>\n<p>trickbatch sizemomentum</p>\n<p><img src=\"/img/hinton_06_tricks_for_adaptive_lr.png\" alt=\"Tricks for adaptive lr\"></p>\n<h2 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h2><p>rpropstep sizefull batch GDRMSPropmini batch SGDrprop</p>\n<p>mean squareRMSMS</p>\n<script type=\"math/tex; mode=display\">\\text{MeanSquare}(w, t) = 0.9 \\text{MeanSquare}(w, t-1) + 0.1g_t^2</script><p>Mean Square</p>\n<p>RMSProp<br><img src=\"/img/hinton_06_rmsprop_improvement.png\" alt=\"Otehr RMSProp\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>full batch GDLBFGSadaptive learning raterprop</li>\n<li>mini batch SGDmomentmumRMSProp</li>\n</ul>\n<p><br><img src=\"/img/hinton_06_summary.png\" alt=\"\"></p>\n<h2 id=\"Modern-SGD\"><a href=\"#Modern-SGD\" class=\"headerlink\" title=\"Modern SGD\"></a>Modern SGD</h2><p>HintonModern C++Modern SGD</p>\n<ul>\n<li>loss</li>\n<li>loss</li>\n<li>Hinton</li>\n<li></li>\n</ul>\n<p><img src=\"/img/hinton_06_maanmian.jpg\" alt=\"\"></p>\n<h3 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h3><p><a href=\"http://jmlr.org/papers/v12/duchi11a.html\" target=\"_blank\" rel=\"external\">Adagrad</a>AdaAdaptive$t$$i$$g_{i}$</p>\n<script type=\"math/tex; mode=display\">g_{i} = \\bigtriangledown_{\\theta_i} J(\\theta)</script><p>Adagrad</p>\n<script type=\"math/tex; mode=display\">\\hat{g_i} = \\frac{1}{\\sqrt{G_i+\\epsilon}}g_i</script><p>$G_i$$t$$\\theta_i$$g_i$</p>\n<p>$\\odot$element-wise product$G_t = g_t \\odot g_t$</p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t+\\epsilon}}\\odot g_t</script><p>PyTorch</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># for each gradient of parameters:</span></div><div class=\"line\"><span class=\"comment\"># addcmul(t, alpha, t1, t2): t = t1*t2*alpha + t</span></div><div class=\"line\"><span class=\"comment\"># let epsilon = 1E-10</span></div><div class=\"line\">state[<span class=\"string\">'sum'</span>].addcmul_(<span class=\"number\">1</span>, grad, grad)   <span class=\"comment\">#  G</span></div><div class=\"line\">std = state[<span class=\"string\">'sum'</span>].sqrt().add_(<span class=\"number\">1e-10</span>)  <span class=\"comment\">#  \\sqrt(G)</span></div><div class=\"line\">p.data.addcdiv_(-clr, grad, std)       <span class=\"comment\"># </span></div></pre></td></tr></table></figure>\n<p>Adagrad$0.01$AdagradPyTorch</p>\n<p>Adagrad$G_t$Adadelta</p>\n<h3 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h3><p><a href=\"https://arxiv.org/abs/1212.5701\" target=\"_blank\" rel=\"external\">Adadelta</a>$g$$w$$\\gamma$$0.9$$E[g_t^2]$</p>\n<script type=\"math/tex; mode=display\">E[g_t^2] = \\gamma E[g_{t-1}^2] + (1-\\gamma)g_t^2</script><p>$\\sqrt{E[g_t^2]}$$g$RMSHintonRMSprop</p>\n<script type=\"math/tex; mode=display\">\\hat{g}_t = \\frac{1}{\\text{RMS}[g]}g_t</script><p>$\\theta$$\\Delta \\theta$$\\Delta \\theta$$\\text{RMS}[\\Delta \\theta]$$\\eta$</p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\text{RMS}[\\Delta \\theta]}{\\text{RMS}[g]}g_t</script><p>PyTorch<code>lr</code>$1.0$<code>MS</code>$E[x^2]$$\\text{RMS}[x] = \\sqrt{\\text{MS}[x]+\\epsilon}$<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># update: MS[g] = MS[g]*\\rho + g*g*(1-\\rho)</span></div><div class=\"line\">square_avg.mul_(rho).addcmul_(<span class=\"number\">1</span> - rho, grad, grad)</div><div class=\"line\"><span class=\"comment\"># current RMS[g] = sqrt(MS[g] + \\epsilon)</span></div><div class=\"line\">std = square_avg.add(eps).sqrt_()</div><div class=\"line\"><span class=\"comment\"># \\Delta \\theta = RMS[\\Delta \\theta] / RMS[g]) * g</span></div><div class=\"line\">delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)</div><div class=\"line\"><span class=\"comment\"># update parameter: \\theta -= lr * \\Delta \\theta</span></div><div class=\"line\">p.data.add_(-group[<span class=\"string\">'lr'</span>], delta)</div><div class=\"line\"><span class=\"comment\"># update MS[\\Delta \\theta] = MS[\\Delta \\theta] * \\rho + \\Delta \\theta^2 * (1-\\rho)</span></div><div class=\"line\">acc_delta.mul_(rho).addcmul_(<span class=\"number\">1</span> - rho, delta, delta)</div></pre></td></tr></table></figure></p>\n<h3 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h3><p><a href=\"https://arxiv.org/abs/1412.6980\" target=\"_blank\" rel=\"external\">Adaptive momen EstimationAdam</a>Adam</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}m_t&=\\beta_1 m_{t-1}+(1-\\beta_1)g_t\\\\v_t&=\\beta_2 v_{t-1}+(1-\\beta_2)g_t^2\\end{aligned}</script><p>biase towards $0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\hat{m} &= \\frac{m}{1-\\beta_1}\\\\ \\hat{v}&=\\frac{v}{1-\\beta_2}\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t} + \\epsilon}}\\hat{m_t}</script><p>$\\beta_1 = 0.9$$\\beta_2=0.999$$\\epsilon=10^{-8}$</p>\n<p>PyTorch</p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta = \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta \\frac{m_t}{\\sqrt{v_t}}</script><p>$\\text{step_size} =  \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta$$\\beta$$\\beta_t = \\beta_0^t$</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># exp_avg is `m`: expected average of g</span></div><div class=\"line\">exp_avg.mul_(beta1).add_(<span class=\"number\">1</span> - beta1, grad)</div><div class=\"line\"><span class=\"comment\"># exp_avg_sq is `v`: expected average of g's square</span></div><div class=\"line\">exp_avg_sq.mul_(beta2).addcmul_(<span class=\"number\">1</span> - beta2, grad, grad)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># \\sqrt&#123;v_t + \\epsilon&#125;</span></div><div class=\"line\">denom = exp_avg_sq.sqrt().add_(group[<span class=\"string\">'eps'</span>])</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 1 - \\beta_1^t</span></div><div class=\"line\">bias_correction1 = <span class=\"number\">1</span> - beta1 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\"><span class=\"comment\"># 1 - \\beta_2^t</span></div><div class=\"line\">bias_correction2 = <span class=\"number\">1</span> - beta2 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\"><span class=\"comment\"># get step_size</span></div><div class=\"line\">step_size = group[<span class=\"string\">'lr'</span>] * math.sqrt(bias_correction2) / bias_correction1</div><div class=\"line\"><span class=\"comment\"># delta = -step_size * m / sqrt(v)</span></div><div class=\"line\">p.data.addcdiv_(-step_size, exp_avg, denom)</div></pre></td></tr></table></figure>\n<h3 id=\"AdaMax\"><a href=\"#AdaMax\" class=\"headerlink\" title=\"AdaMax\"></a>AdaMax</h3><p>Adam$g$$2$$\\sqrt{\\hat{v_t}}$$g$Normalization$p$$1$$2$$p$</p>\n<p><a href=\"https://arxiv.org/abs/1412.6980\" target=\"_blank\" rel=\"external\">AdaMax</a>$\\hat{v_t}$$u_t$</p>\n<script type=\"math/tex; mode=display\">u_t = \\beta_2^\\infty u_{t-1} + (1-\\beta_2^\\infty) g_t^\\infty</script><p>$u_t$$u_t$$u_{t-1}$</p>\n<p><img src=\"/img/hinton_06_adamax.png\" alt=\"Adamaxut\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t -\\frac{\\eta}{u_t}\\hat{m}_t</script><p>PyTorch<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Update biased first moment estimate, which is \\hat&#123;m&#125;_t</span></div><div class=\"line\">exp_avg.mul_(beta1).add_(<span class=\"number\">1</span> - beta1, grad)</div><div class=\"line\"><span class=\"comment\">#  max(A, B) </span></div><div class=\"line\"><span class=\"comment\"># Update the exponentially weighted infinity norm.</span></div><div class=\"line\">norm_buf = torch.cat([</div><div class=\"line\">    exp_inf.mul_(beta2).unsqueeze(<span class=\"number\">0</span>),</div><div class=\"line\">    grad.abs().add_(eps).unsqueeze_(<span class=\"number\">0</span>)</div><div class=\"line\">], <span class=\"number\">0</span>)</div><div class=\"line\"><span class=\"comment\">##  exp_inf  g~</span></div><div class=\"line\">torch.max(norm_buf, <span class=\"number\">0</span>, keepdim=<span class=\"keyword\">False</span>, out=(exp_inf, exp_inf.new().long()))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## beta1 correction</span></div><div class=\"line\">bias_correction = <span class=\"number\">1</span> - beta1 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\">clr = group[<span class=\"string\">'lr'</span>] / bias_correction</div><div class=\"line\"></div><div class=\"line\">p.data.addcdiv_(-clr, exp_avg, exp_inf)</div></pre></td></tr></table></figure></p>\n","excerpt":"<p>SGDfull batch GDmini batch SGDtrickPCAXavierGDHinton<a href=\"http://sebastianruder.com/optimizing-gradient-descent/index.html\"></a><a href=\"https://arxiv.org/abs/1609.04747\"></a>PyTorch</p>\n<p></p>\n<p><img src=\"/img/contours_evaluation_optimizers.gif\" alt=\"\"><br>","more":"</p>\n<h2 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Momentum\"></a>Momentum</h2><p>GDmomentumGD</p>\n<p>$\\epsilon$$\\alpha$momentum</p>\n<script type=\"math/tex; mode=display\">\\Delta w_t = v_t = \\alpha v_{t-1} - \\epsilon g_t = \\Delta w_t - \\epsilon g_t</script><p>momentum$g$</p>\n<script type=\"math/tex; mode=display\">v_t = \\alpha(v_{t-1} + \\frac{\\epsilon g}{1-\\alpha}) - \\frac{\\epsilon g}{1-\\alpha}</script><p>$\\alpha &lt; 0$$t = \\infty$</p>\n<script type=\"math/tex; mode=display\">v_\\infty = -\\frac{\\epsilon}{1-\\alpha}g</script><p>$\\frac{1}{1-\\alpha}$$\\alpha=0.99$$100$</p>\n<p>Hintonmomentum$0.5$</p>\n<p>NesterovNesterov</p>\n<p><img src=\"/img/hinton_06_nesterov_momentum.png\" alt=\"Nesterov\"></p>\n<h2 id=\"Adaptive-Learning-Rate\"><a href=\"#Adaptive-Learning-Rate\" class=\"headerlink\" title=\"Adaptive Learning Rate\"></a>Adaptive Learning Rate</h2><p>layerlayer</p>\n<p>$w_{ij}$$0.95$$0.05$$1$$1$<br><img src=\"/img/hinton_06_learningrate.png\" alt=\"Different learning rate gain\"></p>\n<p>trickbatch sizemomentum</p>\n<p><img src=\"/img/hinton_06_tricks_for_adaptive_lr.png\" alt=\"Tricks for adaptive lr\"></p>\n<h2 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h2><p>rpropstep sizefull batch GDRMSPropmini batch SGDrprop</p>\n<p>mean squareRMSMS</p>\n<script type=\"math/tex; mode=display\">\\text{MeanSquare}(w, t) = 0.9 \\text{MeanSquare}(w, t-1) + 0.1g_t^2</script><p>Mean Square</p>\n<p>RMSProp<br><img src=\"/img/hinton_06_rmsprop_improvement.png\" alt=\"Otehr RMSProp\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>full batch GDLBFGSadaptive learning raterprop</li>\n<li>mini batch SGDmomentmumRMSProp</li>\n</ul>\n<p><br><img src=\"/img/hinton_06_summary.png\" alt=\"\"></p>\n<h2 id=\"Modern-SGD\"><a href=\"#Modern-SGD\" class=\"headerlink\" title=\"Modern SGD\"></a>Modern SGD</h2><p>HintonModern C++Modern SGD</p>\n<ul>\n<li>loss</li>\n<li>loss</li>\n<li>Hinton</li>\n<li></li>\n</ul>\n<p><img src=\"/img/hinton_06_maanmian.jpg\" alt=\"\"></p>\n<h3 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h3><p><a href=\"http://jmlr.org/papers/v12/duchi11a.html\">Adagrad</a>AdaAdaptive$t$$i$$g_{i}$</p>\n<script type=\"math/tex; mode=display\">g_{i} = \\bigtriangledown_{\\theta_i} J(\\theta)</script><p>Adagrad</p>\n<script type=\"math/tex; mode=display\">\\hat{g_i} = \\frac{1}{\\sqrt{G_i+\\epsilon}}g_i</script><p>$G_i$$t$$\\theta_i$$g_i$</p>\n<p>$\\odot$element-wise product$G_t = g_t \\odot g_t$</p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t+\\epsilon}}\\odot g_t</script><p>PyTorch</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># for each gradient of parameters:</span></div><div class=\"line\"><span class=\"comment\"># addcmul(t, alpha, t1, t2): t = t1*t2*alpha + t</span></div><div class=\"line\"><span class=\"comment\"># let epsilon = 1E-10</span></div><div class=\"line\">state[<span class=\"string\">'sum'</span>].addcmul_(<span class=\"number\">1</span>, grad, grad)   <span class=\"comment\">#  G</span></div><div class=\"line\">std = state[<span class=\"string\">'sum'</span>].sqrt().add_(<span class=\"number\">1e-10</span>)  <span class=\"comment\">#  \\sqrt(G)</span></div><div class=\"line\">p.data.addcdiv_(-clr, grad, std)       <span class=\"comment\"># </span></div></pre></td></tr></table></figure>\n<p>Adagrad$0.01$AdagradPyTorch</p>\n<p>Adagrad$G_t$Adadelta</p>\n<h3 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h3><p><a href=\"https://arxiv.org/abs/1212.5701\">Adadelta</a>$g$$w$$\\gamma$$0.9$$E[g_t^2]$</p>\n<script type=\"math/tex; mode=display\">E[g_t^2] = \\gamma E[g_{t-1}^2] + (1-\\gamma)g_t^2</script><p>$\\sqrt{E[g_t^2]}$$g$RMSHintonRMSprop</p>\n<script type=\"math/tex; mode=display\">\\hat{g}_t = \\frac{1}{\\text{RMS}[g]}g_t</script><p>$\\theta$$\\Delta \\theta$$\\Delta \\theta$$\\text{RMS}[\\Delta \\theta]$$\\eta$</p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\text{RMS}[\\Delta \\theta]}{\\text{RMS}[g]}g_t</script><p>PyTorch<code>lr</code>$1.0$<code>MS</code>$E[x^2]$$\\text{RMS}[x] = \\sqrt{\\text{MS}[x]+\\epsilon}$<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># update: MS[g] = MS[g]*\\rho + g*g*(1-\\rho)</span></div><div class=\"line\">square_avg.mul_(rho).addcmul_(<span class=\"number\">1</span> - rho, grad, grad)</div><div class=\"line\"><span class=\"comment\"># current RMS[g] = sqrt(MS[g] + \\epsilon)</span></div><div class=\"line\">std = square_avg.add(eps).sqrt_()</div><div class=\"line\"><span class=\"comment\"># \\Delta \\theta = RMS[\\Delta \\theta] / RMS[g]) * g</span></div><div class=\"line\">delta = acc_delta.add(eps).sqrt_().div_(std).mul_(grad)</div><div class=\"line\"><span class=\"comment\"># update parameter: \\theta -= lr * \\Delta \\theta</span></div><div class=\"line\">p.data.add_(-group[<span class=\"string\">'lr'</span>], delta)</div><div class=\"line\"><span class=\"comment\"># update MS[\\Delta \\theta] = MS[\\Delta \\theta] * \\rho + \\Delta \\theta^2 * (1-\\rho)</span></div><div class=\"line\">acc_delta.mul_(rho).addcmul_(<span class=\"number\">1</span> - rho, delta, delta)</div></pre></td></tr></table></figure></p>\n<h3 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h3><p><a href=\"https://arxiv.org/abs/1412.6980\">Adaptive momen EstimationAdam</a>Adam</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}m_t&=\\beta_1 m_{t-1}+(1-\\beta_1)g_t\\\\v_t&=\\beta_2 v_{t-1}+(1-\\beta_2)g_t^2\\end{aligned}</script><p>biase towards $0$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\hat{m} &= \\frac{m}{1-\\beta_1}\\\\ \\hat{v}&=\\frac{v}{1-\\beta_2}\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t} + \\epsilon}}\\hat{m_t}</script><p>$\\beta_1 = 0.9$$\\beta_2=0.999$$\\epsilon=10^{-8}$</p>\n<p>PyTorch</p>\n<script type=\"math/tex; mode=display\">\\Delta \\theta = \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta \\frac{m_t}{\\sqrt{v_t}}</script><p>$\\text{step_size} =  \\frac{\\sqrt{1-\\beta_2}}{1-\\beta_1}\\eta$$\\beta$$\\beta_t = \\beta_0^t$</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># exp_avg is `m`: expected average of g</span></div><div class=\"line\">exp_avg.mul_(beta1).add_(<span class=\"number\">1</span> - beta1, grad)</div><div class=\"line\"><span class=\"comment\"># exp_avg_sq is `v`: expected average of g's square</span></div><div class=\"line\">exp_avg_sq.mul_(beta2).addcmul_(<span class=\"number\">1</span> - beta2, grad, grad)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># \\sqrt&#123;v_t + \\epsilon&#125;</span></div><div class=\"line\">denom = exp_avg_sq.sqrt().add_(group[<span class=\"string\">'eps'</span>])</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 1 - \\beta_1^t</span></div><div class=\"line\">bias_correction1 = <span class=\"number\">1</span> - beta1 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\"><span class=\"comment\"># 1 - \\beta_2^t</span></div><div class=\"line\">bias_correction2 = <span class=\"number\">1</span> - beta2 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\"><span class=\"comment\"># get step_size</span></div><div class=\"line\">step_size = group[<span class=\"string\">'lr'</span>] * math.sqrt(bias_correction2) / bias_correction1</div><div class=\"line\"><span class=\"comment\"># delta = -step_size * m / sqrt(v)</span></div><div class=\"line\">p.data.addcdiv_(-step_size, exp_avg, denom)</div></pre></td></tr></table></figure>\n<h3 id=\"AdaMax\"><a href=\"#AdaMax\" class=\"headerlink\" title=\"AdaMax\"></a>AdaMax</h3><p>Adam$g$$2$$\\sqrt{\\hat{v_t}}$$g$Normalization$p$$1$$2$$p$</p>\n<p><a href=\"https://arxiv.org/abs/1412.6980\">AdaMax</a>$\\hat{v_t}$$u_t$</p>\n<script type=\"math/tex; mode=display\">u_t = \\beta_2^\\infty u_{t-1} + (1-\\beta_2^\\infty) g_t^\\infty</script><p>$u_t$$u_t$$u_{t-1}$</p>\n<p><img src=\"/img/hinton_06_adamax.png\" alt=\"Adamaxut\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\theta_{t+1} = \\theta_t -\\frac{\\eta}{u_t}\\hat{m}_t</script><p>PyTorch<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Update biased first moment estimate, which is \\hat&#123;m&#125;_t</span></div><div class=\"line\">exp_avg.mul_(beta1).add_(<span class=\"number\">1</span> - beta1, grad)</div><div class=\"line\"><span class=\"comment\">#  max(A, B) </span></div><div class=\"line\"><span class=\"comment\"># Update the exponentially weighted infinity norm.</span></div><div class=\"line\">norm_buf = torch.cat([</div><div class=\"line\">    exp_inf.mul_(beta2).unsqueeze(<span class=\"number\">0</span>),</div><div class=\"line\">    grad.abs().add_(eps).unsqueeze_(<span class=\"number\">0</span>)</div><div class=\"line\">], <span class=\"number\">0</span>)</div><div class=\"line\"><span class=\"comment\">##  exp_inf  g~</span></div><div class=\"line\">torch.max(norm_buf, <span class=\"number\">0</span>, keepdim=<span class=\"keyword\">False</span>, out=(exp_inf, exp_inf.new().long()))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## beta1 correction</span></div><div class=\"line\">bias_correction = <span class=\"number\">1</span> - beta1 ** state[<span class=\"string\">'step'</span>]</div><div class=\"line\">clr = group[<span class=\"string\">'lr'</span>] / bias_correction</div><div class=\"line\"></div><div class=\"line\">p.data.addcdiv_(-clr, exp_avg, exp_inf)</div></pre></td></tr></table></figure></p>"},{"title":"Incremental Network Quantization ","date":"2018-01-25T07:30:28.000Z","_content":"[Incremental Network Quantization](https://arxiv.org/abs/1702.03044)5bitINQFP32GitHub[Incremental-Network-Quantization](https://github.com/Zhouaojun/Incremental-Network-Quantization)\n![](/img/paper-inq-result.png)\n<!-- more -->\n\n## \nINQ$2$$0$$W_l$$l$$n_1 > n_2$\n![](/img/paper-inq-quantize-set.png)\n\n$b$bit$1$$0$\n\nPS$1$$0$($2^b$ vs $2^{b-1}+1$)GitHub[issue](https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/12)$0$$2$$b-1$\n\n$b-1$$2$$n_1$$n_2$\n$$(n_1-n_2 + 1) \\times 2 = 2^{b-1}$$\n\n$2$\n\n$n_1$$b$$n_1$$n_2$$n_1$\n$$n_1 = \\lfloor \\log_2(4s/3) \\rfloor$$\n\n$s$$s = \\max \\vert W_l\\vert$\n\n$2^{n_2}$$0$\n\n## \n weight partition, group-wise quantization re-training\n\nre-trainingfinetuningweight partitiongroup-wise quantizationFP32re-training\n\n> Weight partition is to divide the weights in each layer of a pre-trained full-precision CNN model into two disjoint groups which play comple- mentary roles in our INQ. The weights in the first group are responsible for forming a low-precision base for the original model, thus they are quantized by using Equation (4). The weights in the second group adapt to compensate for the loss in model accuracy, thus they are the ones to be re-trained.\n\n$1$$2$SGD$3$$1$\n![](/img/paper-inq-algorithm-demo.png)\n\n### pruning-inspired strategy\n\n![](/img/paper-inq-different-quantize.png)\n\nINQCaffe`blob.cpp``sgd_solver.cpp``data_copy``mask`\n\n``` cpp\n  // blob.cpp\n  // INQ  \n  if(is_quantization)\n  {\n    Dtype* data_copy=(Dtype*) malloc(count_*sizeof(Dtype));\n    caffe_copy(count_,data_vec,data_copy);\n    caffe_abs(count_,data_copy,data_copy);\n    std::sort(data_copy,data_copy+count_); //data_copy order from small to large\n    \n    //caculate the n1\n    Dtype max_data=data_copy[count_-1];\n    int n1=(int)floor(log2(max_data*4.0/3.0));\n    \n    //quantizate the top 30% of each layer, change the \"partition\" until partition=0\n    int partition=int(count_*0.7)-1;\n\n    for (int i = 0; i < (count_); ++i) {\n    \n      if(std::abs(data_vec[i])>=data_copy[partition])\n        {\n          data_vec[i] = weightCluster_zero(data_vec[i],n1);\n\t  \n          mask_vec[i]=0;\n        }\n    }\n```\n\n### \nre-training`mask`$1$`diff``mask`$0$`diff`$0$\n\n```\n// sgd_solver.cpp\ncaffe_gpu_mul(net_params[param_id]->count(),net_params[param_id]->gpu_mask(),net_params[param_id]->mutable_gpu_diff(),net_params[param_id]->mutable_gpu_diff());\n```\n\n## \n[repo](https://github.com/Zhouaojun/Efficient-Deep-Learning)","source":"_posts/inq-paper.md","raw":"---\ntitle: Incremental Network Quantization \ndate: 2018-01-25 15:30:28\ntags:\n    - paper\n    - quantization\n    - deep learning\n---\n[Incremental Network Quantization](https://arxiv.org/abs/1702.03044)5bitINQFP32GitHub[Incremental-Network-Quantization](https://github.com/Zhouaojun/Incremental-Network-Quantization)\n![](/img/paper-inq-result.png)\n<!-- more -->\n\n## \nINQ$2$$0$$W_l$$l$$n_1 > n_2$\n![](/img/paper-inq-quantize-set.png)\n\n$b$bit$1$$0$\n\nPS$1$$0$($2^b$ vs $2^{b-1}+1$)GitHub[issue](https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/12)$0$$2$$b-1$\n\n$b-1$$2$$n_1$$n_2$\n$$(n_1-n_2 + 1) \\times 2 = 2^{b-1}$$\n\n$2$\n\n$n_1$$b$$n_1$$n_2$$n_1$\n$$n_1 = \\lfloor \\log_2(4s/3) \\rfloor$$\n\n$s$$s = \\max \\vert W_l\\vert$\n\n$2^{n_2}$$0$\n\n## \n weight partition, group-wise quantization re-training\n\nre-trainingfinetuningweight partitiongroup-wise quantizationFP32re-training\n\n> Weight partition is to divide the weights in each layer of a pre-trained full-precision CNN model into two disjoint groups which play comple- mentary roles in our INQ. The weights in the first group are responsible for forming a low-precision base for the original model, thus they are quantized by using Equation (4). The weights in the second group adapt to compensate for the loss in model accuracy, thus they are the ones to be re-trained.\n\n$1$$2$SGD$3$$1$\n![](/img/paper-inq-algorithm-demo.png)\n\n### pruning-inspired strategy\n\n![](/img/paper-inq-different-quantize.png)\n\nINQCaffe`blob.cpp``sgd_solver.cpp``data_copy``mask`\n\n``` cpp\n  // blob.cpp\n  // INQ  \n  if(is_quantization)\n  {\n    Dtype* data_copy=(Dtype*) malloc(count_*sizeof(Dtype));\n    caffe_copy(count_,data_vec,data_copy);\n    caffe_abs(count_,data_copy,data_copy);\n    std::sort(data_copy,data_copy+count_); //data_copy order from small to large\n    \n    //caculate the n1\n    Dtype max_data=data_copy[count_-1];\n    int n1=(int)floor(log2(max_data*4.0/3.0));\n    \n    //quantizate the top 30% of each layer, change the \"partition\" until partition=0\n    int partition=int(count_*0.7)-1;\n\n    for (int i = 0; i < (count_); ++i) {\n    \n      if(std::abs(data_vec[i])>=data_copy[partition])\n        {\n          data_vec[i] = weightCluster_zero(data_vec[i],n1);\n\t  \n          mask_vec[i]=0;\n        }\n    }\n```\n\n### \nre-training`mask`$1$`diff``mask`$0$`diff`$0$\n\n```\n// sgd_solver.cpp\ncaffe_gpu_mul(net_params[param_id]->count(),net_params[param_id]->gpu_mask(),net_params[param_id]->mutable_gpu_diff(),net_params[param_id]->mutable_gpu_diff());\n```\n\n## \n[repo](https://github.com/Zhouaojun/Efficient-Deep-Learning)","slug":"inq-paper","published":1,"updated":"2018-10-27T07:16:52.398Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mb0029ae7b14vfj77t","content":"<p><a href=\"https://arxiv.org/abs/1702.03044\" target=\"_blank\" rel=\"external\">Incremental Network Quantization</a>5bitINQFP32GitHub<a href=\"https://github.com/Zhouaojun/Incremental-Network-Quantization\" target=\"_blank\" rel=\"external\">Incremental-Network-Quantization</a><br><img src=\"/img/paper-inq-result.png\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>INQ$2$$0$$W_l$$l$$n_1 &gt; n_2$<br><img src=\"/img/paper-inq-quantize-set.png\" alt=\"\"></p>\n<p>$b$bit$1$$0$</p>\n<p>PS$1$$0$($2^b$ vs $2^{b-1}+1$)GitHub<a href=\"https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/12\" target=\"_blank\" rel=\"external\">issue</a>$0$$2$$b-1$</p>\n<p>$b-1$$2$$n_1$$n_2$</p>\n<script type=\"math/tex; mode=display\">(n_1-n_2 + 1) \\times 2 = 2^{b-1}</script><p>$2$</p>\n<p>$n_1$$b$$n_1$$n_2$$n_1$</p>\n<script type=\"math/tex; mode=display\">n_1 = \\lfloor \\log_2(4s/3) \\rfloor</script><p>$s$$s = \\max \\vert W_l\\vert$</p>\n<p>$2^{n_2}$$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> weight partition, group-wise quantization re-training</p>\n<p>re-trainingfinetuningweight partitiongroup-wise quantizationFP32re-training</p>\n<blockquote>\n<p>Weight partition is to divide the weights in each layer of a pre-trained full-precision CNN model into two disjoint groups which play comple- mentary roles in our INQ. The weights in the first group are responsible for forming a low-precision base for the original model, thus they are quantized by using Equation (4). The weights in the second group adapt to compensate for the loss in model accuracy, thus they are the ones to be re-trained.</p>\n</blockquote>\n<p>$1$$2$SGD$3$$1$<br><img src=\"/img/paper-inq-algorithm-demo.png\" alt=\"\"></p>\n<h3 id=\"pruning-inspired-strategy\"><a href=\"#pruning-inspired-strategy\" class=\"headerlink\" title=\"pruning-inspired strategy\"></a>pruning-inspired strategy</h3><p><br><img src=\"/img/paper-inq-different-quantize.png\" alt=\"\"></p>\n<p>INQCaffe<code>blob.cpp</code><code>sgd_solver.cpp</code><code>data_copy</code><code>mask</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// blob.cpp</span></div><div class=\"line\"><span class=\"comment\">// INQ  </span></div><div class=\"line\"><span class=\"keyword\">if</span>(is_quantization)</div><div class=\"line\">&#123;</div><div class=\"line\">  Dtype* data_copy=(Dtype*) <span class=\"built_in\">malloc</span>(count_*<span class=\"keyword\">sizeof</span>(Dtype));</div><div class=\"line\">  caffe_copy(count_,data_vec,data_copy);</div><div class=\"line\">  caffe_abs(count_,data_copy,data_copy);</div><div class=\"line\">  <span class=\"built_in\">std</span>::sort(data_copy,data_copy+count_); <span class=\"comment\">//data_copy order from small to large</span></div><div class=\"line\">  </div><div class=\"line\">  <span class=\"comment\">//caculate the n1</span></div><div class=\"line\">  Dtype max_data=data_copy[count_<span class=\"number\">-1</span>];</div><div class=\"line\">  <span class=\"keyword\">int</span> n1=(<span class=\"keyword\">int</span>)<span class=\"built_in\">floor</span>(log2(max_data*<span class=\"number\">4.0</span>/<span class=\"number\">3.0</span>));</div><div class=\"line\">  </div><div class=\"line\">  <span class=\"comment\">//quantizate the top 30% of each layer, change the \"partition\" until partition=0</span></div><div class=\"line\">  <span class=\"keyword\">int</span> partition=<span class=\"keyword\">int</span>(count_*<span class=\"number\">0.7</span>)<span class=\"number\">-1</span>;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; (count_); ++i) &#123;</div><div class=\"line\">  </div><div class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"built_in\">std</span>::<span class=\"built_in\">abs</span>(data_vec[i])&gt;=data_copy[partition])</div><div class=\"line\">      &#123;</div><div class=\"line\">        data_vec[i] = weightCluster_zero(data_vec[i],n1);</div><div class=\"line\"> </div><div class=\"line\">        mask_vec[i]=<span class=\"number\">0</span>;</div><div class=\"line\">      &#125;</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>re-training<code>mask</code>$1$<code>diff</code><code>mask</code>$0$<code>diff</code>$0$</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// sgd_solver.cpp</div><div class=\"line\">caffe_gpu_mul(net_params[param_id]-&gt;count(),net_params[param_id]-&gt;gpu_mask(),net_params[param_id]-&gt;mutable_gpu_diff(),net_params[param_id]-&gt;mutable_gpu_diff());</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://github.com/Zhouaojun/Efficient-Deep-Learning\" target=\"_blank\" rel=\"external\">repo</a></p>\n","excerpt":"<p><a href=\"https://arxiv.org/abs/1702.03044\">Incremental Network Quantization</a>5bitINQFP32GitHub<a href=\"https://github.com/Zhouaojun/Incremental-Network-Quantization\">Incremental-Network-Quantization</a><br><img src=\"/img/paper-inq-result.png\" alt=\"\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>INQ$2$$0$$W_l$$l$$n_1 &gt; n_2$<br><img src=\"/img/paper-inq-quantize-set.png\" alt=\"\"></p>\n<p>$b$bit$1$$0$</p>\n<p>PS$1$$0$($2^b$ vs $2^{b-1}+1$)GitHub<a href=\"https://github.com/Zhouaojun/Incremental-Network-Quantization/issues/12\">issue</a>$0$$2$$b-1$</p>\n<p>$b-1$$2$$n_1$$n_2$</p>\n<script type=\"math/tex; mode=display\">(n_1-n_2 + 1) \\times 2 = 2^{b-1}</script><p>$2$</p>\n<p>$n_1$$b$$n_1$$n_2$$n_1$</p>\n<script type=\"math/tex; mode=display\">n_1 = \\lfloor \\log_2(4s/3) \\rfloor</script><p>$s$$s = \\max \\vert W_l\\vert$</p>\n<p>$2^{n_2}$$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> weight partition, group-wise quantization re-training</p>\n<p>re-trainingfinetuningweight partitiongroup-wise quantizationFP32re-training</p>\n<blockquote>\n<p>Weight partition is to divide the weights in each layer of a pre-trained full-precision CNN model into two disjoint groups which play comple- mentary roles in our INQ. The weights in the first group are responsible for forming a low-precision base for the original model, thus they are quantized by using Equation (4). The weights in the second group adapt to compensate for the loss in model accuracy, thus they are the ones to be re-trained.</p>\n</blockquote>\n<p>$1$$2$SGD$3$$1$<br><img src=\"/img/paper-inq-algorithm-demo.png\" alt=\"\"></p>\n<h3 id=\"pruning-inspired-strategy\"><a href=\"#pruning-inspired-strategy\" class=\"headerlink\" title=\"pruning-inspired strategy\"></a>pruning-inspired strategy</h3><p><br><img src=\"/img/paper-inq-different-quantize.png\" alt=\"\"></p>\n<p>INQCaffe<code>blob.cpp</code><code>sgd_solver.cpp</code><code>data_copy</code><code>mask</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// blob.cpp</span></div><div class=\"line\"><span class=\"comment\">// INQ  </span></div><div class=\"line\"><span class=\"keyword\">if</span>(is_quantization)</div><div class=\"line\">&#123;</div><div class=\"line\">  Dtype* data_copy=(Dtype*) <span class=\"built_in\">malloc</span>(count_*<span class=\"keyword\">sizeof</span>(Dtype));</div><div class=\"line\">  caffe_copy(count_,data_vec,data_copy);</div><div class=\"line\">  caffe_abs(count_,data_copy,data_copy);</div><div class=\"line\">  <span class=\"built_in\">std</span>::sort(data_copy,data_copy+count_); <span class=\"comment\">//data_copy order from small to large</span></div><div class=\"line\">  </div><div class=\"line\">  <span class=\"comment\">//caculate the n1</span></div><div class=\"line\">  Dtype max_data=data_copy[count_<span class=\"number\">-1</span>];</div><div class=\"line\">  <span class=\"keyword\">int</span> n1=(<span class=\"keyword\">int</span>)<span class=\"built_in\">floor</span>(log2(max_data*<span class=\"number\">4.0</span>/<span class=\"number\">3.0</span>));</div><div class=\"line\">  </div><div class=\"line\">  <span class=\"comment\">//quantizate the top 30% of each layer, change the \"partition\" until partition=0</span></div><div class=\"line\">  <span class=\"keyword\">int</span> partition=<span class=\"keyword\">int</span>(count_*<span class=\"number\">0.7</span>)<span class=\"number\">-1</span>;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; (count_); ++i) &#123;</div><div class=\"line\">  </div><div class=\"line\">    <span class=\"keyword\">if</span>(<span class=\"built_in\">std</span>::<span class=\"built_in\">abs</span>(data_vec[i])&gt;=data_copy[partition])</div><div class=\"line\">      &#123;</div><div class=\"line\">        data_vec[i] = weightCluster_zero(data_vec[i],n1);</div><div class=\"line\"> </div><div class=\"line\">        mask_vec[i]=<span class=\"number\">0</span>;</div><div class=\"line\">      &#125;</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>re-training<code>mask</code>$1$<code>diff</code><code>mask</code>$0$<code>diff</code>$0$</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// sgd_solver.cpp</div><div class=\"line\">caffe_gpu_mul(net_params[param_id]-&gt;count(),net_params[param_id]-&gt;gpu_mask(),net_params[param_id]-&gt;mutable_gpu_diff(),net_params[param_id]-&gt;mutable_gpu_diff());</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://github.com/Zhouaojun/Efficient-Deep-Learning\">repo</a></p>"},{"title":" - Distilling the Knowledge in a Neural Network","date":"2018-06-07T13:56:12.000Z","_content":"Knowledge DistillingTeacherStudentTeacherHinton[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)KD\n\n<!--more -->\n\n## \nWang Naiyang[](https://www.zhihu.com/question/50519680/answer/136363665\n)KDmotivationKD\n\n> Knowledge DistillImagenet10001000one hotlabellog(class)bitKDteacher modellabelone hotlabelvariancedistanceteacher modelpaper KD\"\"studentmatch teacherteacher model\n\n## \n\nsoften softmax probone-hot$\\{1,2,\\dots,K\\}$target\n$$\\mathcal{L} = -\\sum_{i=1}^{K}t_i\\log p_i$$\n\none-hot$2$$3$$2$$2$$0.99$$3$$10^{-2}$$7$$10^{-4}$Teacher\n\nsoftmaxsoftmaxlogit\n$$q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n\n$T = 1$softmax$T > 1$softmax$1$squashsqushOKTeacherStudent\n\nTeacherlogitsoft targetone-hotground truthsoftmaxprobtarget\nStudent\n\n$$\\mathcal{L}_{soft}=-\\sum_{i=1}^{K}p_i\\log q_i$$\n\n$p_i$Teachersoft target$q_i$Studentsoft outputmulti task learninghard target\n\n$$\\mathcal{L} = \\mathcal{L}_{hard} + \\lambda \\mathcal{L}_{soft}$$\n\n$\\mathcal{L}_{hard}$softened softmax$T$soft target$T^2$$\\lambda$$T^2$\n\nPS:loss[loss function? - Alan Huang - ](https://www.zhihu.com/question/268105631/answer/335246543)\n\n## \nMXNet:[kd loss by mxnet](https://github.com/TuSimple/neuron-selectivity-transfer/blob/master/symbol/transfer.py#L4)MXNet`SoftmaxOutput`one-hotarraylabellabel`dtype`\n\n``` py\ndef kd(student_hard_logits, teacher_hard_logits, temperature, weight_lambda, prefix):\n    student_soft_logits = student_hard_logits / temperature\n    teacher_soft_logits = teacher_hard_logits / temperature\n    teacher_soft_labels = mx.symbol.SoftmaxActivation(teacher_soft_logits,\n        name=\"teacher%s_soft_labels\" % prefix)\n    kd_loss = mx.symbol.SoftmaxOutput(data=student_soft_logits, label=teacher_soft_labels,\n                                      grad_scale=weight_lambda, name=\"%skd_loss\" % prefix)\n    return kd_loss\n\n```\n\n## matching logit\n\n\nHintonTeacherStudentlogitHinton$C$soft targetlossTeacherStudent$i$logit$v_i$$z_i$softened softmax$p_i$$q_i$\n$$C = -\\sum_{j=1}^{C}p_j \\log q_j$$\n\n\n$$p_i = \\frac{\\exp(v_i/T)}{\\sum_j \\exp(v_j/T)}$$\n$$q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n\n$T$$\\frac{1}{T}$\n$$\\frac{\\partial C}{\\partial z_i} = -\\sum_{j=1}^{K}p_j\\frac{1}{q_j}\\frac{\\partial q_j}{\\partial z_i}$$\n\n$i = j$\n$$\\frac{\\partial q_j}{\\partial z_i} = q_i (1-q_i)$$\n\n$i \\neq j$\n$$\\begin{aligned}\n\\frac{\\partial q_j}{\\partial z_i} &= \\frac{-e^{z_i}e^{z_j}}{(\\sum_k e^{z_k})^2}  \\\\\n&=-q_iq_j\n\\end{aligned}$$\n\n\n$$\n\\begin{aligned} \n\\frac{\\partial C}{\\partial z_i} &= - p_i\\frac{1}{q_i}q_i(1-q_i) + \\sum_{j=1, j\\neq i}^{K}p_j\\frac{1}{q_j}q_iq_j  \\\\\n&= -p_i + p_iq_i + \\sum_{j=1, j\\neq i}^K p_jq_i \\\\\n&= q_i -p_i\n\\end{aligned}$$\none-hot\n\nlogit$\\sum_j z_j = \\sum_j v_j = 0$\n$$\\frac{\\partial C}{\\partial z_i} \\sim \\frac{1}{NT^2}(z_i - v_i)$$\n\nMSElogit\n\n## \nMNIST$2$$3$$3$KDstudent$3$KDstudent$3$GoogleJFT dataset\n\n## \n- soft targetWang NaiyanZhou Bolei[soft target\n](https://www.zhihu.com/question/50519680)\n\n","source":"_posts/knowledge-distilling.md","raw":"---\ntitle:  - Distilling the Knowledge in a Neural Network\ndate: 2018-06-07 21:56:12\ntags:\n    - paper\n    - deep learning\n    - model compression\n---\nKnowledge DistillingTeacherStudentTeacherHinton[Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)KD\n\n<!--more -->\n\n## \nWang Naiyang[](https://www.zhihu.com/question/50519680/answer/136363665\n)KDmotivationKD\n\n> Knowledge DistillImagenet10001000one hotlabellog(class)bitKDteacher modellabelone hotlabelvariancedistanceteacher modelpaper KD\"\"studentmatch teacherteacher model\n\n## \n\nsoften softmax probone-hot$\\{1,2,\\dots,K\\}$target\n$$\\mathcal{L} = -\\sum_{i=1}^{K}t_i\\log p_i$$\n\none-hot$2$$3$$2$$2$$0.99$$3$$10^{-2}$$7$$10^{-4}$Teacher\n\nsoftmaxsoftmaxlogit\n$$q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n\n$T = 1$softmax$T > 1$softmax$1$squashsqushOKTeacherStudent\n\nTeacherlogitsoft targetone-hotground truthsoftmaxprobtarget\nStudent\n\n$$\\mathcal{L}_{soft}=-\\sum_{i=1}^{K}p_i\\log q_i$$\n\n$p_i$Teachersoft target$q_i$Studentsoft outputmulti task learninghard target\n\n$$\\mathcal{L} = \\mathcal{L}_{hard} + \\lambda \\mathcal{L}_{soft}$$\n\n$\\mathcal{L}_{hard}$softened softmax$T$soft target$T^2$$\\lambda$$T^2$\n\nPS:loss[loss function? - Alan Huang - ](https://www.zhihu.com/question/268105631/answer/335246543)\n\n## \nMXNet:[kd loss by mxnet](https://github.com/TuSimple/neuron-selectivity-transfer/blob/master/symbol/transfer.py#L4)MXNet`SoftmaxOutput`one-hotarraylabellabel`dtype`\n\n``` py\ndef kd(student_hard_logits, teacher_hard_logits, temperature, weight_lambda, prefix):\n    student_soft_logits = student_hard_logits / temperature\n    teacher_soft_logits = teacher_hard_logits / temperature\n    teacher_soft_labels = mx.symbol.SoftmaxActivation(teacher_soft_logits,\n        name=\"teacher%s_soft_labels\" % prefix)\n    kd_loss = mx.symbol.SoftmaxOutput(data=student_soft_logits, label=teacher_soft_labels,\n                                      grad_scale=weight_lambda, name=\"%skd_loss\" % prefix)\n    return kd_loss\n\n```\n\n## matching logit\n\n\nHintonTeacherStudentlogitHinton$C$soft targetlossTeacherStudent$i$logit$v_i$$z_i$softened softmax$p_i$$q_i$\n$$C = -\\sum_{j=1}^{C}p_j \\log q_j$$\n\n\n$$p_i = \\frac{\\exp(v_i/T)}{\\sum_j \\exp(v_j/T)}$$\n$$q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n\n$T$$\\frac{1}{T}$\n$$\\frac{\\partial C}{\\partial z_i} = -\\sum_{j=1}^{K}p_j\\frac{1}{q_j}\\frac{\\partial q_j}{\\partial z_i}$$\n\n$i = j$\n$$\\frac{\\partial q_j}{\\partial z_i} = q_i (1-q_i)$$\n\n$i \\neq j$\n$$\\begin{aligned}\n\\frac{\\partial q_j}{\\partial z_i} &= \\frac{-e^{z_i}e^{z_j}}{(\\sum_k e^{z_k})^2}  \\\\\n&=-q_iq_j\n\\end{aligned}$$\n\n\n$$\n\\begin{aligned} \n\\frac{\\partial C}{\\partial z_i} &= - p_i\\frac{1}{q_i}q_i(1-q_i) + \\sum_{j=1, j\\neq i}^{K}p_j\\frac{1}{q_j}q_iq_j  \\\\\n&= -p_i + p_iq_i + \\sum_{j=1, j\\neq i}^K p_jq_i \\\\\n&= q_i -p_i\n\\end{aligned}$$\none-hot\n\nlogit$\\sum_j z_j = \\sum_j v_j = 0$\n$$\\frac{\\partial C}{\\partial z_i} \\sim \\frac{1}{NT^2}(z_i - v_i)$$\n\nMSElogit\n\n## \nMNIST$2$$3$$3$KDstudent$3$KDstudent$3$GoogleJFT dataset\n\n## \n- soft targetWang NaiyanZhou Bolei[soft target\n](https://www.zhihu.com/question/50519680)\n\n","slug":"knowledge-distilling","published":1,"updated":"2018-10-27T07:16:52.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mf002cae7bum47b59i","content":"<p>Knowledge DistillingTeacherStudentTeacherHinton<a href=\"https://arxiv.org/abs/1503.02531\" target=\"_blank\" rel=\"external\">Distilling the Knowledge in a Neural Network</a>KD</p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Wang Naiyang<a href=\"https://www.zhihu.com/question/50519680/answer/136363665\" target=\"_blank\" rel=\"external\"></a>KDmotivationKD</p>\n<blockquote>\n<p>Knowledge DistillImagenet10001000one hotlabellog(class)bitKDteacher modellabelone hotlabelvariancedistanceteacher modelpaper KDstudentmatch teacherteacher model</p>\n</blockquote>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>soften softmax probone-hot${1,2,\\dots,K}$target</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = -\\sum_{i=1}^{K}t_i\\log p_i</script><p>one-hot$2$$3$$2$$2$$0.99$$3$$10^{-2}$$7$$10^{-4}$Teacher</p>\n<p>softmaxsoftmaxlogit</p>\n<script type=\"math/tex; mode=display\">q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}</script><p>$T = 1$softmax$T &gt; 1$softmax$1$squashsqushOKTeacherStudent</p>\n<p>Teacherlogitsoft targetone-hotground truthsoftmaxprobtarget<br>Student</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}_{soft}=-\\sum_{i=1}^{K}p_i\\log q_i</script><p>$p_i$Teachersoft target$q_i$Studentsoft outputmulti task learninghard target</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = \\mathcal{L}_{hard} + \\lambda \\mathcal{L}_{soft}</script><p>$\\mathcal{L}_{hard}$softened softmax$T$soft target$T^2$$\\lambda$$T^2$</p>\n<p>PS:loss<a href=\"https://www.zhihu.com/question/268105631/answer/335246543\" target=\"_blank\" rel=\"external\">loss function? - Alan Huang - </a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MXNet:<a href=\"https://github.com/TuSimple/neuron-selectivity-transfer/blob/master/symbol/transfer.py#L4\" target=\"_blank\" rel=\"external\">kd loss by mxnet</a>MXNet<code>SoftmaxOutput</code>one-hotarraylabellabel<code>dtype</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">kd</span><span class=\"params\">(student_hard_logits, teacher_hard_logits, temperature, weight_lambda, prefix)</span>:</span></div><div class=\"line\">    student_soft_logits = student_hard_logits / temperature</div><div class=\"line\">    teacher_soft_logits = teacher_hard_logits / temperature</div><div class=\"line\">    teacher_soft_labels = mx.symbol.SoftmaxActivation(teacher_soft_logits,</div><div class=\"line\">        name=<span class=\"string\">\"teacher%s_soft_labels\"</span> % prefix)</div><div class=\"line\">    kd_loss = mx.symbol.SoftmaxOutput(data=student_soft_logits, label=teacher_soft_labels,</div><div class=\"line\">                                      grad_scale=weight_lambda, name=<span class=\"string\">\"%skd_loss\"</span> % prefix)</div><div class=\"line\">    <span class=\"keyword\">return</span> kd_loss</div></pre></td></tr></table></figure>\n<h2 id=\"matching-logit\"><a href=\"#matching-logit\" class=\"headerlink\" title=\"matching logit\"></a>matching logit</h2><p></p>\n<p>HintonTeacherStudentlogitHinton$C$soft targetlossTeacherStudent$i$logit$v_i$$z_i$softened softmax$p_i$$q_i$</p>\n<script type=\"math/tex; mode=display\">C = -\\sum_{j=1}^{C}p_j \\log q_j</script><p></p>\n<script type=\"math/tex; mode=display\">p_i = \\frac{\\exp(v_i/T)}{\\sum_j \\exp(v_j/T)}</script><script type=\"math/tex; mode=display\">q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}</script><p>$T$$\\frac{1}{T}$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial C}{\\partial z_i} = -\\sum_{j=1}^{K}p_j\\frac{1}{q_j}\\frac{\\partial q_j}{\\partial z_i}</script><p>$i = j$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial q_j}{\\partial z_i} = q_i (1-q_i)</script><p>$i \\neq j$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\n\\frac{\\partial q_j}{\\partial z_i} &= \\frac{-e^{z_i}e^{z_j}}{(\\sum_k e^{z_k})^2}  \\\\\n&=-q_iq_j\n\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned} \n\\frac{\\partial C}{\\partial z_i} &= - p_i\\frac{1}{q_i}q_i(1-q_i) + \\sum_{j=1, j\\neq i}^{K}p_j\\frac{1}{q_j}q_iq_j  \\\\\n&= -p_i + p_iq_i + \\sum_{j=1, j\\neq i}^K p_jq_i \\\\\n&= q_i -p_i\n\\end{aligned}</script><p>one-hot</p>\n<p>logit$\\sum_j z_j = \\sum_j v_j = 0$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial C}{\\partial z_i} \\sim \\frac{1}{NT^2}(z_i - v_i)</script><p>MSElogit</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MNIST$2$$3$$3$KDstudent$3$KDstudent$3$GoogleJFT dataset</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>soft targetWang NaiyanZhou Bolei<a href=\"https://www.zhihu.com/question/50519680\" target=\"_blank\" rel=\"external\">soft target\n</a></li>\n</ul>\n","excerpt":"<p>Knowledge DistillingTeacherStudentTeacherHinton<a href=\"https://arxiv.org/abs/1503.02531\">Distilling the Knowledge in a Neural Network</a>KD</p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Wang Naiyang<a href=\"https://www.zhihu.com/question/50519680/answer/136363665\"></a>KDmotivationKD</p>\n<blockquote>\n<p>Knowledge DistillImagenet10001000one hotlabellog(class)bitKDteacher modellabelone hotlabelvariancedistanceteacher modelpaper KDstudentmatch teacherteacher model</p>\n</blockquote>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>soften softmax probone-hot${1,2,\\dots,K}$target</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = -\\sum_{i=1}^{K}t_i\\log p_i</script><p>one-hot$2$$3$$2$$2$$0.99$$3$$10^{-2}$$7$$10^{-4}$Teacher</p>\n<p>softmaxsoftmaxlogit</p>\n<script type=\"math/tex; mode=display\">q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}</script><p>$T = 1$softmax$T &gt; 1$softmax$1$squashsqushOKTeacherStudent</p>\n<p>Teacherlogitsoft targetone-hotground truthsoftmaxprobtarget<br>Student</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}_{soft}=-\\sum_{i=1}^{K}p_i\\log q_i</script><p>$p_i$Teachersoft target$q_i$Studentsoft outputmulti task learninghard target</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = \\mathcal{L}_{hard} + \\lambda \\mathcal{L}_{soft}</script><p>$\\mathcal{L}_{hard}$softened softmax$T$soft target$T^2$$\\lambda$$T^2$</p>\n<p>PS:loss<a href=\"https://www.zhihu.com/question/268105631/answer/335246543\">loss function? - Alan Huang - </a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MXNet:<a href=\"https://github.com/TuSimple/neuron-selectivity-transfer/blob/master/symbol/transfer.py#L4\">kd loss by mxnet</a>MXNet<code>SoftmaxOutput</code>one-hotarraylabellabel<code>dtype</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">kd</span><span class=\"params\">(student_hard_logits, teacher_hard_logits, temperature, weight_lambda, prefix)</span>:</span></div><div class=\"line\">    student_soft_logits = student_hard_logits / temperature</div><div class=\"line\">    teacher_soft_logits = teacher_hard_logits / temperature</div><div class=\"line\">    teacher_soft_labels = mx.symbol.SoftmaxActivation(teacher_soft_logits,</div><div class=\"line\">        name=<span class=\"string\">\"teacher%s_soft_labels\"</span> % prefix)</div><div class=\"line\">    kd_loss = mx.symbol.SoftmaxOutput(data=student_soft_logits, label=teacher_soft_labels,</div><div class=\"line\">                                      grad_scale=weight_lambda, name=<span class=\"string\">\"%skd_loss\"</span> % prefix)</div><div class=\"line\">    <span class=\"keyword\">return</span> kd_loss</div></pre></td></tr></table></figure>\n<h2 id=\"matching-logit\"><a href=\"#matching-logit\" class=\"headerlink\" title=\"matching logit\"></a>matching logit</h2><p></p>\n<p>HintonTeacherStudentlogitHinton$C$soft targetlossTeacherStudent$i$logit$v_i$$z_i$softened softmax$p_i$$q_i$</p>\n<script type=\"math/tex; mode=display\">C = -\\sum_{j=1}^{C}p_j \\log q_j</script><p></p>\n<script type=\"math/tex; mode=display\">p_i = \\frac{\\exp(v_i/T)}{\\sum_j \\exp(v_j/T)}</script><script type=\"math/tex; mode=display\">q_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}</script><p>$T$$\\frac{1}{T}$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial C}{\\partial z_i} = -\\sum_{j=1}^{K}p_j\\frac{1}{q_j}\\frac{\\partial q_j}{\\partial z_i}</script><p>$i = j$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial q_j}{\\partial z_i} = q_i (1-q_i)</script><p>$i \\neq j$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\n\\frac{\\partial q_j}{\\partial z_i} &= \\frac{-e^{z_i}e^{z_j}}{(\\sum_k e^{z_k})^2}  \\\\\n&=-q_iq_j\n\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned} \n\\frac{\\partial C}{\\partial z_i} &= - p_i\\frac{1}{q_i}q_i(1-q_i) + \\sum_{j=1, j\\neq i}^{K}p_j\\frac{1}{q_j}q_iq_j  \\\\\n&= -p_i + p_iq_i + \\sum_{j=1, j\\neq i}^K p_jq_i \\\\\n&= q_i -p_i\n\\end{aligned}</script><p>one-hot</p>\n<p>logit$\\sum_j z_j = \\sum_j v_j = 0$</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial C}{\\partial z_i} \\sim \\frac{1}{NT^2}(z_i - v_i)</script><p>MSElogit</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MNIST$2$$3$$3$KDstudent$3$KDstudent$3$GoogleJFT dataset</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>soft targetWang NaiyanZhou Bolei<a href=\"https://www.zhihu.com/question/50519680\">soft target\n</a></li>\n</ul>"},{"title":"DELL 7559UbuntuCUDA","date":"2017-08-10T03:29:38.000Z","_content":"DELL 7559Ubuntu+Windows[](https://hemenkapadia.github.io/blog/2016/11/11/Ubuntu-with-Nvidia-CUDA-Bumblebee.html)Ubuntu16.04CUDAbumblee\n![](/img/install_ubuntu_in_dell_kaiyuandafahao.jpg)\n<!-- more -->\n## \nUbuntu14.04Ubuntu15.1016.04.\n\n## Ubuntu\nUbuntu16.04.3WindowsUltraISOUWindowsDELLF12BIOSSecurity BootF10U\n\nInstall Ubuntu`e``quiet splash``quiet splash`\n\n``` sh\nnomodeset i915.modeset=1 quiet splash\n```\n\nF10UbuntuUbuntuUbuntu GRUBUbuntu`e``quiet splash`Ubuntu\n\n## GRUB\nGRUB`sudo vi /etc/default/grub``GRUB_CMDLINE_LINUX_DEFAULT`\n\n``` sh\nGRUB_CMDLINE_LINUX_DEFAULT=\"nomodeset i915.modeset=1 quiet splash\"\n```\n\n## \n700K\n\n```\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get dist-upgrade\nsudo apt-get autoremove\n```\n\nGRUBUbuntu16.04\n\nVim\n``` sh\nsudo apt-get install vim\n```\n\n\n\n## NvidiaNouveau\nALT+CTL+F1lightdm\n``` sh\nsudo service lightdm stop\n```\n\n\n``` sh\nsudo apt-get remove --purge nvidia*\nsudo apt-get remove --purge bumblebee*\nsudo apt-get --purge remove xserver-xorg-video-nouveau*\n```\n\n`/etc/modprobe.d/blacklist.conf`Nouveau\n```\nblacklist nouveau\nblacklist lbm-nouveau\nalias nouveau off\nalias lbm-nouveau off\noptions nouveau modeset=0\n```\n\n`/etc/init/gpu-manager.conf`gpu-manager\n``` sh\n# Comment these start on settings ; GPU Manager ruins our work\n#start on (starting lightdm\n#          or starting kdm\n#          or starting xdm\n#          or starting lxdm)\ntask\nexec gpu-manager --log /var/log/gpu-manager.log\n```\n\ninitramfs\n``` sh\nsudo update-initramfs -u -k all\n```\n\nNouveau\n``` sh\n# \nlsmod | grep nouveau\n```\n\ngpu-manager\n``` sh\nsudo service gpu-manager stop\n```\n\nUbuntuCUDAUbuntu/\n![](/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg)\n\n## CUDA\nNvidiaCUDACUDA-8.0-linux.deb\n\nALT+CTL+F1lightdm\n``` sh\nsudo service lightdm stop\nsudo apt-get install linux-headers-$(uname -r)\nsudo apt-get install mesa-utils\n```\n\nCUDA\n``` sh\nsudo dpkg -i YOUR_CUDA_DEB_PATH\nsudo apt-get update\nsudo apt-get install cuda-8-0\nsudo apt-get autoremove\n```\n`sudo reboot`\n\n\n\n## CUDA\nCUDAshell`~/.bashrc``~/.zshrc`zsh\n``` sh\nexport PATH=\"$PATH:/usr/local/cuda-8.0/bin\"\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib\"\n```\n\nCUDAexample\n``` sh\n# \nsource ~/.bashrc\ncd /usr/local/cuda-8.0/bin\n# CUDA example$HOME\n./cuda-install-samples-8.0.sh ~\n#  build\ncd ~/NVIDIA_CUDA-8.0_Samples\nmake -j12\n# ~\n```\n\n## Last But Not Least\nCUDAKernelXserver\n![](/img/install_ubuntu_in_dell_weixiaojiuhao.jpg)\n","source":"_posts/install-ubuntu-in-dell.md","raw":"---\ntitle: DELL 7559UbuntuCUDA\ndate: 2017-08-10 11:29:38\ntags:\n    - ubuntu\n---\nDELL 7559Ubuntu+Windows[](https://hemenkapadia.github.io/blog/2016/11/11/Ubuntu-with-Nvidia-CUDA-Bumblebee.html)Ubuntu16.04CUDAbumblee\n![](/img/install_ubuntu_in_dell_kaiyuandafahao.jpg)\n<!-- more -->\n## \nUbuntu14.04Ubuntu15.1016.04.\n\n## Ubuntu\nUbuntu16.04.3WindowsUltraISOUWindowsDELLF12BIOSSecurity BootF10U\n\nInstall Ubuntu`e``quiet splash``quiet splash`\n\n``` sh\nnomodeset i915.modeset=1 quiet splash\n```\n\nF10UbuntuUbuntuUbuntu GRUBUbuntu`e``quiet splash`Ubuntu\n\n## GRUB\nGRUB`sudo vi /etc/default/grub``GRUB_CMDLINE_LINUX_DEFAULT`\n\n``` sh\nGRUB_CMDLINE_LINUX_DEFAULT=\"nomodeset i915.modeset=1 quiet splash\"\n```\n\n## \n700K\n\n```\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get dist-upgrade\nsudo apt-get autoremove\n```\n\nGRUBUbuntu16.04\n\nVim\n``` sh\nsudo apt-get install vim\n```\n\n\n\n## NvidiaNouveau\nALT+CTL+F1lightdm\n``` sh\nsudo service lightdm stop\n```\n\n\n``` sh\nsudo apt-get remove --purge nvidia*\nsudo apt-get remove --purge bumblebee*\nsudo apt-get --purge remove xserver-xorg-video-nouveau*\n```\n\n`/etc/modprobe.d/blacklist.conf`Nouveau\n```\nblacklist nouveau\nblacklist lbm-nouveau\nalias nouveau off\nalias lbm-nouveau off\noptions nouveau modeset=0\n```\n\n`/etc/init/gpu-manager.conf`gpu-manager\n``` sh\n# Comment these start on settings ; GPU Manager ruins our work\n#start on (starting lightdm\n#          or starting kdm\n#          or starting xdm\n#          or starting lxdm)\ntask\nexec gpu-manager --log /var/log/gpu-manager.log\n```\n\ninitramfs\n``` sh\nsudo update-initramfs -u -k all\n```\n\nNouveau\n``` sh\n# \nlsmod | grep nouveau\n```\n\ngpu-manager\n``` sh\nsudo service gpu-manager stop\n```\n\nUbuntuCUDAUbuntu/\n![](/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg)\n\n## CUDA\nNvidiaCUDACUDA-8.0-linux.deb\n\nALT+CTL+F1lightdm\n``` sh\nsudo service lightdm stop\nsudo apt-get install linux-headers-$(uname -r)\nsudo apt-get install mesa-utils\n```\n\nCUDA\n``` sh\nsudo dpkg -i YOUR_CUDA_DEB_PATH\nsudo apt-get update\nsudo apt-get install cuda-8-0\nsudo apt-get autoremove\n```\n`sudo reboot`\n\n\n\n## CUDA\nCUDAshell`~/.bashrc``~/.zshrc`zsh\n``` sh\nexport PATH=\"$PATH:/usr/local/cuda-8.0/bin\"\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib\"\n```\n\nCUDAexample\n``` sh\n# \nsource ~/.bashrc\ncd /usr/local/cuda-8.0/bin\n# CUDA example$HOME\n./cuda-install-samples-8.0.sh ~\n#  build\ncd ~/NVIDIA_CUDA-8.0_Samples\nmake -j12\n# ~\n```\n\n## Last But Not Least\nCUDAKernelXserver\n![](/img/install_ubuntu_in_dell_weixiaojiuhao.jpg)\n","slug":"install-ubuntu-in-dell","published":1,"updated":"2018-10-27T07:16:52.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mg002dae7b1y7wx9hn","content":"<p>DELL 7559Ubuntu+Windows<a href=\"https://hemenkapadia.github.io/blog/2016/11/11/Ubuntu-with-Nvidia-CUDA-Bumblebee.html\" target=\"_blank\" rel=\"external\"></a>Ubuntu16.04CUDAbumblee<br><img src=\"/img/install_ubuntu_in_dell_kaiyuandafahao.jpg\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Ubuntu14.04Ubuntu15.1016.04.</p>\n<h2 id=\"Ubuntu\"><a href=\"#Ubuntu\" class=\"headerlink\" title=\"Ubuntu\"></a>Ubuntu</h2><p>Ubuntu16.04.3WindowsUltraISOUWindowsDELLF12BIOSSecurity BootF10U</p>\n<p>Install Ubuntu<code>e</code><code>quiet splash</code><code>quiet splash</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">nomodeset i915.modeset=1 quiet splash</div></pre></td></tr></table></figure>\n<p>F10UbuntuUbuntuUbuntu GRUBUbuntu<code>e</code><code>quiet splash</code>Ubuntu</p>\n<h2 id=\"GRUB\"><a href=\"#GRUB\" class=\"headerlink\" title=\"GRUB\"></a>GRUB</h2><p>GRUB<code>sudo vi /etc/default/grub</code><code>GRUB_CMDLINE_LINUX_DEFAULT</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GRUB_CMDLINE_LINUX_DEFAULT=<span class=\"string\">\"nomodeset i915.modeset=1 quiet splash\"</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>700K</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get upgrade</div><div class=\"line\">sudo apt-get dist-upgrade</div><div class=\"line\">sudo apt-get autoremove</div></pre></td></tr></table></figure>\n<p>GRUBUbuntu16.04</p>\n<p>Vim<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install vim</div></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"NvidiaNouveau\"><a href=\"#NvidiaNouveau\" class=\"headerlink\" title=\"NvidiaNouveau\"></a>NvidiaNouveau</h2><p>ALT+CTL+F1lightdm<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service lightdm stop</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get remove --purge nvidia*</div><div class=\"line\">sudo apt-get remove --purge bumblebee*</div><div class=\"line\">sudo apt-get --purge remove xserver-xorg-video-nouveau*</div></pre></td></tr></table></figure></p>\n<p><code>/etc/modprobe.d/blacklist.conf</code>Nouveau<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">blacklist nouveau</div><div class=\"line\">blacklist lbm-nouveau</div><div class=\"line\">alias nouveau off</div><div class=\"line\">alias lbm-nouveau off</div><div class=\"line\">options nouveau modeset=0</div></pre></td></tr></table></figure></p>\n<p><code>/etc/init/gpu-manager.conf</code>gpu-manager<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Comment these start on settings ; GPU Manager ruins our work</span></div><div class=\"line\"><span class=\"comment\">#start on (starting lightdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting kdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting xdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting lxdm)</span></div><div class=\"line\">task</div><div class=\"line\"><span class=\"built_in\">exec</span> gpu-manager --log /var/<span class=\"built_in\">log</span>/gpu-manager.log</div></pre></td></tr></table></figure></p>\n<p>initramfs<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo update-initramfs -u -k all</div></pre></td></tr></table></figure></p>\n<p>Nouveau<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">lsmod | grep nouveau</div></pre></td></tr></table></figure></p>\n<p>gpu-manager<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service gpu-manager stop</div></pre></td></tr></table></figure></p>\n<p>UbuntuCUDAUbuntu/<br><img src=\"/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg\" alt=\"\"></p>\n<h2 id=\"CUDA\"><a href=\"#CUDA\" class=\"headerlink\" title=\"CUDA\"></a>CUDA</h2><p>NvidiaCUDACUDA-8.0-linux.deb</p>\n<p>ALT+CTL+F1lightdm<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service lightdm stop</div><div class=\"line\">sudo apt-get install linux-headers-$(uname -r)</div><div class=\"line\">sudo apt-get install mesa-utils</div></pre></td></tr></table></figure></p>\n<p>CUDA<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo dpkg -i YOUR_CUDA_DEB_PATH</div><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get install cuda-8-0</div><div class=\"line\">sudo apt-get autoremove</div></pre></td></tr></table></figure></p>\n<p><code>sudo reboot</code></p>\n<p></p>\n<h2 id=\"CUDA\"><a href=\"#CUDA\" class=\"headerlink\" title=\"CUDA\"></a>CUDA</h2><p>CUDAshell<code>~/.bashrc</code><code>~/.zshrc</code>zsh<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"string\">\"<span class=\"variable\">$PATH</span>:/usr/local/cuda-8.0/bin\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=<span class=\"string\">\"<span class=\"variable\">$LD_LIBRARY_PATH</span>:/usr/local/cuda-8.0/lib\"</span></div></pre></td></tr></table></figure></p>\n<p>CUDAexample<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/cuda-8.0/bin</div><div class=\"line\"><span class=\"comment\"># CUDA example$HOME</span></div><div class=\"line\">./cuda-install-samples-8.0.sh ~</div><div class=\"line\"><span class=\"comment\">#  build</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~/NVIDIA_CUDA-8.0_Samples</div><div class=\"line\">make -j12</div><div class=\"line\"><span class=\"comment\"># ~</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Last-But-Not-Least\"><a href=\"#Last-But-Not-Least\" class=\"headerlink\" title=\"Last But Not Least\"></a>Last But Not Least</h2><p>CUDAKernelXserver<br><img src=\"/img/install_ubuntu_in_dell_weixiaojiuhao.jpg\" alt=\"\"></p>\n","excerpt":"<p>DELL 7559Ubuntu+Windows<a href=\"https://hemenkapadia.github.io/blog/2016/11/11/Ubuntu-with-Nvidia-CUDA-Bumblebee.html\"></a>Ubuntu16.04CUDAbumblee<br><img src=\"/img/install_ubuntu_in_dell_kaiyuandafahao.jpg\" alt=\"\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Ubuntu14.04Ubuntu15.1016.04.</p>\n<h2 id=\"Ubuntu\"><a href=\"#Ubuntu\" class=\"headerlink\" title=\"Ubuntu\"></a>Ubuntu</h2><p>Ubuntu16.04.3WindowsUltraISOUWindowsDELLF12BIOSSecurity BootF10U</p>\n<p>Install Ubuntu<code>e</code><code>quiet splash</code><code>quiet splash</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">nomodeset i915.modeset=1 quiet splash</div></pre></td></tr></table></figure>\n<p>F10UbuntuUbuntuUbuntu GRUBUbuntu<code>e</code><code>quiet splash</code>Ubuntu</p>\n<h2 id=\"GRUB\"><a href=\"#GRUB\" class=\"headerlink\" title=\"GRUB\"></a>GRUB</h2><p>GRUB<code>sudo vi /etc/default/grub</code><code>GRUB_CMDLINE_LINUX_DEFAULT</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GRUB_CMDLINE_LINUX_DEFAULT=<span class=\"string\">\"nomodeset i915.modeset=1 quiet splash\"</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>700K</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get upgrade</div><div class=\"line\">sudo apt-get dist-upgrade</div><div class=\"line\">sudo apt-get autoremove</div></pre></td></tr></table></figure>\n<p>GRUBUbuntu16.04</p>\n<p>Vim<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get install vim</div></pre></td></tr></table></figure></p>\n<p></p>\n<h2 id=\"NvidiaNouveau\"><a href=\"#NvidiaNouveau\" class=\"headerlink\" title=\"NvidiaNouveau\"></a>NvidiaNouveau</h2><p>ALT+CTL+F1lightdm<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service lightdm stop</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo apt-get remove --purge nvidia*</div><div class=\"line\">sudo apt-get remove --purge bumblebee*</div><div class=\"line\">sudo apt-get --purge remove xserver-xorg-video-nouveau*</div></pre></td></tr></table></figure></p>\n<p><code>/etc/modprobe.d/blacklist.conf</code>Nouveau<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">blacklist nouveau</div><div class=\"line\">blacklist lbm-nouveau</div><div class=\"line\">alias nouveau off</div><div class=\"line\">alias lbm-nouveau off</div><div class=\"line\">options nouveau modeset=0</div></pre></td></tr></table></figure></p>\n<p><code>/etc/init/gpu-manager.conf</code>gpu-manager<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Comment these start on settings ; GPU Manager ruins our work</span></div><div class=\"line\"><span class=\"comment\">#start on (starting lightdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting kdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting xdm</span></div><div class=\"line\"><span class=\"comment\">#          or starting lxdm)</span></div><div class=\"line\">task</div><div class=\"line\"><span class=\"built_in\">exec</span> gpu-manager --log /var/<span class=\"built_in\">log</span>/gpu-manager.log</div></pre></td></tr></table></figure></p>\n<p>initramfs<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo update-initramfs -u -k all</div></pre></td></tr></table></figure></p>\n<p>Nouveau<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">lsmod | grep nouveau</div></pre></td></tr></table></figure></p>\n<p>gpu-manager<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service gpu-manager stop</div></pre></td></tr></table></figure></p>\n<p>UbuntuCUDAUbuntu/<br><img src=\"/img/install_ubuntu_in_dell_weixiaodaizhepibei.jpg\" alt=\"\"></p>\n<h2 id=\"CUDA\"><a href=\"#CUDA\" class=\"headerlink\" title=\"CUDA\"></a>CUDA</h2><p>NvidiaCUDACUDA-8.0-linux.deb</p>\n<p>ALT+CTL+F1lightdm<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo service lightdm stop</div><div class=\"line\">sudo apt-get install linux-headers-$(uname -r)</div><div class=\"line\">sudo apt-get install mesa-utils</div></pre></td></tr></table></figure></p>\n<p>CUDA<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo dpkg -i YOUR_CUDA_DEB_PATH</div><div class=\"line\">sudo apt-get update</div><div class=\"line\">sudo apt-get install cuda-8-0</div><div class=\"line\">sudo apt-get autoremove</div></pre></td></tr></table></figure></p>\n<p><code>sudo reboot</code></p>\n<p></p>\n<h2 id=\"CUDA\"><a href=\"#CUDA\" class=\"headerlink\" title=\"CUDA\"></a>CUDA</h2><p>CUDAshell<code>~/.bashrc</code><code>~/.zshrc</code>zsh<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"string\">\"<span class=\"variable\">$PATH</span>:/usr/local/cuda-8.0/bin\"</span></div><div class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=<span class=\"string\">\"<span class=\"variable\">$LD_LIBRARY_PATH</span>:/usr/local/cuda-8.0/lib\"</span></div></pre></td></tr></table></figure></p>\n<p>CUDAexample<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\"><span class=\"built_in\">source</span> ~/.bashrc</div><div class=\"line\"><span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/cuda-8.0/bin</div><div class=\"line\"><span class=\"comment\"># CUDA example$HOME</span></div><div class=\"line\">./cuda-install-samples-8.0.sh ~</div><div class=\"line\"><span class=\"comment\">#  build</span></div><div class=\"line\"><span class=\"built_in\">cd</span> ~/NVIDIA_CUDA-8.0_Samples</div><div class=\"line\">make -j12</div><div class=\"line\"><span class=\"comment\"># ~</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"Last-But-Not-Least\"><a href=\"#Last-But-Not-Least\" class=\"headerlink\" title=\"Last But Not Least\"></a>Last But Not Least</h2><p>CUDAKernelXserver<br><img src=\"/img/install_ubuntu_in_dell_weixiaojiuhao.jpg\" alt=\"\"></p>"},{"title":"Jupyter","date":"2017-02-26T11:53:11.000Z","_content":"Jupyter Notebook`jupyter notebook`Jupyter\n![jupyternotebook](/img/jupyternotebook_logo.png)\n<!-- more -->\n\n## jupter notebook\n\n\n``` bash\njupyter notebook --generate-config\n```\n\n\n\n``` bash\nvim ~/.jupyter/jupyter_notebook_config.py\n```\n\n\n\n- `c.NotebookApp.ip='*'`ip\n- `c.NotebookApp.password = u'hash_value'`\n\n`hash_value``ipython`\n\n``` python\nfrom notebook.auth import passwd\npasswd()\n\"\"\"\nhash\n\"\"\"\n```\n\njupyter-notebook`False`\n\n``` bash\nc.NotebookApp.open_browser = True\n```\n\n## notebook\n`jupyter notebook``ip:8888``8888`\n\n## Jupyter Notebook\nVimJupyter Notebook\n- `Esc`\n- `Enter`\n\n\n\n- h\n- mCellMarkdown\n- yCell\n- shift+EnterCellCell\n- Ctrl+EnterCell\n\n\n[jupyter notebook](http://blog.leanote.com/post/jevonswang/jupyter-notebook)[Jupyter Notebook\n](http://www.cnblogs.com/weidiao/p/7792885.html)\n","source":"_posts/jupyternotebook-remote-useage.md","raw":"---\ntitle: Jupyter\ndate: 2017-02-26 19:53:11\ntags:\n    - tool\n---\nJupyter Notebook`jupyter notebook`Jupyter\n![jupyternotebook](/img/jupyternotebook_logo.png)\n<!-- more -->\n\n## jupter notebook\n\n\n``` bash\njupyter notebook --generate-config\n```\n\n\n\n``` bash\nvim ~/.jupyter/jupyter_notebook_config.py\n```\n\n\n\n- `c.NotebookApp.ip='*'`ip\n- `c.NotebookApp.password = u'hash_value'`\n\n`hash_value``ipython`\n\n``` python\nfrom notebook.auth import passwd\npasswd()\n\"\"\"\nhash\n\"\"\"\n```\n\njupyter-notebook`False`\n\n``` bash\nc.NotebookApp.open_browser = True\n```\n\n## notebook\n`jupyter notebook``ip:8888``8888`\n\n## Jupyter Notebook\nVimJupyter Notebook\n- `Esc`\n- `Enter`\n\n\n\n- h\n- mCellMarkdown\n- yCell\n- shift+EnterCellCell\n- Ctrl+EnterCell\n\n\n[jupyter notebook](http://blog.leanote.com/post/jevonswang/jupyter-notebook)[Jupyter Notebook\n](http://www.cnblogs.com/weidiao/p/7792885.html)\n","slug":"jupyternotebook-remote-useage","published":1,"updated":"2018-10-27T07:16:52.400Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mj002fae7bawb3raya","content":"<p>Jupyter Notebook<code>jupyter notebook</code>Jupyter<br><img src=\"/img/jupyternotebook_logo.png\" alt=\"jupyternotebook\"><br><a id=\"more\"></a></p>\n<h2 id=\"jupter-notebook\"><a href=\"#jupter-notebook\" class=\"headerlink\" title=\"jupter notebook\"></a>jupter notebook</h2><p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">jupyter notebook --generate-config</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim ~/.jupyter/jupyter_notebook_config.py</div></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><code>c.NotebookApp.ip=&#39;*&#39;</code>ip</li>\n<li><code>c.NotebookApp.password = u&#39;hash_value&#39;</code></li>\n</ul>\n<p><code>hash_value</code><code>ipython</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> notebook.auth <span class=\"keyword\">import</span> passwd</div><div class=\"line\">passwd()</div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">hash</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p>jupyter-notebook<code>False</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">c.NotebookApp.open_browser = True</div></pre></td></tr></table></figure>\n<h2 id=\"notebook\"><a href=\"#notebook\" class=\"headerlink\" title=\"notebook\"></a>notebook</h2><p><code>jupyter notebook</code><code>ip:8888</code><code>8888</code></p>\n<h2 id=\"Jupyter-Notebook\"><a href=\"#Jupyter-Notebook\" class=\"headerlink\" title=\"Jupyter Notebook\"></a>Jupyter Notebook</h2><p>VimJupyter Notebook</p>\n<ul>\n<li><code>Esc</code></li>\n<li><code>Enter</code></li>\n</ul>\n<p></p>\n<ul>\n<li>h</li>\n<li>mCellMarkdown</li>\n<li>yCell</li>\n<li>shift+EnterCellCell</li>\n<li>Ctrl+EnterCell</li>\n</ul>\n<p><a href=\"http://blog.leanote.com/post/jevonswang/jupyter-notebook\" target=\"_blank\" rel=\"external\">jupyter notebook</a><a href=\"http://www.cnblogs.com/weidiao/p/7792885.html\" target=\"_blank\" rel=\"external\">Jupyter Notebook\n</a></p>\n","excerpt":"<p>Jupyter Notebook<code>jupyter notebook</code>Jupyter<br><img src=\"/img/jupyternotebook_logo.png\" alt=\"jupyternotebook\"><br>","more":"</p>\n<h2 id=\"jupter-notebook\"><a href=\"#jupter-notebook\" class=\"headerlink\" title=\"jupter notebook\"></a>jupter notebook</h2><p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">jupyter notebook --generate-config</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim ~/.jupyter/jupyter_notebook_config.py</div></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><code>c.NotebookApp.ip=&#39;*&#39;</code>ip</li>\n<li><code>c.NotebookApp.password = u&#39;hash_value&#39;</code></li>\n</ul>\n<p><code>hash_value</code><code>ipython</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> notebook.auth <span class=\"keyword\">import</span> passwd</div><div class=\"line\">passwd()</div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">hash</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p>jupyter-notebook<code>False</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">c.NotebookApp.open_browser = True</div></pre></td></tr></table></figure>\n<h2 id=\"notebook\"><a href=\"#notebook\" class=\"headerlink\" title=\"notebook\"></a>notebook</h2><p><code>jupyter notebook</code><code>ip:8888</code><code>8888</code></p>\n<h2 id=\"Jupyter-Notebook\"><a href=\"#Jupyter-Notebook\" class=\"headerlink\" title=\"Jupyter Notebook\"></a>Jupyter Notebook</h2><p>VimJupyter Notebook</p>\n<ul>\n<li><code>Esc</code></li>\n<li><code>Enter</code></li>\n</ul>\n<p></p>\n<ul>\n<li>h</li>\n<li>mCellMarkdown</li>\n<li>yCell</li>\n<li>shift+EnterCellCell</li>\n<li>Ctrl+EnterCell</li>\n</ul>\n<p><a href=\"http://blog.leanote.com/post/jevonswang/jupyter-notebook\">jupyter notebook</a><a href=\"http://www.cnblogs.com/weidiao/p/7792885.html\">Jupyter Notebook\n</a></p>"},{"title":"PyQT","date":"2017-08-29T06:07:55.000Z","_content":"QtGUIC++/PythonPyQT[PyQT5](http://zetcode.com/gui/pyqt5/introduction/)\n<!-- more -->\n\n## \nPyQt5\n- `QtCore`: GUI\n- `QtGui`GUI2D\n- `QtWidget`GUI\n\n`QtBluetooth``QtNetwork`\n\n## HelloWorld\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QWidget\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    w = QWidget()\n    w.resize(250, 150)\n    w.move(300, 300)\n    w.setWindowTitle('Simple')\n    w.show()\n\n    sys.exit(app.exec_())\n```\n\n```py\napp = QApplication(sys.argv)\n```\nQt5application\n``` py\nw = QWidget()\nw.resize(250, 150)\nw.move(300, 300)\nw.setWindowTitle('Simple')\nw.show()\n```\n`QtWidget``Widget`parent widgetWidget`show()`\n\n``` py\nsys.exit(app.exec_())\n```\napplicationCtrl+C\n\n## \n\n\n`QPushButton`\n```py\n__init__ (self, QWidget parent = None)\n```\n`QPushButton``btn``self`parent`sizeHint()`\n\nQt`clicked`PyQtslotPython`__call__()`\n\n`instance()`application`quit()`\n```py\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QToolTip\nfrom PyQt5.QtCore import QCoreApplication\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        btn = QPushButton('quit', self)\n        btn.clicked.connect(QCoreApplication.instance().quit)\n        btn.setToolTip('This is a <b>QPushButton</b> widget')\n        btn.move(50, 50)\n        btn.resize(btn.sizeHint())\n\n        self.setGeometry(300, 300, 300, 200)\n        self.setWindowTitle('Window with Button')\n        self.show()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    window = MyWindow()\n    sys.exit(app.exec_())\n```\n\n## Event\nEvent`event.accept()``ignore()`\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import QWidget, QMessageBox, QApplication\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n    def _init_ui(self):\n        self.setGeometry(300, 300, 300, 200)\n        self.show()\n    def closeEvent(self, ev):\n        reply = QMessageBox.question(self, 'Message', 'Are you sure?',\n                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No)\n        if reply == QMessageBox.Yes:\n            ev.accept()\n        else:\n            ev.ignore()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n## LayoutWidget\nWidget`Layout`\n\nwidget\n- \n- parent resizewidget\n- \n\n`Layout`\n\n### Box Layout\n`QVBoxLayout``QHBoxLayout`widgetlayout`addSkretch()``QSpacerItem`layout\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import (QWidget, QPushButton,\n    QHBoxLayout, QVBoxLayout, QApplication)\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        okButton = QPushButton(\"OK\")\n        cancelButton = QPushButton(\"Cancel\")\n\n        hbox = QHBoxLayout()\n        hbox.addStretch(1)\n        hbox.addWidget(okButton)\n        hbox.addWidget(cancelButton)\n\n        vbox = QVBoxLayout()\n        vbox.addStretch(1)\n        vbox.addLayout(hbox)\n\n        self.setLayout(vbox)    \n\n        self.setGeometry(300, 300, 300, 150)\n        self.setWindowTitle('Buttons')    \n        self.show()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n### Grid Layout\n`QGridLayout`griditem54grid\n``` py\nimport sys\nfrom PyQt5.QtWidgets import (QWidget, QGridLayout,\n    QPushButton, QApplication)\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        grid = QGridLayout()\n        self.setLayout(grid)\n        names = ['Cls', 'Bck', '', 'Close',\n                 '7', '8', '9', '/',\n                '4', '5', '6', '*',\n                 '1', '2', '3', '-',\n                '0', '.', '=', '+']\n        positions = [(i,j) for i in range(5) for j in range(4)]\n        for position, name in zip(positions, names):\n            if name == '':\n                continue\n            button = QPushButton(name)\n            grid.addWidget(button, *position)\n\n        self.move(300, 150)\n        self.setWindowTitle('Calculator')\n        self.show()\n\nif __name__ == '__main__':\n\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n`setSpacing()`widget`addWidget()`\n\n## \nPyQt\n- `event`UI\n- widge\n\n`connect()`Python\n\neventoverride\n","source":"_posts/learn-pyqt.md","raw":"---\ntitle: PyQT\ndate: 2017-08-29 14:07:55\ntags:\n    - python\n    - qt\n---\nQtGUIC++/PythonPyQT[PyQT5](http://zetcode.com/gui/pyqt5/introduction/)\n<!-- more -->\n\n## \nPyQt5\n- `QtCore`: GUI\n- `QtGui`GUI2D\n- `QtWidget`GUI\n\n`QtBluetooth``QtNetwork`\n\n## HelloWorld\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QWidget\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    w = QWidget()\n    w.resize(250, 150)\n    w.move(300, 300)\n    w.setWindowTitle('Simple')\n    w.show()\n\n    sys.exit(app.exec_())\n```\n\n```py\napp = QApplication(sys.argv)\n```\nQt5application\n``` py\nw = QWidget()\nw.resize(250, 150)\nw.move(300, 300)\nw.setWindowTitle('Simple')\nw.show()\n```\n`QtWidget``Widget`parent widgetWidget`show()`\n\n``` py\nsys.exit(app.exec_())\n```\napplicationCtrl+C\n\n## \n\n\n`QPushButton`\n```py\n__init__ (self, QWidget parent = None)\n```\n`QPushButton``btn``self`parent`sizeHint()`\n\nQt`clicked`PyQtslotPython`__call__()`\n\n`instance()`application`quit()`\n```py\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QToolTip\nfrom PyQt5.QtCore import QCoreApplication\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        btn = QPushButton('quit', self)\n        btn.clicked.connect(QCoreApplication.instance().quit)\n        btn.setToolTip('This is a <b>QPushButton</b> widget')\n        btn.move(50, 50)\n        btn.resize(btn.sizeHint())\n\n        self.setGeometry(300, 300, 300, 200)\n        self.setWindowTitle('Window with Button')\n        self.show()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    window = MyWindow()\n    sys.exit(app.exec_())\n```\n\n## Event\nEvent`event.accept()``ignore()`\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import QWidget, QMessageBox, QApplication\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n    def _init_ui(self):\n        self.setGeometry(300, 300, 300, 200)\n        self.show()\n    def closeEvent(self, ev):\n        reply = QMessageBox.question(self, 'Message', 'Are you sure?',\n                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No)\n        if reply == QMessageBox.Yes:\n            ev.accept()\n        else:\n            ev.ignore()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n## LayoutWidget\nWidget`Layout`\n\nwidget\n- \n- parent resizewidget\n- \n\n`Layout`\n\n### Box Layout\n`QVBoxLayout``QHBoxLayout`widgetlayout`addSkretch()``QSpacerItem`layout\n\n``` py\nimport sys\nfrom PyQt5.QtWidgets import (QWidget, QPushButton,\n    QHBoxLayout, QVBoxLayout, QApplication)\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        okButton = QPushButton(\"OK\")\n        cancelButton = QPushButton(\"Cancel\")\n\n        hbox = QHBoxLayout()\n        hbox.addStretch(1)\n        hbox.addWidget(okButton)\n        hbox.addWidget(cancelButton)\n\n        vbox = QVBoxLayout()\n        vbox.addStretch(1)\n        vbox.addLayout(hbox)\n\n        self.setLayout(vbox)    \n\n        self.setGeometry(300, 300, 300, 150)\n        self.setWindowTitle('Buttons')    \n        self.show()\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n### Grid Layout\n`QGridLayout`griditem54grid\n``` py\nimport sys\nfrom PyQt5.QtWidgets import (QWidget, QGridLayout,\n    QPushButton, QApplication)\n\nclass MyWindow(QWidget):\n    def __init__(self):\n        super(MyWindow, self).__init__()\n        self._init_ui()\n\n    def _init_ui(self):\n        grid = QGridLayout()\n        self.setLayout(grid)\n        names = ['Cls', 'Bck', '', 'Close',\n                 '7', '8', '9', '/',\n                '4', '5', '6', '*',\n                 '1', '2', '3', '-',\n                '0', '.', '=', '+']\n        positions = [(i,j) for i in range(5) for j in range(4)]\n        for position, name in zip(positions, names):\n            if name == '':\n                continue\n            button = QPushButton(name)\n            grid.addWidget(button, *position)\n\n        self.move(300, 150)\n        self.setWindowTitle('Calculator')\n        self.show()\n\nif __name__ == '__main__':\n\n    app = QApplication(sys.argv)\n    win = MyWindow()\n    sys.exit(app.exec_())\n```\n\n`setSpacing()`widget`addWidget()`\n\n## \nPyQt\n- `event`UI\n- widge\n\n`connect()`Python\n\neventoverride\n","slug":"learn-pyqt","published":1,"updated":"2018-10-27T07:16:52.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mk002hae7b7lkun84d","content":"<p>QtGUIC++/PythonPyQT<a href=\"http://zetcode.com/gui/pyqt5/introduction/\" target=\"_blank\" rel=\"external\">PyQT5</a><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyQt5</p>\n<ul>\n<li><code>QtCore</code>: GUI</li>\n<li><code>QtGui</code>GUI2D</li>\n<li><code>QtWidget</code>GUI</li>\n</ul>\n<p><code>QtBluetooth</code><code>QtNetwork</code></p>\n<h2 id=\"HelloWorld\"><a href=\"#HelloWorld\" class=\"headerlink\" title=\"HelloWorld\"></a>HelloWorld</h2><p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QApplication, QWidget</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    w = QWidget()</div><div class=\"line\">    w.resize(<span class=\"number\">250</span>, <span class=\"number\">150</span>)</div><div class=\"line\">    w.move(<span class=\"number\">300</span>, <span class=\"number\">300</span>)</div><div class=\"line\">    w.setWindowTitle(<span class=\"string\">'Simple'</span>)</div><div class=\"line\">    w.show()</div><div class=\"line\"></div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">app = QApplication(sys.argv)</div></pre></td></tr></table></figure></p>\n<p>Qt5application<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">w = QWidget()</div><div class=\"line\">w.resize(<span class=\"number\">250</span>, <span class=\"number\">150</span>)</div><div class=\"line\">w.move(<span class=\"number\">300</span>, <span class=\"number\">300</span>)</div><div class=\"line\">w.setWindowTitle(<span class=\"string\">'Simple'</span>)</div><div class=\"line\">w.show()</div></pre></td></tr></table></figure></p>\n<p><code>QtWidget</code><code>Widget</code>parent widgetWidget<code>show()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<p>applicationCtrl+C</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p><code>QPushButton</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">__init__ (self, QWidget parent = <span class=\"keyword\">None</span>)</div></pre></td></tr></table></figure></p>\n<p><code>QPushButton</code><code>btn</code><code>self</code>parent<code>sizeHint()</code></p>\n<p>Qt<code>clicked</code>PyQtslotPython<code>__call__()</code></p>\n<p><code>instance()</code>application<code>quit()</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QApplication, QWidget, QPushButton, QToolTip</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtCore <span class=\"keyword\">import</span> QCoreApplication</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        btn = QPushButton(<span class=\"string\">'quit'</span>, self)</div><div class=\"line\">        btn.clicked.connect(QCoreApplication.instance().quit)</div><div class=\"line\">        btn.setToolTip(<span class=\"string\">'This is a &lt;b&gt;QPushButton&lt;/b&gt; widget'</span>)</div><div class=\"line\">        btn.move(<span class=\"number\">50</span>, <span class=\"number\">50</span>)</div><div class=\"line\">        btn.resize(btn.sizeHint())</div><div class=\"line\"></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">200</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Window with Button'</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    window = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<h2 id=\"Event\"><a href=\"#Event\" class=\"headerlink\" title=\"Event\"></a>Event</h2><p>Event<code>event.accept()</code><code>ignore()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QWidget, QMessageBox, QApplication</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">200</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">closeEvent</span><span class=\"params\">(self, ev)</span>:</span></div><div class=\"line\">        reply = QMessageBox.question(self, <span class=\"string\">'Message'</span>, <span class=\"string\">'Are you sure?'</span>,</div><div class=\"line\">                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No)</div><div class=\"line\">        <span class=\"keyword\">if</span> reply == QMessageBox.Yes:</div><div class=\"line\">            ev.accept()</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ev.ignore()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<h2 id=\"LayoutWidget\"><a href=\"#LayoutWidget\" class=\"headerlink\" title=\"LayoutWidget\"></a>LayoutWidget</h2><p>Widget<code>Layout</code></p>\n<p>widget</p>\n<ul>\n<li></li>\n<li>parent resizewidget</li>\n<li></li>\n</ul>\n<p><code>Layout</code></p>\n<h3 id=\"Box-Layout\"><a href=\"#Box-Layout\" class=\"headerlink\" title=\"Box Layout\"></a>Box Layout</h3><p><code>QVBoxLayout</code><code>QHBoxLayout</code>widgetlayout<code>addSkretch()</code><code>QSpacerItem</code>layout</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> (QWidget, QPushButton,</div><div class=\"line\">    QHBoxLayout, QVBoxLayout, QApplication)</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        okButton = QPushButton(<span class=\"string\">\"OK\"</span>)</div><div class=\"line\">        cancelButton = QPushButton(<span class=\"string\">\"Cancel\"</span>)</div><div class=\"line\"></div><div class=\"line\">        hbox = QHBoxLayout()</div><div class=\"line\">        hbox.addStretch(<span class=\"number\">1</span>)</div><div class=\"line\">        hbox.addWidget(okButton)</div><div class=\"line\">        hbox.addWidget(cancelButton)</div><div class=\"line\"></div><div class=\"line\">        vbox = QVBoxLayout()</div><div class=\"line\">        vbox.addStretch(<span class=\"number\">1</span>)</div><div class=\"line\">        vbox.addLayout(hbox)</div><div class=\"line\"></div><div class=\"line\">        self.setLayout(vbox)    </div><div class=\"line\"></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">150</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Buttons'</span>)    </div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<h3 id=\"Grid-Layout\"><a href=\"#Grid-Layout\" class=\"headerlink\" title=\"Grid Layout\"></a>Grid Layout</h3><p><code>QGridLayout</code>griditem54grid<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> (QWidget, QGridLayout,</div><div class=\"line\">    QPushButton, QApplication)</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        grid = QGridLayout()</div><div class=\"line\">        self.setLayout(grid)</div><div class=\"line\">        names = [<span class=\"string\">'Cls'</span>, <span class=\"string\">'Bck'</span>, <span class=\"string\">''</span>, <span class=\"string\">'Close'</span>,</div><div class=\"line\">                 <span class=\"string\">'7'</span>, <span class=\"string\">'8'</span>, <span class=\"string\">'9'</span>, <span class=\"string\">'/'</span>,</div><div class=\"line\">                <span class=\"string\">'4'</span>, <span class=\"string\">'5'</span>, <span class=\"string\">'6'</span>, <span class=\"string\">'*'</span>,</div><div class=\"line\">                 <span class=\"string\">'1'</span>, <span class=\"string\">'2'</span>, <span class=\"string\">'3'</span>, <span class=\"string\">'-'</span>,</div><div class=\"line\">                <span class=\"string\">'0'</span>, <span class=\"string\">'.'</span>, <span class=\"string\">'='</span>, <span class=\"string\">'+'</span>]</div><div class=\"line\">        positions = [(i,j) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)]</div><div class=\"line\">        <span class=\"keyword\">for</span> position, name <span class=\"keyword\">in</span> zip(positions, names):</div><div class=\"line\">            <span class=\"keyword\">if</span> name == <span class=\"string\">''</span>:</div><div class=\"line\">                <span class=\"keyword\">continue</span></div><div class=\"line\">            button = QPushButton(name)</div><div class=\"line\">            grid.addWidget(button, *position)</div><div class=\"line\"></div><div class=\"line\">        self.move(<span class=\"number\">300</span>, <span class=\"number\">150</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Calculator'</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\"></div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<p><code>setSpacing()</code>widget<code>addWidget()</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyQt</p>\n<ul>\n<li><code>event</code>UI</li>\n<li>widge</li>\n</ul>\n<p><code>connect()</code>Python</p>\n<p>eventoverride</p>\n","excerpt":"<p>QtGUIC++/PythonPyQT<a href=\"http://zetcode.com/gui/pyqt5/introduction/\">PyQT5</a><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyQt5</p>\n<ul>\n<li><code>QtCore</code>: GUI</li>\n<li><code>QtGui</code>GUI2D</li>\n<li><code>QtWidget</code>GUI</li>\n</ul>\n<p><code>QtBluetooth</code><code>QtNetwork</code></p>\n<h2 id=\"HelloWorld\"><a href=\"#HelloWorld\" class=\"headerlink\" title=\"HelloWorld\"></a>HelloWorld</h2><p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QApplication, QWidget</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    w = QWidget()</div><div class=\"line\">    w.resize(<span class=\"number\">250</span>, <span class=\"number\">150</span>)</div><div class=\"line\">    w.move(<span class=\"number\">300</span>, <span class=\"number\">300</span>)</div><div class=\"line\">    w.setWindowTitle(<span class=\"string\">'Simple'</span>)</div><div class=\"line\">    w.show()</div><div class=\"line\"></div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">app = QApplication(sys.argv)</div></pre></td></tr></table></figure></p>\n<p>Qt5application<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">w = QWidget()</div><div class=\"line\">w.resize(<span class=\"number\">250</span>, <span class=\"number\">150</span>)</div><div class=\"line\">w.move(<span class=\"number\">300</span>, <span class=\"number\">300</span>)</div><div class=\"line\">w.setWindowTitle(<span class=\"string\">'Simple'</span>)</div><div class=\"line\">w.show()</div></pre></td></tr></table></figure></p>\n<p><code>QtWidget</code><code>Widget</code>parent widgetWidget<code>show()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<p>applicationCtrl+C</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p><code>QPushButton</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">__init__ (self, QWidget parent = <span class=\"keyword\">None</span>)</div></pre></td></tr></table></figure></p>\n<p><code>QPushButton</code><code>btn</code><code>self</code>parent<code>sizeHint()</code></p>\n<p>Qt<code>clicked</code>PyQtslotPython<code>__call__()</code></p>\n<p><code>instance()</code>application<code>quit()</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QApplication, QWidget, QPushButton, QToolTip</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtCore <span class=\"keyword\">import</span> QCoreApplication</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        btn = QPushButton(<span class=\"string\">'quit'</span>, self)</div><div class=\"line\">        btn.clicked.connect(QCoreApplication.instance().quit)</div><div class=\"line\">        btn.setToolTip(<span class=\"string\">'This is a &lt;b&gt;QPushButton&lt;/b&gt; widget'</span>)</div><div class=\"line\">        btn.move(<span class=\"number\">50</span>, <span class=\"number\">50</span>)</div><div class=\"line\">        btn.resize(btn.sizeHint())</div><div class=\"line\"></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">200</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Window with Button'</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    window = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<h2 id=\"Event\"><a href=\"#Event\" class=\"headerlink\" title=\"Event\"></a>Event</h2><p>Event<code>event.accept()</code><code>ignore()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> QWidget, QMessageBox, QApplication</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">200</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">closeEvent</span><span class=\"params\">(self, ev)</span>:</span></div><div class=\"line\">        reply = QMessageBox.question(self, <span class=\"string\">'Message'</span>, <span class=\"string\">'Are you sure?'</span>,</div><div class=\"line\">                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No)</div><div class=\"line\">        <span class=\"keyword\">if</span> reply == QMessageBox.Yes:</div><div class=\"line\">            ev.accept()</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ev.ignore()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<h2 id=\"LayoutWidget\"><a href=\"#LayoutWidget\" class=\"headerlink\" title=\"LayoutWidget\"></a>LayoutWidget</h2><p>Widget<code>Layout</code></p>\n<p>widget</p>\n<ul>\n<li></li>\n<li>parent resizewidget</li>\n<li></li>\n</ul>\n<p><code>Layout</code></p>\n<h3 id=\"Box-Layout\"><a href=\"#Box-Layout\" class=\"headerlink\" title=\"Box Layout\"></a>Box Layout</h3><p><code>QVBoxLayout</code><code>QHBoxLayout</code>widgetlayout<code>addSkretch()</code><code>QSpacerItem</code>layout</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> (QWidget, QPushButton,</div><div class=\"line\">    QHBoxLayout, QVBoxLayout, QApplication)</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        okButton = QPushButton(<span class=\"string\">\"OK\"</span>)</div><div class=\"line\">        cancelButton = QPushButton(<span class=\"string\">\"Cancel\"</span>)</div><div class=\"line\"></div><div class=\"line\">        hbox = QHBoxLayout()</div><div class=\"line\">        hbox.addStretch(<span class=\"number\">1</span>)</div><div class=\"line\">        hbox.addWidget(okButton)</div><div class=\"line\">        hbox.addWidget(cancelButton)</div><div class=\"line\"></div><div class=\"line\">        vbox = QVBoxLayout()</div><div class=\"line\">        vbox.addStretch(<span class=\"number\">1</span>)</div><div class=\"line\">        vbox.addLayout(hbox)</div><div class=\"line\"></div><div class=\"line\">        self.setLayout(vbox)    </div><div class=\"line\"></div><div class=\"line\">        self.setGeometry(<span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">300</span>, <span class=\"number\">150</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Buttons'</span>)    </div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure>\n<h3 id=\"Grid-Layout\"><a href=\"#Grid-Layout\" class=\"headerlink\" title=\"Grid Layout\"></a>Grid Layout</h3><p><code>QGridLayout</code>griditem54grid<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> sys</div><div class=\"line\"><span class=\"keyword\">from</span> PyQt5.QtWidgets <span class=\"keyword\">import</span> (QWidget, QGridLayout,</div><div class=\"line\">    QPushButton, QApplication)</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MyWindow</span><span class=\"params\">(QWidget)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MyWindow, self).__init__()</div><div class=\"line\">        self._init_ui()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_ui</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        grid = QGridLayout()</div><div class=\"line\">        self.setLayout(grid)</div><div class=\"line\">        names = [<span class=\"string\">'Cls'</span>, <span class=\"string\">'Bck'</span>, <span class=\"string\">''</span>, <span class=\"string\">'Close'</span>,</div><div class=\"line\">                 <span class=\"string\">'7'</span>, <span class=\"string\">'8'</span>, <span class=\"string\">'9'</span>, <span class=\"string\">'/'</span>,</div><div class=\"line\">                <span class=\"string\">'4'</span>, <span class=\"string\">'5'</span>, <span class=\"string\">'6'</span>, <span class=\"string\">'*'</span>,</div><div class=\"line\">                 <span class=\"string\">'1'</span>, <span class=\"string\">'2'</span>, <span class=\"string\">'3'</span>, <span class=\"string\">'-'</span>,</div><div class=\"line\">                <span class=\"string\">'0'</span>, <span class=\"string\">'.'</span>, <span class=\"string\">'='</span>, <span class=\"string\">'+'</span>]</div><div class=\"line\">        positions = [(i,j) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)]</div><div class=\"line\">        <span class=\"keyword\">for</span> position, name <span class=\"keyword\">in</span> zip(positions, names):</div><div class=\"line\">            <span class=\"keyword\">if</span> name == <span class=\"string\">''</span>:</div><div class=\"line\">                <span class=\"keyword\">continue</span></div><div class=\"line\">            button = QPushButton(name)</div><div class=\"line\">            grid.addWidget(button, *position)</div><div class=\"line\"></div><div class=\"line\">        self.move(<span class=\"number\">300</span>, <span class=\"number\">150</span>)</div><div class=\"line\">        self.setWindowTitle(<span class=\"string\">'Calculator'</span>)</div><div class=\"line\">        self.show()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</div><div class=\"line\"></div><div class=\"line\">    app = QApplication(sys.argv)</div><div class=\"line\">    win = MyWindow()</div><div class=\"line\">    sys.exit(app.exec_())</div></pre></td></tr></table></figure></p>\n<p><code>setSpacing()</code>widget<code>addWidget()</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyQt</p>\n<ul>\n<li><code>event</code>UI</li>\n<li>widge</li>\n</ul>\n<p><code>connect()</code>Python</p>\n<p>eventoverride</p>"},{"title":"MacOS Mojave","date":"2018-10-27T06:57:12.000Z","_content":"APPPCMacOSMojave\n<!-- more -->\n\n## Git\n`git`\n\n```\ngit clone xx.git\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n```\n\n[macOS Mojave: invalid active developer path](https://apple.stackexchange.com/questions/254380/macos-mojave-invalid-active-developer-path)\n```\nxcode-select --install\n```\n\n## osxfuse\nGithub[osxfuse not compatible with MacOS Mojave](https://github.com/osxfuse/osxfuse/issues/542)3.8.2\n\n## VSCode\nVSCode\n```\ndefaults write -g CGFontRenderingFontSmoothingDisabled -bool NO\n```\n\n## Mos Caffine IINA APP\nMosMacWindowsMos\"\" -> MosCaffine\n\nIINAMacMacIINAIINA\n\n","source":"_posts/mac-update-mojave.md","raw":"---\ntitle: MacOS Mojave\ndate: 2018-10-27 14:57:12\ntags:\n    - tool\n---\nAPPPCMacOSMojave\n<!-- more -->\n\n## Git\n`git`\n\n```\ngit clone xx.git\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n```\n\n[macOS Mojave: invalid active developer path](https://apple.stackexchange.com/questions/254380/macos-mojave-invalid-active-developer-path)\n```\nxcode-select --install\n```\n\n## osxfuse\nGithub[osxfuse not compatible with MacOS Mojave](https://github.com/osxfuse/osxfuse/issues/542)3.8.2\n\n## VSCode\nVSCode\n```\ndefaults write -g CGFontRenderingFontSmoothingDisabled -bool NO\n```\n\n## Mos Caffine IINA APP\nMosMacWindowsMos\"\" -> MosCaffine\n\nIINAMacMacIINAIINA\n\n","slug":"mac-update-mojave","published":1,"updated":"2018-10-27T07:16:52.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mo002kae7b0h0cl4xi","content":"<p>APPPCMacOSMojave<br><a id=\"more\"></a></p>\n<h2 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h2><p><code>git</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">git clone xx.git</div><div class=\"line\">xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun</div></pre></td></tr></table></figure>\n<p><a href=\"https://apple.stackexchange.com/questions/254380/macos-mojave-invalid-active-developer-path\" target=\"_blank\" rel=\"external\">macOS Mojave: invalid active developer path</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">xcode-select --install</div></pre></td></tr></table></figure></p>\n<h2 id=\"osxfuse\"><a href=\"#osxfuse\" class=\"headerlink\" title=\"osxfuse\"></a>osxfuse</h2><p>Github<a href=\"https://github.com/osxfuse/osxfuse/issues/542\" target=\"_blank\" rel=\"external\">osxfuse not compatible with MacOS Mojave</a>3.8.2</p>\n<h2 id=\"VSCode\"><a href=\"#VSCode\" class=\"headerlink\" title=\"VSCode\"></a>VSCode</h2><p>VSCode<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">defaults write -g CGFontRenderingFontSmoothingDisabled -bool NO</div></pre></td></tr></table></figure></p>\n<h2 id=\"Mos-Caffine-IINA-APP\"><a href=\"#Mos-Caffine-IINA-APP\" class=\"headerlink\" title=\"Mos Caffine IINA APP\"></a>Mos Caffine IINA APP</h2><p>MosMacWindowsMos -&gt; MosCaffine</p>\n<p>IINAMacMacIINAIINA</p>\n<p></p>\n","excerpt":"<p>APPPCMacOSMojave<br>","more":"</p>\n<h2 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h2><p><code>git</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">git clone xx.git</div><div class=\"line\">xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun</div></pre></td></tr></table></figure>\n<p><a href=\"https://apple.stackexchange.com/questions/254380/macos-mojave-invalid-active-developer-path\">macOS Mojave: invalid active developer path</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">xcode-select --install</div></pre></td></tr></table></figure></p>\n<h2 id=\"osxfuse\"><a href=\"#osxfuse\" class=\"headerlink\" title=\"osxfuse\"></a>osxfuse</h2><p>Github<a href=\"https://github.com/osxfuse/osxfuse/issues/542\">osxfuse not compatible with MacOS Mojave</a>3.8.2</p>\n<h2 id=\"VSCode\"><a href=\"#VSCode\" class=\"headerlink\" title=\"VSCode\"></a>VSCode</h2><p>VSCode<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">defaults write -g CGFontRenderingFontSmoothingDisabled -bool NO</div></pre></td></tr></table></figure></p>\n<h2 id=\"Mos-Caffine-IINA-APP\"><a href=\"#Mos-Caffine-IINA-APP\" class=\"headerlink\" title=\"Mos Caffine IINA APP\"></a>Mos Caffine IINA APP</h2><p>MosMacWindowsMos -&gt; MosCaffine</p>\n<p>IINAMacMacIINAIINA</p>\n<p></p>"},{"title":"Caffe","date":"2017-03-08T09:24:48.000Z","_content":"CaffeBLAS[mathfunction.hpp ](https://github.com/BVLC/caffe/blob/master/include/caffe/util/math_functions.hpp)layerCaffescratchCPU/GPU\n![](/img/caffe_mathfunctions_gpuisnuclearweapon.jpg)\n\n<!-- more -->\n## BLAS\n[BLAS wiki](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms)BLASCaffe\n\nBLASBasic Linear Algebra SubprogramsBLASSIMDCFortran\n\nBLAS~~AMDACML~~IntelMKLATLASOpenBLASCaffe\n\nBLAS`gemm`GEMM: General Matrix to Matrix Multiplication`gemv`DL Jia Yangqing\n![](/img/mathfunctions_time_distribution.png)\n\nCPUGPUfeaturefeatureCaffeim2col\n![im2col](/img/mathfunctions_im2col.png)\n\nBLASGEMMDL[Why GEMM is at the heart of deep learning](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/)\n\n## \n`math_functions.hpp`BLASAPI[1]\n\n### \n\n`caffe_cpu_gemm()`BLAS`gemm``caffe_cpu_gemv()``gemv`\n\n``` cpp\ntemplate<>\nvoid caffe_cpu_gemm<float>(const CBLAS_TRANSPOSE TransA,\n    const CBLAS_TRANSPOSE TransB, const int M, const int N, const int K,\n    const float alpha, const float* A, const float* B, const float beta,\n    float* C) {\n  int lda = (TransA == CblasNoTrans) ? K : M;\n  int ldb = (TransB == CblasNoTrans) ? N : K;\n  cblas_sgemm(CblasRowMajor, TransA, TransB, M, N, K, alpha, A, lda, B,\n      ldb, beta, C, N);\n}\n```\n\nSingle FloatBLAS`cblas_sgemm()``C = alpha * A * B + beta * C`BLAS\n\n### /\n`X``src``Y``dst`\n\n- `caffe_axpy(N, alpha, x, mutable y)``Y = alpha * X + Y`\n- `caffe_axpby(N, alpha, x, beta, mutable y)``Y = alpha * X + beta * Y`\n\nloss\n\n``` cpp\ncaffe_cpu_axpby(\n    bottom[i]->count(),              // count\n    alpha,                              // alpha\n    diff_.cpu_data(),                   // a\n    Dtype(0),                           // beta\n    bottom[i]->mutable_cpu_diff());  // b\n}\n```\n`bottom[i]->count()``blob``alpha``top_blob``loss_weight``*top_blob->cpu_diff()/batch_size``diff``bottom_blob``cpu_diff``beta`0\n\n### \nC`memset()``memcpy()`Caffe\n- `caffe_copy(N, x, mutable y)`\n- `caffe_set(N, alpha, mutable x)``alpha`\n\nCaffe`memset()`\n``` cpp\ntemplate <typename Dtype>\nvoid caffe_set(const int N, const Dtype alpha, Dtype* Y) {\n  if (alpha == 0) {\n    memset(Y, 0, sizeof(Dtype) * N);  // NOLINT(caffe/alt_fn)\n    return;\n  }\n  for (int i = 0; i < N; ++i) {\n    Y[i] = alpha;\n  }\n}\n\n// \ntemplate void caffe_set<int>(const int N, const int alpha, int* Y);\ntemplate void caffe_set<float>(const int N, const float alpha, float* Y);\ntemplate void caffe_set<double>(const int N, const double alpha, double* Y);\n```\n\n`caffe_copy()`CPUGPU`cudaMemcpy()``cudaMemcpyDefault`[cudaMemcpyDefault: Default based unified virtual address space](http://horacio9573.no-ip.org/cuda/group__CUDART__TYPES_g18fa99055ee694244a270e4d5101e95b.html)CPUGPU\n\n``` cpp\ntemplate <typename Dtype>\nvoid caffe_copy(const int N, const Dtype* X, Dtype* Y) {\n  if (X != Y) {\n    if (Caffe::mode() == Caffe::GPU) {\n#ifndef CPU_ONLY\n      // NOLINT_NEXT_LINE(caffe/alt_fn)\n      CUDA_CHECK(cudaMemcpy(Y, X, sizeof(Dtype) * N, cudaMemcpyDefault));\n#else\n      NO_GPU;\n#endif\n    } else {\n      memcpy(Y, X, sizeof(Dtype) * N);  // NOLINT(caffe/alt_fn)\n    }\n  }\n}\n```\n\nunified virtual addressUVA[P2P&UVA](http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_GPUDirect_uva.pdf)\n![UVA](/img/caffe_mathfunctions_whatisuva.png)\n\nGPUCUDA\n![How to use UVA](/img/caffe_mathfunctions_useuva.png)\n\n\n![UVA Requirement](/img/caffe_mathfunctions_uvarequirement.png)\n\n### \n- `caffe_add(N, a, b, y)``Y[i] = a[i] + b[i]`\n- `caffe_sub`, `caffe_div`, `caffe_mul`\n- `caffe_exp`, `caffe_powx`, `caffe_abs`, `caffe_sqr`, `caffe_log``caffe_exp()`\n\n``` cpp\n// \ntemplate <>\nvoid caffe_exp<float>(const int n, const float* a, float* y) {\n  vsExp(n, a, y);   //  y[i] = exp(a[i])\n}\n```\n\n- `caffe_scal``loss_layer``loss_weight`\n- `caffe_add_scalar`\n\n## GPU\nBLASCPUGPU`math_functions.hpp``math_functions.cu`\n\n## \nCaffe\n\nCaffeuniformgaussianbernoulli`caffe_rng_distribution_name`\n\n## \n1[seven-first ](http://blog.csdn.net/seven_first/article/details/47378697)\n","source":"_posts/mathfunctions-in-caffe.md","raw":"---\ntitle: Caffe\ndate: 2017-03-08 17:24:48\ntags:\n    - caffe\n---\nCaffeBLAS[mathfunction.hpp ](https://github.com/BVLC/caffe/blob/master/include/caffe/util/math_functions.hpp)layerCaffescratchCPU/GPU\n![](/img/caffe_mathfunctions_gpuisnuclearweapon.jpg)\n\n<!-- more -->\n## BLAS\n[BLAS wiki](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms)BLASCaffe\n\nBLASBasic Linear Algebra SubprogramsBLASSIMDCFortran\n\nBLAS~~AMDACML~~IntelMKLATLASOpenBLASCaffe\n\nBLAS`gemm`GEMM: General Matrix to Matrix Multiplication`gemv`DL Jia Yangqing\n![](/img/mathfunctions_time_distribution.png)\n\nCPUGPUfeaturefeatureCaffeim2col\n![im2col](/img/mathfunctions_im2col.png)\n\nBLASGEMMDL[Why GEMM is at the heart of deep learning](https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/)\n\n## \n`math_functions.hpp`BLASAPI[1]\n\n### \n\n`caffe_cpu_gemm()`BLAS`gemm``caffe_cpu_gemv()``gemv`\n\n``` cpp\ntemplate<>\nvoid caffe_cpu_gemm<float>(const CBLAS_TRANSPOSE TransA,\n    const CBLAS_TRANSPOSE TransB, const int M, const int N, const int K,\n    const float alpha, const float* A, const float* B, const float beta,\n    float* C) {\n  int lda = (TransA == CblasNoTrans) ? K : M;\n  int ldb = (TransB == CblasNoTrans) ? N : K;\n  cblas_sgemm(CblasRowMajor, TransA, TransB, M, N, K, alpha, A, lda, B,\n      ldb, beta, C, N);\n}\n```\n\nSingle FloatBLAS`cblas_sgemm()``C = alpha * A * B + beta * C`BLAS\n\n### /\n`X``src``Y``dst`\n\n- `caffe_axpy(N, alpha, x, mutable y)``Y = alpha * X + Y`\n- `caffe_axpby(N, alpha, x, beta, mutable y)``Y = alpha * X + beta * Y`\n\nloss\n\n``` cpp\ncaffe_cpu_axpby(\n    bottom[i]->count(),              // count\n    alpha,                              // alpha\n    diff_.cpu_data(),                   // a\n    Dtype(0),                           // beta\n    bottom[i]->mutable_cpu_diff());  // b\n}\n```\n`bottom[i]->count()``blob``alpha``top_blob``loss_weight``*top_blob->cpu_diff()/batch_size``diff``bottom_blob``cpu_diff``beta`0\n\n### \nC`memset()``memcpy()`Caffe\n- `caffe_copy(N, x, mutable y)`\n- `caffe_set(N, alpha, mutable x)``alpha`\n\nCaffe`memset()`\n``` cpp\ntemplate <typename Dtype>\nvoid caffe_set(const int N, const Dtype alpha, Dtype* Y) {\n  if (alpha == 0) {\n    memset(Y, 0, sizeof(Dtype) * N);  // NOLINT(caffe/alt_fn)\n    return;\n  }\n  for (int i = 0; i < N; ++i) {\n    Y[i] = alpha;\n  }\n}\n\n// \ntemplate void caffe_set<int>(const int N, const int alpha, int* Y);\ntemplate void caffe_set<float>(const int N, const float alpha, float* Y);\ntemplate void caffe_set<double>(const int N, const double alpha, double* Y);\n```\n\n`caffe_copy()`CPUGPU`cudaMemcpy()``cudaMemcpyDefault`[cudaMemcpyDefault: Default based unified virtual address space](http://horacio9573.no-ip.org/cuda/group__CUDART__TYPES_g18fa99055ee694244a270e4d5101e95b.html)CPUGPU\n\n``` cpp\ntemplate <typename Dtype>\nvoid caffe_copy(const int N, const Dtype* X, Dtype* Y) {\n  if (X != Y) {\n    if (Caffe::mode() == Caffe::GPU) {\n#ifndef CPU_ONLY\n      // NOLINT_NEXT_LINE(caffe/alt_fn)\n      CUDA_CHECK(cudaMemcpy(Y, X, sizeof(Dtype) * N, cudaMemcpyDefault));\n#else\n      NO_GPU;\n#endif\n    } else {\n      memcpy(Y, X, sizeof(Dtype) * N);  // NOLINT(caffe/alt_fn)\n    }\n  }\n}\n```\n\nunified virtual addressUVA[P2P&UVA](http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_GPUDirect_uva.pdf)\n![UVA](/img/caffe_mathfunctions_whatisuva.png)\n\nGPUCUDA\n![How to use UVA](/img/caffe_mathfunctions_useuva.png)\n\n\n![UVA Requirement](/img/caffe_mathfunctions_uvarequirement.png)\n\n### \n- `caffe_add(N, a, b, y)``Y[i] = a[i] + b[i]`\n- `caffe_sub`, `caffe_div`, `caffe_mul`\n- `caffe_exp`, `caffe_powx`, `caffe_abs`, `caffe_sqr`, `caffe_log``caffe_exp()`\n\n``` cpp\n// \ntemplate <>\nvoid caffe_exp<float>(const int n, const float* a, float* y) {\n  vsExp(n, a, y);   //  y[i] = exp(a[i])\n}\n```\n\n- `caffe_scal``loss_layer``loss_weight`\n- `caffe_add_scalar`\n\n## GPU\nBLASCPUGPU`math_functions.hpp``math_functions.cu`\n\n## \nCaffe\n\nCaffeuniformgaussianbernoulli`caffe_rng_distribution_name`\n\n## \n1[seven-first ](http://blog.csdn.net/seven_first/article/details/47378697)\n","slug":"mathfunctions-in-caffe","published":1,"updated":"2018-10-27T07:16:52.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mq002mae7b2l37opdy","content":"<p>CaffeBLAS<a href=\"https://github.com/BVLC/caffe/blob/master/include/caffe/util/math_functions.hpp\" target=\"_blank\" rel=\"external\">mathfunction.hpp </a>layerCaffescratchCPU/GPU<br><img src=\"/img/caffe_mathfunctions_gpuisnuclearweapon.jpg\" alt=\"\"></p>\n<a id=\"more\"></a>\n<h2 id=\"BLAS\"><a href=\"#BLAS\" class=\"headerlink\" title=\"BLAS\"></a>BLAS</h2><p><a href=\"https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\" target=\"_blank\" rel=\"external\">BLAS wiki</a>BLASCaffe</p>\n<p>BLASBasic Linear Algebra SubprogramsBLASSIMDCFortran</p>\n<p>BLAS<del>AMDACML</del>IntelMKLATLASOpenBLASCaffe</p>\n<p>BLAS<code>gemm</code>GEMM: General Matrix to Matrix Multiplication<code>gemv</code>DL Jia Yangqing<br><img src=\"/img/mathfunctions_time_distribution.png\" alt=\"\"></p>\n<p>CPUGPUfeaturefeatureCaffeim2col<br><img src=\"/img/mathfunctions_im2col.png\" alt=\"im2col\"></p>\n<p>BLASGEMMDL<a href=\"https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/\" target=\"_blank\" rel=\"external\">Why GEMM is at the heart of deep learning</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>math_functions.hpp</code>BLASAPI[1]</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>caffe_cpu_gemm()</code>BLAS<code>gemm</code><code>caffe_cpu_gemv()</code><code>gemv</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> caffe_cpu_gemm&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> CBLAS_TRANSPOSE TransA,</div><div class=\"line\">    <span class=\"keyword\">const</span> CBLAS_TRANSPOSE TransB, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> M, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> K,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> alpha, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* A, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* B, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> beta,</div><div class=\"line\">    <span class=\"keyword\">float</span>* C) &#123;</div><div class=\"line\">  <span class=\"keyword\">int</span> lda = (TransA == CblasNoTrans) ? K : M;</div><div class=\"line\">  <span class=\"keyword\">int</span> ldb = (TransB == CblasNoTrans) ? N : K;</div><div class=\"line\">  cblas_sgemm(CblasRowMajor, TransA, TransB, M, N, K, alpha, A, lda, B,</div><div class=\"line\">      ldb, beta, C, N);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Single FloatBLAS<code>cblas_sgemm()</code><code>C = alpha * A * B + beta * C</code>BLAS</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"/\"></a>/</h3><p><code>X</code><code>src</code><code>Y</code><code>dst</code></p>\n<ul>\n<li><code>caffe_axpy(N, alpha, x, mutable y)</code><code>Y = alpha * X + Y</code></li>\n<li><code>caffe_axpby(N, alpha, x, beta, mutable y)</code><code>Y = alpha * X + beta * Y</code></li>\n</ul>\n<p>loss</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">caffe_cpu_axpby(</div><div class=\"line\">    bottom[i]-&gt;count(),              <span class=\"comment\">// count</span></div><div class=\"line\">    alpha,                              <span class=\"comment\">// alpha</span></div><div class=\"line\">    diff_.cpu_data(),                   <span class=\"comment\">// a</span></div><div class=\"line\">    Dtype(<span class=\"number\">0</span>),                           <span class=\"comment\">// beta</span></div><div class=\"line\">    bottom[i]-&gt;mutable_cpu_diff());  <span class=\"comment\">// b</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>bottom[i]-&gt;count()</code><code>blob</code><code>alpha</code><code>top_blob</code><code>loss_weight</code><code>*top_blob-&gt;cpu_diff()/batch_size</code><code>diff</code><code>bottom_blob</code><code>cpu_diff</code><code>beta</code>0</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>C<code>memset()</code><code>memcpy()</code>Caffe</p>\n<ul>\n<li><code>caffe_copy(N, x, mutable y)</code></li>\n<li><code>caffe_set(N, alpha, mutable x)</code><code>alpha</code></li>\n</ul>\n<p>Caffe<code>memset()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">caffe_set</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> Dtype alpha, Dtype* Y)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">if</span> (alpha == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Y, <span class=\"number\">0</span>, <span class=\"keyword\">sizeof</span>(Dtype) * N);  <span class=\"comment\">// NOLINT(caffe/alt_fn)</span></div><div class=\"line\">    <span class=\"keyword\">return</span>;</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; N; ++i) &#123;</div><div class=\"line\">    Y[i] = alpha;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> alpha, <span class=\"keyword\">int</span>* Y);</div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> alpha, <span class=\"keyword\">float</span>* Y);</div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">double</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">double</span> alpha, <span class=\"keyword\">double</span>* Y);</div></pre></td></tr></table></figure></p>\n<p><code>caffe_copy()</code>CPUGPU<code>cudaMemcpy()</code><code>cudaMemcpyDefault</code><a href=\"http://horacio9573.no-ip.org/cuda/group__CUDART__TYPES_g18fa99055ee694244a270e4d5101e95b.html\" target=\"_blank\" rel=\"external\">cudaMemcpyDefault: Default based unified virtual address space</a>CPUGPU</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">caffe_copy</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> Dtype* X, Dtype* Y)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">if</span> (X != Y) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span> (Caffe::mode() == Caffe::GPU) &#123;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">      <span class=\"comment\">// NOLINT_NEXT_LINE(caffe/alt_fn)</span></div><div class=\"line\">      CUDA_CHECK(cudaMemcpy(Y, X, <span class=\"keyword\">sizeof</span>(Dtype) * N, cudaMemcpyDefault));</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></div><div class=\"line\">      NO_GPU;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">      <span class=\"built_in\">memcpy</span>(Y, X, <span class=\"keyword\">sizeof</span>(Dtype) * N);  <span class=\"comment\">// NOLINT(caffe/alt_fn)</span></div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>unified virtual addressUVA<a href=\"http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_GPUDirect_uva.pdf\" target=\"_blank\" rel=\"external\">P2P&amp;UVA</a><br><img src=\"/img/caffe_mathfunctions_whatisuva.png\" alt=\"UVA\"></p>\n<p>GPUCUDA<br><img src=\"/img/caffe_mathfunctions_useuva.png\" alt=\"How to use UVA\"></p>\n<p><br><img src=\"/img/caffe_mathfunctions_uvarequirement.png\" alt=\"UVA Requirement\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><code>caffe_add(N, a, b, y)</code><code>Y[i] = a[i] + b[i]</code></li>\n<li><code>caffe_sub</code>, <code>caffe_div</code>, <code>caffe_mul</code></li>\n<li><code>caffe_exp</code>, <code>caffe_powx</code>, <code>caffe_abs</code>, <code>caffe_sqr</code>, <code>caffe_log</code><code>caffe_exp()</code></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> caffe_exp&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> n, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* a, <span class=\"keyword\">float</span>* y) &#123;</div><div class=\"line\">  vsExp(n, a, y);   <span class=\"comment\">//  y[i] = exp(a[i])</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li><code>caffe_scal</code><code>loss_layer</code><code>loss_weight</code></li>\n<li><code>caffe_add_scalar</code></li>\n</ul>\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><p>BLASCPUGPU<code>math_functions.hpp</code><code>math_functions.cu</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Caffe</p>\n<p>Caffeuniformgaussianbernoulli<code>caffe_rng_distribution_name</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>1<a href=\"http://blog.csdn.net/seven_first/article/details/47378697\" target=\"_blank\" rel=\"external\">seven-first </a></p>\n","excerpt":"<p>CaffeBLAS<a href=\"https://github.com/BVLC/caffe/blob/master/include/caffe/util/math_functions.hpp\">mathfunction.hpp </a>layerCaffescratchCPU/GPU<br><img src=\"/img/caffe_mathfunctions_gpuisnuclearweapon.jpg\" alt=\"\"></p>","more":"<h2 id=\"BLAS\"><a href=\"#BLAS\" class=\"headerlink\" title=\"BLAS\"></a>BLAS</h2><p><a href=\"https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms\">BLAS wiki</a>BLASCaffe</p>\n<p>BLASBasic Linear Algebra SubprogramsBLASSIMDCFortran</p>\n<p>BLAS<del>AMDACML</del>IntelMKLATLASOpenBLASCaffe</p>\n<p>BLAS<code>gemm</code>GEMM: General Matrix to Matrix Multiplication<code>gemv</code>DL Jia Yangqing<br><img src=\"/img/mathfunctions_time_distribution.png\" alt=\"\"></p>\n<p>CPUGPUfeaturefeatureCaffeim2col<br><img src=\"/img/mathfunctions_im2col.png\" alt=\"im2col\"></p>\n<p>BLASGEMMDL<a href=\"https://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/\">Why GEMM is at the heart of deep learning</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>math_functions.hpp</code>BLASAPI[1]</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>caffe_cpu_gemm()</code>BLAS<code>gemm</code><code>caffe_cpu_gemv()</code><code>gemv</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span>&lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> caffe_cpu_gemm&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> CBLAS_TRANSPOSE TransA,</div><div class=\"line\">    <span class=\"keyword\">const</span> CBLAS_TRANSPOSE TransB, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> M, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> K,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> alpha, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* A, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* B, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> beta,</div><div class=\"line\">    <span class=\"keyword\">float</span>* C) &#123;</div><div class=\"line\">  <span class=\"keyword\">int</span> lda = (TransA == CblasNoTrans) ? K : M;</div><div class=\"line\">  <span class=\"keyword\">int</span> ldb = (TransB == CblasNoTrans) ? N : K;</div><div class=\"line\">  cblas_sgemm(CblasRowMajor, TransA, TransB, M, N, K, alpha, A, lda, B,</div><div class=\"line\">      ldb, beta, C, N);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Single FloatBLAS<code>cblas_sgemm()</code><code>C = alpha * A * B + beta * C</code>BLAS</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"/\"></a>/</h3><p><code>X</code><code>src</code><code>Y</code><code>dst</code></p>\n<ul>\n<li><code>caffe_axpy(N, alpha, x, mutable y)</code><code>Y = alpha * X + Y</code></li>\n<li><code>caffe_axpby(N, alpha, x, beta, mutable y)</code><code>Y = alpha * X + beta * Y</code></li>\n</ul>\n<p>loss</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">caffe_cpu_axpby(</div><div class=\"line\">    bottom[i]-&gt;count(),              <span class=\"comment\">// count</span></div><div class=\"line\">    alpha,                              <span class=\"comment\">// alpha</span></div><div class=\"line\">    diff_.cpu_data(),                   <span class=\"comment\">// a</span></div><div class=\"line\">    Dtype(<span class=\"number\">0</span>),                           <span class=\"comment\">// beta</span></div><div class=\"line\">    bottom[i]-&gt;mutable_cpu_diff());  <span class=\"comment\">// b</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>bottom[i]-&gt;count()</code><code>blob</code><code>alpha</code><code>top_blob</code><code>loss_weight</code><code>*top_blob-&gt;cpu_diff()/batch_size</code><code>diff</code><code>bottom_blob</code><code>cpu_diff</code><code>beta</code>0</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>C<code>memset()</code><code>memcpy()</code>Caffe</p>\n<ul>\n<li><code>caffe_copy(N, x, mutable y)</code></li>\n<li><code>caffe_set(N, alpha, mutable x)</code><code>alpha</code></li>\n</ul>\n<p>Caffe<code>memset()</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">caffe_set</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> Dtype alpha, Dtype* Y)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">if</span> (alpha == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(Y, <span class=\"number\">0</span>, <span class=\"keyword\">sizeof</span>(Dtype) * N);  <span class=\"comment\">// NOLINT(caffe/alt_fn)</span></div><div class=\"line\">    <span class=\"keyword\">return</span>;</div><div class=\"line\">  &#125;</div><div class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; N; ++i) &#123;</div><div class=\"line\">    Y[i] = alpha;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">int</span> alpha, <span class=\"keyword\">int</span>* Y);</div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span> alpha, <span class=\"keyword\">float</span>* Y);</div><div class=\"line\"><span class=\"keyword\">template</span> <span class=\"keyword\">void</span> caffe_set&lt;<span class=\"keyword\">double</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> <span class=\"keyword\">double</span> alpha, <span class=\"keyword\">double</span>* Y);</div></pre></td></tr></table></figure></p>\n<p><code>caffe_copy()</code>CPUGPU<code>cudaMemcpy()</code><code>cudaMemcpyDefault</code><a href=\"http://horacio9573.no-ip.org/cuda/group__CUDART__TYPES_g18fa99055ee694244a270e4d5101e95b.html\">cudaMemcpyDefault: Default based unified virtual address space</a>CPUGPU</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> Dtype&gt;</div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">caffe_copy</span><span class=\"params\">(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> N, <span class=\"keyword\">const</span> Dtype* X, Dtype* Y)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">if</span> (X != Y) &#123;</div><div class=\"line\">    <span class=\"keyword\">if</span> (Caffe::mode() == Caffe::GPU) &#123;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifndef</span> CPU_ONLY</span></div><div class=\"line\">      <span class=\"comment\">// NOLINT_NEXT_LINE(caffe/alt_fn)</span></div><div class=\"line\">      CUDA_CHECK(cudaMemcpy(Y, X, <span class=\"keyword\">sizeof</span>(Dtype) * N, cudaMemcpyDefault));</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span></span></div><div class=\"line\">      NO_GPU;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</div><div class=\"line\">      <span class=\"built_in\">memcpy</span>(Y, X, <span class=\"keyword\">sizeof</span>(Dtype) * N);  <span class=\"comment\">// NOLINT(caffe/alt_fn)</span></div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>unified virtual addressUVA<a href=\"http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_GPUDirect_uva.pdf\">P2P&amp;UVA</a><br><img src=\"/img/caffe_mathfunctions_whatisuva.png\" alt=\"UVA\"></p>\n<p>GPUCUDA<br><img src=\"/img/caffe_mathfunctions_useuva.png\" alt=\"How to use UVA\"></p>\n<p><br><img src=\"/img/caffe_mathfunctions_uvarequirement.png\" alt=\"UVA Requirement\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><code>caffe_add(N, a, b, y)</code><code>Y[i] = a[i] + b[i]</code></li>\n<li><code>caffe_sub</code>, <code>caffe_div</code>, <code>caffe_mul</code></li>\n<li><code>caffe_exp</code>, <code>caffe_powx</code>, <code>caffe_abs</code>, <code>caffe_sqr</code>, <code>caffe_log</code><code>caffe_exp()</code></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> caffe_exp&lt;<span class=\"keyword\">float</span>&gt;(<span class=\"keyword\">const</span> <span class=\"keyword\">int</span> n, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* a, <span class=\"keyword\">float</span>* y) &#123;</div><div class=\"line\">  vsExp(n, a, y);   <span class=\"comment\">//  y[i] = exp(a[i])</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<ul>\n<li><code>caffe_scal</code><code>loss_layer</code><code>loss_weight</code></li>\n<li><code>caffe_add_scalar</code></li>\n</ul>\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><p>BLASCPUGPU<code>math_functions.hpp</code><code>math_functions.cu</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Caffe</p>\n<p>Caffeuniformgaussianbernoulli<code>caffe_rng_distribution_name</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>1<a href=\"http://blog.csdn.net/seven_first/article/details/47378697\">seven-first </a></p>"},{"title":"MXNet fit","date":"2018-10-02T14:11:15.000Z","_content":"MXNet`Module``symbol``Module``fit()`detection, segmentation`fit()``fit()`\n\nMXNetTensorFlowPyTorchMXNetLinkedIn[Slide](https://www.slideshare.net/beam2d/differences-of-deep-learning-frameworks)TorchPyTorch\n\n![Differences of Deep Learning Frameworks](/img/differences-of-deep-learning-frameworks-22-638.jpg)\n\n<!-- more-->\n\n## \n\n\nmetric\n\n\n\n## \nSGDdatalabelbatchfeedforward computingbpSGD, SGD with momentum, RMSprop\n\n\n``` py\n# in an epoch\nwhile not end_epoch:\n    batch = next(train_iter)\n    m.forward_backward(batch)\n    m.update()\n    try:\n        next_batch = next(data_iter)\n        m.prepare(next_batch)\n    except StopIteration:\n        end_epoch = True\n```\n\n## metric\nmetricmetricmetricAccuracyTopK-AccuracyMXNet`fit``m.update_metric(eval_metric, data_batch.label)``eval_metric`metric`label`batchlabelMXNetlabel`list`label`list of NDArray`\n\n## logging\neval_metricMXNetcallbackcheckpointcallbackbatchloggingmetricMXNet`BatchEndParam``namedtuple`epochmetriclogging\n\n`Speedometer`metric\n> Logs training speed and evaluation metrics periodically\n\nPS:MXNet`Speedometer``metric`validationbatchmetric`fit``eval_batch_end_callback``Speedometer``auto_reset=False``None``Module.score()`metric\n\n`Speedometer`\n\n``` py\nif param.eval_metric is not None:\n    name_value = param.eval_metric.get_name_value()\n    if self.auto_reset:\n        param.eval_metric.reset()\n```\n\n## \nepochMXNet`score()``score``fit()`forward computing\n\n## \nMXNetMXNetpythonguidetoolmetricDL`fit()`MXNet\n\nTensorFlowDLMXNetCosinelearning rate decayModel Zoo(gluonGluon-CVGluon-NLP)\n\nMXNetpythonmoduleoptimizermetricexampleMXNetMXNet\n","source":"_posts/mxnet-fit-usage.md","raw":"---\ntitle: MXNet fit\ndate: 2018-10-02 22:11:15\ntags:\n     - mxnet\n---\nMXNet`Module``symbol``Module``fit()`detection, segmentation`fit()``fit()`\n\nMXNetTensorFlowPyTorchMXNetLinkedIn[Slide](https://www.slideshare.net/beam2d/differences-of-deep-learning-frameworks)TorchPyTorch\n\n![Differences of Deep Learning Frameworks](/img/differences-of-deep-learning-frameworks-22-638.jpg)\n\n<!-- more-->\n\n## \n\n\nmetric\n\n\n\n## \nSGDdatalabelbatchfeedforward computingbpSGD, SGD with momentum, RMSprop\n\n\n``` py\n# in an epoch\nwhile not end_epoch:\n    batch = next(train_iter)\n    m.forward_backward(batch)\n    m.update()\n    try:\n        next_batch = next(data_iter)\n        m.prepare(next_batch)\n    except StopIteration:\n        end_epoch = True\n```\n\n## metric\nmetricmetricmetricAccuracyTopK-AccuracyMXNet`fit``m.update_metric(eval_metric, data_batch.label)``eval_metric`metric`label`batchlabelMXNetlabel`list`label`list of NDArray`\n\n## logging\neval_metricMXNetcallbackcheckpointcallbackbatchloggingmetricMXNet`BatchEndParam``namedtuple`epochmetriclogging\n\n`Speedometer`metric\n> Logs training speed and evaluation metrics periodically\n\nPS:MXNet`Speedometer``metric`validationbatchmetric`fit``eval_batch_end_callback``Speedometer``auto_reset=False``None``Module.score()`metric\n\n`Speedometer`\n\n``` py\nif param.eval_metric is not None:\n    name_value = param.eval_metric.get_name_value()\n    if self.auto_reset:\n        param.eval_metric.reset()\n```\n\n## \nepochMXNet`score()``score``fit()`forward computing\n\n## \nMXNetMXNetpythonguidetoolmetricDL`fit()`MXNet\n\nTensorFlowDLMXNetCosinelearning rate decayModel Zoo(gluonGluon-CVGluon-NLP)\n\nMXNetpythonmoduleoptimizermetricexampleMXNetMXNet\n","slug":"mxnet-fit-usage","published":1,"updated":"2018-10-27T07:16:52.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mw002pae7babfk8ifu","content":"<p>MXNet<code>Module</code><code>symbol</code><code>Module</code><code>fit()</code>detection, segmentation<code>fit()</code><code>fit()</code></p>\n<p>MXNetTensorFlowPyTorchMXNetLinkedIn<a href=\"https://www.slideshare.net/beam2d/differences-of-deep-learning-frameworks\" target=\"_blank\" rel=\"external\">Slide</a>TorchPyTorch</p>\n<p><img src=\"/img/differences-of-deep-learning-frameworks-22-638.jpg\" alt=\"Differences of Deep Learning Frameworks\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>metric</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SGDdatalabelbatchfeedforward computingbpSGD, SGD with momentum, RMSprop</p>\n<p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># in an epoch</span></div><div class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">not</span> end_epoch:</div><div class=\"line\">    batch = next(train_iter)</div><div class=\"line\">    m.forward_backward(batch)</div><div class=\"line\">    m.update()</div><div class=\"line\">    <span class=\"keyword\">try</span>:</div><div class=\"line\">        next_batch = next(data_iter)</div><div class=\"line\">        m.prepare(next_batch)</div><div class=\"line\">    <span class=\"keyword\">except</span> StopIteration:</div><div class=\"line\">        end_epoch = <span class=\"keyword\">True</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"metric\"><a href=\"#metric\" class=\"headerlink\" title=\"metric\"></a>metric</h2><p>metricmetricmetricAccuracyTopK-AccuracyMXNet<code>fit</code><code>m.update_metric(eval_metric, data_batch.label)</code><code>eval_metric</code>metric<code>label</code>batchlabelMXNetlabel<code>list</code>label<code>list of NDArray</code></p>\n<h2 id=\"logging\"><a href=\"#logging\" class=\"headerlink\" title=\"logging\"></a>logging</h2><p>eval_metricMXNetcallbackcheckpointcallbackbatchloggingmetricMXNet<code>BatchEndParam</code><code>namedtuple</code>epochmetriclogging</p>\n<p><code>Speedometer</code>metric</p>\n<blockquote>\n<p>Logs training speed and evaluation metrics periodically</p>\n</blockquote>\n<p>PS:MXNet<code>Speedometer</code><code>metric</code>validationbatchmetric<code>fit</code><code>eval_batch_end_callback</code><code>Speedometer</code><code>auto_reset=False</code><code>None</code><code>Module.score()</code>metric</p>\n<p><code>Speedometer</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> param.eval_metric <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</div><div class=\"line\">    name_value = param.eval_metric.get_name_value()</div><div class=\"line\">    <span class=\"keyword\">if</span> self.auto_reset:</div><div class=\"line\">        param.eval_metric.reset()</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>epochMXNet<code>score()</code><code>score</code><code>fit()</code>forward computing</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MXNetMXNetpythonguidetoolmetricDL<code>fit()</code>MXNet</p>\n<p>TensorFlowDLMXNetCosinelearning rate decayModel Zoo(gluonGluon-CVGluon-NLP)</p>\n<p>MXNetpythonmoduleoptimizermetricexampleMXNetMXNet</p>\n","excerpt":"<p>MXNet<code>Module</code><code>symbol</code><code>Module</code><code>fit()</code>detection, segmentation<code>fit()</code><code>fit()</code></p>\n<p>MXNetTensorFlowPyTorchMXNetLinkedIn<a href=\"https://www.slideshare.net/beam2d/differences-of-deep-learning-frameworks\">Slide</a>TorchPyTorch</p>\n<p><img src=\"/img/differences-of-deep-learning-frameworks-22-638.jpg\" alt=\"Differences of Deep Learning Frameworks\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>metric</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SGDdatalabelbatchfeedforward computingbpSGD, SGD with momentum, RMSprop</p>\n<p><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># in an epoch</span></div><div class=\"line\"><span class=\"keyword\">while</span> <span class=\"keyword\">not</span> end_epoch:</div><div class=\"line\">    batch = next(train_iter)</div><div class=\"line\">    m.forward_backward(batch)</div><div class=\"line\">    m.update()</div><div class=\"line\">    <span class=\"keyword\">try</span>:</div><div class=\"line\">        next_batch = next(data_iter)</div><div class=\"line\">        m.prepare(next_batch)</div><div class=\"line\">    <span class=\"keyword\">except</span> StopIteration:</div><div class=\"line\">        end_epoch = <span class=\"keyword\">True</span></div></pre></td></tr></table></figure></p>\n<h2 id=\"metric\"><a href=\"#metric\" class=\"headerlink\" title=\"metric\"></a>metric</h2><p>metricmetricmetricAccuracyTopK-AccuracyMXNet<code>fit</code><code>m.update_metric(eval_metric, data_batch.label)</code><code>eval_metric</code>metric<code>label</code>batchlabelMXNetlabel<code>list</code>label<code>list of NDArray</code></p>\n<h2 id=\"logging\"><a href=\"#logging\" class=\"headerlink\" title=\"logging\"></a>logging</h2><p>eval_metricMXNetcallbackcheckpointcallbackbatchloggingmetricMXNet<code>BatchEndParam</code><code>namedtuple</code>epochmetriclogging</p>\n<p><code>Speedometer</code>metric</p>\n<blockquote>\n<p>Logs training speed and evaluation metrics periodically</p>\n</blockquote>\n<p>PS:MXNet<code>Speedometer</code><code>metric</code>validationbatchmetric<code>fit</code><code>eval_batch_end_callback</code><code>Speedometer</code><code>auto_reset=False</code><code>None</code><code>Module.score()</code>metric</p>\n<p><code>Speedometer</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> param.eval_metric <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span>:</div><div class=\"line\">    name_value = param.eval_metric.get_name_value()</div><div class=\"line\">    <span class=\"keyword\">if</span> self.auto_reset:</div><div class=\"line\">        param.eval_metric.reset()</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>epochMXNet<code>score()</code><code>score</code><code>fit()</code>forward computing</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MXNetMXNetpythonguidetoolmetricDL<code>fit()</code>MXNet</p>\n<p>TensorFlowDLMXNetCosinelearning rate decayModel Zoo(gluonGluon-CVGluon-NLP)</p>\n<p>MXNetpythonmoduleoptimizermetricexampleMXNetMXNet</p>"},{"title":"","date":"2018-04-03T13:43:16.000Z","_content":"Newton's Methoddemo[Wiki](https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95)\n<img src=\"/img/newton-method-demo.gif\" width = \"400\" height = \"300\" alt=\"\" align=center />\n<!-- more -->\n\n## \n$f(x) = 0$\n\n$x_0$$(x_0, f(x_0))$$x$$x_1$$x_1$\n\n\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f^\\prime(x_n)}$$\n\n## \n$L$$0$$L$\n$$\\theta_{n+1} = \\theta_n - \\frac{L^\\prime(\\theta_n)}{L^{\\prime\\prime}(\\theta_n)}$$\n\n## \n\n$$\\theta_{n+1} = \\theta_n - H^{-1}\\nabla_\\theta L(\\theta_n)$$\n\n$H$$n\\times n$\n$$H_{ij} = \\frac{\\partial^2 L}{\\partial \\theta_i \\partial \\theta_j}$$\n\n\n\nPS:$\\forall x$$0$$x^THx > 0$\n\n## \nSGD$n\\times n$$n$\n\n## L-BFGS\n$H^{-1}$L-BFGS\n\n**\n\nL-BFGSPyTorchL-BFGS[optim.lbfgs](https://github.com/pytorch/pytorch/blob/master/torch/optim/lbfgs.py)\n\n[L-BFGS](http://www.hankcs.com/ml/l-bfgs.html)","source":"_posts/newton-method.md","raw":"---\ntitle: \ndate: 2018-04-03 21:43:16\ntags:\n    - math\n---\nNewton's Methoddemo[Wiki](https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95)\n<img src=\"/img/newton-method-demo.gif\" width = \"400\" height = \"300\" alt=\"\" align=center />\n<!-- more -->\n\n## \n$f(x) = 0$\n\n$x_0$$(x_0, f(x_0))$$x$$x_1$$x_1$\n\n\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f^\\prime(x_n)}$$\n\n## \n$L$$0$$L$\n$$\\theta_{n+1} = \\theta_n - \\frac{L^\\prime(\\theta_n)}{L^{\\prime\\prime}(\\theta_n)}$$\n\n## \n\n$$\\theta_{n+1} = \\theta_n - H^{-1}\\nabla_\\theta L(\\theta_n)$$\n\n$H$$n\\times n$\n$$H_{ij} = \\frac{\\partial^2 L}{\\partial \\theta_i \\partial \\theta_j}$$\n\n\n\nPS:$\\forall x$$0$$x^THx > 0$\n\n## \nSGD$n\\times n$$n$\n\n## L-BFGS\n$H^{-1}$L-BFGS\n\n**\n\nL-BFGSPyTorchL-BFGS[optim.lbfgs](https://github.com/pytorch/pytorch/blob/master/torch/optim/lbfgs.py)\n\n[L-BFGS](http://www.hankcs.com/ml/l-bfgs.html)","slug":"newton-method","published":1,"updated":"2018-10-27T07:16:52.403Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8mz002rae7bmara1vu7","content":"<p>Newtons Methoddemo<a href=\"https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95\" target=\"_blank\" rel=\"external\">Wiki</a><br><img src=\"/img/newton-method-demo.gif\" width=\"400\" height=\"300\" alt=\"\" align=\"center\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$f(x) = 0$</p>\n<p>$x_0$$(x_0, f(x_0))$$x$$x_1$$x_1$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">x_{n+1} = x_n - \\frac{f(x_n)}{f^\\prime(x_n)}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$L$$0$$L$</p>\n<script type=\"math/tex; mode=display\">\\theta_{n+1} = \\theta_n - \\frac{L^\\prime(\\theta_n)}{L^{\\prime\\prime}(\\theta_n)}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{n+1} = \\theta_n - H^{-1}\\nabla_\\theta L(\\theta_n)</script><p>$H$$n\\times n$</p>\n<script type=\"math/tex; mode=display\">H_{ij} = \\frac{\\partial^2 L}{\\partial \\theta_i \\partial \\theta_j}</script><p></p>\n<p>PS:$\\forall x$$0$$x^THx &gt; 0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SGD$n\\times n$$n$</p>\n<h2 id=\"L-BFGS\"><a href=\"#L-BFGS\" class=\"headerlink\" title=\"L-BFGS\"></a>L-BFGS</h2><p>$H^{-1}$L-BFGS</p>\n<p><em></em></p>\n<p>L-BFGSPyTorchL-BFGS<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/lbfgs.py\" target=\"_blank\" rel=\"external\">optim.lbfgs</a></p>\n<p><a href=\"http://www.hankcs.com/ml/l-bfgs.html\" target=\"_blank\" rel=\"external\">L-BFGS</a></p>\n","excerpt":"<p>Newtons Methoddemo<a href=\"https://zh.wikipedia.org/wiki/%E7%89%9B%E9%A1%BF%E6%B3%95\">Wiki</a><br><img src=\"/img/newton-method-demo.gif\" width = \"400\" height = \"300\" alt=\"\" align=center /><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$f(x) = 0$</p>\n<p>$x_0$$(x_0, f(x_0))$$x$$x_1$$x_1$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">x_{n+1} = x_n - \\frac{f(x_n)}{f^\\prime(x_n)}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$L$$0$$L$</p>\n<script type=\"math/tex; mode=display\">\\theta_{n+1} = \\theta_n - \\frac{L^\\prime(\\theta_n)}{L^{\\prime\\prime}(\\theta_n)}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\theta_{n+1} = \\theta_n - H^{-1}\\nabla_\\theta L(\\theta_n)</script><p>$H$$n\\times n$</p>\n<script type=\"math/tex; mode=display\">H_{ij} = \\frac{\\partial^2 L}{\\partial \\theta_i \\partial \\theta_j}</script><p></p>\n<p>PS:$\\forall x$$0$$x^THx &gt; 0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SGD$n\\times n$$n$</p>\n<h2 id=\"L-BFGS\"><a href=\"#L-BFGS\" class=\"headerlink\" title=\"L-BFGS\"></a>L-BFGS</h2><p>$H^{-1}$L-BFGS</p>\n<p><em></em></p>\n<p>L-BFGSPyTorchL-BFGS<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/optim/lbfgs.py\">optim.lbfgs</a></p>\n<p><a href=\"http://www.hankcs.com/ml/l-bfgs.html\">L-BFGS</a></p>"},{"title":" - Like What You Like - Knowledge Distill via Neuron Selectivity Transfer","date":"2018-10-02T13:32:05.000Z","_content":"[Like What You Like: Knowledge Distill via Neuron Selectivity Transfer](https://arxiv.org/abs/1707.01219)Knowledge DistillingNeural Selectivity TransferKD + NSTSOTAPSDLLike what you like\n\n![jump if you jump](/img/paper-nst-kt-like-what-you-like.gif)\n\nWang NaiyanHuang ZehaoECCV 2018[Data-driven sparse structure selection for deep neural networks](https://arxiv.org/abs/1707.01213)\n\nArxiv[](https://www.zhihu.com/question/62068158)DL/CVNaiyanfollow\n\n<!-- more -->\n\n## Motivation\nKDsoftmaxDetectionSegmentationKDsimilarityKDbest\n\nCNNfeature mapStudentfeature mapTeacherStudentTeacherCNNfilterfeature mappatchfilterfeaturemapfilterpatchfilterSobelimagefilterCNNfilter\n\nAttention Transfer[Improving the Performance of Convolutional Neural Networks via Attention Transfer](https://arxiv.org/abs/1612.03928)NSTStudentTeacherFeature map\n![NST](/img/paper-nst-student-and-teacher.png)\n\n## Maximum Mean Discrepancy\nMMD sampled data$p$$q$Data set$\\mathcal{X}$$\\mathcal{Y}$MMD\n$$\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\Vert \\frac{1}{N}\\sum_{i=1}^{N}\\phi(x^i) - \\frac{1}{M}\\sum_{j=1}^{M}\\phi(y^j) \\Vert_2^2$$\n\n$\\phi$mapping function\n\n$$\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\frac{1}{N^2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}k(x^i, x^j) + \\frac{1}{M^2}\\sum_{i=1}^{M}\\sum_{j=1}^{M}k(y^i, y^j) - \\frac{2}{MN}\\sum_{i=1}^{N}\\sum_{j=1}^{M}k(x^i, y^j)$$\n\n$k$kernel function$k(x, y) = \\phi(x)^{T}\\phi(y)$\n\nMMDStudentTeacherfeature mapSTMMDNST loss$S$Student$T$Teacher$\\mathcal{H}$CrossEntropy LossMMD Loss\n$$\\mathcal{L} = \\mathcal{H}(y, p_S) + \\frac{\\lambda}{2}\\mathcal{L}_{MMD}(F_T, F_S)$$\n\n$F_T$$F_S$feature mapchannel$HW$feature vector$\\mathcal{X}$STfeature mapspatial dimension\n\nfeature vectornormalization\n\nkernal\n\n## \n$\\phi$identity mappingMMDAT\n\n$\\mathcal{L}\\_{MMD}(F\\_T, F\\_S) = \\Vert G\\_T - G\\_S\\Vert\\_F^2$$G \\in \\mathbb{R}^{HW\\times HW}$Gram$g_{ij} = (f^i)^Tf^j$\n\n## \nCIFAR10ImageNetStudentInception-BNTeacherResNet-1001ResNet-101\n\nCIFAR10CIFAR10NSTCIFAR100KDKD+NST\n![CIFAR10 ](/img/paper-nst-cifar10-results.png)\n\nImageNetKD+NST\n![ImageNet](/img/paper-nst-imagenet-results.png)\n\nNSTStudentTeacherFeature mapNSTST\n![NSTTSfeature mapdistance](/img/paper-nst-visulization-teacher-student-feature-map.png)\n\nDetectionPASCAL VOC2007Faster RCNNbackboneInception BN`4b`layerfeature mapstide16\n\n![PASCAL VOC](/img/paper-nst-pascal-voc-results.png)","source":"_posts/paper-knowledge-transfer-neural-selectivity-transfer.md","raw":"---\ntitle:  - Like What You Like - Knowledge Distill via Neuron Selectivity Transfer\ndate: 2018-10-02 21:32:05\ntags:\n     - paper\n     - deep learning\n     - model compression\n---\n[Like What You Like: Knowledge Distill via Neuron Selectivity Transfer](https://arxiv.org/abs/1707.01219)Knowledge DistillingNeural Selectivity TransferKD + NSTSOTAPSDLLike what you like\n\n![jump if you jump](/img/paper-nst-kt-like-what-you-like.gif)\n\nWang NaiyanHuang ZehaoECCV 2018[Data-driven sparse structure selection for deep neural networks](https://arxiv.org/abs/1707.01213)\n\nArxiv[](https://www.zhihu.com/question/62068158)DL/CVNaiyanfollow\n\n<!-- more -->\n\n## Motivation\nKDsoftmaxDetectionSegmentationKDsimilarityKDbest\n\nCNNfeature mapStudentfeature mapTeacherStudentTeacherCNNfilterfeature mappatchfilterfeaturemapfilterpatchfilterSobelimagefilterCNNfilter\n\nAttention Transfer[Improving the Performance of Convolutional Neural Networks via Attention Transfer](https://arxiv.org/abs/1612.03928)NSTStudentTeacherFeature map\n![NST](/img/paper-nst-student-and-teacher.png)\n\n## Maximum Mean Discrepancy\nMMD sampled data$p$$q$Data set$\\mathcal{X}$$\\mathcal{Y}$MMD\n$$\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\Vert \\frac{1}{N}\\sum_{i=1}^{N}\\phi(x^i) - \\frac{1}{M}\\sum_{j=1}^{M}\\phi(y^j) \\Vert_2^2$$\n\n$\\phi$mapping function\n\n$$\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\frac{1}{N^2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}k(x^i, x^j) + \\frac{1}{M^2}\\sum_{i=1}^{M}\\sum_{j=1}^{M}k(y^i, y^j) - \\frac{2}{MN}\\sum_{i=1}^{N}\\sum_{j=1}^{M}k(x^i, y^j)$$\n\n$k$kernel function$k(x, y) = \\phi(x)^{T}\\phi(y)$\n\nMMDStudentTeacherfeature mapSTMMDNST loss$S$Student$T$Teacher$\\mathcal{H}$CrossEntropy LossMMD Loss\n$$\\mathcal{L} = \\mathcal{H}(y, p_S) + \\frac{\\lambda}{2}\\mathcal{L}_{MMD}(F_T, F_S)$$\n\n$F_T$$F_S$feature mapchannel$HW$feature vector$\\mathcal{X}$STfeature mapspatial dimension\n\nfeature vectornormalization\n\nkernal\n\n## \n$\\phi$identity mappingMMDAT\n\n$\\mathcal{L}\\_{MMD}(F\\_T, F\\_S) = \\Vert G\\_T - G\\_S\\Vert\\_F^2$$G \\in \\mathbb{R}^{HW\\times HW}$Gram$g_{ij} = (f^i)^Tf^j$\n\n## \nCIFAR10ImageNetStudentInception-BNTeacherResNet-1001ResNet-101\n\nCIFAR10CIFAR10NSTCIFAR100KDKD+NST\n![CIFAR10 ](/img/paper-nst-cifar10-results.png)\n\nImageNetKD+NST\n![ImageNet](/img/paper-nst-imagenet-results.png)\n\nNSTStudentTeacherFeature mapNSTST\n![NSTTSfeature mapdistance](/img/paper-nst-visulization-teacher-student-feature-map.png)\n\nDetectionPASCAL VOC2007Faster RCNNbackboneInception BN`4b`layerfeature mapstide16\n\n![PASCAL VOC](/img/paper-nst-pascal-voc-results.png)","slug":"paper-knowledge-transfer-neural-selectivity-transfer","published":1,"updated":"2018-10-27T07:16:52.405Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8n1002uae7bgeqitutd","content":"<p><a href=\"https://arxiv.org/abs/1707.01219\" target=\"_blank\" rel=\"external\">Like What You Like: Knowledge Distill via Neuron Selectivity Transfer</a>Knowledge DistillingNeural Selectivity TransferKD + NSTSOTAPSDLLike what you like</p>\n<p><img src=\"/img/paper-nst-kt-like-what-you-like.gif\" alt=\"jump if you jump\"></p>\n<p>Wang NaiyanHuang ZehaoECCV 2018<a href=\"https://arxiv.org/abs/1707.01213\" target=\"_blank\" rel=\"external\">Data-driven sparse structure selection for deep neural networks</a></p>\n<p>Arxiv<a href=\"https://www.zhihu.com/question/62068158\" target=\"_blank\" rel=\"external\"></a>DL/CVNaiyanfollow</p>\n<a id=\"more\"></a>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>KDsoftmaxDetectionSegmentationKDsimilarityKDbest</p>\n<p>CNNfeature mapStudentfeature mapTeacherStudentTeacherCNNfilterfeature mappatchfilterfeaturemapfilterpatchfilterSobelimagefilterCNNfilter</p>\n<p>Attention Transfer<a href=\"https://arxiv.org/abs/1612.03928\" target=\"_blank\" rel=\"external\">Improving the Performance of Convolutional Neural Networks via Attention Transfer</a>NSTStudentTeacherFeature map<br><img src=\"/img/paper-nst-student-and-teacher.png\" alt=\"NST\"></p>\n<h2 id=\"Maximum-Mean-Discrepancy\"><a href=\"#Maximum-Mean-Discrepancy\" class=\"headerlink\" title=\"Maximum Mean Discrepancy\"></a>Maximum Mean Discrepancy</h2><p>MMD sampled data$p$$q$Data set$\\mathcal{X}$$\\mathcal{Y}$MMD</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\Vert \\frac{1}{N}\\sum_{i=1}^{N}\\phi(x^i) - \\frac{1}{M}\\sum_{j=1}^{M}\\phi(y^j) \\Vert_2^2</script><p>$\\phi$mapping function</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\frac{1}{N^2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}k(x^i, x^j) + \\frac{1}{M^2}\\sum_{i=1}^{M}\\sum_{j=1}^{M}k(y^i, y^j) - \\frac{2}{MN}\\sum_{i=1}^{N}\\sum_{j=1}^{M}k(x^i, y^j)</script><p>$k$kernel function$k(x, y) = \\phi(x)^{T}\\phi(y)$</p>\n<p>MMDStudentTeacherfeature mapSTMMDNST loss$S$Student$T$Teacher$\\mathcal{H}$CrossEntropy LossMMD Loss</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = \\mathcal{H}(y, p_S) + \\frac{\\lambda}{2}\\mathcal{L}_{MMD}(F_T, F_S)</script><p>$F_T$$F_S$feature mapchannel$HW$feature vector$\\mathcal{X}$STfeature mapspatial dimension</p>\n<p>feature vectornormalization</p>\n<p>kernal</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\phi$identity mappingMMDAT</p>\n<p>$\\mathcal{L}_{MMD}(F_T, F_S) = \\Vert G_T - G_S\\Vert_F^2$$G \\in \\mathbb{R}^{HW\\times HW}$Gram$g_{ij} = (f^i)^Tf^j$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CIFAR10ImageNetStudentInception-BNTeacherResNet-1001ResNet-101</p>\n<p>CIFAR10CIFAR10NSTCIFAR100KDKD+NST<br><img src=\"/img/paper-nst-cifar10-results.png\" alt=\"CIFAR10 \"></p>\n<p>ImageNetKD+NST<br><img src=\"/img/paper-nst-imagenet-results.png\" alt=\"ImageNet\"></p>\n<p>NSTStudentTeacherFeature mapNSTST<br><img src=\"/img/paper-nst-visulization-teacher-student-feature-map.png\" alt=\"NSTTSfeature mapdistance\"></p>\n<p>DetectionPASCAL VOC2007Faster RCNNbackboneInception BN<code>4b</code>layerfeature mapstide16</p>\n<p><img src=\"/img/paper-nst-pascal-voc-results.png\" alt=\"PASCAL VOC\"></p>\n","excerpt":"<p><a href=\"https://arxiv.org/abs/1707.01219\">Like What You Like: Knowledge Distill via Neuron Selectivity Transfer</a>Knowledge DistillingNeural Selectivity TransferKD + NSTSOTAPSDLLike what you like</p>\n<p><img src=\"/img/paper-nst-kt-like-what-you-like.gif\" alt=\"jump if you jump\"></p>\n<p>Wang NaiyanHuang ZehaoECCV 2018<a href=\"https://arxiv.org/abs/1707.01213\">Data-driven sparse structure selection for deep neural networks</a></p>\n<p>Arxiv<a href=\"https://www.zhihu.com/question/62068158\"></a>DL/CVNaiyanfollow</p>","more":"<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>KDsoftmaxDetectionSegmentationKDsimilarityKDbest</p>\n<p>CNNfeature mapStudentfeature mapTeacherStudentTeacherCNNfilterfeature mappatchfilterfeaturemapfilterpatchfilterSobelimagefilterCNNfilter</p>\n<p>Attention Transfer<a href=\"https://arxiv.org/abs/1612.03928\">Improving the Performance of Convolutional Neural Networks via Attention Transfer</a>NSTStudentTeacherFeature map<br><img src=\"/img/paper-nst-student-and-teacher.png\" alt=\"NST\"></p>\n<h2 id=\"Maximum-Mean-Discrepancy\"><a href=\"#Maximum-Mean-Discrepancy\" class=\"headerlink\" title=\"Maximum Mean Discrepancy\"></a>Maximum Mean Discrepancy</h2><p>MMD sampled data$p$$q$Data set$\\mathcal{X}$$\\mathcal{Y}$MMD</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\Vert \\frac{1}{N}\\sum_{i=1}^{N}\\phi(x^i) - \\frac{1}{M}\\sum_{j=1}^{M}\\phi(y^j) \\Vert_2^2</script><p>$\\phi$mapping function</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\frac{1}{N^2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}k(x^i, x^j) + \\frac{1}{M^2}\\sum_{i=1}^{M}\\sum_{j=1}^{M}k(y^i, y^j) - \\frac{2}{MN}\\sum_{i=1}^{N}\\sum_{j=1}^{M}k(x^i, y^j)</script><p>$k$kernel function$k(x, y) = \\phi(x)^{T}\\phi(y)$</p>\n<p>MMDStudentTeacherfeature mapSTMMDNST loss$S$Student$T$Teacher$\\mathcal{H}$CrossEntropy LossMMD Loss</p>\n<script type=\"math/tex; mode=display\">\\mathcal{L} = \\mathcal{H}(y, p_S) + \\frac{\\lambda}{2}\\mathcal{L}_{MMD}(F_T, F_S)</script><p>$F_T$$F_S$feature mapchannel$HW$feature vector$\\mathcal{X}$STfeature mapspatial dimension</p>\n<p>feature vectornormalization</p>\n<p>kernal</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\phi$identity mappingMMDAT</p>\n<p>$\\mathcal{L}_{MMD}(F_T, F_S) = \\Vert G_T - G_S\\Vert_F^2$$G \\in \\mathbb{R}^{HW\\times HW}$Gram$g_{ij} = (f^i)^Tf^j$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CIFAR10ImageNetStudentInception-BNTeacherResNet-1001ResNet-101</p>\n<p>CIFAR10CIFAR10NSTCIFAR100KDKD+NST<br><img src=\"/img/paper-nst-cifar10-results.png\" alt=\"CIFAR10 \"></p>\n<p>ImageNetKD+NST<br><img src=\"/img/paper-nst-imagenet-results.png\" alt=\"ImageNet\"></p>\n<p>NSTStudentTeacherFeature mapNSTST<br><img src=\"/img/paper-nst-visulization-teacher-student-feature-map.png\" alt=\"NSTTSfeature mapdistance\"></p>\n<p>DetectionPASCAL VOC2007Faster RCNNbackboneInception BN<code>4b</code>layerfeature mapstide16</p>\n<p><img src=\"/img/paper-nst-pascal-voc-results.png\" alt=\"PASCAL VOC\"></p>"},{"title":" - MobileNets, Efficient Convolutional Neural Networks for Mobile Vision Applications","date":"2018-03-23T02:53:43.000Z","_content":"[MobileNet](https://arxiv.org/abs/1704.04861)Depthwise Separable ConvMobileNetinference[MobileNet v2](https://arxiv.org/abs/1801.04381)\n<!-- more -->\n\n## Depthwise Separable Conv\nDepthwise Separable Convdepthwise convfilterchannelpointwise conv$1\\times 1$channelcombinationCaffeDL`group`inputchanneldepthwise convpointwise conv`kernel size = 1`PyTorch[](https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L67)\n\n``` py\ndef conv_dw(inp, oup, stride):\n    return nn.Sequential(\n        ## group=input channelsdepthwise conv\n        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n        nn.BatchNorm2d(inp),\n        nn.ReLU(inplace=True),\n    \n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True),\n    )\n```\nconvfilter$N$kernel size$D_k$$D_F\\times D_F\\times M$$D_K\\times D_K\\times M\\times N\\times D_F\\times D_F$`stride=1`feature mapspatial\n\nDepthwise Separable Conv$D_K\\times D_K\\times M\\times D_F \\times D_F + M\\times N\\times D_F\\times D_F$$\\frac{1}{N} + \\frac{1}{D_K^2} < 1$\n![Depthwise Separable Conv](/img/paper-mobilenet-depthwise-separable-conv.png)\n\nBN\n![Conv-BN-ReLU](/img/paper-mobilenet-conv-unit.png)\n\n## MobileNet\nDepthwise Separable ConvMobileNet`dw`depthwise conv`stride=1`convpointwise convpoolingfc-1000\n![body arch](/img/paper-mobilenet-net-arch.png)\n\nGEMMCaffeim2colGEMMpointwis= convreorderingPyTorchTensorFlowpointwise convdepthwise conv\n\ndepthwise conv layerweight decay\n\nPyTorch[](https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L78)\n``` py\nself.model = nn.Sequential(\n    conv_bn(  3,  32, 2), \n    conv_dw( 32,  64, 1),\n    conv_dw( 64, 128, 2),\n    conv_dw(128, 128, 1),\n    conv_dw(128, 256, 2),\n    conv_dw(256, 256, 1),\n    conv_dw(256, 512, 2),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 1024, 2),\n    conv_dw(1024, 1024, 1),\n    nn.AvgPool2d(7),\n)\nself.fc = nn.Linear(1024, 1000)\n```\n\n### \n#### wideror thinner\nfilterfilterfeatureMobileNet$\\alpha$filterfilterinput channel$\\alpha$input channel$\\alpha^2$\n\n#### resolution\nspatial dimension$\\rho$$D_F$$\\alpha$$\\rho^2$\n\n$\\alpha$$\\rho$$1$mobilenet\n![reduce](/img/paper-mobilenet-alpha-rho-effect.png)\n\n### Depthwise Separable Conv\n/Depthwise Separable ConvImageNet$1$\n![Depthwise Separable vs Full Convolution MobileNet](/img/paper-mobilenet-depthwise-vs-full-conv.png)\n\n### \n\n![Narrow vs Shallow MobileNet](/img/paper-mobilenet-narrow-vs-shallow-net.png)\n\n### alpharho\n$\\alpha$$\\rho$$\\alpha$\n![MobileNet Width Multiplier](/img/paper-mobilenet-alpha-compact.png)\n\nresolution\n![MobileNet Resolution](/img/paper-mobilenet-rho-compact.png)\n\n### \nSqueezeNetMobileNetdepthwise separable conv\n![](/img/paper-mobilenet-comparision-with-other-model.png)\n\n## \nMobileNetMobileNetdetectionclassification","source":"_posts/paper-mobilenet.md","raw":"---\ntitle:  - MobileNets, Efficient Convolutional Neural Networks for Mobile Vision Applications\ndate: 2018-03-23 10:53:43\ntags:\n     - paper\n     - deep learning\n     - model arch\n     - model compression\n---\n[MobileNet](https://arxiv.org/abs/1704.04861)Depthwise Separable ConvMobileNetinference[MobileNet v2](https://arxiv.org/abs/1801.04381)\n<!-- more -->\n\n## Depthwise Separable Conv\nDepthwise Separable Convdepthwise convfilterchannelpointwise conv$1\\times 1$channelcombinationCaffeDL`group`inputchanneldepthwise convpointwise conv`kernel size = 1`PyTorch[](https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L67)\n\n``` py\ndef conv_dw(inp, oup, stride):\n    return nn.Sequential(\n        ## group=input channelsdepthwise conv\n        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n        nn.BatchNorm2d(inp),\n        nn.ReLU(inplace=True),\n    \n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True),\n    )\n```\nconvfilter$N$kernel size$D_k$$D_F\\times D_F\\times M$$D_K\\times D_K\\times M\\times N\\times D_F\\times D_F$`stride=1`feature mapspatial\n\nDepthwise Separable Conv$D_K\\times D_K\\times M\\times D_F \\times D_F + M\\times N\\times D_F\\times D_F$$\\frac{1}{N} + \\frac{1}{D_K^2} < 1$\n![Depthwise Separable Conv](/img/paper-mobilenet-depthwise-separable-conv.png)\n\nBN\n![Conv-BN-ReLU](/img/paper-mobilenet-conv-unit.png)\n\n## MobileNet\nDepthwise Separable ConvMobileNet`dw`depthwise conv`stride=1`convpointwise convpoolingfc-1000\n![body arch](/img/paper-mobilenet-net-arch.png)\n\nGEMMCaffeim2colGEMMpointwis= convreorderingPyTorchTensorFlowpointwise convdepthwise conv\n\ndepthwise conv layerweight decay\n\nPyTorch[](https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L78)\n``` py\nself.model = nn.Sequential(\n    conv_bn(  3,  32, 2), \n    conv_dw( 32,  64, 1),\n    conv_dw( 64, 128, 2),\n    conv_dw(128, 128, 1),\n    conv_dw(128, 256, 2),\n    conv_dw(256, 256, 1),\n    conv_dw(256, 512, 2),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 512, 1),\n    conv_dw(512, 1024, 2),\n    conv_dw(1024, 1024, 1),\n    nn.AvgPool2d(7),\n)\nself.fc = nn.Linear(1024, 1000)\n```\n\n### \n#### wideror thinner\nfilterfilterfeatureMobileNet$\\alpha$filterfilterinput channel$\\alpha$input channel$\\alpha^2$\n\n#### resolution\nspatial dimension$\\rho$$D_F$$\\alpha$$\\rho^2$\n\n$\\alpha$$\\rho$$1$mobilenet\n![reduce](/img/paper-mobilenet-alpha-rho-effect.png)\n\n### Depthwise Separable Conv\n/Depthwise Separable ConvImageNet$1$\n![Depthwise Separable vs Full Convolution MobileNet](/img/paper-mobilenet-depthwise-vs-full-conv.png)\n\n### \n\n![Narrow vs Shallow MobileNet](/img/paper-mobilenet-narrow-vs-shallow-net.png)\n\n### alpharho\n$\\alpha$$\\rho$$\\alpha$\n![MobileNet Width Multiplier](/img/paper-mobilenet-alpha-compact.png)\n\nresolution\n![MobileNet Resolution](/img/paper-mobilenet-rho-compact.png)\n\n### \nSqueezeNetMobileNetdepthwise separable conv\n![](/img/paper-mobilenet-comparision-with-other-model.png)\n\n## \nMobileNetMobileNetdetectionclassification","slug":"paper-mobilenet","published":1,"updated":"2018-10-27T07:16:52.405Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8n6002wae7bc4hh6bir","content":"<p><a href=\"https://arxiv.org/abs/1704.04861\" target=\"_blank\" rel=\"external\">MobileNet</a>Depthwise Separable ConvMobileNetinference<a href=\"https://arxiv.org/abs/1801.04381\" target=\"_blank\" rel=\"external\">MobileNet v2</a><br><a id=\"more\"></a></p>\n<h2 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h2><p>Depthwise Separable Convdepthwise convfilterchannelpointwise conv$1\\times 1$channelcombinationCaffeDL<code>group</code>inputchanneldepthwise convpointwise conv<code>kernel size = 1</code>PyTorch<a href=\"https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L67\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_dw</span><span class=\"params\">(inp, oup, stride)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</div><div class=\"line\">        <span class=\"comment\">## group=input channelsdepthwise conv</span></div><div class=\"line\">        nn.Conv2d(inp, inp, <span class=\"number\">3</span>, stride, <span class=\"number\">1</span>, groups=inp, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">        nn.BatchNorm2d(inp),</div><div class=\"line\">        nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">    </div><div class=\"line\">        nn.Conv2d(inp, oup, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">        nn.BatchNorm2d(oup),</div><div class=\"line\">        nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">    )</div></pre></td></tr></table></figure>\n<p>convfilter$N$kernel size$D_k$$D_F\\times D_F\\times M$$D_K\\times D_K\\times M\\times N\\times D_F\\times D_F$<code>stride=1</code>feature mapspatial</p>\n<p>Depthwise Separable Conv$D_K\\times D_K\\times M\\times D_F \\times D_F + M\\times N\\times D_F\\times D_F$$\\frac{1}{N} + \\frac{1}{D_K^2} &lt; 1$<br><img src=\"/img/paper-mobilenet-depthwise-separable-conv.png\" alt=\"Depthwise Separable Conv\"></p>\n<p>BN<br><img src=\"/img/paper-mobilenet-conv-unit.png\" alt=\"Conv-BN-ReLU\"></p>\n<h2 id=\"MobileNet\"><a href=\"#MobileNet\" class=\"headerlink\" title=\"MobileNet\"></a>MobileNet</h2><p>Depthwise Separable ConvMobileNet<code>dw</code>depthwise conv<code>stride=1</code>convpointwise convpoolingfc-1000<br><img src=\"/img/paper-mobilenet-net-arch.png\" alt=\"body arch\"></p>\n<p>GEMMCaffeim2colGEMMpointwis= convreorderingPyTorchTensorFlowpointwise convdepthwise conv</p>\n<p>depthwise conv layerweight decay</p>\n<p>PyTorch<a href=\"https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L78\" target=\"_blank\" rel=\"external\"></a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">self.model = nn.Sequential(</div><div class=\"line\">    conv_bn(  <span class=\"number\">3</span>,  <span class=\"number\">32</span>, <span class=\"number\">2</span>), </div><div class=\"line\">    conv_dw( <span class=\"number\">32</span>,  <span class=\"number\">64</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw( <span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">128</span>, <span class=\"number\">256</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">256</span>, <span class=\"number\">512</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">1024</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">1024</span>, <span class=\"number\">1024</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    nn.AvgPool2d(<span class=\"number\">7</span>),</div><div class=\"line\">)</div><div class=\"line\">self.fc = nn.Linear(<span class=\"number\">1024</span>, <span class=\"number\">1000</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"wideror-thinner\"><a href=\"#wideror-thinner\" class=\"headerlink\" title=\"wideror thinner\"></a>wideror thinner</h4><p>filterfilterfeatureMobileNet$\\alpha$filterfilterinput channel$\\alpha$input channel$\\alpha^2$</p>\n<h4 id=\"resolution\"><a href=\"#resolution\" class=\"headerlink\" title=\"resolution\"></a>resolution</h4><p>spatial dimension$\\rho$$D_F$$\\alpha$$\\rho^2$</p>\n<p>$\\alpha$$\\rho$$1$mobilenet<br><img src=\"/img/paper-mobilenet-alpha-rho-effect.png\" alt=\"reduce\"></p>\n<h3 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h3><p>/Depthwise Separable ConvImageNet$1$<br><img src=\"/img/paper-mobilenet-depthwise-vs-full-conv.png\" alt=\"Depthwise Separable vs Full Convolution MobileNet\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><img src=\"/img/paper-mobilenet-narrow-vs-shallow-net.png\" alt=\"Narrow vs Shallow MobileNet\"></p>\n<h3 id=\"alpharho\"><a href=\"#alpharho\" class=\"headerlink\" title=\"alpharho\"></a>alpharho</h3><p>$\\alpha$$\\rho$$\\alpha$<br><img src=\"/img/paper-mobilenet-alpha-compact.png\" alt=\"MobileNet Width Multiplier\"></p>\n<p>resolution<br><img src=\"/img/paper-mobilenet-rho-compact.png\" alt=\"MobileNet Resolution\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>SqueezeNetMobileNetdepthwise separable conv<br><img src=\"/img/paper-mobilenet-comparision-with-other-model.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MobileNetMobileNetdetectionclassification</p>\n","excerpt":"<p><a href=\"https://arxiv.org/abs/1704.04861\">MobileNet</a>Depthwise Separable ConvMobileNetinference<a href=\"https://arxiv.org/abs/1801.04381\">MobileNet v2</a><br>","more":"</p>\n<h2 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h2><p>Depthwise Separable Convdepthwise convfilterchannelpointwise conv$1\\times 1$channelcombinationCaffeDL<code>group</code>inputchanneldepthwise convpointwise conv<code>kernel size = 1</code>PyTorch<a href=\"https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L67\"></a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_dw</span><span class=\"params\">(inp, oup, stride)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(</div><div class=\"line\">        <span class=\"comment\">## group=input channelsdepthwise conv</span></div><div class=\"line\">        nn.Conv2d(inp, inp, <span class=\"number\">3</span>, stride, <span class=\"number\">1</span>, groups=inp, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">        nn.BatchNorm2d(inp),</div><div class=\"line\">        nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">    </div><div class=\"line\">        nn.Conv2d(inp, oup, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">        nn.BatchNorm2d(oup),</div><div class=\"line\">        nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">    )</div></pre></td></tr></table></figure>\n<p>convfilter$N$kernel size$D_k$$D_F\\times D_F\\times M$$D_K\\times D_K\\times M\\times N\\times D_F\\times D_F$<code>stride=1</code>feature mapspatial</p>\n<p>Depthwise Separable Conv$D_K\\times D_K\\times M\\times D_F \\times D_F + M\\times N\\times D_F\\times D_F$$\\frac{1}{N} + \\frac{1}{D_K^2} &lt; 1$<br><img src=\"/img/paper-mobilenet-depthwise-separable-conv.png\" alt=\"Depthwise Separable Conv\"></p>\n<p>BN<br><img src=\"/img/paper-mobilenet-conv-unit.png\" alt=\"Conv-BN-ReLU\"></p>\n<h2 id=\"MobileNet\"><a href=\"#MobileNet\" class=\"headerlink\" title=\"MobileNet\"></a>MobileNet</h2><p>Depthwise Separable ConvMobileNet<code>dw</code>depthwise conv<code>stride=1</code>convpointwise convpoolingfc-1000<br><img src=\"/img/paper-mobilenet-net-arch.png\" alt=\"body arch\"></p>\n<p>GEMMCaffeim2colGEMMpointwis= convreorderingPyTorchTensorFlowpointwise convdepthwise conv</p>\n<p>depthwise conv layerweight decay</p>\n<p>PyTorch<a href=\"https://github.com/marvis/pytorch-mobilenet/blob/master/main.py#L78\"></a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">self.model = nn.Sequential(</div><div class=\"line\">    conv_bn(  <span class=\"number\">3</span>,  <span class=\"number\">32</span>, <span class=\"number\">2</span>), </div><div class=\"line\">    conv_dw( <span class=\"number\">32</span>,  <span class=\"number\">64</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw( <span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">128</span>, <span class=\"number\">256</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">256</span>, <span class=\"number\">512</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">512</span>, <span class=\"number\">1024</span>, <span class=\"number\">2</span>),</div><div class=\"line\">    conv_dw(<span class=\"number\">1024</span>, <span class=\"number\">1024</span>, <span class=\"number\">1</span>),</div><div class=\"line\">    nn.AvgPool2d(<span class=\"number\">7</span>),</div><div class=\"line\">)</div><div class=\"line\">self.fc = nn.Linear(<span class=\"number\">1024</span>, <span class=\"number\">1000</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"wideror-thinner\"><a href=\"#wideror-thinner\" class=\"headerlink\" title=\"wideror thinner\"></a>wideror thinner</h4><p>filterfilterfeatureMobileNet$\\alpha$filterfilterinput channel$\\alpha$input channel$\\alpha^2$</p>\n<h4 id=\"resolution\"><a href=\"#resolution\" class=\"headerlink\" title=\"resolution\"></a>resolution</h4><p>spatial dimension$\\rho$$D_F$$\\alpha$$\\rho^2$</p>\n<p>$\\alpha$$\\rho$$1$mobilenet<br><img src=\"/img/paper-mobilenet-alpha-rho-effect.png\" alt=\"reduce\"></p>\n<h3 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h3><p>/Depthwise Separable ConvImageNet$1$<br><img src=\"/img/paper-mobilenet-depthwise-vs-full-conv.png\" alt=\"Depthwise Separable vs Full Convolution MobileNet\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><img src=\"/img/paper-mobilenet-narrow-vs-shallow-net.png\" alt=\"Narrow vs Shallow MobileNet\"></p>\n<h3 id=\"alpharho\"><a href=\"#alpharho\" class=\"headerlink\" title=\"alpharho\"></a>alpharho</h3><p>$\\alpha$$\\rho$$\\alpha$<br><img src=\"/img/paper-mobilenet-alpha-compact.png\" alt=\"MobileNet Width Multiplier\"></p>\n<p>resolution<br><img src=\"/img/paper-mobilenet-rho-compact.png\" alt=\"MobileNet Resolution\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>SqueezeNetMobileNetdepthwise separable conv<br><img src=\"/img/paper-mobilenet-comparision-with-other-model.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MobileNetMobileNetdetectionclassification</p>"},{"title":" - Feature Pyramid Networks for Object Detection (FPN)","date":"2018-04-02T02:12:03.000Z","_content":"CV[SIFT](https://xmfbit.github.io/2017/01/30/cs131-sift/)DoGDeep LearningCV detectiondetector\n<!-- more -->\n## Pyramid or not? It's a question.\nDLCVSIFT/Harr/HoGmulti scaleCNNscaleCOCOTESTTRAINTESTTRAINFast/Faster RCNN\n\nCNNConv/Poolinglayerfeature mapspatial dimensioninherent multi-scale pyramidal hierarchy of deep CNNfeature mapfeature pyramidlayerfeature mapfeature mapresolutiontoo yong too simple\n\nSSDlayerlayerreuse high resolutionfeature maphigh resolution feature map\n\n\n- low resolutionstrong semantic infohigh resolutionweak semantic info\n- single scale\n\nlayerfeature mapaNNbFaster RCNNsingle scaleclayerfeature mapfeature pyramiddfeature mapmergelevel\n![](/img/paper-fpn-different-pyramids.png)\n\nFPNCOCOdetectionFPNMaskRCNNFPN\n\n## FPN\nlayermergeskip connectionsingle scaleoutput feature mapall level\n![](/img/paper-fpn-different-with-related-work.png)\n\n### Bottom-up pathway\n Bottom-up pathwayscale2xfeature mapdownsamplelayerspatial dimensionspatial dimensionlayerstageCNN\n\n ResNetstageresidual blockfeature map`C2~C5`$4, 8, 16, 32$`conv1`\n\n### Top-down pathwaylateral connection\nTop-down pathwayfeatureupsamplinghigher resolutionbottom-upfeaturelateral connection\n\nlateral connectionlayerfeature`2x up`spatial dimensionfeature`1x1 conv`channel dimensionelement-wisestagepredictionfeature`3x3 conv`\n![lateral connection](/img/paper-fpn-lateral-connection.png)\n\n\n\n> To start the iteration, we simply attach a 1x1 convolutional layer on C5 to produce the coarsest resolution map. Finally, we append a 3x3 convolution on each merged map to generate the final feature map, which is to reduce the aliasing effect of upsampling.\n\nfeatureclassifierregressorchannel dimension$256$conv layer\n\nPyTorchFPN[kuangliu/pytorch-fpn](https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py)\n``` py\n## ResNetblock\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass FPN(nn.Module):\n    def __init__(self, block, num_blocks):\n        super(FPN, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        # Bottom-up layers, backbone of the network\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n\n        # Top layer\n        # C51x1, 256 convfeature\n        self.toplayer = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)  # Reduce channels\n\n        # Smooth layers\n        # aliasing3x3\n        self.smooth1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n        self.smooth2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n        self.smooth3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n\n        # Lateral layers\n        # channel dimension1x1\n        # backboneextra conv256 channel\n        self.latlayer1 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n        self.latlayer2 = nn.Conv2d( 512, 256, kernel_size=1, stride=1, padding=0)\n        self.latlayer3 = nn.Conv2d( 256, 256, kernel_size=1, stride=1, padding=0)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    ## FPNlateral connection: upsampleelement-wise\n    def _upsample_add(self, x, y):\n        '''Upsample and add two feature maps.\n        Args:\n          x: (Variable) top feature map to be upsampled.\n          y: (Variable) lateral feature map.\n        Returns:\n          (Variable) added feature map.\n        Note in PyTorch, when input size is odd, the upsampled feature map\n        with `F.upsample(..., scale_factor=2, mode='nearest')`\n        maybe not equal to the lateral feature map size.\n        e.g.\n        original input size: [N,_,15,15] ->\n        conv2d feature map size: [N,_,8,8] ->\n        upsampled feature map size: [N,_,16,16]\n        So we choose bilinear upsample which supports arbitrary output sizes.\n        '''\n        _,_,H,W = y.size()\n        return F.upsample(x, size=(H,W), mode='bilinear') + y\n\n    def forward(self, x):\n        # Bottom-up\n        c1 = F.relu(self.bn1(self.conv1(x)))\n        c1 = F.max_pool2d(c1, kernel_size=3, stride=2, padding=1)\n        c2 = self.layer1(c1)\n        c3 = self.layer2(c2)\n        c4 = self.layer3(c3)\n        c5 = self.layer4(c4)\n        # Top-down\n        # P5: feature\n        p5 = self.toplayer(c5)\n        # P4:  p5 +  c4\n        # \n        p4 = self._upsample_add(p5, self.latlayer1(c4))\n        p3 = self._upsample_add(p4, self.latlayer2(c3))\n        p2 = self._upsample_add(p3, self.latlayer3(c2))\n        # Smooth\n        # smooth\n        p4 = self.smooth1(p4)\n        p3 = self.smooth2(p3)\n        p2 = self.smooth3(p2)\n        return p2, p3, p4, p5\n```\n\n## \nFPNFasterRCNNRPNFast RCNN\n### FPNRPN\nFaster RCNNRPNROIproposalbackbonesingle feature map$3\\times 3$sliding window$1\\times 1$objectnessbounding boxanchor boxclassifierregressorhead\n\nFPNfeature maphead$3\\times 3$ + two sibling $1\\times 1$anchor boxlevelanchor box$5$level`P2 - P6`anchor box$32^2, 64^2, 128^2, 256^2, 512^2$anchor box$3$$1:2, 1:1, 2:1$$5\\times 3 = 15$anchor box\n\nanchor boxesground truthIoUground truthIoU$0.7$anchor boxespositive labelground truthIoU$0.3$negtive label\n\nheadlevelaccuracylevelresolution\n\n### FPNFast RCNN\nFast RCNNsingle scalefeature mapFPNROI proposalpyramidlabelImageNettransfer learningbase modelImageNet$224\\times 224$ROIROIlevel\n$$k = \\lfloor k_0 + \\log_2(\\sqrt{wh}/224)\\rfloor$$\n\npredictor head$1024d$fc layerfinal classificationregressionlevel","source":"_posts/paper-fpn.md","raw":"---\ntitle:  - Feature Pyramid Networks for Object Detection (FPN)\ndate: 2018-04-02 10:12:03\ntags:\n    - paper\n    - deep learning\n    - detection\n---\nCV[SIFT](https://xmfbit.github.io/2017/01/30/cs131-sift/)DoGDeep LearningCV detectiondetector\n<!-- more -->\n## Pyramid or not? It's a question.\nDLCVSIFT/Harr/HoGmulti scaleCNNscaleCOCOTESTTRAINTESTTRAINFast/Faster RCNN\n\nCNNConv/Poolinglayerfeature mapspatial dimensioninherent multi-scale pyramidal hierarchy of deep CNNfeature mapfeature pyramidlayerfeature mapfeature mapresolutiontoo yong too simple\n\nSSDlayerlayerreuse high resolutionfeature maphigh resolution feature map\n\n\n- low resolutionstrong semantic infohigh resolutionweak semantic info\n- single scale\n\nlayerfeature mapaNNbFaster RCNNsingle scaleclayerfeature mapfeature pyramiddfeature mapmergelevel\n![](/img/paper-fpn-different-pyramids.png)\n\nFPNCOCOdetectionFPNMaskRCNNFPN\n\n## FPN\nlayermergeskip connectionsingle scaleoutput feature mapall level\n![](/img/paper-fpn-different-with-related-work.png)\n\n### Bottom-up pathway\n Bottom-up pathwayscale2xfeature mapdownsamplelayerspatial dimensionspatial dimensionlayerstageCNN\n\n ResNetstageresidual blockfeature map`C2~C5`$4, 8, 16, 32$`conv1`\n\n### Top-down pathwaylateral connection\nTop-down pathwayfeatureupsamplinghigher resolutionbottom-upfeaturelateral connection\n\nlateral connectionlayerfeature`2x up`spatial dimensionfeature`1x1 conv`channel dimensionelement-wisestagepredictionfeature`3x3 conv`\n![lateral connection](/img/paper-fpn-lateral-connection.png)\n\n\n\n> To start the iteration, we simply attach a 1x1 convolutional layer on C5 to produce the coarsest resolution map. Finally, we append a 3x3 convolution on each merged map to generate the final feature map, which is to reduce the aliasing effect of upsampling.\n\nfeatureclassifierregressorchannel dimension$256$conv layer\n\nPyTorchFPN[kuangliu/pytorch-fpn](https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py)\n``` py\n## ResNetblock\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass FPN(nn.Module):\n    def __init__(self, block, num_blocks):\n        super(FPN, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        # Bottom-up layers, backbone of the network\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n\n        # Top layer\n        # C51x1, 256 convfeature\n        self.toplayer = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)  # Reduce channels\n\n        # Smooth layers\n        # aliasing3x3\n        self.smooth1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n        self.smooth2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n        self.smooth3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n\n        # Lateral layers\n        # channel dimension1x1\n        # backboneextra conv256 channel\n        self.latlayer1 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n        self.latlayer2 = nn.Conv2d( 512, 256, kernel_size=1, stride=1, padding=0)\n        self.latlayer3 = nn.Conv2d( 256, 256, kernel_size=1, stride=1, padding=0)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    ## FPNlateral connection: upsampleelement-wise\n    def _upsample_add(self, x, y):\n        '''Upsample and add two feature maps.\n        Args:\n          x: (Variable) top feature map to be upsampled.\n          y: (Variable) lateral feature map.\n        Returns:\n          (Variable) added feature map.\n        Note in PyTorch, when input size is odd, the upsampled feature map\n        with `F.upsample(..., scale_factor=2, mode='nearest')`\n        maybe not equal to the lateral feature map size.\n        e.g.\n        original input size: [N,_,15,15] ->\n        conv2d feature map size: [N,_,8,8] ->\n        upsampled feature map size: [N,_,16,16]\n        So we choose bilinear upsample which supports arbitrary output sizes.\n        '''\n        _,_,H,W = y.size()\n        return F.upsample(x, size=(H,W), mode='bilinear') + y\n\n    def forward(self, x):\n        # Bottom-up\n        c1 = F.relu(self.bn1(self.conv1(x)))\n        c1 = F.max_pool2d(c1, kernel_size=3, stride=2, padding=1)\n        c2 = self.layer1(c1)\n        c3 = self.layer2(c2)\n        c4 = self.layer3(c3)\n        c5 = self.layer4(c4)\n        # Top-down\n        # P5: feature\n        p5 = self.toplayer(c5)\n        # P4:  p5 +  c4\n        # \n        p4 = self._upsample_add(p5, self.latlayer1(c4))\n        p3 = self._upsample_add(p4, self.latlayer2(c3))\n        p2 = self._upsample_add(p3, self.latlayer3(c2))\n        # Smooth\n        # smooth\n        p4 = self.smooth1(p4)\n        p3 = self.smooth2(p3)\n        p2 = self.smooth3(p2)\n        return p2, p3, p4, p5\n```\n\n## \nFPNFasterRCNNRPNFast RCNN\n### FPNRPN\nFaster RCNNRPNROIproposalbackbonesingle feature map$3\\times 3$sliding window$1\\times 1$objectnessbounding boxanchor boxclassifierregressorhead\n\nFPNfeature maphead$3\\times 3$ + two sibling $1\\times 1$anchor boxlevelanchor box$5$level`P2 - P6`anchor box$32^2, 64^2, 128^2, 256^2, 512^2$anchor box$3$$1:2, 1:1, 2:1$$5\\times 3 = 15$anchor box\n\nanchor boxesground truthIoUground truthIoU$0.7$anchor boxespositive labelground truthIoU$0.3$negtive label\n\nheadlevelaccuracylevelresolution\n\n### FPNFast RCNN\nFast RCNNsingle scalefeature mapFPNROI proposalpyramidlabelImageNettransfer learningbase modelImageNet$224\\times 224$ROIROIlevel\n$$k = \\lfloor k_0 + \\log_2(\\sqrt{wh}/224)\\rfloor$$\n\npredictor head$1024d$fc layerfinal classificationregressionlevel","slug":"paper-fpn","published":1,"updated":"2018-10-27T07:16:52.404Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8n9002zae7bqfhqzqqq","content":"<p>CV<a href=\"https://xmfbit.github.io/2017/01/30/cs131-sift/\">SIFT</a>DoGDeep LearningCV detectiondetector<br><a id=\"more\"></a></p>\n<h2 id=\"Pyramid-or-not-Its-a-question\"><a href=\"#Pyramid-or-not-Its-a-question\" class=\"headerlink\" title=\"Pyramid or not? Its a question.\"></a>Pyramid or not? Its a question.</h2><p>DLCVSIFT/Harr/HoGmulti scaleCNNscaleCOCOTESTTRAINTESTTRAINFast/Faster RCNN</p>\n<p>CNNConv/Poolinglayerfeature mapspatial dimensioninherent multi-scale pyramidal hierarchy of deep CNNfeature mapfeature pyramidlayerfeature mapfeature mapresolutiontoo yong too simple</p>\n<p>SSDlayerlayerreuse high resolutionfeature maphigh resolution feature map</p>\n<p></p>\n<ul>\n<li>low resolutionstrong semantic infohigh resolutionweak semantic info</li>\n<li>single scale</li>\n</ul>\n<p>layerfeature mapaNNbFaster RCNNsingle scaleclayerfeature mapfeature pyramiddfeature mapmergelevel<br><img src=\"/img/paper-fpn-different-pyramids.png\" alt=\"\"></p>\n<p>FPNCOCOdetectionFPNMaskRCNNFPN</p>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p>layermergeskip connectionsingle scaleoutput feature mapall level<br><img src=\"/img/paper-fpn-different-with-related-work.png\" alt=\"\"></p>\n<h3 id=\"Bottom-up-pathway\"><a href=\"#Bottom-up-pathway\" class=\"headerlink\" title=\"Bottom-up pathway\"></a>Bottom-up pathway</h3><p> Bottom-up pathwayscale2xfeature mapdownsamplelayerspatial dimensionspatial dimensionlayerstageCNN</p>\n<p> ResNetstageresidual blockfeature map<code>C2~C5</code>$4, 8, 16, 32$<code>conv1</code></p>\n<h3 id=\"Top-down-pathwaylateral-connection\"><a href=\"#Top-down-pathwaylateral-connection\" class=\"headerlink\" title=\"Top-down pathwaylateral connection\"></a>Top-down pathwaylateral connection</h3><p>Top-down pathwayfeatureupsamplinghigher resolutionbottom-upfeaturelateral connection</p>\n<p>lateral connectionlayerfeature<code>2x up</code>spatial dimensionfeature<code>1x1 conv</code>channel dimensionelement-wisestagepredictionfeature<code>3x3 conv</code><br><img src=\"/img/paper-fpn-lateral-connection.png\" alt=\"lateral connection\"></p>\n<p></p>\n<blockquote>\n<p>To start the iteration, we simply attach a 1x1 convolutional layer on C5 to produce the coarsest resolution map. Finally, we append a 3x3 convolution on each merged map to generate the final feature map, which is to reduce the aliasing effect of upsampling.</p>\n</blockquote>\n<p>featureclassifierregressorchannel dimension$256$conv layer</p>\n<p>PyTorchFPN<a href=\"https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py\" target=\"_blank\" rel=\"external\">kuangliu/pytorch-fpn</a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## ResNetblock</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Bottleneck</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    expansion = <span class=\"number\">4</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, in_planes, planes, stride=<span class=\"number\">1</span>)</span>:</span></div><div class=\"line\">        super(Bottleneck, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn1 = nn.BatchNorm2d(planes)</div><div class=\"line\">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class=\"number\">3</span>, stride=stride, padding=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn2 = nn.BatchNorm2d(planes)</div><div class=\"line\">        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn3 = nn.BatchNorm2d(self.expansion*planes)</div><div class=\"line\"></div><div class=\"line\">        self.shortcut = nn.Sequential()</div><div class=\"line\">        <span class=\"keyword\">if</span> stride != <span class=\"number\">1</span> <span class=\"keyword\">or</span> in_planes != self.expansion*planes:</div><div class=\"line\">            self.shortcut = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=<span class=\"number\">1</span>, stride=stride, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">                nn.BatchNorm2d(self.expansion*planes)</div><div class=\"line\">            )</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        out = F.relu(self.bn1(self.conv1(x)))</div><div class=\"line\">        out = F.relu(self.bn2(self.conv2(out)))</div><div class=\"line\">        out = self.bn3(self.conv3(out))</div><div class=\"line\">        out += self.shortcut(x)</div><div class=\"line\">        out = F.relu(out)</div><div class=\"line\">        <span class=\"keyword\">return</span> out</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FPN</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, block, num_blocks)</span>:</span></div><div class=\"line\">        super(FPN, self).__init__()</div><div class=\"line\">        self.in_planes = <span class=\"number\">64</span></div><div class=\"line\"></div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn1 = nn.BatchNorm2d(<span class=\"number\">64</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Bottom-up layers, backbone of the network</span></div><div class=\"line\">        self.layer1 = self._make_layer(block,  <span class=\"number\">64</span>, num_blocks[<span class=\"number\">0</span>], stride=<span class=\"number\">1</span>)</div><div class=\"line\">        self.layer2 = self._make_layer(block, <span class=\"number\">128</span>, num_blocks[<span class=\"number\">1</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\">        self.layer3 = self._make_layer(block, <span class=\"number\">256</span>, num_blocks[<span class=\"number\">2</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\">        self.layer4 = self._make_layer(block, <span class=\"number\">512</span>, num_blocks[<span class=\"number\">3</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Top layer</span></div><div class=\"line\">        <span class=\"comment\"># C51x1, 256 convfeature</span></div><div class=\"line\">        self.toplayer = nn.Conv2d(<span class=\"number\">2048</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)  <span class=\"comment\"># Reduce channels</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Smooth layers</span></div><div class=\"line\">        <span class=\"comment\"># aliasing3x3</span></div><div class=\"line\">        self.smooth1 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.smooth2 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.smooth3 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Lateral layers</span></div><div class=\"line\">        <span class=\"comment\"># channel dimension1x1</span></div><div class=\"line\">        <span class=\"comment\"># backboneextra conv256 channel</span></div><div class=\"line\">        self.latlayer1 = nn.Conv2d(<span class=\"number\">1024</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\">        self.latlayer2 = nn.Conv2d( <span class=\"number\">512</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\">        self.latlayer3 = nn.Conv2d( <span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_make_layer</span><span class=\"params\">(self, block, planes, num_blocks, stride)</span>:</span></div><div class=\"line\">        strides = [stride] + [<span class=\"number\">1</span>]*(num_blocks<span class=\"number\">-1</span>)</div><div class=\"line\">        layers = []</div><div class=\"line\">        <span class=\"keyword\">for</span> stride <span class=\"keyword\">in</span> strides:</div><div class=\"line\">            layers.append(block(self.in_planes, planes, stride))</div><div class=\"line\">            self.in_planes = planes * block.expansion</div><div class=\"line\">        <span class=\"keyword\">return</span> nn.Sequential(*layers)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">## FPNlateral connection: upsampleelement-wise</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_upsample_add</span><span class=\"params\">(self, x, y)</span>:</span></div><div class=\"line\">        <span class=\"string\">'''Upsample and add two feature maps.</span></div><div class=\"line\">        Args:</div><div class=\"line\">          x: (Variable) top feature map to be upsampled.</div><div class=\"line\">          y: (Variable) lateral feature map.</div><div class=\"line\">        Returns:</div><div class=\"line\">          (Variable) added feature map.</div><div class=\"line\">        Note in PyTorch, when input size is odd, the upsampled feature map</div><div class=\"line\">        with `F.upsample(..., scale_factor=2, mode='nearest')`</div><div class=\"line\">        maybe not equal to the lateral feature map size.</div><div class=\"line\">        e.g.</div><div class=\"line\">        original input size: [N,_,15,15] -&gt;</div><div class=\"line\">        conv2d feature map size: [N,_,8,8] -&gt;</div><div class=\"line\">        upsampled feature map size: [N,_,16,16]</div><div class=\"line\">        So we choose bilinear upsample which supports arbitrary output sizes.</div><div class=\"line\">        '''</div><div class=\"line\">        _,_,H,W = y.size()</div><div class=\"line\">        <span class=\"keyword\">return</span> F.upsample(x, size=(H,W), mode=<span class=\"string\">'bilinear'</span>) + y</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># Bottom-up</span></div><div class=\"line\">        c1 = F.relu(self.bn1(self.conv1(x)))</div><div class=\"line\">        c1 = F.max_pool2d(c1, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        c2 = self.layer1(c1)</div><div class=\"line\">        c3 = self.layer2(c2)</div><div class=\"line\">        c4 = self.layer3(c3)</div><div class=\"line\">        c5 = self.layer4(c4)</div><div class=\"line\">        <span class=\"comment\"># Top-down</span></div><div class=\"line\">        <span class=\"comment\"># P5: feature</span></div><div class=\"line\">        p5 = self.toplayer(c5)</div><div class=\"line\">        <span class=\"comment\"># P4:  p5 +  c4</span></div><div class=\"line\">        <span class=\"comment\"># </span></div><div class=\"line\">        p4 = self._upsample_add(p5, self.latlayer1(c4))</div><div class=\"line\">        p3 = self._upsample_add(p4, self.latlayer2(c3))</div><div class=\"line\">        p2 = self._upsample_add(p3, self.latlayer3(c2))</div><div class=\"line\">        <span class=\"comment\"># Smooth</span></div><div class=\"line\">        <span class=\"comment\"># smooth</span></div><div class=\"line\">        p4 = self.smooth1(p4)</div><div class=\"line\">        p3 = self.smooth2(p3)</div><div class=\"line\">        p2 = self.smooth3(p2)</div><div class=\"line\">        <span class=\"keyword\">return</span> p2, p3, p4, p5</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FPNFasterRCNNRPNFast RCNN</p>\n<h3 id=\"FPNRPN\"><a href=\"#FPNRPN\" class=\"headerlink\" title=\"FPNRPN\"></a>FPNRPN</h3><p>Faster RCNNRPNROIproposalbackbonesingle feature map$3\\times 3$sliding window$1\\times 1$objectnessbounding boxanchor boxclassifierregressorhead</p>\n<p>FPNfeature maphead$3\\times 3$ + two sibling $1\\times 1$anchor boxlevelanchor box$5$level<code>P2 - P6</code>anchor box$32^2, 64^2, 128^2, 256^2, 512^2$anchor box$3$$1:2, 1:1, 2:1$$5\\times 3 = 15$anchor box</p>\n<p>anchor boxesground truthIoUground truthIoU$0.7$anchor boxespositive labelground truthIoU$0.3$negtive label</p>\n<p>headlevelaccuracylevelresolution</p>\n<h3 id=\"FPNFast-RCNN\"><a href=\"#FPNFast-RCNN\" class=\"headerlink\" title=\"FPNFast RCNN\"></a>FPNFast RCNN</h3><p>Fast RCNNsingle scalefeature mapFPNROI proposalpyramidlabelImageNettransfer learningbase modelImageNet$224\\times 224$ROIROIlevel</p>\n<script type=\"math/tex; mode=display\">k = \\lfloor k_0 + \\log_2(\\sqrt{wh}/224)\\rfloor</script><p>predictor head$1024d$fc layerfinal classificationregressionlevel</p>\n","excerpt":"<p>CV<a href=\"https://xmfbit.github.io/2017/01/30/cs131-sift/\">SIFT</a>DoGDeep LearningCV detectiondetector<br>","more":"</p>\n<h2 id=\"Pyramid-or-not-Its-a-question\"><a href=\"#Pyramid-or-not-Its-a-question\" class=\"headerlink\" title=\"Pyramid or not? Its a question.\"></a>Pyramid or not? Its a question.</h2><p>DLCVSIFT/Harr/HoGmulti scaleCNNscaleCOCOTESTTRAINTESTTRAINFast/Faster RCNN</p>\n<p>CNNConv/Poolinglayerfeature mapspatial dimensioninherent multi-scale pyramidal hierarchy of deep CNNfeature mapfeature pyramidlayerfeature mapfeature mapresolutiontoo yong too simple</p>\n<p>SSDlayerlayerreuse high resolutionfeature maphigh resolution feature map</p>\n<p></p>\n<ul>\n<li>low resolutionstrong semantic infohigh resolutionweak semantic info</li>\n<li>single scale</li>\n</ul>\n<p>layerfeature mapaNNbFaster RCNNsingle scaleclayerfeature mapfeature pyramiddfeature mapmergelevel<br><img src=\"/img/paper-fpn-different-pyramids.png\" alt=\"\"></p>\n<p>FPNCOCOdetectionFPNMaskRCNNFPN</p>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p>layermergeskip connectionsingle scaleoutput feature mapall level<br><img src=\"/img/paper-fpn-different-with-related-work.png\" alt=\"\"></p>\n<h3 id=\"Bottom-up-pathway\"><a href=\"#Bottom-up-pathway\" class=\"headerlink\" title=\"Bottom-up pathway\"></a>Bottom-up pathway</h3><p> Bottom-up pathwayscale2xfeature mapdownsamplelayerspatial dimensionspatial dimensionlayerstageCNN</p>\n<p> ResNetstageresidual blockfeature map<code>C2~C5</code>$4, 8, 16, 32$<code>conv1</code></p>\n<h3 id=\"Top-down-pathwaylateral-connection\"><a href=\"#Top-down-pathwaylateral-connection\" class=\"headerlink\" title=\"Top-down pathwaylateral connection\"></a>Top-down pathwaylateral connection</h3><p>Top-down pathwayfeatureupsamplinghigher resolutionbottom-upfeaturelateral connection</p>\n<p>lateral connectionlayerfeature<code>2x up</code>spatial dimensionfeature<code>1x1 conv</code>channel dimensionelement-wisestagepredictionfeature<code>3x3 conv</code><br><img src=\"/img/paper-fpn-lateral-connection.png\" alt=\"lateral connection\"></p>\n<p></p>\n<blockquote>\n<p>To start the iteration, we simply attach a 1x1 convolutional layer on C5 to produce the coarsest resolution map. Finally, we append a 3x3 convolution on each merged map to generate the final feature map, which is to reduce the aliasing effect of upsampling.</p>\n</blockquote>\n<p>featureclassifierregressorchannel dimension$256$conv layer</p>\n<p>PyTorchFPN<a href=\"https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py\">kuangliu/pytorch-fpn</a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## ResNetblock</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Bottleneck</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    expansion = <span class=\"number\">4</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, in_planes, planes, stride=<span class=\"number\">1</span>)</span>:</span></div><div class=\"line\">        super(Bottleneck, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn1 = nn.BatchNorm2d(planes)</div><div class=\"line\">        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class=\"number\">3</span>, stride=stride, padding=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn2 = nn.BatchNorm2d(planes)</div><div class=\"line\">        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=<span class=\"number\">1</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn3 = nn.BatchNorm2d(self.expansion*planes)</div><div class=\"line\"></div><div class=\"line\">        self.shortcut = nn.Sequential()</div><div class=\"line\">        <span class=\"keyword\">if</span> stride != <span class=\"number\">1</span> <span class=\"keyword\">or</span> in_planes != self.expansion*planes:</div><div class=\"line\">            self.shortcut = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=<span class=\"number\">1</span>, stride=stride, bias=<span class=\"keyword\">False</span>),</div><div class=\"line\">                nn.BatchNorm2d(self.expansion*planes)</div><div class=\"line\">            )</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        out = F.relu(self.bn1(self.conv1(x)))</div><div class=\"line\">        out = F.relu(self.bn2(self.conv2(out)))</div><div class=\"line\">        out = self.bn3(self.conv3(out))</div><div class=\"line\">        out += self.shortcut(x)</div><div class=\"line\">        out = F.relu(out)</div><div class=\"line\">        <span class=\"keyword\">return</span> out</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">FPN</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, block, num_blocks)</span>:</span></div><div class=\"line\">        super(FPN, self).__init__()</div><div class=\"line\">        self.in_planes = <span class=\"number\">64</span></div><div class=\"line\"></div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">3</span>, bias=<span class=\"keyword\">False</span>)</div><div class=\"line\">        self.bn1 = nn.BatchNorm2d(<span class=\"number\">64</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Bottom-up layers, backbone of the network</span></div><div class=\"line\">        self.layer1 = self._make_layer(block,  <span class=\"number\">64</span>, num_blocks[<span class=\"number\">0</span>], stride=<span class=\"number\">1</span>)</div><div class=\"line\">        self.layer2 = self._make_layer(block, <span class=\"number\">128</span>, num_blocks[<span class=\"number\">1</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\">        self.layer3 = self._make_layer(block, <span class=\"number\">256</span>, num_blocks[<span class=\"number\">2</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\">        self.layer4 = self._make_layer(block, <span class=\"number\">512</span>, num_blocks[<span class=\"number\">3</span>], stride=<span class=\"number\">2</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Top layer</span></div><div class=\"line\">        <span class=\"comment\"># C51x1, 256 convfeature</span></div><div class=\"line\">        self.toplayer = nn.Conv2d(<span class=\"number\">2048</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)  <span class=\"comment\"># Reduce channels</span></div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Smooth layers</span></div><div class=\"line\">        <span class=\"comment\"># aliasing3x3</span></div><div class=\"line\">        self.smooth1 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.smooth2 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.smooth3 = nn.Conv2d(<span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># Lateral layers</span></div><div class=\"line\">        <span class=\"comment\"># channel dimension1x1</span></div><div class=\"line\">        <span class=\"comment\"># backboneextra conv256 channel</span></div><div class=\"line\">        self.latlayer1 = nn.Conv2d(<span class=\"number\">1024</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\">        self.latlayer2 = nn.Conv2d( <span class=\"number\">512</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\">        self.latlayer3 = nn.Conv2d( <span class=\"number\">256</span>, <span class=\"number\">256</span>, kernel_size=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_make_layer</span><span class=\"params\">(self, block, planes, num_blocks, stride)</span>:</span></div><div class=\"line\">        strides = [stride] + [<span class=\"number\">1</span>]*(num_blocks<span class=\"number\">-1</span>)</div><div class=\"line\">        layers = []</div><div class=\"line\">        <span class=\"keyword\">for</span> stride <span class=\"keyword\">in</span> strides:</div><div class=\"line\">            layers.append(block(self.in_planes, planes, stride))</div><div class=\"line\">            self.in_planes = planes * block.expansion</div><div class=\"line\">        <span class=\"keyword\">return</span> nn.Sequential(*layers)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">## FPNlateral connection: upsampleelement-wise</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_upsample_add</span><span class=\"params\">(self, x, y)</span>:</span></div><div class=\"line\">        <span class=\"string\">'''Upsample and add two feature maps.</div><div class=\"line\">        Args:</div><div class=\"line\">          x: (Variable) top feature map to be upsampled.</div><div class=\"line\">          y: (Variable) lateral feature map.</div><div class=\"line\">        Returns:</div><div class=\"line\">          (Variable) added feature map.</div><div class=\"line\">        Note in PyTorch, when input size is odd, the upsampled feature map</div><div class=\"line\">        with `F.upsample(..., scale_factor=2, mode='nearest')`</div><div class=\"line\">        maybe not equal to the lateral feature map size.</div><div class=\"line\">        e.g.</div><div class=\"line\">        original input size: [N,_,15,15] -&gt;</div><div class=\"line\">        conv2d feature map size: [N,_,8,8] -&gt;</div><div class=\"line\">        upsampled feature map size: [N,_,16,16]</div><div class=\"line\">        So we choose bilinear upsample which supports arbitrary output sizes.</div><div class=\"line\">        '''</span></div><div class=\"line\">        _,_,H,W = y.size()</div><div class=\"line\">        <span class=\"keyword\">return</span> F.upsample(x, size=(H,W), mode=<span class=\"string\">'bilinear'</span>) + y</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># Bottom-up</span></div><div class=\"line\">        c1 = F.relu(self.bn1(self.conv1(x)))</div><div class=\"line\">        c1 = F.max_pool2d(c1, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        c2 = self.layer1(c1)</div><div class=\"line\">        c3 = self.layer2(c2)</div><div class=\"line\">        c4 = self.layer3(c3)</div><div class=\"line\">        c5 = self.layer4(c4)</div><div class=\"line\">        <span class=\"comment\"># Top-down</span></div><div class=\"line\">        <span class=\"comment\"># P5: feature</span></div><div class=\"line\">        p5 = self.toplayer(c5)</div><div class=\"line\">        <span class=\"comment\"># P4:  p5 +  c4</span></div><div class=\"line\">        <span class=\"comment\"># </span></div><div class=\"line\">        p4 = self._upsample_add(p5, self.latlayer1(c4))</div><div class=\"line\">        p3 = self._upsample_add(p4, self.latlayer2(c3))</div><div class=\"line\">        p2 = self._upsample_add(p3, self.latlayer3(c2))</div><div class=\"line\">        <span class=\"comment\"># Smooth</span></div><div class=\"line\">        <span class=\"comment\"># smooth</span></div><div class=\"line\">        p4 = self.smooth1(p4)</div><div class=\"line\">        p3 = self.smooth2(p3)</div><div class=\"line\">        p2 = self.smooth3(p2)</div><div class=\"line\">        <span class=\"keyword\">return</span> p2, p3, p4, p5</div></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>FPNFasterRCNNRPNFast RCNN</p>\n<h3 id=\"FPNRPN\"><a href=\"#FPNRPN\" class=\"headerlink\" title=\"FPNRPN\"></a>FPNRPN</h3><p>Faster RCNNRPNROIproposalbackbonesingle feature map$3\\times 3$sliding window$1\\times 1$objectnessbounding boxanchor boxclassifierregressorhead</p>\n<p>FPNfeature maphead$3\\times 3$ + two sibling $1\\times 1$anchor boxlevelanchor box$5$level<code>P2 - P6</code>anchor box$32^2, 64^2, 128^2, 256^2, 512^2$anchor box$3$$1:2, 1:1, 2:1$$5\\times 3 = 15$anchor box</p>\n<p>anchor boxesground truthIoUground truthIoU$0.7$anchor boxespositive labelground truthIoU$0.3$negtive label</p>\n<p>headlevelaccuracylevelresolution</p>\n<h3 id=\"FPNFast-RCNN\"><a href=\"#FPNFast-RCNN\" class=\"headerlink\" title=\"FPNFast RCNN\"></a>FPNFast RCNN</h3><p>Fast RCNNsingle scalefeature mapFPNROI proposalpyramidlabelImageNettransfer learningbase modelImageNet$224\\times 224$ROIROIlevel</p>\n<script type=\"math/tex; mode=display\">k = \\lfloor k_0 + \\log_2(\\sqrt{wh}/224)\\rfloor</script><p>predictor head$1024d$fc layerfinal classificationregressionlevel</p>"},{"title":" - Learning both Weights and Connections for Efficient Neural Networks","date":"2018-03-14T08:18:53.000Z","_content":"Han SongDeep CompressionDeep Compression[Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626)\n![Pruning](/img/paper-pruning-network-demo.png)\n<!-- more -->\n\n## \nDNNDRAM$0$dense modelsparse model\n![](/img/paper-pruning-network-energy-for-different-memory-hieracy.png)\n\n### \nDNN\n\n### work\nDNNNIPS 2013[Predicting parameters in deep learning](https://arxiv.org/abs/1306.0543)\n\n> Neural networks are typically over-parameterized, and there is significant redundancy for deep learning models \n\n\n\n### \n\n- Train Connectivity: \n- Prune Connection: $0$\n- Re-Train: pruning\n\n$2$$3$\n\n## \nsize\n\n- weight8bit32bitactivation\n- \n- NINGlobal Average PoolingFCFCPoolingfctransfer learning\n- Hessianweight decay\n- HashedNet\n\n## Prune\n    \n![](/img/paper-pruning-network-algrithem.png)\n\n### \nL1L2pruningretrainingL2with/without retrainL1L2pruning\n\n![L1/L2 Regularization](/img/paper-pruning-network-regularization.png)\n\n### Dropout\nDropoutretrainingDropout ratiodropout\n\nFC$i$$N\\_i$$C\\_i$$C\\_i = N\\_{i-1}N\\_i$$C\\sim N^2$dropoutdropout$N\\_i$dropout$D^2 \\sim C$\n$$D_r = D_o \\sqrt{\\frac{C_{ir}}{C_{io}}}$$\n$r$retraining$o$(original)\n\n## Local Pruning\nretrainingfine tuneFCCONV\n\nlayerCONVFC$1$CONVAlexNetlayer\n\n![CONVFCprune](/img/paper-pruning-network-layer-sensitivity.png)\n## \n + \n![](/img/paper-pruning-network-iterative-pruning.png)\n\n## \nconnection$0$$0$connectiondead$0$$0$\n\n## \nCaffe`mask`layer[Add pruning possibilities at inner_product_layer #4294 ](https://github.com/BVLC/caffe/pull/4294/files)CafferepoFC[Github: DeepCompression](https://github.com/may0324/DeepCompression-caffe),Deep Compression\n\nLeNetAlexNetmark\n> On the ImageNet dataset, the pruning method reduced the number of parameters of AlexNet by a factor of 9 (61 to 6.7 million), without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13 (138 to 10.3 million), again with no loss of accuracy. We also experimented with the more efficient fully-convolutional neural networks: GoogleNet (Inception-V1), SqueezeNet, and ResNet-50, which have zero or very thin fully connected layers. From these experiments we find that they share very similar pruning ratios before the accuracy drops: 70% of the parameters in those fully-convolutional neural networks can be pruned. GoogleNet is pruned from 7 million to 2 million parameters, SqueezeNet from 1.2 million to 0.38 million, and ResNet-50 from 25.5 million to 7.47 million, all with no loss of Top-1 and Top-5 accuracy on Imagenet.\n\n![Results](/img/paper-pruning-network-results.png)\n\n  GitHubDeep Compression\n\n### \n$LR$$LR\\_1$$LR\\_2$retraining$LR_1$$1 \\sim 2$\n\n### RNNLSTM\nRNN/LSTMNeural Talk\n![LSTM](/img/paper-pruning-network-lstm.png)\n\n## \n- HanSong[Homepage](http://stanford.edu/~songhan/)\n- HanSong[Efficient Methods and Hardware for Deep Learning](https://purl.stanford.edu/qf934gh3708)\n- Deep Compression[DEEP COMPRESSION- COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING](https://arxiv.org/abs/1510.00149)\n- Deep Compression AlexNet: [Github: Deep-Compression-AlexNet](https://github.com/songhan/Deep-Compression-AlexNet)\n","source":"_posts/paper-network-prune-hansong.md","raw":"---\ntitle:  - Learning both Weights and Connections for Efficient Neural Networks\ndate: 2018-03-14 16:18:53\ntags:\n     - paper\n     - deep learning\n     - model compression\n---\nHan SongDeep CompressionDeep Compression[Learning both Weights and Connections for Efficient Neural Networks](https://arxiv.org/abs/1506.02626)\n![Pruning](/img/paper-pruning-network-demo.png)\n<!-- more -->\n\n## \nDNNDRAM$0$dense modelsparse model\n![](/img/paper-pruning-network-energy-for-different-memory-hieracy.png)\n\n### \nDNN\n\n### work\nDNNNIPS 2013[Predicting parameters in deep learning](https://arxiv.org/abs/1306.0543)\n\n> Neural networks are typically over-parameterized, and there is significant redundancy for deep learning models \n\n\n\n### \n\n- Train Connectivity: \n- Prune Connection: $0$\n- Re-Train: pruning\n\n$2$$3$\n\n## \nsize\n\n- weight8bit32bitactivation\n- \n- NINGlobal Average PoolingFCFCPoolingfctransfer learning\n- Hessianweight decay\n- HashedNet\n\n## Prune\n    \n![](/img/paper-pruning-network-algrithem.png)\n\n### \nL1L2pruningretrainingL2with/without retrainL1L2pruning\n\n![L1/L2 Regularization](/img/paper-pruning-network-regularization.png)\n\n### Dropout\nDropoutretrainingDropout ratiodropout\n\nFC$i$$N\\_i$$C\\_i$$C\\_i = N\\_{i-1}N\\_i$$C\\sim N^2$dropoutdropout$N\\_i$dropout$D^2 \\sim C$\n$$D_r = D_o \\sqrt{\\frac{C_{ir}}{C_{io}}}$$\n$r$retraining$o$(original)\n\n## Local Pruning\nretrainingfine tuneFCCONV\n\nlayerCONVFC$1$CONVAlexNetlayer\n\n![CONVFCprune](/img/paper-pruning-network-layer-sensitivity.png)\n## \n + \n![](/img/paper-pruning-network-iterative-pruning.png)\n\n## \nconnection$0$$0$connectiondead$0$$0$\n\n## \nCaffe`mask`layer[Add pruning possibilities at inner_product_layer #4294 ](https://github.com/BVLC/caffe/pull/4294/files)CafferepoFC[Github: DeepCompression](https://github.com/may0324/DeepCompression-caffe),Deep Compression\n\nLeNetAlexNetmark\n> On the ImageNet dataset, the pruning method reduced the number of parameters of AlexNet by a factor of 9 (61 to 6.7 million), without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13 (138 to 10.3 million), again with no loss of accuracy. We also experimented with the more efficient fully-convolutional neural networks: GoogleNet (Inception-V1), SqueezeNet, and ResNet-50, which have zero or very thin fully connected layers. From these experiments we find that they share very similar pruning ratios before the accuracy drops: 70% of the parameters in those fully-convolutional neural networks can be pruned. GoogleNet is pruned from 7 million to 2 million parameters, SqueezeNet from 1.2 million to 0.38 million, and ResNet-50 from 25.5 million to 7.47 million, all with no loss of Top-1 and Top-5 accuracy on Imagenet.\n\n![Results](/img/paper-pruning-network-results.png)\n\n  GitHubDeep Compression\n\n### \n$LR$$LR\\_1$$LR\\_2$retraining$LR_1$$1 \\sim 2$\n\n### RNNLSTM\nRNN/LSTMNeural Talk\n![LSTM](/img/paper-pruning-network-lstm.png)\n\n## \n- HanSong[Homepage](http://stanford.edu/~songhan/)\n- HanSong[Efficient Methods and Hardware for Deep Learning](https://purl.stanford.edu/qf934gh3708)\n- Deep Compression[DEEP COMPRESSION- COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING](https://arxiv.org/abs/1510.00149)\n- Deep Compression AlexNet: [Github: Deep-Compression-AlexNet](https://github.com/songhan/Deep-Compression-AlexNet)\n","slug":"paper-network-prune-hansong","published":1,"updated":"2018-10-27T07:16:52.406Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nb0031ae7bhkjicr0v","content":"<p>Han SongDeep CompressionDeep Compression<a href=\"https://arxiv.org/abs/1506.02626\" target=\"_blank\" rel=\"external\">Learning both Weights and Connections for Efficient Neural Networks</a><br><img src=\"/img/paper-pruning-network-demo.png\" alt=\"Pruning\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNDRAM$0$dense modelsparse model<br><img src=\"/img/paper-pruning-network-energy-for-different-memory-hieracy.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DNN</p>\n<h3 id=\"work\"><a href=\"#work\" class=\"headerlink\" title=\"work\"></a>work</h3><p>DNNNIPS 2013<a href=\"https://arxiv.org/abs/1306.0543\" target=\"_blank\" rel=\"external\">Predicting parameters in deep learning</a></p>\n<blockquote>\n<p>Neural networks are typically over-parameterized, and there is significant redundancy for deep learning models </p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>Train Connectivity: </li>\n<li>Prune Connection: $0$</li>\n<li>Re-Train: pruning</li>\n</ul>\n<p>$2$$3$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>size</p>\n<ul>\n<li>weight8bit32bitactivation</li>\n<li></li>\n<li>NINGlobal Average PoolingFCFCPoolingfctransfer learning</li>\n<li>Hessianweight decay</li>\n<li>HashedNet</li>\n</ul>\n<h2 id=\"Prune\"><a href=\"#Prune\" class=\"headerlink\" title=\"Prune\"></a>Prune</h2><p>    <br><img src=\"/img/paper-pruning-network-algrithem.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>L1L2pruningretrainingL2with/without retrainL1L2pruning</p>\n<p><img src=\"/img/paper-pruning-network-regularization.png\" alt=\"L1/L2 Regularization\"></p>\n<h3 id=\"Dropout\"><a href=\"#Dropout\" class=\"headerlink\" title=\"Dropout\"></a>Dropout</h3><p>DropoutretrainingDropout ratiodropout</p>\n<p>FC$i$$N_i$$C_i$$C_i = N_{i-1}N_i$$C\\sim N^2$dropoutdropout$N_i$dropout$D^2 \\sim C$</p>\n<script type=\"math/tex; mode=display\">D_r = D_o \\sqrt{\\frac{C_{ir}}{C_{io}}}</script><p>$r$retraining$o$(original)</p>\n<h2 id=\"Local-Pruning\"><a href=\"#Local-Pruning\" class=\"headerlink\" title=\"Local Pruning\"></a>Local Pruning</h2><p>retrainingfine tuneFCCONV</p>\n<p>layerCONVFC$1$CONVAlexNetlayer</p>\n<p><img src=\"/img/paper-pruning-network-layer-sensitivity.png\" alt=\"CONVFCprune\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> + <br><img src=\"/img/paper-pruning-network-iterative-pruning.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>connection$0$$0$connectiondead$0$$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Caffe<code>mask</code>layer<a href=\"https://github.com/BVLC/caffe/pull/4294/files\" target=\"_blank\" rel=\"external\">Add pruning possibilities at inner_product_layer #4294 </a>CafferepoFC<a href=\"https://github.com/may0324/DeepCompression-caffe\" target=\"_blank\" rel=\"external\">Github: DeepCompression</a>,Deep Compression</p>\n<p>LeNetAlexNetmark</p>\n<blockquote>\n<p>On the ImageNet dataset, the pruning method reduced the number of parameters of AlexNet by a factor of 9 (61 to 6.7 million), without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13 (138 to 10.3 million), again with no loss of accuracy. We also experimented with the more efficient fully-convolutional neural networks: GoogleNet (Inception-V1), SqueezeNet, and ResNet-50, which have zero or very thin fully connected layers. From these experiments we find that they share very similar pruning ratios before the accuracy drops: 70% of the parameters in those fully-convolutional neural networks can be pruned. GoogleNet is pruned from 7 million to 2 million parameters, SqueezeNet from 1.2 million to 0.38 million, and ResNet-50 from 25.5 million to 7.47 million, all with no loss of Top-1 and Top-5 accuracy on Imagenet.</p>\n</blockquote>\n<p><img src=\"/img/paper-pruning-network-results.png\" alt=\"Results\"></p>\n<p>  GitHubDeep Compression</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$LR$$LR_1$$LR_2$retraining$LR_1$$1 \\sim 2$</p>\n<h3 id=\"RNNLSTM\"><a href=\"#RNNLSTM\" class=\"headerlink\" title=\"RNNLSTM\"></a>RNNLSTM</h3><p>RNN/LSTMNeural Talk<br><img src=\"/img/paper-pruning-network-lstm.png\" alt=\"LSTM\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>HanSong<a href=\"http://stanford.edu/~songhan/\" target=\"_blank\" rel=\"external\">Homepage</a></li>\n<li>HanSong<a href=\"https://purl.stanford.edu/qf934gh3708\" target=\"_blank\" rel=\"external\">Efficient Methods and Hardware for Deep Learning</a></li>\n<li>Deep Compression<a href=\"https://arxiv.org/abs/1510.00149\" target=\"_blank\" rel=\"external\">DEEP COMPRESSION- COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING</a></li>\n<li>Deep Compression AlexNet: <a href=\"https://github.com/songhan/Deep-Compression-AlexNet\" target=\"_blank\" rel=\"external\">Github: Deep-Compression-AlexNet</a></li>\n</ul>\n","excerpt":"<p>Han SongDeep CompressionDeep Compression<a href=\"https://arxiv.org/abs/1506.02626\">Learning both Weights and Connections for Efficient Neural Networks</a><br><img src=\"/img/paper-pruning-network-demo.png\" alt=\"Pruning\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNDRAM$0$dense modelsparse model<br><img src=\"/img/paper-pruning-network-energy-for-different-memory-hieracy.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DNN</p>\n<h3 id=\"work\"><a href=\"#work\" class=\"headerlink\" title=\"work\"></a>work</h3><p>DNNNIPS 2013<a href=\"https://arxiv.org/abs/1306.0543\">Predicting parameters in deep learning</a></p>\n<blockquote>\n<p>Neural networks are typically over-parameterized, and there is significant redundancy for deep learning models </p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>Train Connectivity: </li>\n<li>Prune Connection: $0$</li>\n<li>Re-Train: pruning</li>\n</ul>\n<p>$2$$3$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>size</p>\n<ul>\n<li>weight8bit32bitactivation</li>\n<li></li>\n<li>NINGlobal Average PoolingFCFCPoolingfctransfer learning</li>\n<li>Hessianweight decay</li>\n<li>HashedNet</li>\n</ul>\n<h2 id=\"Prune\"><a href=\"#Prune\" class=\"headerlink\" title=\"Prune\"></a>Prune</h2><p>    <br><img src=\"/img/paper-pruning-network-algrithem.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>L1L2pruningretrainingL2with/without retrainL1L2pruning</p>\n<p><img src=\"/img/paper-pruning-network-regularization.png\" alt=\"L1/L2 Regularization\"></p>\n<h3 id=\"Dropout\"><a href=\"#Dropout\" class=\"headerlink\" title=\"Dropout\"></a>Dropout</h3><p>DropoutretrainingDropout ratiodropout</p>\n<p>FC$i$$N_i$$C_i$$C_i = N_{i-1}N_i$$C\\sim N^2$dropoutdropout$N_i$dropout$D^2 \\sim C$</p>\n<script type=\"math/tex; mode=display\">D_r = D_o \\sqrt{\\frac{C_{ir}}{C_{io}}}</script><p>$r$retraining$o$(original)</p>\n<h2 id=\"Local-Pruning\"><a href=\"#Local-Pruning\" class=\"headerlink\" title=\"Local Pruning\"></a>Local Pruning</h2><p>retrainingfine tuneFCCONV</p>\n<p>layerCONVFC$1$CONVAlexNetlayer</p>\n<p><img src=\"/img/paper-pruning-network-layer-sensitivity.png\" alt=\"CONVFCprune\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> + <br><img src=\"/img/paper-pruning-network-iterative-pruning.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>connection$0$$0$connectiondead$0$$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Caffe<code>mask</code>layer<a href=\"https://github.com/BVLC/caffe/pull/4294/files\">Add pruning possibilities at inner_product_layer #4294 </a>CafferepoFC<a href=\"https://github.com/may0324/DeepCompression-caffe\">Github: DeepCompression</a>,Deep Compression</p>\n<p>LeNetAlexNetmark</p>\n<blockquote>\n<p>On the ImageNet dataset, the pruning method reduced the number of parameters of AlexNet by a factor of 9 (61 to 6.7 million), without incurring accuracy loss. Similar experiments with VGG-16 found that the total number of parameters can be reduced by 13 (138 to 10.3 million), again with no loss of accuracy. We also experimented with the more efficient fully-convolutional neural networks: GoogleNet (Inception-V1), SqueezeNet, and ResNet-50, which have zero or very thin fully connected layers. From these experiments we find that they share very similar pruning ratios before the accuracy drops: 70% of the parameters in those fully-convolutional neural networks can be pruned. GoogleNet is pruned from 7 million to 2 million parameters, SqueezeNet from 1.2 million to 0.38 million, and ResNet-50 from 25.5 million to 7.47 million, all with no loss of Top-1 and Top-5 accuracy on Imagenet.</p>\n</blockquote>\n<p><img src=\"/img/paper-pruning-network-results.png\" alt=\"Results\"></p>\n<p>  GitHubDeep Compression</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$LR$$LR_1$$LR_2$retraining$LR_1$$1 \\sim 2$</p>\n<h3 id=\"RNNLSTM\"><a href=\"#RNNLSTM\" class=\"headerlink\" title=\"RNNLSTM\"></a>RNNLSTM</h3><p>RNN/LSTMNeural Talk<br><img src=\"/img/paper-pruning-network-lstm.png\" alt=\"LSTM\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>HanSong<a href=\"http://stanford.edu/~songhan/\">Homepage</a></li>\n<li>HanSong<a href=\"https://purl.stanford.edu/qf934gh3708\">Efficient Methods and Hardware for Deep Learning</a></li>\n<li>Deep Compression<a href=\"https://arxiv.org/abs/1510.00149\">DEEP COMPRESSION- COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING</a></li>\n<li>Deep Compression AlexNet: <a href=\"https://github.com/songhan/Deep-Compression-AlexNet\">Github: Deep-Compression-AlexNet</a></li>\n</ul>"},{"title":" - Learning Structured Sparsity in Deep Neural Networks","date":"2018-02-24T02:21:14.000Z","_content":"DNNL1FPGA/AISCDNNDNNcache missing[](https://arxiv.org/pdf/1608.03665.pdf)[](http://www.pittnuts.com/)Chen YiranDNNNIPS 2016[GitHub](https://github.com/wenwei202/caffe/tree/scnn)\n![SSL](/img/paper-ssldnn.png)\n<!-- more-->\n\n## \nDNNStructure Sparisity Learning (SSL)DNNCNN filterfilterchannel\n- DNN -->  --> \n-  --> \n-  --> \n\nCPU/GPUAlexNet$5.1$$3,1$CIFAR10ResNet$20$$18$\n\n## LASSO\nSSLGroup LASSOLASSOGroup LASSO\n[LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))(least absolute shrinkage and selection operator)L1 norm$\\beta$wiki\n\n$$\\min_{\\beta \\in R^p}\\frac{1}{N} \\Vert(y-X\\beta)\\Vert_2^2 + \\lambda \\Vert \\beta \\Vert_1$$\n\nGroup LASSOLASSO\n\nLASSOSSLLASSO\n\n## \nDNNconnection pruning, low rank approximationL1$2$`conv3``conv4``conv5`$1$\n![](/img/paper-ssldnn-random-sparity-is-bad.png)\n\nlow rank approx\n\nSSL\n- filterchannel\n- filter\n- layer\n\n\n$l$$4D$Tensor$W^{(l)}\\in R^{N_l \\times C_l \\times M_l \\times N_l}$SSL\n$$E(W)=E_D{W} + \\lambda R(W) + \\lambda_g \\sum_{l=1}^{L}R_g(W^{(l)})$$\n\n$W$DNN$E_D(W)$loss$R$L2 norm$R_g$group LASSO\n\n$$R_g(w) = \\sum_{g=1}^{G}\\Vert w^{(g)} \\Vert_g$$\n\n$w^{(g)}$$W^{(l)}$$G$$\\Vert \\cdot \\Vert\\_g$group LASSO$\\Vert w^{(g)}\\Vert\\_g = \\sqrt{\\sum_{i=1}^{|w^{(g)}|}(w_i^{(g)})^2}$$2$\n\n## SSL\nSSLweight\n\n### filterchannel\n$W^{(l)}\\_{n\\_l,:,:,:}$$n$filter$W^{(l)}\\_{:, c\\_l, :,:}$weight$c$channelfilterchannel$l$weightfilter$0$feature map$0$filterchannel$R(W)$\n\n$$E(W) = E_D(W) + \\lambda_n \\sum_{l=1}^{L}(\\sum_{n_l=1}^{N_l}\\Vert W^{(l)}_{n_l,:,:,:}\\Vert_g) + \\lambda_c\\sum_{l=1}^{L}(\\sum_{cl=1}^{C_l}\\Vert W^{(l)}_{:,c_l,:,:}\\Vert_g)$$\n\n### filter\nfilterfilter$0$\n$$E(W) = E_D(W) + \\lambda_s \\sum_{l=1}^{L}(\\sum_{c_l=1}^{C_l}\\sum_{m_l=1}^{M_l}\\sum_{k_l=1}^{K_l})\\Vert W^{(l)}_{:,c_l,m_l,k_l} \\Vert_g$$\n\n### \n\n$$E(W) = E_D(W) + \\lambda_d \\sum_{l=1}^{L}\\Vert W^{(l)}\\Vert_g$$\n\nlayerResNetshort-cutSSLlayerfilterfeature map\n\n### \n\n\n#### 2D filter sparsity\n3D2Dspatialchannel2Dfilter$W^{(l)}_{n_l,c_l,:,:}$groupgroup LASSOfilter-wisechannel-wise\n\n#### filter-wiseshape-wiseGEMM\nCaffe3Dtensorreshape$N_l$filter2D$W^{(l)}_{:,c_l,m_l,k_l}$shape sparsityGEMM\n\n## \nMNISTCIFAR10ImageNetbaselineSSL\n### LeNet&MLP@MNIST\nCaffeLeNetMLP\n\n#### LeNet\nSSLfilter-wisechannel-wisefilterLeNet-1baseline23($0.1%$)filterchannelFLOP\n![1](/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png)\n\n`conv1`filterLeNet2filter\n![LeNet](/img/paper-ssldnn-experiment-on-lenet.png)","source":"_posts/paper-ssl-dnn.md","raw":"---\ntitle:  - Learning Structured Sparsity in Deep Neural Networks\ndate: 2018-02-24 10:21:14\ntags:\n    - deep learning\n    - paper\n    - model compression\n---\nDNNL1FPGA/AISCDNNDNNcache missing[](https://arxiv.org/pdf/1608.03665.pdf)[](http://www.pittnuts.com/)Chen YiranDNNNIPS 2016[GitHub](https://github.com/wenwei202/caffe/tree/scnn)\n![SSL](/img/paper-ssldnn.png)\n<!-- more-->\n\n## \nDNNStructure Sparisity Learning (SSL)DNNCNN filterfilterchannel\n- DNN -->  --> \n-  --> \n-  --> \n\nCPU/GPUAlexNet$5.1$$3,1$CIFAR10ResNet$20$$18$\n\n## LASSO\nSSLGroup LASSOLASSOGroup LASSO\n[LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics))(least absolute shrinkage and selection operator)L1 norm$\\beta$wiki\n\n$$\\min_{\\beta \\in R^p}\\frac{1}{N} \\Vert(y-X\\beta)\\Vert_2^2 + \\lambda \\Vert \\beta \\Vert_1$$\n\nGroup LASSOLASSO\n\nLASSOSSLLASSO\n\n## \nDNNconnection pruning, low rank approximationL1$2$`conv3``conv4``conv5`$1$\n![](/img/paper-ssldnn-random-sparity-is-bad.png)\n\nlow rank approx\n\nSSL\n- filterchannel\n- filter\n- layer\n\n\n$l$$4D$Tensor$W^{(l)}\\in R^{N_l \\times C_l \\times M_l \\times N_l}$SSL\n$$E(W)=E_D{W} + \\lambda R(W) + \\lambda_g \\sum_{l=1}^{L}R_g(W^{(l)})$$\n\n$W$DNN$E_D(W)$loss$R$L2 norm$R_g$group LASSO\n\n$$R_g(w) = \\sum_{g=1}^{G}\\Vert w^{(g)} \\Vert_g$$\n\n$w^{(g)}$$W^{(l)}$$G$$\\Vert \\cdot \\Vert\\_g$group LASSO$\\Vert w^{(g)}\\Vert\\_g = \\sqrt{\\sum_{i=1}^{|w^{(g)}|}(w_i^{(g)})^2}$$2$\n\n## SSL\nSSLweight\n\n### filterchannel\n$W^{(l)}\\_{n\\_l,:,:,:}$$n$filter$W^{(l)}\\_{:, c\\_l, :,:}$weight$c$channelfilterchannel$l$weightfilter$0$feature map$0$filterchannel$R(W)$\n\n$$E(W) = E_D(W) + \\lambda_n \\sum_{l=1}^{L}(\\sum_{n_l=1}^{N_l}\\Vert W^{(l)}_{n_l,:,:,:}\\Vert_g) + \\lambda_c\\sum_{l=1}^{L}(\\sum_{cl=1}^{C_l}\\Vert W^{(l)}_{:,c_l,:,:}\\Vert_g)$$\n\n### filter\nfilterfilter$0$\n$$E(W) = E_D(W) + \\lambda_s \\sum_{l=1}^{L}(\\sum_{c_l=1}^{C_l}\\sum_{m_l=1}^{M_l}\\sum_{k_l=1}^{K_l})\\Vert W^{(l)}_{:,c_l,m_l,k_l} \\Vert_g$$\n\n### \n\n$$E(W) = E_D(W) + \\lambda_d \\sum_{l=1}^{L}\\Vert W^{(l)}\\Vert_g$$\n\nlayerResNetshort-cutSSLlayerfilterfeature map\n\n### \n\n\n#### 2D filter sparsity\n3D2Dspatialchannel2Dfilter$W^{(l)}_{n_l,c_l,:,:}$groupgroup LASSOfilter-wisechannel-wise\n\n#### filter-wiseshape-wiseGEMM\nCaffe3Dtensorreshape$N_l$filter2D$W^{(l)}_{:,c_l,m_l,k_l}$shape sparsityGEMM\n\n## \nMNISTCIFAR10ImageNetbaselineSSL\n### LeNet&MLP@MNIST\nCaffeLeNetMLP\n\n#### LeNet\nSSLfilter-wisechannel-wisefilterLeNet-1baseline23($0.1%$)filterchannelFLOP\n![1](/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png)\n\n`conv1`filterLeNet2filter\n![LeNet](/img/paper-ssldnn-experiment-on-lenet.png)","slug":"paper-ssl-dnn","published":1,"updated":"2018-10-27T07:16:52.409Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ne0034ae7by6q0ddm7","content":"<p>DNNL1FPGA/AISCDNNDNNcache missing<a href=\"https://arxiv.org/pdf/1608.03665.pdf\" target=\"_blank\" rel=\"external\"></a><a href=\"http://www.pittnuts.com/\" target=\"_blank\" rel=\"external\"></a>Chen YiranDNNNIPS 2016<a href=\"https://github.com/wenwei202/caffe/tree/scnn\" target=\"_blank\" rel=\"external\">GitHub</a><br><img src=\"/img/paper-ssldnn.png\" alt=\"SSL\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNStructure Sparisity Learning (SSL)DNNCNN filterfilterchannel</p>\n<ul>\n<li>DNN &gt;  &gt; </li>\n<li> &gt; </li>\n<li> &gt; </li>\n</ul>\n<p>CPU/GPUAlexNet$5.1$$3,1$CIFAR10ResNet$20$$18$</p>\n<h2 id=\"LASSO\"><a href=\"#LASSO\" class=\"headerlink\" title=\"LASSO\"></a>LASSO</h2><p>SSLGroup LASSOLASSOGroup LASSO<br><a href=\"https://en.wikipedia.org/wiki/Lasso_(statistics\" target=\"_blank\" rel=\"external\">LASSO</a>)(least absolute shrinkage and selection operator)L1 norm$\\beta$wiki</p>\n<script type=\"math/tex; mode=display\">\\min_{\\beta \\in R^p}\\frac{1}{N} \\Vert(y-X\\beta)\\Vert_2^2 + \\lambda \\Vert \\beta \\Vert_1</script><p>Group LASSOLASSO</p>\n<p>LASSOSSLLASSO</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNconnection pruning, low rank approximationL1$2$<code>conv3</code><code>conv4</code><code>conv5</code>$1$<br><img src=\"/img/paper-ssldnn-random-sparity-is-bad.png\" alt=\"\"></p>\n<p>low rank approx</p>\n<p>SSL</p>\n<ul>\n<li>filterchannel</li>\n<li>filter</li>\n<li>layer</li>\n</ul>\n<p>$l$$4D$Tensor$W^{(l)}\\in R^{N_l \\times C_l \\times M_l \\times N_l}$SSL</p>\n<script type=\"math/tex; mode=display\">E(W)=E_D{W} + \\lambda R(W) + \\lambda_g \\sum_{l=1}^{L}R_g(W^{(l)})</script><p>$W$DNN$E_D(W)$loss$R$L2 norm$R_g$group LASSO</p>\n<script type=\"math/tex; mode=display\">R_g(w) = \\sum_{g=1}^{G}\\Vert w^{(g)} \\Vert_g</script><p>$w^{(g)}$$W^{(l)}$$G$$\\Vert \\cdot \\Vert_g$group LASSO$\\Vert w^{(g)}\\Vert_g = \\sqrt{\\sum_{i=1}^{|w^{(g)}|}(w_i^{(g)})^2}$$2$</p>\n<h2 id=\"SSL\"><a href=\"#SSL\" class=\"headerlink\" title=\"SSL\"></a>SSL</h2><p>SSLweight</p>\n<h3 id=\"filterchannel\"><a href=\"#filterchannel\" class=\"headerlink\" title=\"filterchannel\"></a>filterchannel</h3><p>$W^{(l)}_{n_l,:,:,:}$$n$filter$W^{(l)}_{:, c_l, :,:}$weight$c$channelfilterchannel$l$weightfilter$0$feature map$0$filterchannel$R(W)$</p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_n \\sum_{l=1}^{L}(\\sum_{n_l=1}^{N_l}\\Vert W^{(l)}_{n_l,:,:,:}\\Vert_g) + \\lambda_c\\sum_{l=1}^{L}(\\sum_{cl=1}^{C_l}\\Vert W^{(l)}_{:,c_l,:,:}\\Vert_g)</script><h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><p>filterfilter$0$</p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_s \\sum_{l=1}^{L}(\\sum_{c_l=1}^{C_l}\\sum_{m_l=1}^{M_l}\\sum_{k_l=1}^{K_l})\\Vert W^{(l)}_{:,c_l,m_l,k_l} \\Vert_g</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_d \\sum_{l=1}^{L}\\Vert W^{(l)}\\Vert_g</script><p>layerResNetshort-cutSSLlayerfilterfeature map</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h4 id=\"2D-filter-sparsity\"><a href=\"#2D-filter-sparsity\" class=\"headerlink\" title=\"2D filter sparsity\"></a>2D filter sparsity</h4><p>3D2Dspatialchannel2Dfilter$W^{(l)}_{n_l,c_l,:,:}$groupgroup LASSOfilter-wisechannel-wise</p>\n<h4 id=\"filter-wiseshape-wiseGEMM\"><a href=\"#filter-wiseshape-wiseGEMM\" class=\"headerlink\" title=\"filter-wiseshape-wiseGEMM\"></a>filter-wiseshape-wiseGEMM</h4><p>Caffe3Dtensorreshape$N<em>l$filter2D$W^{(l)}</em>{:,c_l,m_l,k_l}$shape sparsityGEMM</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MNISTCIFAR10ImageNetbaselineSSL</p>\n<h3 id=\"LeNet-amp-MLP-MNIST\"><a href=\"#LeNet-amp-MLP-MNIST\" class=\"headerlink\" title=\"LeNet&amp;MLP@MNIST\"></a>LeNet&amp;MLP@MNIST</h3><p>CaffeLeNetMLP</p>\n<h4 id=\"LeNet\"><a href=\"#LeNet\" class=\"headerlink\" title=\"LeNet\"></a>LeNet</h4><p>SSLfilter-wisechannel-wisefilterLeNet-1baseline23($0.1%$)filterchannelFLOP<br><img src=\"/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png\" alt=\"1\"></p>\n<p><code>conv1</code>filterLeNet2filter<br><img src=\"/img/paper-ssldnn-experiment-on-lenet.png\" alt=\"LeNet\"></p>\n","excerpt":"<p>DNNL1FPGA/AISCDNNDNNcache missing<a href=\"https://arxiv.org/pdf/1608.03665.pdf\"></a><a href=\"http://www.pittnuts.com/\"></a>Chen YiranDNNNIPS 2016<a href=\"https://github.com/wenwei202/caffe/tree/scnn\">GitHub</a><br><img src=\"/img/paper-ssldnn.png\" alt=\"SSL\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNStructure Sparisity Learning (SSL)DNNCNN filterfilterchannel</p>\n<ul>\n<li>DNN &gt;  &gt; </li>\n<li> &gt; </li>\n<li> &gt; </li>\n</ul>\n<p>CPU/GPUAlexNet$5.1$$3,1$CIFAR10ResNet$20$$18$</p>\n<h2 id=\"LASSO\"><a href=\"#LASSO\" class=\"headerlink\" title=\"LASSO\"></a>LASSO</h2><p>SSLGroup LASSOLASSOGroup LASSO<br><a href=\"https://en.wikipedia.org/wiki/Lasso_(statistics\">LASSO</a>)(least absolute shrinkage and selection operator)L1 norm$\\beta$wiki</p>\n<script type=\"math/tex; mode=display\">\\min_{\\beta \\in R^p}\\frac{1}{N} \\Vert(y-X\\beta)\\Vert_2^2 + \\lambda \\Vert \\beta \\Vert_1</script><p>Group LASSOLASSO</p>\n<p>LASSOSSLLASSO</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>DNNconnection pruning, low rank approximationL1$2$<code>conv3</code><code>conv4</code><code>conv5</code>$1$<br><img src=\"/img/paper-ssldnn-random-sparity-is-bad.png\" alt=\"\"></p>\n<p>low rank approx</p>\n<p>SSL</p>\n<ul>\n<li>filterchannel</li>\n<li>filter</li>\n<li>layer</li>\n</ul>\n<p>$l$$4D$Tensor$W^{(l)}\\in R^{N_l \\times C_l \\times M_l \\times N_l}$SSL</p>\n<script type=\"math/tex; mode=display\">E(W)=E_D{W} + \\lambda R(W) + \\lambda_g \\sum_{l=1}^{L}R_g(W^{(l)})</script><p>$W$DNN$E_D(W)$loss$R$L2 norm$R_g$group LASSO</p>\n<script type=\"math/tex; mode=display\">R_g(w) = \\sum_{g=1}^{G}\\Vert w^{(g)} \\Vert_g</script><p>$w^{(g)}$$W^{(l)}$$G$$\\Vert \\cdot \\Vert_g$group LASSO$\\Vert w^{(g)}\\Vert_g = \\sqrt{\\sum_{i=1}^{|w^{(g)}|}(w_i^{(g)})^2}$$2$</p>\n<h2 id=\"SSL\"><a href=\"#SSL\" class=\"headerlink\" title=\"SSL\"></a>SSL</h2><p>SSLweight</p>\n<h3 id=\"filterchannel\"><a href=\"#filterchannel\" class=\"headerlink\" title=\"filterchannel\"></a>filterchannel</h3><p>$W^{(l)}_{n_l,:,:,:}$$n$filter$W^{(l)}_{:, c_l, :,:}$weight$c$channelfilterchannel$l$weightfilter$0$feature map$0$filterchannel$R(W)$</p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_n \\sum_{l=1}^{L}(\\sum_{n_l=1}^{N_l}\\Vert W^{(l)}_{n_l,:,:,:}\\Vert_g) + \\lambda_c\\sum_{l=1}^{L}(\\sum_{cl=1}^{C_l}\\Vert W^{(l)}_{:,c_l,:,:}\\Vert_g)</script><h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><p>filterfilter$0$</p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_s \\sum_{l=1}^{L}(\\sum_{c_l=1}^{C_l}\\sum_{m_l=1}^{M_l}\\sum_{k_l=1}^{K_l})\\Vert W^{(l)}_{:,c_l,m_l,k_l} \\Vert_g</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<script type=\"math/tex; mode=display\">E(W) = E_D(W) + \\lambda_d \\sum_{l=1}^{L}\\Vert W^{(l)}\\Vert_g</script><p>layerResNetshort-cutSSLlayerfilterfeature map</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h4 id=\"2D-filter-sparsity\"><a href=\"#2D-filter-sparsity\" class=\"headerlink\" title=\"2D filter sparsity\"></a>2D filter sparsity</h4><p>3D2Dspatialchannel2Dfilter$W^{(l)}_{n_l,c_l,:,:}$groupgroup LASSOfilter-wisechannel-wise</p>\n<h4 id=\"filter-wiseshape-wiseGEMM\"><a href=\"#filter-wiseshape-wiseGEMM\" class=\"headerlink\" title=\"filter-wiseshape-wiseGEMM\"></a>filter-wiseshape-wiseGEMM</h4><p>Caffe3Dtensorreshape$N<em>l$filter2D$W^{(l)}</em>{:,c_l,m_l,k_l}$shape sparsityGEMM</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MNISTCIFAR10ImageNetbaselineSSL</p>\n<h3 id=\"LeNet-amp-MLP-MNIST\"><a href=\"#LeNet-amp-MLP-MNIST\" class=\"headerlink\" title=\"LeNet&amp;MLP@MNIST\"></a>LeNet&amp;MLP@MNIST</h3><p>CaffeLeNetMLP</p>\n<h4 id=\"LeNet\"><a href=\"#LeNet\" class=\"headerlink\" title=\"LeNet\"></a>LeNet</h4><p>SSLfilter-wisechannel-wisefilterLeNet-1baseline23($0.1%$)filterchannelFLOP<br><img src=\"/img/paper-ssldnn-lenet-penalizing-unimportant-filter-channel.png\" alt=\"1\"></p>\n<p><code>conv1</code>filterLeNet2filter<br><img src=\"/img/paper-ssldnn-experiment-on-lenet.png\" alt=\"LeNet\"></p>"},{"title":" - SqueezeNet, AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size","date":"2018-03-24T06:02:53.000Z","_content":"[SqueezeNet](https://arxiv.org/abs/1602.07360)HanSongAlexNet$50$ImageNetcomparableaccuracyHanSoingDeep CompressionsizeSqueezeNet\n\n<!-- more -->\n## \n\n- serverserver\n- app\n- FPGARAM\n\n\n\nSVDDeep CompressionGoogLeNetInception module*Xception*XceptionXception\n\nSqueezeNetAlexNet$50$ImageNetcomparableCNNarchmodel sizeaccuracy*CNN microarch**CNN macroarch*layerCNNlayer\n\n*PS: SqueezeNetCNN*\n\n## SqueezeNet\n*SNet*SNet*Fire*moduleCONV layer$K \\times K \\times M \\times N$$K$filterspatial size$M$$N$feature mapactivationchannel sizeSNet\n- $3\\times 3$$1\\times 1$$K$\n- $3\\times 3$filterfeature mapchannel$M$\n- delayed downsampleactivationfeature mapaccuracyCNNdownsampleCONV layerpooling layerstride$1$\n\n> Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.\n\n### Fire Module\nFire ModuleSNet*squeeze*$1\\times 1$channel squeeze*expand*$1\\times 1$$3\\times 3$mix$s\\_{1 x 1}$$e\\_{1x1}$$e\\_{3x3}$squeezeexpandchannel$s\\_{1x1} < e\\_{1x1} + e\\_{3x3}$2.\n![Fire Module](/img/paper-squeezenet-fire-module.png)\n\nPyTorchSNetFireCONVReLU\n``` py\nclass Fire(nn.Module):\n    def __init__(self, inplanes, squeeze_planes,\n                 expand1x1_planes, expand3x3_planes):\n        super(Fire, self).__init__()\n        self.inplanes = inplanes\n        ## squeeze \n        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n        self.squeeze_activation = nn.ReLU(inplace=True)\n        ## expand 1x1 \n        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n                                   kernel_size=1)\n        self.expand1x1_activation = nn.ReLU(inplace=True)\n        ## expand 3x3\n        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n                                   kernel_size=3, padding=1)\n        self.expand3x3_activation = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.squeeze_activation(self.squeeze(x))\n        ## expand 1x13x3cat\n        return torch.cat([\n            self.expand1x1_activation(self.expand1x1(x)),\n            self.expand3x3_activation(self.expand3x3(x))], 1)\n```\n\n### SNet\nFire ModuleSNet`conv1` layer$8$Fire Module`conv10` layer`conv1``fire4`, `fire8``conv10``stride=2`MAX Pooling layerpooling$3$Fire ModuleResNetbypassSNet\n![SNet](/img/paper-squeezenet-macroarch.png)\n\n\n- $1\\times 1$$3\\times 3$spatial size$3\\times 3$`padding=1`\n- squeeze layerexpand layerReLU\n- `fire 9`drop ratio$0.5$Dropout layer\n- NINSNetfc\n- GitHub[repo](https://github.com/DeepScale/SqueezeNet)\n\nPyTorchv1.0v1.1v1.1v1.0\n\n> SqueezeNet v1.1 (in this repo), which requires 2.4x less computation than SqueezeNet v1.0 without diminshing accuracy.\n\n``` py\nclass SqueezeNet(nn.Module):\n    def __init__(self, version=1.0, num_classes=1000):\n        super(SqueezeNet, self).__init__()\n        if version not in [1.0, 1.1]:\n            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n                             \"1.0 or 1.1 expected\".format(version=version))\n        self.num_classes = num_classes\n        if version == 1.0:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(96, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                Fire(128, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 32, 128, 128),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(512, 64, 256, 256),\n            )\n        else:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(64, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(128, 32, 128, 128),\n                Fire(256, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                Fire(512, 64, 256, 256),\n            )\n        # Final convolution is initialized differently form the rest\n        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.5),\n            final_conv,\n            nn.ReLU(inplace=True),\n            nn.AvgPool2d(13, stride=1)\n)\n```\n\n## \nSNetAlexNetDeep CompressionImageNetSNetAlexNet$50$accuracySNet$0.5$MAlexNet$500+$\n![](/img/paper-squeezenet-benchmark.png)\n\nHanSongDeep Compression+codebookCPU/GPUEIE$8$[Ristretto](http://lepsucd.com/?page_id=630)SNet\n\n## Micro Arch\nCNNMicro Archfilterkernel sizeSNetfilter$s\\_{1x1}$$e\\_{1x1}$$e\\_{3x3}$$8$Fire Module$24$\n\n$base_e$Fire Moduleexpand layerfilter$freq$Fire Module$incr_e$Fire Moduleexpand layer filter$e_i = base_e + (incr_e \\times \\lfloor \\frac{i}{freq}\\rfloor)$\n\nexpand layer$e\\_i = e\\_{i,1x1} + e\\_{i,3x3}$$pct\\_{3x3} = e\\_{i,3x3}/e\\_i$$3\\times 3$conv\n\n$SR = s\\_{i,1x1} / e\\_i$squeezeexpand filter\n\n### SR\n$SR$$[0.125, 1]$accuracy$SR$size$SR$$0.75$$1.0$accuracypublishSNet$SR=0.125$\n![SR](/img/paper-squeeze-sr-impact.png)\n\n### 1X13x3pct\n$3\\times 3$$1\\times 1$expand layer$pct$$[0.01, 0.99]$accuracymodel size$pct$$0.5$accuracy\n![pct](/img/paper-squeezenet-pct-impact.png)\n\n## Macro Arch\nResNetbypass\n![bypass](/img/paper-squeezenet-bypass.png)","source":"_posts/paper-squeezenet.md","raw":"---\ntitle:  - SqueezeNet, AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\ndate: 2018-03-24 14:02:53\ntags:\n    - paper\n    - deep learning\n    - model compression\n---\n[SqueezeNet](https://arxiv.org/abs/1602.07360)HanSongAlexNet$50$ImageNetcomparableaccuracyHanSoingDeep CompressionsizeSqueezeNet\n\n<!-- more -->\n## \n\n- serverserver\n- app\n- FPGARAM\n\n\n\nSVDDeep CompressionGoogLeNetInception module*Xception*XceptionXception\n\nSqueezeNetAlexNet$50$ImageNetcomparableCNNarchmodel sizeaccuracy*CNN microarch**CNN macroarch*layerCNNlayer\n\n*PS: SqueezeNetCNN*\n\n## SqueezeNet\n*SNet*SNet*Fire*moduleCONV layer$K \\times K \\times M \\times N$$K$filterspatial size$M$$N$feature mapactivationchannel sizeSNet\n- $3\\times 3$$1\\times 1$$K$\n- $3\\times 3$filterfeature mapchannel$M$\n- delayed downsampleactivationfeature mapaccuracyCNNdownsampleCONV layerpooling layerstride$1$\n\n> Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.\n\n### Fire Module\nFire ModuleSNet*squeeze*$1\\times 1$channel squeeze*expand*$1\\times 1$$3\\times 3$mix$s\\_{1 x 1}$$e\\_{1x1}$$e\\_{3x3}$squeezeexpandchannel$s\\_{1x1} < e\\_{1x1} + e\\_{3x3}$2.\n![Fire Module](/img/paper-squeezenet-fire-module.png)\n\nPyTorchSNetFireCONVReLU\n``` py\nclass Fire(nn.Module):\n    def __init__(self, inplanes, squeeze_planes,\n                 expand1x1_planes, expand3x3_planes):\n        super(Fire, self).__init__()\n        self.inplanes = inplanes\n        ## squeeze \n        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n        self.squeeze_activation = nn.ReLU(inplace=True)\n        ## expand 1x1 \n        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n                                   kernel_size=1)\n        self.expand1x1_activation = nn.ReLU(inplace=True)\n        ## expand 3x3\n        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n                                   kernel_size=3, padding=1)\n        self.expand3x3_activation = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.squeeze_activation(self.squeeze(x))\n        ## expand 1x13x3cat\n        return torch.cat([\n            self.expand1x1_activation(self.expand1x1(x)),\n            self.expand3x3_activation(self.expand3x3(x))], 1)\n```\n\n### SNet\nFire ModuleSNet`conv1` layer$8$Fire Module`conv10` layer`conv1``fire4`, `fire8``conv10``stride=2`MAX Pooling layerpooling$3$Fire ModuleResNetbypassSNet\n![SNet](/img/paper-squeezenet-macroarch.png)\n\n\n- $1\\times 1$$3\\times 3$spatial size$3\\times 3$`padding=1`\n- squeeze layerexpand layerReLU\n- `fire 9`drop ratio$0.5$Dropout layer\n- NINSNetfc\n- GitHub[repo](https://github.com/DeepScale/SqueezeNet)\n\nPyTorchv1.0v1.1v1.1v1.0\n\n> SqueezeNet v1.1 (in this repo), which requires 2.4x less computation than SqueezeNet v1.0 without diminshing accuracy.\n\n``` py\nclass SqueezeNet(nn.Module):\n    def __init__(self, version=1.0, num_classes=1000):\n        super(SqueezeNet, self).__init__()\n        if version not in [1.0, 1.1]:\n            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n                             \"1.0 or 1.1 expected\".format(version=version))\n        self.num_classes = num_classes\n        if version == 1.0:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(96, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                Fire(128, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 32, 128, 128),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(512, 64, 256, 256),\n            )\n        else:\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(64, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(128, 32, 128, 128),\n                Fire(256, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                Fire(512, 64, 256, 256),\n            )\n        # Final convolution is initialized differently form the rest\n        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=0.5),\n            final_conv,\n            nn.ReLU(inplace=True),\n            nn.AvgPool2d(13, stride=1)\n)\n```\n\n## \nSNetAlexNetDeep CompressionImageNetSNetAlexNet$50$accuracySNet$0.5$MAlexNet$500+$\n![](/img/paper-squeezenet-benchmark.png)\n\nHanSongDeep Compression+codebookCPU/GPUEIE$8$[Ristretto](http://lepsucd.com/?page_id=630)SNet\n\n## Micro Arch\nCNNMicro Archfilterkernel sizeSNetfilter$s\\_{1x1}$$e\\_{1x1}$$e\\_{3x3}$$8$Fire Module$24$\n\n$base_e$Fire Moduleexpand layerfilter$freq$Fire Module$incr_e$Fire Moduleexpand layer filter$e_i = base_e + (incr_e \\times \\lfloor \\frac{i}{freq}\\rfloor)$\n\nexpand layer$e\\_i = e\\_{i,1x1} + e\\_{i,3x3}$$pct\\_{3x3} = e\\_{i,3x3}/e\\_i$$3\\times 3$conv\n\n$SR = s\\_{i,1x1} / e\\_i$squeezeexpand filter\n\n### SR\n$SR$$[0.125, 1]$accuracy$SR$size$SR$$0.75$$1.0$accuracypublishSNet$SR=0.125$\n![SR](/img/paper-squeeze-sr-impact.png)\n\n### 1X13x3pct\n$3\\times 3$$1\\times 1$expand layer$pct$$[0.01, 0.99]$accuracymodel size$pct$$0.5$accuracy\n![pct](/img/paper-squeezenet-pct-impact.png)\n\n## Macro Arch\nResNetbypass\n![bypass](/img/paper-squeezenet-bypass.png)","slug":"paper-squeezenet","published":1,"updated":"2018-10-27T07:16:52.408Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nf0035ae7b7o3qxr04","content":"<p><a href=\"https://arxiv.org/abs/1602.07360\" target=\"_blank\" rel=\"external\">SqueezeNet</a>HanSongAlexNet$50$ImageNetcomparableaccuracyHanSoingDeep CompressionsizeSqueezeNet</p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>serverserver</li>\n<li>app</li>\n<li>FPGARAM</li>\n</ul>\n<p></p>\n<p>SVDDeep CompressionGoogLeNetInception module<em>Xception</em>XceptionXception</p>\n<p>SqueezeNetAlexNet$50$ImageNetcomparableCNNarchmodel sizeaccuracy<em>CNN microarch</em><em>CNN macroarch</em>layerCNNlayer</p>\n<p><em>PS: SqueezeNetCNN</em></p>\n<h2 id=\"SqueezeNet\"><a href=\"#SqueezeNet\" class=\"headerlink\" title=\"SqueezeNet\"></a>SqueezeNet</h2><p><em>SNet</em>SNet<em>Fire</em>moduleCONV layer$K \\times K \\times M \\times N$$K$filterspatial size$M$$N$feature mapactivationchannel sizeSNet</p>\n<ul>\n<li>$3\\times 3$$1\\times 1$$K$</li>\n<li>$3\\times 3$filterfeature mapchannel$M$</li>\n<li>delayed downsampleactivationfeature mapaccuracyCNNdownsampleCONV layerpooling layerstride$1$</li>\n</ul>\n<blockquote>\n<p>Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.</p>\n</blockquote>\n<h3 id=\"Fire-Module\"><a href=\"#Fire-Module\" class=\"headerlink\" title=\"Fire Module\"></a>Fire Module</h3><p>Fire ModuleSNet<em>squeeze</em>$1\\times 1$channel squeeze<em>expand</em>$1\\times 1$$3\\times 3$mix$s_{1 x 1}$$e_{1x1}$$e_{3x3}$squeezeexpandchannel$s_{1x1} &lt; e_{1x1} + e_{3x3}$2.<br><img src=\"/img/paper-squeezenet-fire-module.png\" alt=\"Fire Module\"></p>\n<p>PyTorchSNetFireCONVReLU<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Fire</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, inplanes, squeeze_planes,</span></span></div><div class=\"line\">                 expand1x1_planes, expand3x3_planes):</div><div class=\"line\">        super(Fire, self).__init__()</div><div class=\"line\">        self.inplanes = inplanes</div><div class=\"line\">        <span class=\"comment\">## squeeze </span></div><div class=\"line\">        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.squeeze_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\">        <span class=\"comment\">## expand 1x1 </span></div><div class=\"line\">        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,</div><div class=\"line\">                                   kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.expand1x1_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\">        <span class=\"comment\">## expand 3x3</span></div><div class=\"line\">        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,</div><div class=\"line\">                                   kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.expand3x3_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = self.squeeze_activation(self.squeeze(x))</div><div class=\"line\">        <span class=\"comment\">## expand 1x13x3cat</span></div><div class=\"line\">        <span class=\"keyword\">return</span> torch.cat([</div><div class=\"line\">            self.expand1x1_activation(self.expand1x1(x)),</div><div class=\"line\">            self.expand3x3_activation(self.expand3x3(x))], <span class=\"number\">1</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"SNet\"><a href=\"#SNet\" class=\"headerlink\" title=\"SNet\"></a>SNet</h3><p>Fire ModuleSNet<code>conv1</code> layer$8$Fire Module<code>conv10</code> layer<code>conv1</code><code>fire4</code>, <code>fire8</code><code>conv10</code><code>stride=2</code>MAX Pooling layerpooling$3$Fire ModuleResNetbypassSNet<br><img src=\"/img/paper-squeezenet-macroarch.png\" alt=\"SNet\"></p>\n<p></p>\n<ul>\n<li>$1\\times 1$$3\\times 3$spatial size$3\\times 3$<code>padding=1</code></li>\n<li>squeeze layerexpand layerReLU</li>\n<li><code>fire 9</code>drop ratio$0.5$Dropout layer</li>\n<li>NINSNetfc</li>\n<li>GitHub<a href=\"https://github.com/DeepScale/SqueezeNet\" target=\"_blank\" rel=\"external\">repo</a></li>\n</ul>\n<p>PyTorchv1.0v1.1v1.1v1.0</p>\n<blockquote>\n<p>SqueezeNet v1.1 (in this repo), which requires 2.4x less computation than SqueezeNet v1.0 without diminshing accuracy.</p>\n</blockquote>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SqueezeNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, version=<span class=\"number\">1.0</span>, num_classes=<span class=\"number\">1000</span>)</span>:</span></div><div class=\"line\">        super(SqueezeNet, self).__init__()</div><div class=\"line\">        <span class=\"keyword\">if</span> version <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">1.0</span>, <span class=\"number\">1.1</span>]:</div><div class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">\"Unsupported SqueezeNet version &#123;version&#125;:\"</span></div><div class=\"line\">                             <span class=\"string\">\"1.0 or 1.1 expected\"</span>.format(version=version))</div><div class=\"line\">        self.num_classes = num_classes</div><div class=\"line\">        <span class=\"keyword\">if</span> version == <span class=\"number\">1.0</span>:</div><div class=\"line\">            self.features = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">96</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>),</div><div class=\"line\">                nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">96</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">512</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">            )</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            self.features = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),</div><div class=\"line\">                nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">64</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">                Fire(<span class=\"number\">512</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">            )</div><div class=\"line\">        <span class=\"comment\"># Final convolution is initialized differently form the rest</span></div><div class=\"line\">        final_conv = nn.Conv2d(<span class=\"number\">512</span>, self.num_classes, kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.classifier = nn.Sequential(</div><div class=\"line\">            nn.Dropout(p=<span class=\"number\">0.5</span>),</div><div class=\"line\">            final_conv,</div><div class=\"line\">            nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">            nn.AvgPool2d(<span class=\"number\">13</span>, stride=<span class=\"number\">1</span>)</div><div class=\"line\">)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SNetAlexNetDeep CompressionImageNetSNetAlexNet$50$accuracySNet$0.5$MAlexNet$500+$<br><img src=\"/img/paper-squeezenet-benchmark.png\" alt=\"\"></p>\n<p>HanSongDeep Compression+codebookCPU/GPUEIE$8$<a href=\"http://lepsucd.com/?page_id=630\" target=\"_blank\" rel=\"external\">Ristretto</a>SNet</p>\n<h2 id=\"Micro-Arch\"><a href=\"#Micro-Arch\" class=\"headerlink\" title=\"Micro Arch\"></a>Micro Arch</h2><p>CNNMicro Archfilterkernel sizeSNetfilter$s_{1x1}$$e_{1x1}$$e_{3x3}$$8$Fire Module$24$</p>\n<p>$base_e$Fire Moduleexpand layerfilter$freq$Fire Module$incr_e$Fire Moduleexpand layer filter$e_i = base_e + (incr_e \\times \\lfloor \\frac{i}{freq}\\rfloor)$</p>\n<p>expand layer$e_i = e_{i,1x1} + e_{i,3x3}$$pct_{3x3} = e_{i,3x3}/e_i$$3\\times 3$conv</p>\n<p>$SR = s_{i,1x1} / e_i$squeezeexpand filter</p>\n<h3 id=\"SR\"><a href=\"#SR\" class=\"headerlink\" title=\"SR\"></a>SR</h3><p>$SR$$[0.125, 1]$accuracy$SR$size$SR$$0.75$$1.0$accuracypublishSNet$SR=0.125$<br><img src=\"/img/paper-squeeze-sr-impact.png\" alt=\"SR\"></p>\n<h3 id=\"1X13x3pct\"><a href=\"#1X13x3pct\" class=\"headerlink\" title=\"1X13x3pct\"></a>1X13x3pct</h3><p>$3\\times 3$$1\\times 1$expand layer$pct$$[0.01, 0.99]$accuracymodel size$pct$$0.5$accuracy<br><img src=\"/img/paper-squeezenet-pct-impact.png\" alt=\"pct\"></p>\n<h2 id=\"Macro-Arch\"><a href=\"#Macro-Arch\" class=\"headerlink\" title=\"Macro Arch\"></a>Macro Arch</h2><p>ResNetbypass<br><img src=\"/img/paper-squeezenet-bypass.png\" alt=\"bypass\"></p>\n","excerpt":"<p><a href=\"https://arxiv.org/abs/1602.07360\">SqueezeNet</a>HanSongAlexNet$50$ImageNetcomparableaccuracyHanSoingDeep CompressionsizeSqueezeNet</p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>serverserver</li>\n<li>app</li>\n<li>FPGARAM</li>\n</ul>\n<p></p>\n<p>SVDDeep CompressionGoogLeNetInception module<em>Xception</em>XceptionXception</p>\n<p>SqueezeNetAlexNet$50$ImageNetcomparableCNNarchmodel sizeaccuracy<em>CNN microarch</em><em>CNN macroarch</em>layerCNNlayer</p>\n<p><em>PS: SqueezeNetCNN</em></p>\n<h2 id=\"SqueezeNet\"><a href=\"#SqueezeNet\" class=\"headerlink\" title=\"SqueezeNet\"></a>SqueezeNet</h2><p><em>SNet</em>SNet<em>Fire</em>moduleCONV layer$K \\times K \\times M \\times N$$K$filterspatial size$M$$N$feature mapactivationchannel sizeSNet</p>\n<ul>\n<li>$3\\times 3$$1\\times 1$$K$</li>\n<li>$3\\times 3$filterfeature mapchannel$M$</li>\n<li>delayed downsampleactivationfeature mapaccuracyCNNdownsampleCONV layerpooling layerstride$1$</li>\n</ul>\n<blockquote>\n<p>Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.</p>\n</blockquote>\n<h3 id=\"Fire-Module\"><a href=\"#Fire-Module\" class=\"headerlink\" title=\"Fire Module\"></a>Fire Module</h3><p>Fire ModuleSNet<em>squeeze</em>$1\\times 1$channel squeeze<em>expand</em>$1\\times 1$$3\\times 3$mix$s_{1 x 1}$$e_{1x1}$$e_{3x3}$squeezeexpandchannel$s_{1x1} &lt; e_{1x1} + e_{3x3}$2.<br><img src=\"/img/paper-squeezenet-fire-module.png\" alt=\"Fire Module\"></p>\n<p>PyTorchSNetFireCONVReLU<br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Fire</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, inplanes, squeeze_planes,</div><div class=\"line\">                 expand1x1_planes, expand3x3_planes)</span>:</span></div><div class=\"line\">        super(Fire, self).__init__()</div><div class=\"line\">        self.inplanes = inplanes</div><div class=\"line\">        <span class=\"comment\">## squeeze </span></div><div class=\"line\">        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.squeeze_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\">        <span class=\"comment\">## expand 1x1 </span></div><div class=\"line\">        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,</div><div class=\"line\">                                   kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.expand1x1_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\">        <span class=\"comment\">## expand 3x3</span></div><div class=\"line\">        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,</div><div class=\"line\">                                   kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</div><div class=\"line\">        self.expand3x3_activation = nn.ReLU(inplace=<span class=\"keyword\">True</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = self.squeeze_activation(self.squeeze(x))</div><div class=\"line\">        <span class=\"comment\">## expand 1x13x3cat</span></div><div class=\"line\">        <span class=\"keyword\">return</span> torch.cat([</div><div class=\"line\">            self.expand1x1_activation(self.expand1x1(x)),</div><div class=\"line\">            self.expand3x3_activation(self.expand3x3(x))], <span class=\"number\">1</span>)</div></pre></td></tr></table></figure></p>\n<h3 id=\"SNet\"><a href=\"#SNet\" class=\"headerlink\" title=\"SNet\"></a>SNet</h3><p>Fire ModuleSNet<code>conv1</code> layer$8$Fire Module<code>conv10</code> layer<code>conv1</code><code>fire4</code>, <code>fire8</code><code>conv10</code><code>stride=2</code>MAX Pooling layerpooling$3$Fire ModuleResNetbypassSNet<br><img src=\"/img/paper-squeezenet-macroarch.png\" alt=\"SNet\"></p>\n<p></p>\n<ul>\n<li>$1\\times 1$$3\\times 3$spatial size$3\\times 3$<code>padding=1</code></li>\n<li>squeeze layerexpand layerReLU</li>\n<li><code>fire 9</code>drop ratio$0.5$Dropout layer</li>\n<li>NINSNetfc</li>\n<li>GitHub<a href=\"https://github.com/DeepScale/SqueezeNet\">repo</a></li>\n</ul>\n<p>PyTorchv1.0v1.1v1.1v1.0</p>\n<blockquote>\n<p>SqueezeNet v1.1 (in this repo), which requires 2.4x less computation than SqueezeNet v1.0 without diminshing accuracy.</p>\n</blockquote>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SqueezeNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, version=<span class=\"number\">1.0</span>, num_classes=<span class=\"number\">1000</span>)</span>:</span></div><div class=\"line\">        super(SqueezeNet, self).__init__()</div><div class=\"line\">        <span class=\"keyword\">if</span> version <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> [<span class=\"number\">1.0</span>, <span class=\"number\">1.1</span>]:</div><div class=\"line\">            <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">\"Unsupported SqueezeNet version &#123;version&#125;:\"</span></div><div class=\"line\">                             <span class=\"string\">\"1.0 or 1.1 expected\"</span>.format(version=version))</div><div class=\"line\">        self.num_classes = num_classes</div><div class=\"line\">        <span class=\"keyword\">if</span> version == <span class=\"number\">1.0</span>:</div><div class=\"line\">            self.features = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">96</span>, kernel_size=<span class=\"number\">7</span>, stride=<span class=\"number\">2</span>),</div><div class=\"line\">                nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">96</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">512</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">            )</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            self.features = nn.Sequential(</div><div class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>),</div><div class=\"line\">                nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">64</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>, <span class=\"number\">64</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">128</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">32</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>),</div><div class=\"line\">                nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, ceil_mode=<span class=\"keyword\">True</span>),</div><div class=\"line\">                Fire(<span class=\"number\">256</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">48</span>, <span class=\"number\">192</span>, <span class=\"number\">192</span>),</div><div class=\"line\">                Fire(<span class=\"number\">384</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">                Fire(<span class=\"number\">512</span>, <span class=\"number\">64</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>),</div><div class=\"line\">            )</div><div class=\"line\">        <span class=\"comment\"># Final convolution is initialized differently form the rest</span></div><div class=\"line\">        final_conv = nn.Conv2d(<span class=\"number\">512</span>, self.num_classes, kernel_size=<span class=\"number\">1</span>)</div><div class=\"line\">        self.classifier = nn.Sequential(</div><div class=\"line\">            nn.Dropout(p=<span class=\"number\">0.5</span>),</div><div class=\"line\">            final_conv,</div><div class=\"line\">            nn.ReLU(inplace=<span class=\"keyword\">True</span>),</div><div class=\"line\">            nn.AvgPool2d(<span class=\"number\">13</span>, stride=<span class=\"number\">1</span>)</div><div class=\"line\">)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SNetAlexNetDeep CompressionImageNetSNetAlexNet$50$accuracySNet$0.5$MAlexNet$500+$<br><img src=\"/img/paper-squeezenet-benchmark.png\" alt=\"\"></p>\n<p>HanSongDeep Compression+codebookCPU/GPUEIE$8$<a href=\"http://lepsucd.com/?page_id=630\">Ristretto</a>SNet</p>\n<h2 id=\"Micro-Arch\"><a href=\"#Micro-Arch\" class=\"headerlink\" title=\"Micro Arch\"></a>Micro Arch</h2><p>CNNMicro Archfilterkernel sizeSNetfilter$s_{1x1}$$e_{1x1}$$e_{3x3}$$8$Fire Module$24$</p>\n<p>$base_e$Fire Moduleexpand layerfilter$freq$Fire Module$incr_e$Fire Moduleexpand layer filter$e_i = base_e + (incr_e \\times \\lfloor \\frac{i}{freq}\\rfloor)$</p>\n<p>expand layer$e_i = e_{i,1x1} + e_{i,3x3}$$pct_{3x3} = e_{i,3x3}/e_i$$3\\times 3$conv</p>\n<p>$SR = s_{i,1x1} / e_i$squeezeexpand filter</p>\n<h3 id=\"SR\"><a href=\"#SR\" class=\"headerlink\" title=\"SR\"></a>SR</h3><p>$SR$$[0.125, 1]$accuracy$SR$size$SR$$0.75$$1.0$accuracypublishSNet$SR=0.125$<br><img src=\"/img/paper-squeeze-sr-impact.png\" alt=\"SR\"></p>\n<h3 id=\"1X13x3pct\"><a href=\"#1X13x3pct\" class=\"headerlink\" title=\"1X13x3pct\"></a>1X13x3pct</h3><p>$3\\times 3$$1\\times 1$expand layer$pct$$[0.01, 0.99]$accuracymodel size$pct$$0.5$accuracy<br><img src=\"/img/paper-squeezenet-pct-impact.png\" alt=\"pct\"></p>\n<h2 id=\"Macro-Arch\"><a href=\"#Macro-Arch\" class=\"headerlink\" title=\"Macro Arch\"></a>Macro Arch</h2><p>ResNetbypass<br><img src=\"/img/paper-squeezenet-bypass.png\" alt=\"bypass\"></p>"},{"title":" - Rethinking The Value of Network Pruning","date":"2018-10-22T14:25:42.000Z","_content":"[](https://openreview.net/forum?id=rJlnB3C5Ym)ICLR 2019[ -  Model Pruning](https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/)\n\nDLDLAlexNetinceptionGlobal PoolingResNetsizefine tune\n\n[Eric-mingjie/rethinking-network-pruning](https://github.com/Eric-mingjie/rethinking-network-pruning)\n\n<!-- more -->\n\n## FLOP\nPyTorchFLOPs[compute_flops.py](https://github.com/Eric-mingjie/rethinking-network-pruning/blob/master/imagenet/l1-norm-pruning/compute_flops.py)\n\n## ThiNet\n\n## \n\n## \n\n\n1. ImageNet/CIFAR\n  - prune\n  - prune ImageNet\n  - prunework\n\n2. prunepruneABwork\n\n3. /pruneECCV 2018HanSongHe YihuiAMC\n\n\"\"\n","source":"_posts/paper-rethinking-the-value-of-network-pruning.md","raw":"---\ntitle:  - Rethinking The Value of Network Pruning \ndate: 2018-10-22 22:25:42\ntags:\n    - deep learning\n    - model compression\n    - paper\n---\n[](https://openreview.net/forum?id=rJlnB3C5Ym)ICLR 2019[ -  Model Pruning](https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/)\n\nDLDLAlexNetinceptionGlobal PoolingResNetsizefine tune\n\n[Eric-mingjie/rethinking-network-pruning](https://github.com/Eric-mingjie/rethinking-network-pruning)\n\n<!-- more -->\n\n## FLOP\nPyTorchFLOPs[compute_flops.py](https://github.com/Eric-mingjie/rethinking-network-pruning/blob/master/imagenet/l1-norm-pruning/compute_flops.py)\n\n## ThiNet\n\n## \n\n## \n\n\n1. ImageNet/CIFAR\n  - prune\n  - prune ImageNet\n  - prunework\n\n2. prunepruneABwork\n\n3. /pruneECCV 2018HanSongHe YihuiAMC\n\n\"\"\n","slug":"paper-rethinking-the-value-of-network-pruning","published":1,"updated":"2018-10-27T07:16:52.407Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ni0037ae7beh04md2o","content":"<p><a href=\"https://openreview.net/forum?id=rJlnB3C5Ym\" target=\"_blank\" rel=\"external\"></a>ICLR 2019<a href=\"https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/\"> -  Model Pruning</a></p>\n<p>DLDLAlexNetinceptionGlobal PoolingResNetsizefine tune</p>\n<p><a href=\"https://github.com/Eric-mingjie/rethinking-network-pruning\" target=\"_blank\" rel=\"external\">Eric-mingjie/rethinking-network-pruning</a></p>\n<a id=\"more\"></a>\n<h2 id=\"FLOP\"><a href=\"#FLOP\" class=\"headerlink\" title=\"FLOP\"></a>FLOP</h2><p>PyTorchFLOPs<a href=\"https://github.com/Eric-mingjie/rethinking-network-pruning/blob/master/imagenet/l1-norm-pruning/compute_flops.py\" target=\"_blank\" rel=\"external\">compute_flops.py</a></p>\n<h2 id=\"ThiNet\"><a href=\"#ThiNet\" class=\"headerlink\" title=\"ThiNet\"></a>ThiNet</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ol>\n<li><p>ImageNet/CIFAR</p>\n<ul>\n<li>prune</li>\n<li>prune ImageNet</li>\n<li>prunework</li>\n</ul>\n</li>\n<li><p>prunepruneABwork</p>\n</li>\n<li><p>/pruneECCV 2018HanSongHe YihuiAMC</p>\n</li>\n</ol>\n<p></p>\n","excerpt":"<p><a href=\"https://openreview.net/forum?id=rJlnB3C5Ym\"></a>ICLR 2019<a href=\"https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/\"> -  Model Pruning</a></p>\n<p>DLDLAlexNetinceptionGlobal PoolingResNetsizefine tune</p>\n<p><a href=\"https://github.com/Eric-mingjie/rethinking-network-pruning\">Eric-mingjie/rethinking-network-pruning</a></p>","more":"<h2 id=\"FLOP\"><a href=\"#FLOP\" class=\"headerlink\" title=\"FLOP\"></a>FLOP</h2><p>PyTorchFLOPs<a href=\"https://github.com/Eric-mingjie/rethinking-network-pruning/blob/master/imagenet/l1-norm-pruning/compute_flops.py\">compute_flops.py</a></p>\n<h2 id=\"ThiNet\"><a href=\"#ThiNet\" class=\"headerlink\" title=\"ThiNet\"></a>ThiNet</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ol>\n<li><p>ImageNet/CIFAR</p>\n<ul>\n<li>prune</li>\n<li>prune ImageNet</li>\n<li>prunework</li>\n</ul>\n</li>\n<li><p>prunepruneABwork</p>\n</li>\n<li><p>/pruneECCV 2018HanSongHe YihuiAMC</p>\n</li>\n</ol>\n<p></p>"},{"title":" -  Model Pruning","date":"2018-10-03T08:31:07.000Z","_content":"\n\n![](/img/paper-summary-model-pruning-joke.jpg)\n\n<!--more -->\n## Deep Compression, Han Song\nLeCun90HanSongNIPS 2015[Learning both weights and connections for efficient neural network](https://arxiv.org/abs/1506.02626)[](https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/)\n\nL1 normneuronmetrictrain -> pruning -> retrainiteratively pruningEIEGPUCPU\n\n## SSLWenWei\nGPU/CPUConvfilterfilterlayerWenWei[Learning Structured Sparsity in Deep Neural Networks](https://arxiv.org/abs/1608.03665)NIPS 2016LASSO[](https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/)\n\nLASSO\n\n## L1-norm Filter PruningLi Hao\nGPU/CPUFilterICLR 2017[Pruning Filters for Efficient ConvNets](https://arxiv.org/abs/1608.08710)filter\n\nFilterL1 normfilterfilterfine tunelayersensitivity$i$layer$j$filterfeature map$j$channelBNConvchannel\n\nResNetblockconvchannelidentityindex$\\mathcal{F}(x)$conv\n\nImageNetsensitivity analysislayer\n\n![sensitivity](/img/paper-model-pruning-filter-pruning-sensitivity-results.png)\n\n\n## Automated Gradual Pruning, Gupta\nNIPS 2017workshop[To prune, or not to prune: exploring the efficacy of pruning for model compression](https://arxiv.org/abs/1710.01878)TensorFlowrepo[Model pruning: Training tensorflow models to have masked connections](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/model_pruning)Yes\n\n![](/img/paper-model-pruning-why-so-baixue.jpg)\n\nlargeprunelarge-sparsememory footprintcompact-smallCNNstacked LSTM, seq-to-seq LSTM\n\npruningimportancesparsity\n\n$$s_t = s_f + (s_i-s_f)(1-\\frac{t-t_0}{n\\Delta t})^3 \\quad \\text{for}\\quad t \\in \\{t_0, t_0+\\Delta t,\\dots,t_0+n\\Delta t\\}$$\n\n$s_i$$0$$s_f$$t_0$$\\Delta t$$n$\n\n## Net Sliming, Liu Zhuang & Huang Gao\n[Learning Efficient Convolutional Networks through Network Slimming](https://arxiv.org/abs/1708.06519)ICCV 2017CNNBNgammalayerchannelDenseNet[liuzhuang13/slimming](https://github.com/liuzhuang13/slimming)\n\nBNgammaconvfeature mapchannelconvfilter\n\nBNgammaL1 $L= \\sum\\_{(x,y)}l(f(x, W), y) + \\lambda \\sum\\_{\\gamma \\in \\Gamma}g(\\gamma)$\n\ngammagammachannelfilterfinetune\n![Net Sliming](/img/paper-model-pruning-net-sliming-procedure.png)\n\nResNetDenseNet Feature map\"channel selection layer\"feature mapmaskchannel[channel selection layer](https://github.com/Eric-mingjie/network-slimming/blob/master/models/channel_selection.py#L6)\n\n``` py\nclass channel_selection(nn.Module):\n    \"\"\"\n    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n    \"\"\"\n    def __init__(self, num_channels):\n        \"\"\"\n        Initialize the `indexes` with all one vector with the length same as the number of channels.\n        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n        \"\"\"\n        super(channel_selection, self).__init__()\n        self.indexes = nn.Parameter(torch.ones(num_channels))\n\n    def forward(self, input_tensor):\n        \"\"\"\n        Parameter\n        ---------\n        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n        \"\"\"\n        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n        if selected_index.size == 1:\n            selected_index = np.resize(selected_index, (1,))\n        output = input_tensor[:, selected_index, :, :]\n        return output\n```\n\nL1gammaidentityindex$0$maskchannel\n\n## AutoPruner, Wu Jianxin\n[AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference](https://arxiv.org/abs/1805.08941)Wu JianxinArvixThiNet[ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression](https://arxiv.org/abs/1707.06342)ICCV 2017\n\n$i$ConvFeature mapBatch-wise Pooling -> FC -> scaled sigmoidchannel$[0,1]$maskFeature mapmaskchannelFCmask$i$Convfilterscaled sigmoid$y = \\sigma(\\alpha x)$$\\alpha$sigmoid$0-1$\n![AutoPruner](/img/paper-summary-autopruner-arch.png)\n\n$\\mathcal{L} = \\mathcal{L}\\_{\\text{cross-entropy}} + \\lambda \\Vert \\frac{\\Vert v \\Vert\\_1}{C} - r \\Vert\\_2^2$$v$sigmoidmask$C$channel$r$\n\nFC\n- FC$0$$10\\sqrt{\\frac{2}{n}}$$n = C\\times H \\times W$\n- $\\alpha$$\\alpha$if-else\n- $\\lambda$$\\lambda = 100 \\vert r\\_b - r\\vert$\n\n![AutoPruner Alg](/img/paper-summary-model-compression-autopruner-alg.png)\n\n## Rethinking Net Pruning, \n[Rethinking the Value of Network Pruning](https://openreview.net/pdf?id=rJlnB3C5Ym)ICLR 2019model pruningdissHe Yihui\n\n\n1. \n2. weightaccuracy\n\ncheckSOAfinetunerandomperformance\n1. over parametermodelefficient\n2. important\n3. weight\n\n\n1. over-parameter\n2. finetune\n\n\n\ndiss~\n\nNet SlimingLiu ZhuangHuang Gao\n\n## \n- [Distiller](https://nervanasystems.github.io/distiller/index.html)PyTorch\n\n","source":"_posts/paper-summary-model-pruning.md","raw":"---\ntitle:  -  Model Pruning\ndate: 2018-10-03 16:31:07\ntags:\n    - paper\n    - deep learning\n    - model compression\n---\n\n\n![](/img/paper-summary-model-pruning-joke.jpg)\n\n<!--more -->\n## Deep Compression, Han Song\nLeCun90HanSongNIPS 2015[Learning both weights and connections for efficient neural network](https://arxiv.org/abs/1506.02626)[](https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/)\n\nL1 normneuronmetrictrain -> pruning -> retrainiteratively pruningEIEGPUCPU\n\n## SSLWenWei\nGPU/CPUConvfilterfilterlayerWenWei[Learning Structured Sparsity in Deep Neural Networks](https://arxiv.org/abs/1608.03665)NIPS 2016LASSO[](https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/)\n\nLASSO\n\n## L1-norm Filter PruningLi Hao\nGPU/CPUFilterICLR 2017[Pruning Filters for Efficient ConvNets](https://arxiv.org/abs/1608.08710)filter\n\nFilterL1 normfilterfilterfine tunelayersensitivity$i$layer$j$filterfeature map$j$channelBNConvchannel\n\nResNetblockconvchannelidentityindex$\\mathcal{F}(x)$conv\n\nImageNetsensitivity analysislayer\n\n![sensitivity](/img/paper-model-pruning-filter-pruning-sensitivity-results.png)\n\n\n## Automated Gradual Pruning, Gupta\nNIPS 2017workshop[To prune, or not to prune: exploring the efficacy of pruning for model compression](https://arxiv.org/abs/1710.01878)TensorFlowrepo[Model pruning: Training tensorflow models to have masked connections](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/model_pruning)Yes\n\n![](/img/paper-model-pruning-why-so-baixue.jpg)\n\nlargeprunelarge-sparsememory footprintcompact-smallCNNstacked LSTM, seq-to-seq LSTM\n\npruningimportancesparsity\n\n$$s_t = s_f + (s_i-s_f)(1-\\frac{t-t_0}{n\\Delta t})^3 \\quad \\text{for}\\quad t \\in \\{t_0, t_0+\\Delta t,\\dots,t_0+n\\Delta t\\}$$\n\n$s_i$$0$$s_f$$t_0$$\\Delta t$$n$\n\n## Net Sliming, Liu Zhuang & Huang Gao\n[Learning Efficient Convolutional Networks through Network Slimming](https://arxiv.org/abs/1708.06519)ICCV 2017CNNBNgammalayerchannelDenseNet[liuzhuang13/slimming](https://github.com/liuzhuang13/slimming)\n\nBNgammaconvfeature mapchannelconvfilter\n\nBNgammaL1 $L= \\sum\\_{(x,y)}l(f(x, W), y) + \\lambda \\sum\\_{\\gamma \\in \\Gamma}g(\\gamma)$\n\ngammagammachannelfilterfinetune\n![Net Sliming](/img/paper-model-pruning-net-sliming-procedure.png)\n\nResNetDenseNet Feature map\"channel selection layer\"feature mapmaskchannel[channel selection layer](https://github.com/Eric-mingjie/network-slimming/blob/master/models/channel_selection.py#L6)\n\n``` py\nclass channel_selection(nn.Module):\n    \"\"\"\n    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n    \"\"\"\n    def __init__(self, num_channels):\n        \"\"\"\n        Initialize the `indexes` with all one vector with the length same as the number of channels.\n        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n        \"\"\"\n        super(channel_selection, self).__init__()\n        self.indexes = nn.Parameter(torch.ones(num_channels))\n\n    def forward(self, input_tensor):\n        \"\"\"\n        Parameter\n        ---------\n        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n        \"\"\"\n        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n        if selected_index.size == 1:\n            selected_index = np.resize(selected_index, (1,))\n        output = input_tensor[:, selected_index, :, :]\n        return output\n```\n\nL1gammaidentityindex$0$maskchannel\n\n## AutoPruner, Wu Jianxin\n[AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference](https://arxiv.org/abs/1805.08941)Wu JianxinArvixThiNet[ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression](https://arxiv.org/abs/1707.06342)ICCV 2017\n\n$i$ConvFeature mapBatch-wise Pooling -> FC -> scaled sigmoidchannel$[0,1]$maskFeature mapmaskchannelFCmask$i$Convfilterscaled sigmoid$y = \\sigma(\\alpha x)$$\\alpha$sigmoid$0-1$\n![AutoPruner](/img/paper-summary-autopruner-arch.png)\n\n$\\mathcal{L} = \\mathcal{L}\\_{\\text{cross-entropy}} + \\lambda \\Vert \\frac{\\Vert v \\Vert\\_1}{C} - r \\Vert\\_2^2$$v$sigmoidmask$C$channel$r$\n\nFC\n- FC$0$$10\\sqrt{\\frac{2}{n}}$$n = C\\times H \\times W$\n- $\\alpha$$\\alpha$if-else\n- $\\lambda$$\\lambda = 100 \\vert r\\_b - r\\vert$\n\n![AutoPruner Alg](/img/paper-summary-model-compression-autopruner-alg.png)\n\n## Rethinking Net Pruning, \n[Rethinking the Value of Network Pruning](https://openreview.net/pdf?id=rJlnB3C5Ym)ICLR 2019model pruningdissHe Yihui\n\n\n1. \n2. weightaccuracy\n\ncheckSOAfinetunerandomperformance\n1. over parametermodelefficient\n2. important\n3. weight\n\n\n1. over-parameter\n2. finetune\n\n\n\ndiss~\n\nNet SlimingLiu ZhuangHuang Gao\n\n## \n- [Distiller](https://nervanasystems.github.io/distiller/index.html)PyTorch\n\n","slug":"paper-summary-model-pruning","published":1,"updated":"2018-10-27T07:16:52.410Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nm0039ae7bt3ify52z","content":"<p></p>\n<p><img src=\"/img/paper-summary-model-pruning-joke.jpg\" alt=\"\"></p>\n<a id=\"more\"></a>\n<h2 id=\"Deep-Compression-Han-Song\"><a href=\"#Deep-Compression-Han-Song\" class=\"headerlink\" title=\"Deep Compression, Han Song\"></a>Deep Compression, Han Song</h2><p>LeCun90HanSongNIPS 2015<a href=\"https://arxiv.org/abs/1506.02626\" target=\"_blank\" rel=\"external\">Learning both weights and connections for efficient neural network</a><a href=\"https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/\"></a></p>\n<p>L1 normneuronmetrictrain -&gt; pruning -&gt; retrainiteratively pruningEIEGPUCPU</p>\n<h2 id=\"SSLWenWei\"><a href=\"#SSLWenWei\" class=\"headerlink\" title=\"SSLWenWei\"></a>SSLWenWei</h2><p>GPU/CPUConvfilterfilterlayerWenWei<a href=\"https://arxiv.org/abs/1608.03665\" target=\"_blank\" rel=\"external\">Learning Structured Sparsity in Deep Neural Networks</a>NIPS 2016LASSO<a href=\"https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/\"></a></p>\n<p>LASSO</p>\n<h2 id=\"L1-norm-Filter-PruningLi-Hao\"><a href=\"#L1-norm-Filter-PruningLi-Hao\" class=\"headerlink\" title=\"L1-norm Filter PruningLi Hao\"></a>L1-norm Filter PruningLi Hao</h2><p>GPU/CPUFilterICLR 2017<a href=\"https://arxiv.org/abs/1608.08710\" target=\"_blank\" rel=\"external\">Pruning Filters for Efficient ConvNets</a>filter</p>\n<p>FilterL1 normfilterfilterfine tunelayersensitivity$i$layer$j$filterfeature map$j$channelBNConvchannel</p>\n<p>ResNetblockconvchannelidentityindex$\\mathcal{F}(x)$conv</p>\n<p>ImageNetsensitivity analysislayer</p>\n<p><img src=\"/img/paper-model-pruning-filter-pruning-sensitivity-results.png\" alt=\"sensitivity\"></p>\n<h2 id=\"Automated-Gradual-Pruning-Gupta\"><a href=\"#Automated-Gradual-Pruning-Gupta\" class=\"headerlink\" title=\"Automated Gradual Pruning, Gupta\"></a>Automated Gradual Pruning, Gupta</h2><p>NIPS 2017workshop<a href=\"https://arxiv.org/abs/1710.01878\" target=\"_blank\" rel=\"external\">To prune, or not to prune: exploring the efficacy of pruning for model compression</a>TensorFlowrepo<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/model_pruning\" target=\"_blank\" rel=\"external\">Model pruning: Training tensorflow models to have masked connections</a>Yes</p>\n<p><img src=\"/img/paper-model-pruning-why-so-baixue.jpg\" alt=\"\"></p>\n<p>largeprunelarge-sparsememory footprintcompact-smallCNNstacked LSTM, seq-to-seq LSTM</p>\n<p>pruningimportancesparsity</p>\n<script type=\"math/tex; mode=display\">s_t = s_f + (s_i-s_f)(1-\\frac{t-t_0}{n\\Delta t})^3 \\quad \\text{for}\\quad t \\in \\{t_0, t_0+\\Delta t,\\dots,t_0+n\\Delta t\\}</script><p>$s_i$$0$$s_f$$t_0$$\\Delta t$$n$</p>\n<h2 id=\"Net-Sliming-Liu-Zhuang-amp-Huang-Gao\"><a href=\"#Net-Sliming-Liu-Zhuang-amp-Huang-Gao\" class=\"headerlink\" title=\"Net Sliming, Liu Zhuang &amp; Huang Gao\"></a>Net Sliming, Liu Zhuang &amp; Huang Gao</h2><p><a href=\"https://arxiv.org/abs/1708.06519\" target=\"_blank\" rel=\"external\">Learning Efficient Convolutional Networks through Network Slimming</a>ICCV 2017CNNBNgammalayerchannelDenseNet<a href=\"https://github.com/liuzhuang13/slimming\" target=\"_blank\" rel=\"external\">liuzhuang13/slimming</a></p>\n<p>BNgammaconvfeature mapchannelconvfilter</p>\n<p>BNgammaL1 $L= \\sum_{(x,y)}l(f(x, W), y) + \\lambda \\sum_{\\gamma \\in \\Gamma}g(\\gamma)$</p>\n<p>gammagammachannelfilterfinetune<br><img src=\"/img/paper-model-pruning-net-sliming-procedure.png\" alt=\"Net Sliming\"></p>\n<p>ResNetDenseNet Feature mapchannel selection layerfeature mapmaskchannel<a href=\"https://github.com/Eric-mingjie/network-slimming/blob/master/models/channel_selection.py#L6\" target=\"_blank\" rel=\"external\">channel selection layer</a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">channel_selection</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"</span></div><div class=\"line\">    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.</div><div class=\"line\">    The output shape of this layer is determined by the number of 1 in `self.indexes`.</div><div class=\"line\">    \"\"\"</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, num_channels)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\"</span></div><div class=\"line\">        Initialize the `indexes` with all one vector with the length same as the number of channels.</div><div class=\"line\">        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.</div><div class=\"line\">        \"\"\"</div><div class=\"line\">        super(channel_selection, self).__init__()</div><div class=\"line\">        self.indexes = nn.Parameter(torch.ones(num_channels))</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, input_tensor)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\"</span></div><div class=\"line\">        Parameter</div><div class=\"line\">        ---------</div><div class=\"line\">        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.</div><div class=\"line\">        \"\"\"</div><div class=\"line\">        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))</div><div class=\"line\">        <span class=\"keyword\">if</span> selected_index.size == <span class=\"number\">1</span>:</div><div class=\"line\">            selected_index = np.resize(selected_index, (<span class=\"number\">1</span>,))</div><div class=\"line\">        output = input_tensor[:, selected_index, :, :]</div><div class=\"line\">        <span class=\"keyword\">return</span> output</div></pre></td></tr></table></figure>\n<p>L1gammaidentityindex$0$maskchannel</p>\n<h2 id=\"AutoPruner-Wu-Jianxin\"><a href=\"#AutoPruner-Wu-Jianxin\" class=\"headerlink\" title=\"AutoPruner, Wu Jianxin\"></a>AutoPruner, Wu Jianxin</h2><p><a href=\"https://arxiv.org/abs/1805.08941\" target=\"_blank\" rel=\"external\">AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference</a>Wu JianxinArvixThiNet<a href=\"https://arxiv.org/abs/1707.06342\" target=\"_blank\" rel=\"external\">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression</a>ICCV 2017</p>\n<p>$i$ConvFeature mapBatch-wise Pooling -&gt; FC -&gt; scaled sigmoidchannel$[0,1]$maskFeature mapmaskchannelFCmask$i$Convfilterscaled sigmoid$y = \\sigma(\\alpha x)$$\\alpha$sigmoid$0-1$<br><img src=\"/img/paper-summary-autopruner-arch.png\" alt=\"AutoPruner\"></p>\n<p>$\\mathcal{L} = \\mathcal{L}_{\\text{cross-entropy}} + \\lambda \\Vert \\frac{\\Vert v \\Vert_1}{C} - r \\Vert_2^2$$v$sigmoidmask$C$channel$r$</p>\n<p>FC</p>\n<ul>\n<li>FC$0$$10\\sqrt{\\frac{2}{n}}$$n = C\\times H \\times W$</li>\n<li>$\\alpha$$\\alpha$if-else</li>\n<li>$\\lambda$$\\lambda = 100 \\vert r_b - r\\vert$</li>\n</ul>\n<p><img src=\"/img/paper-summary-model-compression-autopruner-alg.png\" alt=\"AutoPruner Alg\"></p>\n<h2 id=\"Rethinking-Net-Pruning-\"><a href=\"#Rethinking-Net-Pruning-\" class=\"headerlink\" title=\"Rethinking Net Pruning, \"></a>Rethinking Net Pruning, </h2><p><a href=\"https://openreview.net/pdf?id=rJlnB3C5Ym\" target=\"_blank\" rel=\"external\">Rethinking the Value of Network Pruning</a>ICLR 2019model pruningdissHe Yihui</p>\n<p></p>\n<ol>\n<li></li>\n<li>weightaccuracy</li>\n</ol>\n<p>checkSOAfinetunerandomperformance</p>\n<ol>\n<li>over parametermodelefficient</li>\n<li>important</li>\n<li>weight</li>\n</ol>\n<p></p>\n<ol>\n<li>over-parameter</li>\n<li>finetune</li>\n</ol>\n<p></p>\n<p>diss~</p>\n<p>Net SlimingLiu ZhuangHuang Gao</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"https://nervanasystems.github.io/distiller/index.html\" target=\"_blank\" rel=\"external\">Distiller</a>PyTorch</li>\n</ul>\n","excerpt":"<p></p>\n<p><img src=\"/img/paper-summary-model-pruning-joke.jpg\" alt=\"\"></p>","more":"<h2 id=\"Deep-Compression-Han-Song\"><a href=\"#Deep-Compression-Han-Song\" class=\"headerlink\" title=\"Deep Compression, Han Song\"></a>Deep Compression, Han Song</h2><p>LeCun90HanSongNIPS 2015<a href=\"https://arxiv.org/abs/1506.02626\">Learning both weights and connections for efficient neural network</a><a href=\"https://xmfbit.github.io/2018/03/14/paper-network-prune-hansong/\"></a></p>\n<p>L1 normneuronmetrictrain -&gt; pruning -&gt; retrainiteratively pruningEIEGPUCPU</p>\n<h2 id=\"SSLWenWei\"><a href=\"#SSLWenWei\" class=\"headerlink\" title=\"SSLWenWei\"></a>SSLWenWei</h2><p>GPU/CPUConvfilterfilterlayerWenWei<a href=\"https://arxiv.org/abs/1608.03665\">Learning Structured Sparsity in Deep Neural Networks</a>NIPS 2016LASSO<a href=\"https://xmfbit.github.io/2018/02/24/paper-ssl-dnn/\"></a></p>\n<p>LASSO</p>\n<h2 id=\"L1-norm-Filter-PruningLi-Hao\"><a href=\"#L1-norm-Filter-PruningLi-Hao\" class=\"headerlink\" title=\"L1-norm Filter PruningLi Hao\"></a>L1-norm Filter PruningLi Hao</h2><p>GPU/CPUFilterICLR 2017<a href=\"https://arxiv.org/abs/1608.08710\">Pruning Filters for Efficient ConvNets</a>filter</p>\n<p>FilterL1 normfilterfilterfine tunelayersensitivity$i$layer$j$filterfeature map$j$channelBNConvchannel</p>\n<p>ResNetblockconvchannelidentityindex$\\mathcal{F}(x)$conv</p>\n<p>ImageNetsensitivity analysislayer</p>\n<p><img src=\"/img/paper-model-pruning-filter-pruning-sensitivity-results.png\" alt=\"sensitivity\"></p>\n<h2 id=\"Automated-Gradual-Pruning-Gupta\"><a href=\"#Automated-Gradual-Pruning-Gupta\" class=\"headerlink\" title=\"Automated Gradual Pruning, Gupta\"></a>Automated Gradual Pruning, Gupta</h2><p>NIPS 2017workshop<a href=\"https://arxiv.org/abs/1710.01878\">To prune, or not to prune: exploring the efficacy of pruning for model compression</a>TensorFlowrepo<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/model_pruning\">Model pruning: Training tensorflow models to have masked connections</a>Yes</p>\n<p><img src=\"/img/paper-model-pruning-why-so-baixue.jpg\" alt=\"\"></p>\n<p>largeprunelarge-sparsememory footprintcompact-smallCNNstacked LSTM, seq-to-seq LSTM</p>\n<p>pruningimportancesparsity</p>\n<script type=\"math/tex; mode=display\">s_t = s_f + (s_i-s_f)(1-\\frac{t-t_0}{n\\Delta t})^3 \\quad \\text{for}\\quad t \\in \\{t_0, t_0+\\Delta t,\\dots,t_0+n\\Delta t\\}</script><p>$s_i$$0$$s_f$$t_0$$\\Delta t$$n$</p>\n<h2 id=\"Net-Sliming-Liu-Zhuang-amp-Huang-Gao\"><a href=\"#Net-Sliming-Liu-Zhuang-amp-Huang-Gao\" class=\"headerlink\" title=\"Net Sliming, Liu Zhuang &amp; Huang Gao\"></a>Net Sliming, Liu Zhuang &amp; Huang Gao</h2><p><a href=\"https://arxiv.org/abs/1708.06519\">Learning Efficient Convolutional Networks through Network Slimming</a>ICCV 2017CNNBNgammalayerchannelDenseNet<a href=\"https://github.com/liuzhuang13/slimming\">liuzhuang13/slimming</a></p>\n<p>BNgammaconvfeature mapchannelconvfilter</p>\n<p>BNgammaL1 $L= \\sum_{(x,y)}l(f(x, W), y) + \\lambda \\sum_{\\gamma \\in \\Gamma}g(\\gamma)$</p>\n<p>gammagammachannelfilterfinetune<br><img src=\"/img/paper-model-pruning-net-sliming-procedure.png\" alt=\"Net Sliming\"></p>\n<p>ResNetDenseNet Feature mapchannel selection layerfeature mapmaskchannel<a href=\"https://github.com/Eric-mingjie/network-slimming/blob/master/models/channel_selection.py#L6\">channel selection layer</a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">channel_selection</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"</div><div class=\"line\">    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.</div><div class=\"line\">    The output shape of this layer is determined by the number of 1 in `self.indexes`.</div><div class=\"line\">    \"\"\"</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, num_channels)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\"</div><div class=\"line\">        Initialize the `indexes` with all one vector with the length same as the number of channels.</div><div class=\"line\">        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.</div><div class=\"line\">        \"\"\"</span></div><div class=\"line\">        super(channel_selection, self).__init__()</div><div class=\"line\">        self.indexes = nn.Parameter(torch.ones(num_channels))</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, input_tensor)</span>:</span></div><div class=\"line\">        <span class=\"string\">\"\"\"</div><div class=\"line\">        Parameter</div><div class=\"line\">        ---------</div><div class=\"line\">        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.</div><div class=\"line\">        \"\"\"</span></div><div class=\"line\">        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))</div><div class=\"line\">        <span class=\"keyword\">if</span> selected_index.size == <span class=\"number\">1</span>:</div><div class=\"line\">            selected_index = np.resize(selected_index, (<span class=\"number\">1</span>,))</div><div class=\"line\">        output = input_tensor[:, selected_index, :, :]</div><div class=\"line\">        <span class=\"keyword\">return</span> output</div></pre></td></tr></table></figure>\n<p>L1gammaidentityindex$0$maskchannel</p>\n<h2 id=\"AutoPruner-Wu-Jianxin\"><a href=\"#AutoPruner-Wu-Jianxin\" class=\"headerlink\" title=\"AutoPruner, Wu Jianxin\"></a>AutoPruner, Wu Jianxin</h2><p><a href=\"https://arxiv.org/abs/1805.08941\">AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference</a>Wu JianxinArvixThiNet<a href=\"https://arxiv.org/abs/1707.06342\">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression</a>ICCV 2017</p>\n<p>$i$ConvFeature mapBatch-wise Pooling -&gt; FC -&gt; scaled sigmoidchannel$[0,1]$maskFeature mapmaskchannelFCmask$i$Convfilterscaled sigmoid$y = \\sigma(\\alpha x)$$\\alpha$sigmoid$0-1$<br><img src=\"/img/paper-summary-autopruner-arch.png\" alt=\"AutoPruner\"></p>\n<p>$\\mathcal{L} = \\mathcal{L}_{\\text{cross-entropy}} + \\lambda \\Vert \\frac{\\Vert v \\Vert_1}{C} - r \\Vert_2^2$$v$sigmoidmask$C$channel$r$</p>\n<p>FC</p>\n<ul>\n<li>FC$0$$10\\sqrt{\\frac{2}{n}}$$n = C\\times H \\times W$</li>\n<li>$\\alpha$$\\alpha$if-else</li>\n<li>$\\lambda$$\\lambda = 100 \\vert r_b - r\\vert$</li>\n</ul>\n<p><img src=\"/img/paper-summary-model-compression-autopruner-alg.png\" alt=\"AutoPruner Alg\"></p>\n<h2 id=\"Rethinking-Net-Pruning-\"><a href=\"#Rethinking-Net-Pruning-\" class=\"headerlink\" title=\"Rethinking Net Pruning, \"></a>Rethinking Net Pruning, </h2><p><a href=\"https://openreview.net/pdf?id=rJlnB3C5Ym\">Rethinking the Value of Network Pruning</a>ICLR 2019model pruningdissHe Yihui</p>\n<p></p>\n<ol>\n<li></li>\n<li>weightaccuracy</li>\n</ol>\n<p>checkSOAfinetunerandomperformance</p>\n<ol>\n<li>over parametermodelefficient</li>\n<li>important</li>\n<li>weight</li>\n</ol>\n<p></p>\n<ol>\n<li>over-parameter</li>\n<li>finetune</li>\n</ol>\n<p></p>\n<p>diss~</p>\n<p>Net SlimingLiu ZhuangHuang Gao</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"https://nervanasystems.github.io/distiller/index.html\">Distiller</a>PyTorch</li>\n</ul>"},{"title":" - Xception, Deep Learning with Depthwise separable Convolution","date":"2018-03-22T01:44:38.000Z","_content":"MobileNet, ShuffleMet**depthwise separable conv**[Xception: Deep Learning with Depthwise separable Convolution](https://arxiv.org/abs/1610.02357)\n<!-- more -->\n\n## \nAlexNetDNNZFNet->VGGNet->GoogLeNet->ResNetGoogLeNetInceptionInceptionVGGmoduleInception V3Inception\n![Inception](/img/paper-xception-inception-module.png)\n\nCONV$3D$filterspatial dimensionwidthheightchannel dimensionfilter$3$\n```\n// ifilter\n// (x, y)\nsum = 0\nfor c in 1:C\n  for h in 1:K\n    for w in 1:K\n      sum += in[c, y-K/2+h, x-K/2+w] * filter_i[c, h, w]\nout[i, y, x] = sum\n```\n\n$3D$channelspatial\n\nInception$1\\times 1$channel(cross-channel correlation)channel dimension$3\\sim 4$$4$`concat`$3\\times 3$$5\\times 5$\n\nInceptionworkchannelspatial\n\n## Inception\nInceptionAVE Pooling\n![Inception](/img/paper-xception-simplified-inception-module.png)\n\n$3$$1\\times 1$$1\\times 1$channelschannelgroup$3\\times 3$$3$\n![](/img/paper-xception-equivalent-inception-module.png)\n\ngroup number = channel number\n![](/img/paper-xception-extreme-version.png)\n\n\n## Depthwise Separable Conv\n**depthwise separable conv**group convspatial dimension$1\\times 1$cross channel*pointwise conv*\n\n- TensorFlowdepthwise separable convchannelwisefilterspatial dimension$1\\times 1$channelInception$1\\times 1$\n- InceptionconvReLUdepthwise separable conv\n\nblock\n![](/img/paper-xception-experiment-intermediate-activation.png)\n\n## Xception\ncross channelspatial****\n\n> we make the following hypothesis: that the mapping of cross-channels correlations and spatial correlations in the feature maps of convolutional neural networks can be *entirely* decoupled. \n\nXceptionResNetdepthwise separable convEntryMiddleExit\n\n> The Xception architecture: the data first goes through the entry flow, then through the middle flow which is repeated eight times, and finally through the exit flow. Note that all Convolution and SeparableConvolution layers are followed by batch normalization [7] (not included in the diagram). All SeparableConvolution layers use a depth multiplier of 1 (no depth expansion).\n\n![Xception](/img/paper-xception-arch.png)\n","source":"_posts/paper-xception.md","raw":"---\ntitle:  - Xception, Deep Learning with Depthwise separable Convolution\ndate: 2018-03-22 09:44:38\ntags:\n    - paper\n    - deep learning\n    - model compression\n---\nMobileNet, ShuffleMet**depthwise separable conv**[Xception: Deep Learning with Depthwise separable Convolution](https://arxiv.org/abs/1610.02357)\n<!-- more -->\n\n## \nAlexNetDNNZFNet->VGGNet->GoogLeNet->ResNetGoogLeNetInceptionInceptionVGGmoduleInception V3Inception\n![Inception](/img/paper-xception-inception-module.png)\n\nCONV$3D$filterspatial dimensionwidthheightchannel dimensionfilter$3$\n```\n// ifilter\n// (x, y)\nsum = 0\nfor c in 1:C\n  for h in 1:K\n    for w in 1:K\n      sum += in[c, y-K/2+h, x-K/2+w] * filter_i[c, h, w]\nout[i, y, x] = sum\n```\n\n$3D$channelspatial\n\nInception$1\\times 1$channel(cross-channel correlation)channel dimension$3\\sim 4$$4$`concat`$3\\times 3$$5\\times 5$\n\nInceptionworkchannelspatial\n\n## Inception\nInceptionAVE Pooling\n![Inception](/img/paper-xception-simplified-inception-module.png)\n\n$3$$1\\times 1$$1\\times 1$channelschannelgroup$3\\times 3$$3$\n![](/img/paper-xception-equivalent-inception-module.png)\n\ngroup number = channel number\n![](/img/paper-xception-extreme-version.png)\n\n\n## Depthwise Separable Conv\n**depthwise separable conv**group convspatial dimension$1\\times 1$cross channel*pointwise conv*\n\n- TensorFlowdepthwise separable convchannelwisefilterspatial dimension$1\\times 1$channelInception$1\\times 1$\n- InceptionconvReLUdepthwise separable conv\n\nblock\n![](/img/paper-xception-experiment-intermediate-activation.png)\n\n## Xception\ncross channelspatial****\n\n> we make the following hypothesis: that the mapping of cross-channels correlations and spatial correlations in the feature maps of convolutional neural networks can be *entirely* decoupled. \n\nXceptionResNetdepthwise separable convEntryMiddleExit\n\n> The Xception architecture: the data first goes through the entry flow, then through the middle flow which is repeated eight times, and finally through the exit flow. Note that all Convolution and SeparableConvolution layers are followed by batch normalization [7] (not included in the diagram). All SeparableConvolution layers use a depth multiplier of 1 (no depth expansion).\n\n![Xception](/img/paper-xception-arch.png)\n","slug":"paper-xception","published":1,"updated":"2018-10-27T07:16:52.411Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8np003cae7b7rgm79pn","content":"<p>MobileNet, ShuffleMet<strong>depthwise separable conv</strong><a href=\"https://arxiv.org/abs/1610.02357\" target=\"_blank\" rel=\"external\">Xception: Deep Learning with Depthwise separable Convolution</a><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>AlexNetDNNZFNet-&gt;VGGNet-&gt;GoogLeNet-&gt;ResNetGoogLeNetInceptionInceptionVGGmoduleInception V3Inception<br><img src=\"/img/paper-xception-inception-module.png\" alt=\"Inception\"></p>\n<p>CONV$3D$filterspatial dimensionwidthheightchannel dimensionfilter$3$<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">// ifilter</div><div class=\"line\">// (x, y)</div><div class=\"line\">sum = 0</div><div class=\"line\">for c in 1:C</div><div class=\"line\">  for h in 1:K</div><div class=\"line\">    for w in 1:K</div><div class=\"line\">      sum += in[c, y-K/2+h, x-K/2+w] * filter_i[c, h, w]</div><div class=\"line\">out[i, y, x] = sum</div></pre></td></tr></table></figure></p>\n<p>$3D$channelspatial</p>\n<p>Inception$1\\times 1$channel(cross-channel correlation)channel dimension$3\\sim 4$$4$<code>concat</code>$3\\times 3$$5\\times 5$</p>\n<p>Inceptionworkchannelspatial</p>\n<h2 id=\"Inception\"><a href=\"#Inception\" class=\"headerlink\" title=\"Inception\"></a>Inception</h2><p>InceptionAVE Pooling<br><img src=\"/img/paper-xception-simplified-inception-module.png\" alt=\"Inception\"></p>\n<p>$3$$1\\times 1$$1\\times 1$channelschannelgroup$3\\times 3$$3$<br><img src=\"/img/paper-xception-equivalent-inception-module.png\" alt=\"\"></p>\n<p>group number = channel number<br><img src=\"/img/paper-xception-extreme-version.png\" alt=\"\"></p>\n<h2 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h2><p><strong>depthwise separable conv</strong>group convspatial dimension$1\\times 1$cross channel<em>pointwise conv</em></p>\n<ul>\n<li>TensorFlowdepthwise separable convchannelwisefilterspatial dimension$1\\times 1$channelInception$1\\times 1$</li>\n<li>InceptionconvReLUdepthwise separable conv</li>\n</ul>\n<p>block<br><img src=\"/img/paper-xception-experiment-intermediate-activation.png\" alt=\"\"></p>\n<h2 id=\"Xception\"><a href=\"#Xception\" class=\"headerlink\" title=\"Xception\"></a>Xception</h2><p>cross channelspatial<strong></strong></p>\n<blockquote>\n<p>we make the following hypothesis: that the mapping of cross-channels correlations and spatial correlations in the feature maps of convolutional neural networks can be <em>entirely</em> decoupled. </p>\n</blockquote>\n<p>XceptionResNetdepthwise separable convEntryMiddleExit</p>\n<blockquote>\n<p>The Xception architecture: the data first goes through the entry flow, then through the middle flow which is repeated eight times, and finally through the exit flow. Note that all Convolution and SeparableConvolution layers are followed by batch normalization [7] (not included in the diagram). All SeparableConvolution layers use a depth multiplier of 1 (no depth expansion).</p>\n</blockquote>\n<p><img src=\"/img/paper-xception-arch.png\" alt=\"Xception\"></p>\n","excerpt":"<p>MobileNet, ShuffleMet<strong>depthwise separable conv</strong><a href=\"https://arxiv.org/abs/1610.02357\">Xception: Deep Learning with Depthwise separable Convolution</a><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>AlexNetDNNZFNet-&gt;VGGNet-&gt;GoogLeNet-&gt;ResNetGoogLeNetInceptionInceptionVGGmoduleInception V3Inception<br><img src=\"/img/paper-xception-inception-module.png\" alt=\"Inception\"></p>\n<p>CONV$3D$filterspatial dimensionwidthheightchannel dimensionfilter$3$<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">// ifilter</div><div class=\"line\">// (x, y)</div><div class=\"line\">sum = 0</div><div class=\"line\">for c in 1:C</div><div class=\"line\">  for h in 1:K</div><div class=\"line\">    for w in 1:K</div><div class=\"line\">      sum += in[c, y-K/2+h, x-K/2+w] * filter_i[c, h, w]</div><div class=\"line\">out[i, y, x] = sum</div></pre></td></tr></table></figure></p>\n<p>$3D$channelspatial</p>\n<p>Inception$1\\times 1$channel(cross-channel correlation)channel dimension$3\\sim 4$$4$<code>concat</code>$3\\times 3$$5\\times 5$</p>\n<p>Inceptionworkchannelspatial</p>\n<h2 id=\"Inception\"><a href=\"#Inception\" class=\"headerlink\" title=\"Inception\"></a>Inception</h2><p>InceptionAVE Pooling<br><img src=\"/img/paper-xception-simplified-inception-module.png\" alt=\"Inception\"></p>\n<p>$3$$1\\times 1$$1\\times 1$channelschannelgroup$3\\times 3$$3$<br><img src=\"/img/paper-xception-equivalent-inception-module.png\" alt=\"\"></p>\n<p>group number = channel number<br><img src=\"/img/paper-xception-extreme-version.png\" alt=\"\"></p>\n<h2 id=\"Depthwise-Separable-Conv\"><a href=\"#Depthwise-Separable-Conv\" class=\"headerlink\" title=\"Depthwise Separable Conv\"></a>Depthwise Separable Conv</h2><p><strong>depthwise separable conv</strong>group convspatial dimension$1\\times 1$cross channel<em>pointwise conv</em></p>\n<ul>\n<li>TensorFlowdepthwise separable convchannelwisefilterspatial dimension$1\\times 1$channelInception$1\\times 1$</li>\n<li>InceptionconvReLUdepthwise separable conv</li>\n</ul>\n<p>block<br><img src=\"/img/paper-xception-experiment-intermediate-activation.png\" alt=\"\"></p>\n<h2 id=\"Xception\"><a href=\"#Xception\" class=\"headerlink\" title=\"Xception\"></a>Xception</h2><p>cross channelspatial<strong></strong></p>\n<blockquote>\n<p>we make the following hypothesis: that the mapping of cross-channels correlations and spatial correlations in the feature maps of convolutional neural networks can be <em>entirely</em> decoupled. </p>\n</blockquote>\n<p>XceptionResNetdepthwise separable convEntryMiddleExit</p>\n<blockquote>\n<p>The Xception architecture: the data first goes through the entry flow, then through the middle flow which is repeated eight times, and finally through the exit flow. Note that all Convolution and SeparableConvolution layers are followed by batch normalization [7] (not included in the diagram). All SeparableConvolution layers use a depth multiplier of 1 (no depth expansion).</p>\n</blockquote>\n<p><img src=\"/img/paper-xception-arch.png\" alt=\"Xception\"></p>"},{"title":" - YOLO v3","date":"2018-04-01T08:48:45.000Z","_content":"YOLOV3[YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf)YOLO V3RetinaNet\n![YOLO v3RetinaNet](/img/paper-yolov3-comparison-retinanet.png)\n\nYOLO\n<!-- more -->\n\n## YOLO v3\nYOLO v3$320\\times 320$$22$msmAP$28.2$SSD$3$TitanXYOLO v3$51$ms$AP\\_{50}$$57.9$RetinaNet$198$ms$AP\\_{50}$$57.5$\n\n### psAP\nAPaverage precisiondetectionbounding boxground truthIoU$0.5$True PositiveFalse Positive\n\nprecisionTrue Positiverecallground truthclassificationIoUdetection\n\nprecisio vs recallAPCOCO`0.5:0.05:0.95`[COCO](http://cocodataset.org/#detections-eval)detectionAPmAP\n\n$0.5$AP$AP\\_{50}$YOLO v3$AP\\_{50}$bounding boxRetinaNetIoU$0.5$\n\n## Bounding Box\nv2anchor box$p_w$$p_h$$t_x$$t_y$$t_w$$t_h$YOLO$M\\times M$feature map$M \\times M$cellcellimagetop left corner$(c_x, c_y)$cellcellbounding box\n$$\\begin{aligned}b_x &= \\sigma(t_x) + c_x\\\\ b_y &= \\sigma(t_y) + c_y\\\\ b_w &= p_w e^{t_w}\\\\ b_h &= p_h e^{t_h}\\end{aligned}$$\n\nPSFasterRCNNYOLObounding box$b_w = p_w t_w^\\prime$$\\log(\\cdot)$\n\n$t_w^\\prime$$t_w^\\prime > 0$SGD\n\n![bounding box](/img/paper=yolov3-bbox-regression.png)\n\n\n\nYOLObounding boxobjectobjectslogisticbounding boxground truthIoUbounding boxtarget$1$bounding boxIoUIoU$0.5$Faster RCNNground truthbounding boxFaster RCNNbounding boxassignground truthclassobjectnessconfidence\n\n## \nsoftmaxlogisitcOpen Image Dataset`Woman``Person`\n\n## FPN\nYOLO[FPN](https://arxiv.org/abs/1612.03144)v3$3$COCO$3$$9$feature map$N\\times N\\times [3\\times (4+1+80)]$\n\nfeature mapupsample 2xfeature mapelement-widemergefeature mapconvfeature mapspatial dimension$2$\n\nfinal scale\n## \nv3`yolo`layer\n```\n[yolo]\nmask = 0,1,2\n## 9anchor9\nanchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\nclasses=20   ## VOC20\nnum=9\njitter=.3\nignore_thresh = .5\ntruth_thresh = 1\nrandom=1\n```\n\n`yolo_layer.c``forward`[]()activationv2softmaxsoftmax treelogistic\n``` cpp\nfor (b = 0; b < l.batch; ++b){\n    for(n = 0; n < l.n; ++n){\n        int index = entry_index(l, b, n*l.w*l.h, 0);\n        //  tx, tylogistic\n        activate_array(l.output + index, 2*l.w*l.h, LOGISTIC);\n        index = entry_index(l, b, n*l.w*l.h, 4);\n        // confidenceClogistic\n        activate_array(l.output + index, (1+l.classes)*l.w*l.h, LOGISTIC);\n    }\n}\n```\n\n\n``` cpp\nfor (j = 0; j < l.h; ++j) {\n    for (i = 0; i < l.w; ++i) {\n        for (n = 0; n < l.n; ++n) {\n            // bounding box\n            // IoUground truth\n            int box_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 0);\n            box pred = get_yolo_box(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.w*l.h);\n            float best_iou = 0;\n            int best_t = 0;\n            for(t = 0; t < l.max_boxes; ++t){\n                box truth = float_to_box(net.truth + t*(4 + 1) + b*l.truths, 1);\n                if(!truth.x) break;\n                float iou = box_iou(pred, truth);\n                if (iou > best_iou) {\n                    best_iou = iou;\n                    best_t = t;\n                }\n            }\n            int obj_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 4);\n            avg_anyobj += l.output[obj_index];\n            // \n            // ignore_thresh, \n            // ignore_threshtarget = 0\n            // diff = -gradient = target - output\n            // \n            l.delta[obj_index] = 0 - l.output[obj_index];\n            if (best_iou > l.ignore_thresh) {\n                l.delta[obj_index] = 0;\n            }\n            // truth_thresh?1\n            // iou1\n            if (best_iou > l.truth_thresh) {\n                // confidence target = 1\n                l.delta[obj_index] = 1 - l.output[obj_index];\n                int class = net.truth[best_t*(4 + 1) + b*l.truths + 4];\n                if (l.map) class = l.map[class];\n                int class_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 4 + 1);\n                // class\n                delta_yolo_class(l.output, l.delta, class_index, class, l.classes, l.w*l.h, 0);\n                box truth = float_to_box(net.truth + best_t*(4 + 1) + b*l.truths, 1);\n                // box\n                delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.delta, (2-truth.w*truth.h), l.w*l.h);\n            }\n        }\n    }\n}\n```\nconfidenceclassification`diff``target - output`logistic regressionlogistic$o = f(x;\\theta)$$\\theta$$y = h(o)$$h$logisticsigmoid\n$$\\begin{aligned}P(y=1|x) &= h(o)\\\\ P(y=0|x) &= 1-h(o)\\end{aligned}$$\n\n\n$$\\log L = \\sum y\\log h+(1-y)\\log(1-h)$$\n\nSGD\n$$J = -\\log L = \\sum -y\\log h-(1-y)\\log(1-h)$$\n\n$i$$o_i$\n$$\\begin{aligned}\\frac{\\partial J}{\\partial o_i} &= \\frac{\\partial J}{\\partial h_i}\\frac{\\partial h_i}{\\partial o_i}\\\\\n&= [-y_i/h_i-(y_i-1)/(1-h_i)] \\frac{\\partial h_i}{\\partial o_i} \\\\\n&= \\frac{h_i-y_i}{h_i(1-h_i)} \\frac{\\partial h_i}{\\partial o_i}\\end{aligned}$$\n\nlogistic\n$$\\frac{\\partial h_i}{\\partial o_i} = h_i(1-h_i)$$\n\n\n$$\\frac{\\partial J}{\\partial o_i} = h_i-y_i$$\n\n$h_i$logistic$y_i$targetYOLO`diff``-gradient``delta = target - output`\n\nlogistic[CS229 ](https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/)\n\n`delta_yolo_class``delta_yolo_box`\n``` cpp\n// classground truth\n// classes\n// indexfeature mapclass prediction\nvoid delta_yolo_class(float *output, float *delta, int index, \n  int class, int classes, int stride, float *avg_cat) {\n    int n;\n    // \n    if (delta[index]){\n        delta[index + stride*class] = 1 - output[index + stride*class];\n        if(avg_cat) *avg_cat += output[index + stride*class];\n        return;\n    }\n    for(n = 0; n < classes; ++n){\n        // diff = target - prediction\n        delta[index + stride*n] = ((n == class)?1 : 0) - output[index + stride*n];\n        if(n == class && avg_cat) *avg_cat += output[index + stride*n];\n    }\n}\n// box deltasquare error\nfloat delta_yolo_box(box truth, float *x, float *biases, int n, \n  int index, int i, int j, int lw, int lh, int w, int h, \n  float *delta, float scale, int stride) {\n    box pred = get_yolo_box(x, biases, n, index, i, j, lw, lh, w, h, stride);\n    float iou = box_iou(pred, truth);\n    float tx = (truth.x*lw - i);\n    float ty = (truth.y*lh - j);\n    float tw = log(truth.w*w / biases[2*n]);\n    float th = log(truth.h*h / biases[2*n + 1]);\n\n    delta[index + 0*stride] = scale * (tx - x[index + 0*stride]);\n    delta[index + 1*stride] = scale * (ty - x[index + 1*stride]);\n    delta[index + 2*stride] = scale * (tw - x[index + 2*stride]);\n    delta[index + 3*stride] = scale * (th - x[index + 3*stride]);\n    return iou;\n}\n```\npredictionbounding boxground truthIoU\n``` cpp\n// ground truth\nfor(t = 0; t < l.max_boxes; ++t){\n    box truth = float_to_box(net.truth + t*(4 + 1) + b*l.truths, 1);\n    if(!truth.x) break;\n    // ioubounding box\n    float best_iou = 0;\n    int best_n = 0;\n    i = (truth.x * l.w);\n    j = (truth.y * l.h);\n    box truth_shift = truth;\n    truth_shift.x = truth_shift.y = 0;\n    for(n = 0; n < l.total; ++n){\n        box pred = {0};\n        pred.w = l.biases[2*n]/net.w;\n        pred.h = l.biases[2*n+1]/net.h;\n        float iou = box_iou(pred, truth_shift);\n        if (iou > best_iou){\n            best_iou = iou;\n            best_n = n;\n        }\n    }\n    \n    int mask_n = int_index(l.mask, best_n, l.n);\n    if(mask_n >= 0){\n        int box_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 0);\n        float iou = delta_yolo_box(truth, l.output, l.biases, best_n, \n          box_index, i, j, l.w, l.h, net.w, net.h, l.delta, \n          (2-truth.w*truth.h), l.w*l.h);\n        int obj_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 4);\n        avg_obj += l.output[obj_index];\n        // objectness target = 1\n        l.delta[obj_index] = 1 - l.output[obj_index];\n        int class = net.truth[t*(4 + 1) + b*l.truths + 4];\n        if (l.map) class = l.map[class];\n        int class_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 4 + 1);\n        delta_yolo_class(l.output, l.delta, class_index, class, l.classes, l.w*l.h, &avg_cat);\n        ++count;\n        ++class_count;\n        if(iou > .5) recall += 1;\n        if(iou > .75) recall75 += 1;\n        avg_iou += iou;\n    }\n}\n```\n\n## Darknet\nResidualNet$3\\times 3$$1\\times 1$shortcutDarknet-53\n![darknet-63](/img/paper-yolov3-darknet53.png)\n\n## YOLO\nYOLO v3IoUYOLO\n\n> Russakovsky et al report that that humans have a hard time distinguishing an IOU of .3 from .5! Training humans to visually inspect a bounding box with IOU of 0.3 and distinguish it from one with IOU 0.5 is surprisingly difficult. [16] If humans have a hard time telling the difference, how much does it matter?\n\nv3mediumlarge\n\n\n![](/img/paper-yolov3-comparisons.png)\n\n## \n\n- anchor box$(x, y)$anchor boxoffsetno stable\n- offsetlogistic\n- focal loss\n- IoUFaster RCNN\n\n\n## \n\n- YOLO[Darknet YOLO](https://pjreddie.com/darknet/yolo/)\n- [paper](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n- [](https://zhuanlan.zhihu.com/p/34945787)\n- FPN[Feature pyramid networks for object detection](https://arxiv.org/abs/1612.03144)\n- [AP](https://www.zhihu.com/question/41540197)","source":"_posts/paper-yolov3.md","raw":"---\ntitle:  - YOLO v3\ndate: 2018-04-01 16:48:45\ntags:\n    - paper\n    - deep learning\n    - detection\n    - yolo\n---\nYOLOV3[YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf)YOLO V3RetinaNet\n![YOLO v3RetinaNet](/img/paper-yolov3-comparison-retinanet.png)\n\nYOLO\n<!-- more -->\n\n## YOLO v3\nYOLO v3$320\\times 320$$22$msmAP$28.2$SSD$3$TitanXYOLO v3$51$ms$AP\\_{50}$$57.9$RetinaNet$198$ms$AP\\_{50}$$57.5$\n\n### psAP\nAPaverage precisiondetectionbounding boxground truthIoU$0.5$True PositiveFalse Positive\n\nprecisionTrue Positiverecallground truthclassificationIoUdetection\n\nprecisio vs recallAPCOCO`0.5:0.05:0.95`[COCO](http://cocodataset.org/#detections-eval)detectionAPmAP\n\n$0.5$AP$AP\\_{50}$YOLO v3$AP\\_{50}$bounding boxRetinaNetIoU$0.5$\n\n## Bounding Box\nv2anchor box$p_w$$p_h$$t_x$$t_y$$t_w$$t_h$YOLO$M\\times M$feature map$M \\times M$cellcellimagetop left corner$(c_x, c_y)$cellcellbounding box\n$$\\begin{aligned}b_x &= \\sigma(t_x) + c_x\\\\ b_y &= \\sigma(t_y) + c_y\\\\ b_w &= p_w e^{t_w}\\\\ b_h &= p_h e^{t_h}\\end{aligned}$$\n\nPSFasterRCNNYOLObounding box$b_w = p_w t_w^\\prime$$\\log(\\cdot)$\n\n$t_w^\\prime$$t_w^\\prime > 0$SGD\n\n![bounding box](/img/paper=yolov3-bbox-regression.png)\n\n\n\nYOLObounding boxobjectobjectslogisticbounding boxground truthIoUbounding boxtarget$1$bounding boxIoUIoU$0.5$Faster RCNNground truthbounding boxFaster RCNNbounding boxassignground truthclassobjectnessconfidence\n\n## \nsoftmaxlogisitcOpen Image Dataset`Woman``Person`\n\n## FPN\nYOLO[FPN](https://arxiv.org/abs/1612.03144)v3$3$COCO$3$$9$feature map$N\\times N\\times [3\\times (4+1+80)]$\n\nfeature mapupsample 2xfeature mapelement-widemergefeature mapconvfeature mapspatial dimension$2$\n\nfinal scale\n## \nv3`yolo`layer\n```\n[yolo]\nmask = 0,1,2\n## 9anchor9\nanchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\nclasses=20   ## VOC20\nnum=9\njitter=.3\nignore_thresh = .5\ntruth_thresh = 1\nrandom=1\n```\n\n`yolo_layer.c``forward`[]()activationv2softmaxsoftmax treelogistic\n``` cpp\nfor (b = 0; b < l.batch; ++b){\n    for(n = 0; n < l.n; ++n){\n        int index = entry_index(l, b, n*l.w*l.h, 0);\n        //  tx, tylogistic\n        activate_array(l.output + index, 2*l.w*l.h, LOGISTIC);\n        index = entry_index(l, b, n*l.w*l.h, 4);\n        // confidenceClogistic\n        activate_array(l.output + index, (1+l.classes)*l.w*l.h, LOGISTIC);\n    }\n}\n```\n\n\n``` cpp\nfor (j = 0; j < l.h; ++j) {\n    for (i = 0; i < l.w; ++i) {\n        for (n = 0; n < l.n; ++n) {\n            // bounding box\n            // IoUground truth\n            int box_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 0);\n            box pred = get_yolo_box(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.w*l.h);\n            float best_iou = 0;\n            int best_t = 0;\n            for(t = 0; t < l.max_boxes; ++t){\n                box truth = float_to_box(net.truth + t*(4 + 1) + b*l.truths, 1);\n                if(!truth.x) break;\n                float iou = box_iou(pred, truth);\n                if (iou > best_iou) {\n                    best_iou = iou;\n                    best_t = t;\n                }\n            }\n            int obj_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 4);\n            avg_anyobj += l.output[obj_index];\n            // \n            // ignore_thresh, \n            // ignore_threshtarget = 0\n            // diff = -gradient = target - output\n            // \n            l.delta[obj_index] = 0 - l.output[obj_index];\n            if (best_iou > l.ignore_thresh) {\n                l.delta[obj_index] = 0;\n            }\n            // truth_thresh?1\n            // iou1\n            if (best_iou > l.truth_thresh) {\n                // confidence target = 1\n                l.delta[obj_index] = 1 - l.output[obj_index];\n                int class = net.truth[best_t*(4 + 1) + b*l.truths + 4];\n                if (l.map) class = l.map[class];\n                int class_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, 4 + 1);\n                // class\n                delta_yolo_class(l.output, l.delta, class_index, class, l.classes, l.w*l.h, 0);\n                box truth = float_to_box(net.truth + best_t*(4 + 1) + b*l.truths, 1);\n                // box\n                delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.delta, (2-truth.w*truth.h), l.w*l.h);\n            }\n        }\n    }\n}\n```\nconfidenceclassification`diff``target - output`logistic regressionlogistic$o = f(x;\\theta)$$\\theta$$y = h(o)$$h$logisticsigmoid\n$$\\begin{aligned}P(y=1|x) &= h(o)\\\\ P(y=0|x) &= 1-h(o)\\end{aligned}$$\n\n\n$$\\log L = \\sum y\\log h+(1-y)\\log(1-h)$$\n\nSGD\n$$J = -\\log L = \\sum -y\\log h-(1-y)\\log(1-h)$$\n\n$i$$o_i$\n$$\\begin{aligned}\\frac{\\partial J}{\\partial o_i} &= \\frac{\\partial J}{\\partial h_i}\\frac{\\partial h_i}{\\partial o_i}\\\\\n&= [-y_i/h_i-(y_i-1)/(1-h_i)] \\frac{\\partial h_i}{\\partial o_i} \\\\\n&= \\frac{h_i-y_i}{h_i(1-h_i)} \\frac{\\partial h_i}{\\partial o_i}\\end{aligned}$$\n\nlogistic\n$$\\frac{\\partial h_i}{\\partial o_i} = h_i(1-h_i)$$\n\n\n$$\\frac{\\partial J}{\\partial o_i} = h_i-y_i$$\n\n$h_i$logistic$y_i$targetYOLO`diff``-gradient``delta = target - output`\n\nlogistic[CS229 ](https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/)\n\n`delta_yolo_class``delta_yolo_box`\n``` cpp\n// classground truth\n// classes\n// indexfeature mapclass prediction\nvoid delta_yolo_class(float *output, float *delta, int index, \n  int class, int classes, int stride, float *avg_cat) {\n    int n;\n    // \n    if (delta[index]){\n        delta[index + stride*class] = 1 - output[index + stride*class];\n        if(avg_cat) *avg_cat += output[index + stride*class];\n        return;\n    }\n    for(n = 0; n < classes; ++n){\n        // diff = target - prediction\n        delta[index + stride*n] = ((n == class)?1 : 0) - output[index + stride*n];\n        if(n == class && avg_cat) *avg_cat += output[index + stride*n];\n    }\n}\n// box deltasquare error\nfloat delta_yolo_box(box truth, float *x, float *biases, int n, \n  int index, int i, int j, int lw, int lh, int w, int h, \n  float *delta, float scale, int stride) {\n    box pred = get_yolo_box(x, biases, n, index, i, j, lw, lh, w, h, stride);\n    float iou = box_iou(pred, truth);\n    float tx = (truth.x*lw - i);\n    float ty = (truth.y*lh - j);\n    float tw = log(truth.w*w / biases[2*n]);\n    float th = log(truth.h*h / biases[2*n + 1]);\n\n    delta[index + 0*stride] = scale * (tx - x[index + 0*stride]);\n    delta[index + 1*stride] = scale * (ty - x[index + 1*stride]);\n    delta[index + 2*stride] = scale * (tw - x[index + 2*stride]);\n    delta[index + 3*stride] = scale * (th - x[index + 3*stride]);\n    return iou;\n}\n```\npredictionbounding boxground truthIoU\n``` cpp\n// ground truth\nfor(t = 0; t < l.max_boxes; ++t){\n    box truth = float_to_box(net.truth + t*(4 + 1) + b*l.truths, 1);\n    if(!truth.x) break;\n    // ioubounding box\n    float best_iou = 0;\n    int best_n = 0;\n    i = (truth.x * l.w);\n    j = (truth.y * l.h);\n    box truth_shift = truth;\n    truth_shift.x = truth_shift.y = 0;\n    for(n = 0; n < l.total; ++n){\n        box pred = {0};\n        pred.w = l.biases[2*n]/net.w;\n        pred.h = l.biases[2*n+1]/net.h;\n        float iou = box_iou(pred, truth_shift);\n        if (iou > best_iou){\n            best_iou = iou;\n            best_n = n;\n        }\n    }\n    \n    int mask_n = int_index(l.mask, best_n, l.n);\n    if(mask_n >= 0){\n        int box_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 0);\n        float iou = delta_yolo_box(truth, l.output, l.biases, best_n, \n          box_index, i, j, l.w, l.h, net.w, net.h, l.delta, \n          (2-truth.w*truth.h), l.w*l.h);\n        int obj_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 4);\n        avg_obj += l.output[obj_index];\n        // objectness target = 1\n        l.delta[obj_index] = 1 - l.output[obj_index];\n        int class = net.truth[t*(4 + 1) + b*l.truths + 4];\n        if (l.map) class = l.map[class];\n        int class_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, 4 + 1);\n        delta_yolo_class(l.output, l.delta, class_index, class, l.classes, l.w*l.h, &avg_cat);\n        ++count;\n        ++class_count;\n        if(iou > .5) recall += 1;\n        if(iou > .75) recall75 += 1;\n        avg_iou += iou;\n    }\n}\n```\n\n## Darknet\nResidualNet$3\\times 3$$1\\times 1$shortcutDarknet-53\n![darknet-63](/img/paper-yolov3-darknet53.png)\n\n## YOLO\nYOLO v3IoUYOLO\n\n> Russakovsky et al report that that humans have a hard time distinguishing an IOU of .3 from .5! Training humans to visually inspect a bounding box with IOU of 0.3 and distinguish it from one with IOU 0.5 is surprisingly difficult. [16] If humans have a hard time telling the difference, how much does it matter?\n\nv3mediumlarge\n\n\n![](/img/paper-yolov3-comparisons.png)\n\n## \n\n- anchor box$(x, y)$anchor boxoffsetno stable\n- offsetlogistic\n- focal loss\n- IoUFaster RCNN\n\n\n## \n\n- YOLO[Darknet YOLO](https://pjreddie.com/darknet/yolo/)\n- [paper](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n- [](https://zhuanlan.zhihu.com/p/34945787)\n- FPN[Feature pyramid networks for object detection](https://arxiv.org/abs/1612.03144)\n- [AP](https://www.zhihu.com/question/41540197)","slug":"paper-yolov3","published":1,"updated":"2018-10-27T07:16:52.412Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nr003dae7bhjyys9z1","content":"<p>YOLOV3<a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\" target=\"_blank\" rel=\"external\">YOLOv3: An Incremental Improvement</a>YOLO V3RetinaNet<br><img src=\"/img/paper-yolov3-comparison-retinanet.png\" alt=\"YOLO v3RetinaNet\"></p>\n<p>YOLO<br><a id=\"more\"></a></p>\n<h2 id=\"YOLO-v3\"><a href=\"#YOLO-v3\" class=\"headerlink\" title=\"YOLO v3\"></a>YOLO v3</h2><p>YOLO v3$320\\times 320$$22$msmAP$28.2$SSD$3$TitanXYOLO v3$51$ms$AP_{50}$$57.9$RetinaNet$198$ms$AP_{50}$$57.5$</p>\n<h3 id=\"psAP\"><a href=\"#psAP\" class=\"headerlink\" title=\"psAP\"></a>psAP</h3><p>APaverage precisiondetectionbounding boxground truthIoU$0.5$True PositiveFalse Positive</p>\n<p>precisionTrue Positiverecallground truthclassificationIoUdetection</p>\n<p>precisio vs recallAPCOCO<code>0.5:0.05:0.95</code><a href=\"http://cocodataset.org/#detections-eval\" target=\"_blank\" rel=\"external\">COCO</a>detectionAPmAP</p>\n<p>$0.5$AP$AP_{50}$YOLO v3$AP_{50}$bounding boxRetinaNetIoU$0.5$</p>\n<h2 id=\"Bounding-Box\"><a href=\"#Bounding-Box\" class=\"headerlink\" title=\"Bounding Box\"></a>Bounding Box</h2><p>v2anchor box$p_w$$p_h$$t_x$$t_y$$t_w$$t_h$YOLO$M\\times M$feature map$M \\times M$cellcellimagetop left corner$(c_x, c_y)$cellcellbounding box</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}b_x &= \\sigma(t_x) + c_x\\\\ b_y &= \\sigma(t_y) + c_y\\\\ b_w &= p_w e^{t_w}\\\\ b_h &= p_h e^{t_h}\\end{aligned}</script><p>PSFasterRCNNYOLObounding box$b_w = p_w t_w^\\prime$$\\log(\\cdot)$</p>\n<p>$t_w^\\prime$$t_w^\\prime &gt; 0$SGD</p>\n<p><img src=\"/img/paper=yolov3-bbox-regression.png\" alt=\"bounding box\"></p>\n<p></p>\n<p>YOLObounding boxobjectobjectslogisticbounding boxground truthIoUbounding boxtarget$1$bounding boxIoUIoU$0.5$Faster RCNNground truthbounding boxFaster RCNNbounding boxassignground truthclassobjectnessconfidence</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>softmaxlogisitcOpen Image Dataset<code>Woman</code><code>Person</code></p>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p>YOLO<a href=\"https://arxiv.org/abs/1612.03144\" target=\"_blank\" rel=\"external\">FPN</a>v3$3$COCO$3$$9$feature map$N\\times N\\times [3\\times (4+1+80)]$</p>\n<p>feature mapupsample 2xfeature mapelement-widemergefeature mapconvfeature mapspatial dimension$2$</p>\n<p>final scale</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>v3<code>yolo</code>layer<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">[yolo]</div><div class=\"line\">mask = 0,1,2</div><div class=\"line\">## 9anchor9</div><div class=\"line\">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</div><div class=\"line\">classes=20   ## VOC20</div><div class=\"line\">num=9</div><div class=\"line\">jitter=.3</div><div class=\"line\">ignore_thresh = .5</div><div class=\"line\">truth_thresh = 1</div><div class=\"line\">random=1</div></pre></td></tr></table></figure></p>\n<p><code>yolo_layer.c</code><code>forward</code><a href=\"\"></a>activationv2softmaxsoftmax treelogistic<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> (b = <span class=\"number\">0</span>; b &lt; l.batch; ++b)&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; l.n; ++n)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> index = entry_index(l, b, n*l.w*l.h, <span class=\"number\">0</span>);</div><div class=\"line\">        <span class=\"comment\">//  tx, tylogistic</span></div><div class=\"line\">        activate_array(l.output + index, <span class=\"number\">2</span>*l.w*l.h, LOGISTIC);</div><div class=\"line\">        index = entry_index(l, b, n*l.w*l.h, <span class=\"number\">4</span>);</div><div class=\"line\">        <span class=\"comment\">// confidenceClogistic</span></div><div class=\"line\">        activate_array(l.output + index, (<span class=\"number\">1</span>+l.classes)*l.w*l.h, LOGISTIC);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; l.h; ++j) &#123;</div><div class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; l.w; ++i) &#123;</div><div class=\"line\">        <span class=\"keyword\">for</span> (n = <span class=\"number\">0</span>; n &lt; l.n; ++n) &#123;</div><div class=\"line\">            <span class=\"comment\">// bounding box</span></div><div class=\"line\">            <span class=\"comment\">// IoUground truth</span></div><div class=\"line\">            <span class=\"keyword\">int</span> box_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">0</span>);</div><div class=\"line\">            box pred = get_yolo_box(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.w*l.h);</div><div class=\"line\">            <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">int</span> <span class=\"keyword\">best_t</span> = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">for</span>(t = <span class=\"number\">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class=\"line\">                box truth = float_to_box(net.truth + t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"keyword\">if</span>(!truth.x) <span class=\"keyword\">break</span>;</div><div class=\"line\">                <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">                <span class=\"keyword\">if</span> (iou &gt; best_iou) &#123;</div><div class=\"line\">                    best_iou = iou;</div><div class=\"line\">                    <span class=\"keyword\">best_t</span> = t;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">int</span> obj_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span>);</div><div class=\"line\">            avg_anyobj += l.output[obj_index];</div><div class=\"line\">            <span class=\"comment\">// </span></div><div class=\"line\">            <span class=\"comment\">// ignore_thresh, </span></div><div class=\"line\">            <span class=\"comment\">// ignore_threshtarget = 0</span></div><div class=\"line\">            <span class=\"comment\">// diff = -gradient = target - output</span></div><div class=\"line\">            <span class=\"comment\">// </span></div><div class=\"line\">            l.delta[obj_index] = <span class=\"number\">0</span> - l.output[obj_index];</div><div class=\"line\">            <span class=\"keyword\">if</span> (best_iou &gt; l.ignore_thresh) &#123;</div><div class=\"line\">                l.delta[obj_index] = <span class=\"number\">0</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"comment\">// truth_thresh?1</span></div><div class=\"line\">            <span class=\"comment\">// iou1</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (best_iou &gt; l.truth_thresh) &#123;</div><div class=\"line\">                <span class=\"comment\">// confidence target = 1</span></div><div class=\"line\">                l.delta[obj_index] = <span class=\"number\">1</span> - l.output[obj_index];</div><div class=\"line\">                <span class=\"keyword\">int</span> <span class=\"keyword\">class</span> = net.truth[<span class=\"keyword\">best_t</span>*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths + <span class=\"number\">4</span>];</div><div class=\"line\">                <span class=\"keyword\">if</span> (l.<span class=\"built_in\">map</span>) <span class=\"keyword\">class</span> = l.<span class=\"built_in\">map</span>[<span class=\"keyword\">class</span>];</div><div class=\"line\">                <span class=\"keyword\">int</span> class_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span> + <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"comment\">// class</span></div><div class=\"line\">                delta_yolo_class(l.output, l.delta, class_index, <span class=\"keyword\">class</span>, l.classes, l.w*l.h, <span class=\"number\">0</span>);</div><div class=\"line\">                box truth = float_to_box(net.truth + <span class=\"keyword\">best_t</span>*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"comment\">// box</span></div><div class=\"line\">                delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.delta, (<span class=\"number\">2</span>-truth.w*truth.h), l.w*l.h);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>confidenceclassification<code>diff</code><code>target - output</code>logistic regressionlogistic$o = f(x;\\theta)$$\\theta$$y = h(o)$$h$logisticsigmoid</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}P(y=1|x) &= h(o)\\\\ P(y=0|x) &= 1-h(o)\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log L = \\sum y\\log h+(1-y)\\log(1-h)</script><p>SGD</p>\n<script type=\"math/tex; mode=display\">J = -\\log L = \\sum -y\\log h-(1-y)\\log(1-h)</script><p>$i$$o_i$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\frac{\\partial J}{\\partial o_i} &= \\frac{\\partial J}{\\partial h_i}\\frac{\\partial h_i}{\\partial o_i}\\\\\n&= [-y_i/h_i-(y_i-1)/(1-h_i)] \\frac{\\partial h_i}{\\partial o_i} \\\\\n&= \\frac{h_i-y_i}{h_i(1-h_i)} \\frac{\\partial h_i}{\\partial o_i}\\end{aligned}</script><p>logistic</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial h_i}{\\partial o_i} = h_i(1-h_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial J}{\\partial o_i} = h_i-y_i</script><p>$h_i$logistic$y_i$targetYOLO<code>diff</code><code>-gradient</code><code>delta = target - output</code></p>\n<p>logistic<a href=\"https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/\">CS229 </a></p>\n<p><code>delta_yolo_class</code><code>delta_yolo_box</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// classground truth</span></div><div class=\"line\"><span class=\"comment\">// classes</span></div><div class=\"line\"><span class=\"comment\">// indexfeature mapclass prediction</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">delta_yolo_class</span><span class=\"params\">(<span class=\"keyword\">float</span> *output, <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">int</span> index, </span></span></div><div class=\"line\">  <span class=\"keyword\">int</span> <span class=\"keyword\">class</span>, <span class=\"keyword\">int</span> classes, <span class=\"keyword\">int</span> stride, <span class=\"keyword\">float</span> *avg_cat) &#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"keyword\">if</span> (delta[index])&#123;</div><div class=\"line\">        delta[index + stride*<span class=\"keyword\">class</span>] = <span class=\"number\">1</span> - output[index + stride*<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">if</span>(avg_cat) *avg_cat += output[index + stride*<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; classes; ++n)&#123;</div><div class=\"line\">        <span class=\"comment\">// diff = target - prediction</span></div><div class=\"line\">        delta[index + stride*n] = ((n == <span class=\"keyword\">class</span>)?<span class=\"number\">1</span> : <span class=\"number\">0</span>) - output[index + stride*n];</div><div class=\"line\">        <span class=\"keyword\">if</span>(n == <span class=\"keyword\">class</span> &amp;&amp; avg_cat) *avg_cat += output[index + stride*n];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"comment\">// box deltasquare error</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">delta_yolo_box</span><span class=\"params\">(box truth, <span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases, <span class=\"keyword\">int</span> n, </span></span></div><div class=\"line\">  <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> lw, <span class=\"keyword\">int</span> lh, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h, </div><div class=\"line\">  <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">float</span> scale, <span class=\"keyword\">int</span> stride) &#123;</div><div class=\"line\">    box pred = get_yolo_box(x, biases, n, index, i, j, lw, lh, w, h, stride);</div><div class=\"line\">    <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">    <span class=\"keyword\">float</span> tx = (truth.x*lw - i);</div><div class=\"line\">    <span class=\"keyword\">float</span> ty = (truth.y*lh - j);</div><div class=\"line\">    <span class=\"keyword\">float</span> tw = <span class=\"built_in\">log</span>(truth.w*w / biases[<span class=\"number\">2</span>*n]);</div><div class=\"line\">    <span class=\"keyword\">float</span> th = <span class=\"built_in\">log</span>(truth.h*h / biases[<span class=\"number\">2</span>*n + <span class=\"number\">1</span>]);</div><div class=\"line\"></div><div class=\"line\">    delta[index + <span class=\"number\">0</span>*stride] = scale * (tx - x[index + <span class=\"number\">0</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">1</span>*stride] = scale * (ty - x[index + <span class=\"number\">1</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">2</span>*stride] = scale * (tw - x[index + <span class=\"number\">2</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">3</span>*stride] = scale * (th - x[index + <span class=\"number\">3</span>*stride]);</div><div class=\"line\">    <span class=\"keyword\">return</span> iou;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>predictionbounding boxground truthIoU<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// ground truth</span></div><div class=\"line\"><span class=\"keyword\">for</span>(t = <span class=\"number\">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class=\"line\">    box truth = float_to_box(net.truth + t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span>(!truth.x) <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"comment\">// ioubounding box</span></div><div class=\"line\">    <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> best_n = <span class=\"number\">0</span>;</div><div class=\"line\">    i = (truth.x * l.w);</div><div class=\"line\">    j = (truth.y * l.h);</div><div class=\"line\">    box truth_shift = truth;</div><div class=\"line\">    truth_shift.x = truth_shift.y = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; l.total; ++n)&#123;</div><div class=\"line\">        box pred = &#123;<span class=\"number\">0</span>&#125;;</div><div class=\"line\">        pred.w = l.biases[<span class=\"number\">2</span>*n]/net.w;</div><div class=\"line\">        pred.h = l.biases[<span class=\"number\">2</span>*n+<span class=\"number\">1</span>]/net.h;</div><div class=\"line\">        <span class=\"keyword\">float</span> iou = box_iou(pred, truth_shift);</div><div class=\"line\">        <span class=\"keyword\">if</span> (iou &gt; best_iou)&#123;</div><div class=\"line\">            best_iou = iou;</div><div class=\"line\">            best_n = n;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">int</span> mask_n = int_index(l.mask, best_n, l.n);</div><div class=\"line\">    <span class=\"keyword\">if</span>(mask_n &gt;= <span class=\"number\">0</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> box_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">0</span>);</div><div class=\"line\">        <span class=\"keyword\">float</span> iou = delta_yolo_box(truth, l.output, l.biases, best_n, </div><div class=\"line\">          box_index, i, j, l.w, l.h, net.w, net.h, l.delta, </div><div class=\"line\">          (<span class=\"number\">2</span>-truth.w*truth.h), l.w*l.h);</div><div class=\"line\">        <span class=\"keyword\">int</span> obj_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span>);</div><div class=\"line\">        avg_obj += l.output[obj_index];</div><div class=\"line\">        <span class=\"comment\">// objectness target = 1</span></div><div class=\"line\">        l.delta[obj_index] = <span class=\"number\">1</span> - l.output[obj_index];</div><div class=\"line\">        <span class=\"keyword\">int</span> <span class=\"keyword\">class</span> = net.truth[t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths + <span class=\"number\">4</span>];</div><div class=\"line\">        <span class=\"keyword\">if</span> (l.<span class=\"built_in\">map</span>) <span class=\"keyword\">class</span> = l.<span class=\"built_in\">map</span>[<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">int</span> class_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span> + <span class=\"number\">1</span>);</div><div class=\"line\">        delta_yolo_class(l.output, l.delta, class_index, <span class=\"keyword\">class</span>, l.classes, l.w*l.h, &amp;avg_cat);</div><div class=\"line\">        ++count;</div><div class=\"line\">        ++class_count;</div><div class=\"line\">        <span class=\"keyword\">if</span>(iou &gt; <span class=\"number\">.5</span>) recall += <span class=\"number\">1</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(iou &gt; <span class=\"number\">.75</span>) recall75 += <span class=\"number\">1</span>;</div><div class=\"line\">        avg_iou += iou;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"Darknet\"><a href=\"#Darknet\" class=\"headerlink\" title=\"Darknet\"></a>Darknet</h2><p>ResidualNet$3\\times 3$$1\\times 1$shortcutDarknet-53<br><img src=\"/img/paper-yolov3-darknet53.png\" alt=\"darknet-63\"></p>\n<h2 id=\"YOLO\"><a href=\"#YOLO\" class=\"headerlink\" title=\"YOLO\"></a>YOLO</h2><p>YOLO v3IoUYOLO</p>\n<blockquote>\n<p>Russakovsky et al report that that humans have a hard time distinguishing an IOU of .3 from .5! Training humans to visually inspect a bounding box with IOU of 0.3 and distinguish it from one with IOU 0.5 is surprisingly difficult. [16] If humans have a hard time telling the difference, how much does it matter?</p>\n</blockquote>\n<p>v3mediumlarge</p>\n<p><br><img src=\"/img/paper-yolov3-comparisons.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>anchor box$(x, y)$anchor boxoffsetno stable</li>\n<li>offsetlogistic</li>\n<li>focal loss</li>\n<li>IoUFaster RCNN</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>YOLO<a href=\"https://pjreddie.com/darknet/yolo/\" target=\"_blank\" rel=\"external\">Darknet YOLO</a></li>\n<li><a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\" target=\"_blank\" rel=\"external\">paper</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/34945787\" target=\"_blank\" rel=\"external\"></a></li>\n<li>FPN<a href=\"https://arxiv.org/abs/1612.03144\" target=\"_blank\" rel=\"external\">Feature pyramid networks for object detection</a></li>\n<li><a href=\"https://www.zhihu.com/question/41540197\" target=\"_blank\" rel=\"external\">AP</a></li>\n</ul>\n","excerpt":"<p>YOLOV3<a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\">YOLOv3: An Incremental Improvement</a>YOLO V3RetinaNet<br><img src=\"/img/paper-yolov3-comparison-retinanet.png\" alt=\"YOLO v3RetinaNet\"></p>\n<p>YOLO<br>","more":"</p>\n<h2 id=\"YOLO-v3\"><a href=\"#YOLO-v3\" class=\"headerlink\" title=\"YOLO v3\"></a>YOLO v3</h2><p>YOLO v3$320\\times 320$$22$msmAP$28.2$SSD$3$TitanXYOLO v3$51$ms$AP_{50}$$57.9$RetinaNet$198$ms$AP_{50}$$57.5$</p>\n<h3 id=\"psAP\"><a href=\"#psAP\" class=\"headerlink\" title=\"psAP\"></a>psAP</h3><p>APaverage precisiondetectionbounding boxground truthIoU$0.5$True PositiveFalse Positive</p>\n<p>precisionTrue Positiverecallground truthclassificationIoUdetection</p>\n<p>precisio vs recallAPCOCO<code>0.5:0.05:0.95</code><a href=\"http://cocodataset.org/#detections-eval\">COCO</a>detectionAPmAP</p>\n<p>$0.5$AP$AP_{50}$YOLO v3$AP_{50}$bounding boxRetinaNetIoU$0.5$</p>\n<h2 id=\"Bounding-Box\"><a href=\"#Bounding-Box\" class=\"headerlink\" title=\"Bounding Box\"></a>Bounding Box</h2><p>v2anchor box$p_w$$p_h$$t_x$$t_y$$t_w$$t_h$YOLO$M\\times M$feature map$M \\times M$cellcellimagetop left corner$(c_x, c_y)$cellcellbounding box</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}b_x &= \\sigma(t_x) + c_x\\\\ b_y &= \\sigma(t_y) + c_y\\\\ b_w &= p_w e^{t_w}\\\\ b_h &= p_h e^{t_h}\\end{aligned}</script><p>PSFasterRCNNYOLObounding box$b_w = p_w t_w^\\prime$$\\log(\\cdot)$</p>\n<p>$t_w^\\prime$$t_w^\\prime &gt; 0$SGD</p>\n<p><img src=\"/img/paper=yolov3-bbox-regression.png\" alt=\"bounding box\"></p>\n<p></p>\n<p>YOLObounding boxobjectobjectslogisticbounding boxground truthIoUbounding boxtarget$1$bounding boxIoUIoU$0.5$Faster RCNNground truthbounding boxFaster RCNNbounding boxassignground truthclassobjectnessconfidence</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>softmaxlogisitcOpen Image Dataset<code>Woman</code><code>Person</code></p>\n<h2 id=\"FPN\"><a href=\"#FPN\" class=\"headerlink\" title=\"FPN\"></a>FPN</h2><p>YOLO<a href=\"https://arxiv.org/abs/1612.03144\">FPN</a>v3$3$COCO$3$$9$feature map$N\\times N\\times [3\\times (4+1+80)]$</p>\n<p>feature mapupsample 2xfeature mapelement-widemergefeature mapconvfeature mapspatial dimension$2$</p>\n<p>final scale</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>v3<code>yolo</code>layer<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">[yolo]</div><div class=\"line\">mask = 0,1,2</div><div class=\"line\">## 9anchor9</div><div class=\"line\">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</div><div class=\"line\">classes=20   ## VOC20</div><div class=\"line\">num=9</div><div class=\"line\">jitter=.3</div><div class=\"line\">ignore_thresh = .5</div><div class=\"line\">truth_thresh = 1</div><div class=\"line\">random=1</div></pre></td></tr></table></figure></p>\n<p><code>yolo_layer.c</code><code>forward</code><a href=\"\"></a>activationv2softmaxsoftmax treelogistic<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> (b = <span class=\"number\">0</span>; b &lt; l.batch; ++b)&#123;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; l.n; ++n)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> index = entry_index(l, b, n*l.w*l.h, <span class=\"number\">0</span>);</div><div class=\"line\">        <span class=\"comment\">//  tx, tylogistic</span></div><div class=\"line\">        activate_array(l.output + index, <span class=\"number\">2</span>*l.w*l.h, LOGISTIC);</div><div class=\"line\">        index = entry_index(l, b, n*l.w*l.h, <span class=\"number\">4</span>);</div><div class=\"line\">        <span class=\"comment\">// confidenceClogistic</span></div><div class=\"line\">        activate_array(l.output + index, (<span class=\"number\">1</span>+l.classes)*l.w*l.h, LOGISTIC);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; l.h; ++j) &#123;</div><div class=\"line\">    <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; l.w; ++i) &#123;</div><div class=\"line\">        <span class=\"keyword\">for</span> (n = <span class=\"number\">0</span>; n &lt; l.n; ++n) &#123;</div><div class=\"line\">            <span class=\"comment\">// bounding box</span></div><div class=\"line\">            <span class=\"comment\">// IoUground truth</span></div><div class=\"line\">            <span class=\"keyword\">int</span> box_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">0</span>);</div><div class=\"line\">            box pred = get_yolo_box(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.w*l.h);</div><div class=\"line\">            <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">int</span> <span class=\"keyword\">best_t</span> = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">for</span>(t = <span class=\"number\">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class=\"line\">                box truth = float_to_box(net.truth + t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"keyword\">if</span>(!truth.x) <span class=\"keyword\">break</span>;</div><div class=\"line\">                <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">                <span class=\"keyword\">if</span> (iou &gt; best_iou) &#123;</div><div class=\"line\">                    best_iou = iou;</div><div class=\"line\">                    <span class=\"keyword\">best_t</span> = t;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">int</span> obj_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span>);</div><div class=\"line\">            avg_anyobj += l.output[obj_index];</div><div class=\"line\">            <span class=\"comment\">// </span></div><div class=\"line\">            <span class=\"comment\">// ignore_thresh, </span></div><div class=\"line\">            <span class=\"comment\">// ignore_threshtarget = 0</span></div><div class=\"line\">            <span class=\"comment\">// diff = -gradient = target - output</span></div><div class=\"line\">            <span class=\"comment\">// </span></div><div class=\"line\">            l.delta[obj_index] = <span class=\"number\">0</span> - l.output[obj_index];</div><div class=\"line\">            <span class=\"keyword\">if</span> (best_iou &gt; l.ignore_thresh) &#123;</div><div class=\"line\">                l.delta[obj_index] = <span class=\"number\">0</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"comment\">// truth_thresh?1</span></div><div class=\"line\">            <span class=\"comment\">// iou1</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (best_iou &gt; l.truth_thresh) &#123;</div><div class=\"line\">                <span class=\"comment\">// confidence target = 1</span></div><div class=\"line\">                l.delta[obj_index] = <span class=\"number\">1</span> - l.output[obj_index];</div><div class=\"line\">                <span class=\"keyword\">int</span> <span class=\"keyword\">class</span> = net.truth[<span class=\"keyword\">best_t</span>*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths + <span class=\"number\">4</span>];</div><div class=\"line\">                <span class=\"keyword\">if</span> (l.<span class=\"built_in\">map</span>) <span class=\"keyword\">class</span> = l.<span class=\"built_in\">map</span>[<span class=\"keyword\">class</span>];</div><div class=\"line\">                <span class=\"keyword\">int</span> class_index = entry_index(l, b, n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span> + <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"comment\">// class</span></div><div class=\"line\">                delta_yolo_class(l.output, l.delta, class_index, <span class=\"keyword\">class</span>, l.classes, l.w*l.h, <span class=\"number\">0</span>);</div><div class=\"line\">                box truth = float_to_box(net.truth + <span class=\"keyword\">best_t</span>*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">                <span class=\"comment\">// box</span></div><div class=\"line\">                delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, net.w, net.h, l.delta, (<span class=\"number\">2</span>-truth.w*truth.h), l.w*l.h);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>confidenceclassification<code>diff</code><code>target - output</code>logistic regressionlogistic$o = f(x;\\theta)$$\\theta$$y = h(o)$$h$logisticsigmoid</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}P(y=1|x) &= h(o)\\\\ P(y=0|x) &= 1-h(o)\\end{aligned}</script><p></p>\n<script type=\"math/tex; mode=display\">\\log L = \\sum y\\log h+(1-y)\\log(1-h)</script><p>SGD</p>\n<script type=\"math/tex; mode=display\">J = -\\log L = \\sum -y\\log h-(1-y)\\log(1-h)</script><p>$i$$o_i$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\\frac{\\partial J}{\\partial o_i} &= \\frac{\\partial J}{\\partial h_i}\\frac{\\partial h_i}{\\partial o_i}\\\\\n&= [-y_i/h_i-(y_i-1)/(1-h_i)] \\frac{\\partial h_i}{\\partial o_i} \\\\\n&= \\frac{h_i-y_i}{h_i(1-h_i)} \\frac{\\partial h_i}{\\partial o_i}\\end{aligned}</script><p>logistic</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial h_i}{\\partial o_i} = h_i(1-h_i)</script><p></p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial J}{\\partial o_i} = h_i-y_i</script><p>$h_i$logistic$y_i$targetYOLO<code>diff</code><code>-gradient</code><code>delta = target - output</code></p>\n<p>logistic<a href=\"https://xmfbit.github.io/2018/03/21/cs229-supervised-learning/\">CS229 </a></p>\n<p><code>delta_yolo_class</code><code>delta_yolo_box</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// classground truth</span></div><div class=\"line\"><span class=\"comment\">// classes</span></div><div class=\"line\"><span class=\"comment\">// indexfeature mapclass prediction</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">delta_yolo_class</span><span class=\"params\">(<span class=\"keyword\">float</span> *output, <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">int</span> index, </div><div class=\"line\">  <span class=\"keyword\">int</span> <span class=\"keyword\">class</span>, <span class=\"keyword\">int</span> classes, <span class=\"keyword\">int</span> stride, <span class=\"keyword\">float</span> *avg_cat)</span> </span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> n;</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"keyword\">if</span> (delta[index])&#123;</div><div class=\"line\">        delta[index + stride*<span class=\"keyword\">class</span>] = <span class=\"number\">1</span> - output[index + stride*<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">if</span>(avg_cat) *avg_cat += output[index + stride*<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">return</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; classes; ++n)&#123;</div><div class=\"line\">        <span class=\"comment\">// diff = target - prediction</span></div><div class=\"line\">        delta[index + stride*n] = ((n == <span class=\"keyword\">class</span>)?<span class=\"number\">1</span> : <span class=\"number\">0</span>) - output[index + stride*n];</div><div class=\"line\">        <span class=\"keyword\">if</span>(n == <span class=\"keyword\">class</span> &amp;&amp; avg_cat) *avg_cat += output[index + stride*n];</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\"><span class=\"comment\">// box deltasquare error</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">delta_yolo_box</span><span class=\"params\">(box truth, <span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases, <span class=\"keyword\">int</span> n, </div><div class=\"line\">  <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> lw, <span class=\"keyword\">int</span> lh, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h, </div><div class=\"line\">  <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">float</span> scale, <span class=\"keyword\">int</span> stride)</span> </span>&#123;</div><div class=\"line\">    box pred = get_yolo_box(x, biases, n, index, i, j, lw, lh, w, h, stride);</div><div class=\"line\">    <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">    <span class=\"keyword\">float</span> tx = (truth.x*lw - i);</div><div class=\"line\">    <span class=\"keyword\">float</span> ty = (truth.y*lh - j);</div><div class=\"line\">    <span class=\"keyword\">float</span> tw = <span class=\"built_in\">log</span>(truth.w*w / biases[<span class=\"number\">2</span>*n]);</div><div class=\"line\">    <span class=\"keyword\">float</span> th = <span class=\"built_in\">log</span>(truth.h*h / biases[<span class=\"number\">2</span>*n + <span class=\"number\">1</span>]);</div><div class=\"line\"></div><div class=\"line\">    delta[index + <span class=\"number\">0</span>*stride] = scale * (tx - x[index + <span class=\"number\">0</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">1</span>*stride] = scale * (ty - x[index + <span class=\"number\">1</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">2</span>*stride] = scale * (tw - x[index + <span class=\"number\">2</span>*stride]);</div><div class=\"line\">    delta[index + <span class=\"number\">3</span>*stride] = scale * (th - x[index + <span class=\"number\">3</span>*stride]);</div><div class=\"line\">    <span class=\"keyword\">return</span> iou;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>predictionbounding boxground truthIoU<br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// ground truth</span></div><div class=\"line\"><span class=\"keyword\">for</span>(t = <span class=\"number\">0</span>; t &lt; l.max_boxes; ++t)&#123;</div><div class=\"line\">    box truth = float_to_box(net.truth + t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths, <span class=\"number\">1</span>);</div><div class=\"line\">    <span class=\"keyword\">if</span>(!truth.x) <span class=\"keyword\">break</span>;</div><div class=\"line\">    <span class=\"comment\">// ioubounding box</span></div><div class=\"line\">    <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> best_n = <span class=\"number\">0</span>;</div><div class=\"line\">    i = (truth.x * l.w);</div><div class=\"line\">    j = (truth.y * l.h);</div><div class=\"line\">    box truth_shift = truth;</div><div class=\"line\">    truth_shift.x = truth_shift.y = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">for</span>(n = <span class=\"number\">0</span>; n &lt; l.total; ++n)&#123;</div><div class=\"line\">        box pred = &#123;<span class=\"number\">0</span>&#125;;</div><div class=\"line\">        pred.w = l.biases[<span class=\"number\">2</span>*n]/net.w;</div><div class=\"line\">        pred.h = l.biases[<span class=\"number\">2</span>*n+<span class=\"number\">1</span>]/net.h;</div><div class=\"line\">        <span class=\"keyword\">float</span> iou = box_iou(pred, truth_shift);</div><div class=\"line\">        <span class=\"keyword\">if</span> (iou &gt; best_iou)&#123;</div><div class=\"line\">            best_iou = iou;</div><div class=\"line\">            best_n = n;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"keyword\">int</span> mask_n = int_index(l.mask, best_n, l.n);</div><div class=\"line\">    <span class=\"keyword\">if</span>(mask_n &gt;= <span class=\"number\">0</span>)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> box_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">0</span>);</div><div class=\"line\">        <span class=\"keyword\">float</span> iou = delta_yolo_box(truth, l.output, l.biases, best_n, </div><div class=\"line\">          box_index, i, j, l.w, l.h, net.w, net.h, l.delta, </div><div class=\"line\">          (<span class=\"number\">2</span>-truth.w*truth.h), l.w*l.h);</div><div class=\"line\">        <span class=\"keyword\">int</span> obj_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span>);</div><div class=\"line\">        avg_obj += l.output[obj_index];</div><div class=\"line\">        <span class=\"comment\">// objectness target = 1</span></div><div class=\"line\">        l.delta[obj_index] = <span class=\"number\">1</span> - l.output[obj_index];</div><div class=\"line\">        <span class=\"keyword\">int</span> <span class=\"keyword\">class</span> = net.truth[t*(<span class=\"number\">4</span> + <span class=\"number\">1</span>) + b*l.truths + <span class=\"number\">4</span>];</div><div class=\"line\">        <span class=\"keyword\">if</span> (l.<span class=\"built_in\">map</span>) <span class=\"keyword\">class</span> = l.<span class=\"built_in\">map</span>[<span class=\"keyword\">class</span>];</div><div class=\"line\">        <span class=\"keyword\">int</span> class_index = entry_index(l, b, mask_n*l.w*l.h + j*l.w + i, <span class=\"number\">4</span> + <span class=\"number\">1</span>);</div><div class=\"line\">        delta_yolo_class(l.output, l.delta, class_index, <span class=\"keyword\">class</span>, l.classes, l.w*l.h, &amp;avg_cat);</div><div class=\"line\">        ++count;</div><div class=\"line\">        ++class_count;</div><div class=\"line\">        <span class=\"keyword\">if</span>(iou &gt; <span class=\"number\">.5</span>) recall += <span class=\"number\">1</span>;</div><div class=\"line\">        <span class=\"keyword\">if</span>(iou &gt; <span class=\"number\">.75</span>) recall75 += <span class=\"number\">1</span>;</div><div class=\"line\">        avg_iou += iou;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h2 id=\"Darknet\"><a href=\"#Darknet\" class=\"headerlink\" title=\"Darknet\"></a>Darknet</h2><p>ResidualNet$3\\times 3$$1\\times 1$shortcutDarknet-53<br><img src=\"/img/paper-yolov3-darknet53.png\" alt=\"darknet-63\"></p>\n<h2 id=\"YOLO\"><a href=\"#YOLO\" class=\"headerlink\" title=\"YOLO\"></a>YOLO</h2><p>YOLO v3IoUYOLO</p>\n<blockquote>\n<p>Russakovsky et al report that that humans have a hard time distinguishing an IOU of .3 from .5! Training humans to visually inspect a bounding box with IOU of 0.3 and distinguish it from one with IOU 0.5 is surprisingly difficult. [16] If humans have a hard time telling the difference, how much does it matter?</p>\n</blockquote>\n<p>v3mediumlarge</p>\n<p><br><img src=\"/img/paper-yolov3-comparisons.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>anchor box$(x, y)$anchor boxoffsetno stable</li>\n<li>offsetlogistic</li>\n<li>focal loss</li>\n<li>IoUFaster RCNN</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>YOLO<a href=\"https://pjreddie.com/darknet/yolo/\">Darknet YOLO</a></li>\n<li><a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\">paper</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/34945787\"></a></li>\n<li>FPN<a href=\"https://arxiv.org/abs/1612.03144\">Feature pyramid networks for object detection</a></li>\n<li><a href=\"https://www.zhihu.com/question/41540197\">AP</a></li>\n</ul>"},{"title":" - Visualizing and Understanding ConvNet","date":"2018-02-08T02:48:21.000Z","_content":"[Visualizing & Understanding ConvNet](https://arxiv.org/pdf/1311.2901.pdf)CNNAlexNet\n\n![](/img/paper_visconvnet_demo.png)\n<!-- more -->\n\n## \nAlexNetCNNImageNetAlextNet\n\n- Large data\n- GPU\n- Dropout\n\nCNNCNNinputFeature map\n\n(CNNCNN)\n\nAlexNet\n\n- $3D$\n- `ReLU(x) = max(0, x)`\n- Feature map\n- LRN\n\n## DeconvNet\nDeconvNet\n\nDeconvNet\n![DeconvNet](/img/paer_visconvnet_deconvnet_structure.png)\n\nfeature map$0$deconvNetlayer\n\n### Uppooling\nCNNmax poolingdeconvNetCNNmax poolingswitchesdeconvNetUppooing\n![Uppooling](/img/paper_visconvnet_uppooling.png)\n\n### Rectification\nCNNreludeconvNet\n\n### Filtering\nCNNfilterfeature mapdeconvNetdeconvfeature map\n\nactivationdeconvpixel space\n\n## CNN\nCNNAlexNetgrouplayer $1$filter size$11\\times 11$$7\\times 7$$2$\n\nImageNetvalidation\n\nlayer $1$$9\\times 9$$9\\times 9$$9$filtertop 9deconvNetimage patchlayer 1filter$9$\n![layer 1](/img/paper_visconvnet_layer1_demo.png)\n\n\n## \nCNN\n\n- Zeilertalk[Visualizing and Understanding Deep Neural Networks by Matt Zeiler](https://www.youtube.com/watch?v=ghEmQSxT6tw)\n- CS231[Visualizing what ConvNets learn](http://cs231n.github.io/understanding-cnn/)\n- ICML 2015CNNpaper[Understanding Neural Networks Through Deep Visualization](https://arxiv.org/pdf/1506.06579.pdf)[deep-visualization-toolbox\n](https://github.com/yosinski/deep-visualization-toolbox)\n- [Deep Visualization:CNN](https://zhuanlan.zhihu.com/p/24833574)","source":"_posts/paper-visualize-convnet.md","raw":"---\ntitle:  - Visualizing and Understanding ConvNet\ndate: 2018-02-08 10:48:21\ntags:\n    - paper\n    - deep learning\n    - visulization\n---\n[Visualizing & Understanding ConvNet](https://arxiv.org/pdf/1311.2901.pdf)CNNAlexNet\n\n![](/img/paper_visconvnet_demo.png)\n<!-- more -->\n\n## \nAlexNetCNNImageNetAlextNet\n\n- Large data\n- GPU\n- Dropout\n\nCNNCNNinputFeature map\n\n(CNNCNN)\n\nAlexNet\n\n- $3D$\n- `ReLU(x) = max(0, x)`\n- Feature map\n- LRN\n\n## DeconvNet\nDeconvNet\n\nDeconvNet\n![DeconvNet](/img/paer_visconvnet_deconvnet_structure.png)\n\nfeature map$0$deconvNetlayer\n\n### Uppooling\nCNNmax poolingdeconvNetCNNmax poolingswitchesdeconvNetUppooing\n![Uppooling](/img/paper_visconvnet_uppooling.png)\n\n### Rectification\nCNNreludeconvNet\n\n### Filtering\nCNNfilterfeature mapdeconvNetdeconvfeature map\n\nactivationdeconvpixel space\n\n## CNN\nCNNAlexNetgrouplayer $1$filter size$11\\times 11$$7\\times 7$$2$\n\nImageNetvalidation\n\nlayer $1$$9\\times 9$$9\\times 9$$9$filtertop 9deconvNetimage patchlayer 1filter$9$\n![layer 1](/img/paper_visconvnet_layer1_demo.png)\n\n\n## \nCNN\n\n- Zeilertalk[Visualizing and Understanding Deep Neural Networks by Matt Zeiler](https://www.youtube.com/watch?v=ghEmQSxT6tw)\n- CS231[Visualizing what ConvNets learn](http://cs231n.github.io/understanding-cnn/)\n- ICML 2015CNNpaper[Understanding Neural Networks Through Deep Visualization](https://arxiv.org/pdf/1506.06579.pdf)[deep-visualization-toolbox\n](https://github.com/yosinski/deep-visualization-toolbox)\n- [Deep Visualization:CNN](https://zhuanlan.zhihu.com/p/24833574)","slug":"paper-visualize-convnet","published":1,"updated":"2018-10-27T07:16:52.411Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nt003fae7b4i9vmrlx","content":"<p><a href=\"https://arxiv.org/pdf/1311.2901.pdf\" target=\"_blank\" rel=\"external\">Visualizing &amp; Understanding ConvNet</a>CNNAlexNet</p>\n<p><img src=\"/img/paper_visconvnet_demo.png\" alt=\"\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>AlexNetCNNImageNetAlextNet</p>\n<ul>\n<li>Large data</li>\n<li>GPU</li>\n<li>Dropout</li>\n</ul>\n<p>CNNCNNinputFeature map</p>\n<p>(CNNCNN)</p>\n<p>AlexNet</p>\n<ul>\n<li>$3D$</li>\n<li><code>ReLU(x) = max(0, x)</code></li>\n<li>Feature map</li>\n<li>LRN</li>\n</ul>\n<h2 id=\"DeconvNet\"><a href=\"#DeconvNet\" class=\"headerlink\" title=\"DeconvNet\"></a>DeconvNet</h2><p>DeconvNet</p>\n<p>DeconvNet<br><img src=\"/img/paer_visconvnet_deconvnet_structure.png\" alt=\"DeconvNet\"></p>\n<p>feature map$0$deconvNetlayer</p>\n<h3 id=\"Uppooling\"><a href=\"#Uppooling\" class=\"headerlink\" title=\"Uppooling\"></a>Uppooling</h3><p>CNNmax poolingdeconvNetCNNmax poolingswitchesdeconvNetUppooing<br><img src=\"/img/paper_visconvnet_uppooling.png\" alt=\"Uppooling\"></p>\n<h3 id=\"Rectification\"><a href=\"#Rectification\" class=\"headerlink\" title=\"Rectification\"></a>Rectification</h3><p>CNNreludeconvNet</p>\n<h3 id=\"Filtering\"><a href=\"#Filtering\" class=\"headerlink\" title=\"Filtering\"></a>Filtering</h3><p>CNNfilterfeature mapdeconvNetdeconvfeature map</p>\n<p>activationdeconvpixel space</p>\n<h2 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h2><p>CNNAlexNetgrouplayer $1$filter size$11\\times 11$$7\\times 7$$2$</p>\n<p>ImageNetvalidation</p>\n<p>layer $1$$9\\times 9$$9\\times 9$$9$filtertop 9deconvNetimage patchlayer 1filter$9$<br><img src=\"/img/paper_visconvnet_layer1_demo.png\" alt=\"layer 1\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CNN</p>\n<ul>\n<li>Zeilertalk<a href=\"https://www.youtube.com/watch?v=ghEmQSxT6tw\" target=\"_blank\" rel=\"external\">Visualizing and Understanding Deep Neural Networks by Matt Zeiler</a></li>\n<li>CS231<a href=\"http://cs231n.github.io/understanding-cnn/\" target=\"_blank\" rel=\"external\">Visualizing what ConvNets learn</a></li>\n<li>ICML 2015CNNpaper<a href=\"https://arxiv.org/pdf/1506.06579.pdf\" target=\"_blank\" rel=\"external\">Understanding Neural Networks Through Deep Visualization</a><a href=\"https://github.com/yosinski/deep-visualization-toolbox\" target=\"_blank\" rel=\"external\">deep-visualization-toolbox\n</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/24833574\" target=\"_blank\" rel=\"external\">Deep Visualization:CNN</a></li>\n</ul>\n","excerpt":"<p><a href=\"https://arxiv.org/pdf/1311.2901.pdf\">Visualizing &amp; Understanding ConvNet</a>CNNAlexNet</p>\n<p><img src=\"/img/paper_visconvnet_demo.png\" alt=\"\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>AlexNetCNNImageNetAlextNet</p>\n<ul>\n<li>Large data</li>\n<li>GPU</li>\n<li>Dropout</li>\n</ul>\n<p>CNNCNNinputFeature map</p>\n<p>(CNNCNN)</p>\n<p>AlexNet</p>\n<ul>\n<li>$3D$</li>\n<li><code>ReLU(x) = max(0, x)</code></li>\n<li>Feature map</li>\n<li>LRN</li>\n</ul>\n<h2 id=\"DeconvNet\"><a href=\"#DeconvNet\" class=\"headerlink\" title=\"DeconvNet\"></a>DeconvNet</h2><p>DeconvNet</p>\n<p>DeconvNet<br><img src=\"/img/paer_visconvnet_deconvnet_structure.png\" alt=\"DeconvNet\"></p>\n<p>feature map$0$deconvNetlayer</p>\n<h3 id=\"Uppooling\"><a href=\"#Uppooling\" class=\"headerlink\" title=\"Uppooling\"></a>Uppooling</h3><p>CNNmax poolingdeconvNetCNNmax poolingswitchesdeconvNetUppooing<br><img src=\"/img/paper_visconvnet_uppooling.png\" alt=\"Uppooling\"></p>\n<h3 id=\"Rectification\"><a href=\"#Rectification\" class=\"headerlink\" title=\"Rectification\"></a>Rectification</h3><p>CNNreludeconvNet</p>\n<h3 id=\"Filtering\"><a href=\"#Filtering\" class=\"headerlink\" title=\"Filtering\"></a>Filtering</h3><p>CNNfilterfeature mapdeconvNetdeconvfeature map</p>\n<p>activationdeconvpixel space</p>\n<h2 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h2><p>CNNAlexNetgrouplayer $1$filter size$11\\times 11$$7\\times 7$$2$</p>\n<p>ImageNetvalidation</p>\n<p>layer $1$$9\\times 9$$9\\times 9$$9$filtertop 9deconvNetimage patchlayer 1filter$9$<br><img src=\"/img/paper_visconvnet_layer1_demo.png\" alt=\"layer 1\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CNN</p>\n<ul>\n<li>Zeilertalk<a href=\"https://www.youtube.com/watch?v=ghEmQSxT6tw\">Visualizing and Understanding Deep Neural Networks by Matt Zeiler</a></li>\n<li>CS231<a href=\"http://cs231n.github.io/understanding-cnn/\">Visualizing what ConvNets learn</a></li>\n<li>ICML 2015CNNpaper<a href=\"https://arxiv.org/pdf/1506.06579.pdf\">Understanding Neural Networks Through Deep Visualization</a><a href=\"https://github.com/yosinski/deep-visualization-toolbox\">deep-visualization-toolbox\n</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/24833574\">Deep Visualization:CNN</a></li>\n</ul>"},{"title":"Python Regular Expressions Python )","date":"2014-07-17T11:00:00.000Z","_content":"\nGoogle DevelopersPython[https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions \"Google Python Class, Regular Expression\")\n\n![regex](/img/regex_picture.jpg)\n<!-- more -->\n\n## \n\nPython **re **\n\n``` py    \n    match = re.search(pattern,str)\n    if match:\n    \tprint 'found',match.group()\n    else:\n        print 'NOT Found!'\n```\n\n## \n\n### \n- a, x, 9  (ordinary characters)\n- . ()'\\n'\n- \\ww [a-zA-Z0-9_];\\W W\n- \\b \n- \\ss whitespace character spacenewlinereturntabform(\\n\\r\\t\\f)\\SS whitespace character\n- \\d  [0-9]\n- ^=start$=end \n- \\  \\. '.'\n### \n\n``` py\n    ## 'piiig''iii'\n    match = re.search(r'iii', 'piiig')  # found, match.group() == \"iii\"\n    match = re.search(r'igs', 'piiig')  #  not found, match == None\n\n    ## . \\n\n    match = re.search(r'..g', 'piiig')  #  found, match.group() == \"iig\"\n\n    ## \\d 0-9, \\w \n    match = re.search(r'\\d\\d\\d', 'p123g') #  found, match.group() == \"123\"\n    match = re.search(r'\\w\\w\\w', '@@abcd!!') #  found, match.group() == \"abc\"   \n```\n\n### \n'+' '*' '?'01\n\n- '+' 1\n- '*' 0\n- '?' 01\n\n'+''*'\n\n### \n\n``` py\n    ## i+  1'i'\n    match = re.search(r'pi+', 'piiig') #  found, match.group() == \"piii\"\n\n    ## \n    ##  'i+'\n    match = re.search(r'i+', 'piigiiii')  #  found, match.group() == \"ii\"\n\n    ## \\s*  01 whitespace\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2   3xx')  #  found, match.group() == \"1 2   3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx12  3xx')    #  found, match.group() == \"12  3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx123xx')      # found, match.group() == \"123\"\n\n    ## ^ \n    match = re.search(r'^b\\w+', 'foobar')  # not found, match == None\n    ## \n    match = re.search(r'b\\w+', 'foobar')   # found, match.group() == \"bar\"\n```\n\n### Email\nEmail`someone@host.com`\n\n```py\n    match = re.search(r'\\w+@\\w+',str)\n```\n\nEmail `xyz alice-b@google.com purple monkey`\n\n### \n[abc]'a''b''c'\\w \\s'.'Email\n\n``` py\n    match = re.search('r[\\w.-]+@[\\w.-]+',str)\n```\n\n'-'[a-z]'-'[ab-]'^'[^ab]'a''b'\n\n## \nEmail'someone''host.com'\n\n\n``` py\n    str = 'purple alice-b@google.com monkey dishwasher'\n    match = re.search('([\\w.-]+)@([\\w.-]+)', str)   #\n    if match:\n        print match.group()   ## 'alice-b@google.com' (the whole match)\n        print match.group(1)  ## 'alice-b' (the username, group 1)\n      \tprint match.group(2)  ## 'google.com' (the host, group 2)\n```\n\n### findall \ngroupfindall\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ## findall list\n    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', str) ## ['alice@google.com', 'bob@abc.com']\n    for email in emails:\n        print email\n```\n\n### findall\nfindall\n\n``` py\n\tf = open(filename.txt,'r')\n\tmatches = re.findall(pattern,f.read())\n```\n\n### findall \ngroup\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ##list\n    tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n    print tuples  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n    ##listtuple\n    for tuple in tuples:\n      print tuple[0]  ## username\n      print tuple[1]  ## host\n```\n\n## \n\n\n\n## \n\n\n\n``` py\n    match = re.search(pat,str,opt)\n```\n\n\n\n- IGNORECASE  \n- DOTALL  '.''\\n'\n- MULTILINE  '^''$'\n","source":"_posts/python-reg-exp.md","raw":"---\ntitle: Python Regular Expressions Python )\ndate: 2014-07-17 19:00:00\ntags:\n    - python\n---\n\nGoogle DevelopersPython[https://developers.google.com/edu/python/regular-expressions](https://developers.google.com/edu/python/regular-expressions \"Google Python Class, Regular Expression\")\n\n![regex](/img/regex_picture.jpg)\n<!-- more -->\n\n## \n\nPython **re **\n\n``` py    \n    match = re.search(pattern,str)\n    if match:\n    \tprint 'found',match.group()\n    else:\n        print 'NOT Found!'\n```\n\n## \n\n### \n- a, x, 9  (ordinary characters)\n- . ()'\\n'\n- \\ww [a-zA-Z0-9_];\\W W\n- \\b \n- \\ss whitespace character spacenewlinereturntabform(\\n\\r\\t\\f)\\SS whitespace character\n- \\d  [0-9]\n- ^=start$=end \n- \\  \\. '.'\n### \n\n``` py\n    ## 'piiig''iii'\n    match = re.search(r'iii', 'piiig')  # found, match.group() == \"iii\"\n    match = re.search(r'igs', 'piiig')  #  not found, match == None\n\n    ## . \\n\n    match = re.search(r'..g', 'piiig')  #  found, match.group() == \"iig\"\n\n    ## \\d 0-9, \\w \n    match = re.search(r'\\d\\d\\d', 'p123g') #  found, match.group() == \"123\"\n    match = re.search(r'\\w\\w\\w', '@@abcd!!') #  found, match.group() == \"abc\"   \n```\n\n### \n'+' '*' '?'01\n\n- '+' 1\n- '*' 0\n- '?' 01\n\n'+''*'\n\n### \n\n``` py\n    ## i+  1'i'\n    match = re.search(r'pi+', 'piiig') #  found, match.group() == \"piii\"\n\n    ## \n    ##  'i+'\n    match = re.search(r'i+', 'piigiiii')  #  found, match.group() == \"ii\"\n\n    ## \\s*  01 whitespace\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2   3xx')  #  found, match.group() == \"1 2   3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx12  3xx')    #  found, match.group() == \"12  3\"\n    match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx123xx')      # found, match.group() == \"123\"\n\n    ## ^ \n    match = re.search(r'^b\\w+', 'foobar')  # not found, match == None\n    ## \n    match = re.search(r'b\\w+', 'foobar')   # found, match.group() == \"bar\"\n```\n\n### Email\nEmail`someone@host.com`\n\n```py\n    match = re.search(r'\\w+@\\w+',str)\n```\n\nEmail `xyz alice-b@google.com purple monkey`\n\n### \n[abc]'a''b''c'\\w \\s'.'Email\n\n``` py\n    match = re.search('r[\\w.-]+@[\\w.-]+',str)\n```\n\n'-'[a-z]'-'[ab-]'^'[^ab]'a''b'\n\n## \nEmail'someone''host.com'\n\n\n``` py\n    str = 'purple alice-b@google.com monkey dishwasher'\n    match = re.search('([\\w.-]+)@([\\w.-]+)', str)   #\n    if match:\n        print match.group()   ## 'alice-b@google.com' (the whole match)\n        print match.group(1)  ## 'alice-b' (the username, group 1)\n      \tprint match.group(2)  ## 'google.com' (the host, group 2)\n```\n\n### findall \ngroupfindall\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ## findall list\n    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', str) ## ['alice@google.com', 'bob@abc.com']\n    for email in emails:\n        print email\n```\n\n### findall\nfindall\n\n``` py\n\tf = open(filename.txt,'r')\n\tmatches = re.findall(pattern,f.read())\n```\n\n### findall \ngroup\n\n``` py\n    str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n    ##list\n    tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n    print tuples  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n    ##listtuple\n    for tuple in tuples:\n      print tuple[0]  ## username\n      print tuple[1]  ## host\n```\n\n## \n\n\n\n## \n\n\n\n``` py\n    match = re.search(pat,str,opt)\n```\n\n\n\n- IGNORECASE  \n- DOTALL  '.''\\n'\n- MULTILINE  '^''$'\n","slug":"python-reg-exp","published":1,"updated":"2018-10-27T07:16:52.413Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nv003hae7bi3wt3pm0","content":"<p>Google DevelopersPython<a href=\"https://developers.google.com/edu/python/regular-expressions\" title=\"Google Python Class, Regular Expression\" target=\"_blank\" rel=\"external\">https://developers.google.com/edu/python/regular-expressions</a></p>\n<p><img src=\"/img/regex_picture.jpg\" alt=\"regex\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Python <strong>re </strong></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pattern,str)</div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">\t<span class=\"keyword\">print</span> <span class=\"string\">'found'</span>,match.group()</div><div class=\"line\"><span class=\"keyword\">else</span>:</div><div class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'NOT Found!'</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>a, x, 9  (ordinary characters)</li>\n<li>. ()\\n</li>\n<li>\\ww [a-zA-Z0-9_];\\W W</li>\n<li>\\b </li>\n<li>\\ss whitespace character spacenewlinereturntabform(\\n\\r\\t\\f)\\SS whitespace character</li>\n<li>\\d  [0-9]</li>\n<li>^=start$=end </li>\n<li>\\  . .<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3></li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## 'piiig''iii'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'iii'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\"># found, match.group() == \"iii\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'igs'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  not found, match == None</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## . \\n</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'..g'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  found, match.group() == \"iig\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\d 0-9, \\w </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\d\\d'</span>, <span class=\"string\">'p123g'</span>) <span class=\"comment\">#  found, match.group() == \"123\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\w\\w\\w'</span>, <span class=\"string\">'@@abcd!!'</span>) <span class=\"comment\">#  found, match.group() == \"abc\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>+ * ?01</p>\n<ul>\n<li>+ 1</li>\n<li>* 0</li>\n<li>? 01</li>\n</ul>\n<p>+*</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## i+  1'i'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'pi+'</span>, <span class=\"string\">'piiig'</span>) <span class=\"comment\">#  found, match.group() == \"piii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\"><span class=\"comment\">##  'i+'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'i+'</span>, <span class=\"string\">'piigiiii'</span>)  <span class=\"comment\">#  found, match.group() == \"ii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\s*  01 whitespace</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx1 2   3xx'</span>)  <span class=\"comment\">#  found, match.group() == \"1 2   3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx12  3xx'</span>)    <span class=\"comment\">#  found, match.group() == \"12  3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx123xx'</span>)      <span class=\"comment\"># found, match.group() == \"123\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## ^ </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'^b\\w+'</span>, <span class=\"string\">'foobar'</span>)  <span class=\"comment\"># not found, match == None</span></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'b\\w+'</span>, <span class=\"string\">'foobar'</span>)   <span class=\"comment\"># found, match.group() == \"bar\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"Email\"><a href=\"#Email\" class=\"headerlink\" title=\"Email\"></a>Email</h3><p>Email<code>someone@host.com</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(<span class=\"string\">r'\\w+@\\w+'</span>,str)</div></pre></td></tr></table></figure>\n<p>Email <code>xyz alice-b@google.com purple monkey</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>[abc]abc\\w \\s.Email</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(<span class=\"string\">'r[\\w.-]+@[\\w.-]+'</span>,str)</div></pre></td></tr></table></figure>\n<p>-[a-z]-[ab-]^<sup><a href=\"#fn_ab\" id=\"reffn_ab\">ab</a></sup>ab</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Emailsomeonehost.com<br></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice-b@google.com monkey dishwasher'</span></div><div class=\"line\">match = re.search(<span class=\"string\">'([\\w.-]+)@([\\w.-]+)'</span>, str)   <span class=\"comment\">#</span></div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">    <span class=\"keyword\">print</span> match.group()   <span class=\"comment\">## 'alice-b@google.com' (the whole match)</span></div><div class=\"line\">    <span class=\"keyword\">print</span> match.group(<span class=\"number\">1</span>)  <span class=\"comment\">## 'alice-b' (the username, group 1)</span></div><div class=\"line\">  \t<span class=\"keyword\">print</span> match.group(<span class=\"number\">2</span>)  <span class=\"comment\">## 'google.com' (the host, group 2)</span></div></pre></td></tr></table></figure>\n<h3 id=\"findall-\"><a href=\"#findall-\" class=\"headerlink\" title=\"findall \"></a>findall </h3><p>groupfindall</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">## findall list</span></div><div class=\"line\">emails = re.findall(<span class=\"string\">r'[\\w\\.-]+@[\\w\\.-]+'</span>, str) <span class=\"comment\">## ['alice@google.com', 'bob@abc.com']</span></div><div class=\"line\"><span class=\"keyword\">for</span> email <span class=\"keyword\">in</span> emails:</div><div class=\"line\">    <span class=\"keyword\">print</span> email</div></pre></td></tr></table></figure>\n<h3 id=\"findall\"><a href=\"#findall\" class=\"headerlink\" title=\"findall\"></a>findall</h3><p>findall</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">f = open(filename.txt,<span class=\"string\">'r'</span>)</div><div class=\"line\">matches = re.findall(pattern,f.read())</div></pre></td></tr></table></figure>\n<h3 id=\"findall-\"><a href=\"#findall-\" class=\"headerlink\" title=\"findall \"></a>findall </h3><p>group</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">##list</span></div><div class=\"line\">tuples = re.findall(<span class=\"string\">r'([\\w\\.-]+)@([\\w\\.-]+)'</span>, str)</div><div class=\"line\"><span class=\"keyword\">print</span> tuples  <span class=\"comment\">## [('alice', 'google.com'), ('bob', 'abc.com')]</span></div><div class=\"line\"><span class=\"comment\">##listtuple</span></div><div class=\"line\"><span class=\"keyword\">for</span> tuple <span class=\"keyword\">in</span> tuples:</div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">0</span>]  <span class=\"comment\">## username</span></div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">1</span>]  <span class=\"comment\">## host</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pat,str,opt)</div></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>IGNORECASE  </li>\n<li>DOTALL  .\\n</li>\n<li>MULTILINE  ^$</li>\n</ul>\n","excerpt":"<p>Google DevelopersPython<a href=\"https://developers.google.com/edu/python/regular-expressions\" title=\"Google Python Class, Regular Expression\">https://developers.google.com/edu/python/regular-expressions</a></p>\n<p><img src=\"/img/regex_picture.jpg\" alt=\"regex\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Python <strong>re </strong></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pattern,str)</div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">\t<span class=\"keyword\">print</span> <span class=\"string\">'found'</span>,match.group()</div><div class=\"line\"><span class=\"keyword\">else</span>:</div><div class=\"line\">    <span class=\"keyword\">print</span> <span class=\"string\">'NOT Found!'</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>a, x, 9  (ordinary characters)</li>\n<li>. ()\\n</li>\n<li>\\ww [a-zA-Z0-9_];\\W W</li>\n<li>\\b </li>\n<li>\\ss whitespace character spacenewlinereturntabform(\\n\\r\\t\\f)\\SS whitespace character</li>\n<li>\\d  [0-9]</li>\n<li>^=start$=end </li>\n<li>\\  . .<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3></li>\n</ul>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## 'piiig''iii'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'iii'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\"># found, match.group() == \"iii\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'igs'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  not found, match == None</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## . \\n</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'..g'</span>, <span class=\"string\">'piiig'</span>)  <span class=\"comment\">#  found, match.group() == \"iig\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\d 0-9, \\w </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\d\\d'</span>, <span class=\"string\">'p123g'</span>) <span class=\"comment\">#  found, match.group() == \"123\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\w\\w\\w'</span>, <span class=\"string\">'@@abcd!!'</span>) <span class=\"comment\">#  found, match.group() == \"abc\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>+ * ?01</p>\n<ul>\n<li>+ 1</li>\n<li>* 0</li>\n<li>? 01</li>\n</ul>\n<p>+*</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## i+  1'i'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'pi+'</span>, <span class=\"string\">'piiig'</span>) <span class=\"comment\">#  found, match.group() == \"piii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\"><span class=\"comment\">##  'i+'</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'i+'</span>, <span class=\"string\">'piigiiii'</span>)  <span class=\"comment\">#  found, match.group() == \"ii\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## \\s*  01 whitespace</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx1 2   3xx'</span>)  <span class=\"comment\">#  found, match.group() == \"1 2   3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx12  3xx'</span>)    <span class=\"comment\">#  found, match.group() == \"12  3\"</span></div><div class=\"line\">match = re.search(<span class=\"string\">r'\\d\\s*\\d\\s*\\d'</span>, <span class=\"string\">'xx123xx'</span>)      <span class=\"comment\"># found, match.group() == \"123\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## ^ </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'^b\\w+'</span>, <span class=\"string\">'foobar'</span>)  <span class=\"comment\"># not found, match == None</span></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\">match = re.search(<span class=\"string\">r'b\\w+'</span>, <span class=\"string\">'foobar'</span>)   <span class=\"comment\"># found, match.group() == \"bar\"</span></div></pre></td></tr></table></figure>\n<h3 id=\"Email\"><a href=\"#Email\" class=\"headerlink\" title=\"Email\"></a>Email</h3><p>Email<code>someone@host.com</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(<span class=\"string\">r'\\w+@\\w+'</span>,str)</div></pre></td></tr></table></figure>\n<p>Email <code>xyz alice-b@google.com purple monkey</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>[abc]abc\\w \\s.Email</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(<span class=\"string\">'r[\\w.-]+@[\\w.-]+'</span>,str)</div></pre></td></tr></table></figure>\n<p>-[a-z]-[ab-]^<sup><a href=\"#fn_ab\" id=\"reffn_ab\">ab</a></sup>ab</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Emailsomeonehost.com<br></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice-b@google.com monkey dishwasher'</span></div><div class=\"line\">match = re.search(<span class=\"string\">'([\\w.-]+)@([\\w.-]+)'</span>, str)   <span class=\"comment\">#</span></div><div class=\"line\"><span class=\"keyword\">if</span> match:</div><div class=\"line\">    <span class=\"keyword\">print</span> match.group()   <span class=\"comment\">## 'alice-b@google.com' (the whole match)</span></div><div class=\"line\">    <span class=\"keyword\">print</span> match.group(<span class=\"number\">1</span>)  <span class=\"comment\">## 'alice-b' (the username, group 1)</span></div><div class=\"line\">  \t<span class=\"keyword\">print</span> match.group(<span class=\"number\">2</span>)  <span class=\"comment\">## 'google.com' (the host, group 2)</span></div></pre></td></tr></table></figure>\n<h3 id=\"findall-\"><a href=\"#findall-\" class=\"headerlink\" title=\"findall \"></a>findall </h3><p>groupfindall</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">## findall list</span></div><div class=\"line\">emails = re.findall(<span class=\"string\">r'[\\w\\.-]+@[\\w\\.-]+'</span>, str) <span class=\"comment\">## ['alice@google.com', 'bob@abc.com']</span></div><div class=\"line\"><span class=\"keyword\">for</span> email <span class=\"keyword\">in</span> emails:</div><div class=\"line\">    <span class=\"keyword\">print</span> email</div></pre></td></tr></table></figure>\n<h3 id=\"findall\"><a href=\"#findall\" class=\"headerlink\" title=\"findall\"></a>findall</h3><p>findall</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">f = open(filename.txt,<span class=\"string\">'r'</span>)</div><div class=\"line\">matches = re.findall(pattern,f.read())</div></pre></td></tr></table></figure>\n<h3 id=\"findall-\"><a href=\"#findall-\" class=\"headerlink\" title=\"findall \"></a>findall </h3><p>group</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">str = <span class=\"string\">'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'</span></div><div class=\"line\"><span class=\"comment\">##list</span></div><div class=\"line\">tuples = re.findall(<span class=\"string\">r'([\\w\\.-]+)@([\\w\\.-]+)'</span>, str)</div><div class=\"line\"><span class=\"keyword\">print</span> tuples  <span class=\"comment\">## [('alice', 'google.com'), ('bob', 'abc.com')]</span></div><div class=\"line\"><span class=\"comment\">##listtuple</span></div><div class=\"line\"><span class=\"keyword\">for</span> tuple <span class=\"keyword\">in</span> tuples:</div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">0</span>]  <span class=\"comment\">## username</span></div><div class=\"line\">  <span class=\"keyword\">print</span> tuple[<span class=\"number\">1</span>]  <span class=\"comment\">## host</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">match = re.search(pat,str,opt)</div></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>IGNORECASE  </li>\n<li>DOTALL  .\\n</li>\n<li>MULTILINE  ^$</li>\n</ul>"},{"title":"Python","date":"2017-04-21T07:53:23.000Z","_content":"STLPythonPython/[Iterators & Generators](http://anandology.com/python-practice-book/iterators.html)\n\n<!-- more -->\n\n## \n`for`\n\n``` py\nfor i in range(100):\n    # do something 100 times\n```\n\nPythonIterable Object`key`\n\n`list()``tuple()`\n\n``` py\nlist({'x':1, 'y':2})  # => ['x', 'y']\n```\n\n`list``str``for x in XXX`\n\nPython`iter()``next()``iter()``__iter__()``next()`Python3`__next__()`\n\n`yrange_iter``yrange``yrange``__iter__()``iter(yrange object)``yrange_iter`\n\n``` py\n# Version 1.0 \nclass yrange_iter(object):\n    def __init__(self, yrange):\n        self.n = yrange.n\n        self.i = 0\n    def next(self):\n        v = self.i\n        self.i += 1\n        return v\n\nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        return yrange_iter(self)\n\nprint type(iter(yrange(5))) # <class '__main__.yrange_iter'>\n```\n\n`next()`\n\n``` py\nIn [3]: yiter = iter(yrange(5))\n\nIn [4]: yiter.next()\nOut[4]: 0\n\nIn [5]: yiter.next()\nOut[5]: 1\n\nIn [6]: yiter.next()\nOut[6]: 2\n```\n\n`yrange_iter``yrange.__iter__()``yrange``__iter__()``next()`\n\n``` py\n# Version2.0 \nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        self.i = 0\n        return self\n    def next(self):\n        v = self.i\n        self.i += 1\n        return v\n\nIn [8]: yiter = iter(yrange(5))\n\nIn [9]: yiter.next()\nOut[9]: 0\n\nIn [10]: yiter.next()\nOut[10]: 1\n\nIn [11]: yiter.next()\nOut[11]: 2\n```\n\n`self.n`010\n\nPython`StopIteration`\n\n``` py\n# Version3.0 \nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        self.i = 0\n        return self\n    def next(self):\n        if self.i == self.n:\n            raise StopIteration\n        v = self.i\n        self.i += 1\n        return v\n\nfor i in yrange(5):\n    print i\n```\n\n### Problem 1\nWrite an iterator class `reverse_iter`, that takes a `list` and iterates it from the reverse direction.\n\n``` py\nclass reverse_iter(object):\n    def __init__(self, alist):\n        self.container = alist\n        self.i = len(alist)\n\n    def next(self):\n        if self.i == 0:\n            raise StopIteration\n        self.i -= 1\n        return self.container[self.i]\nit = reverse_iter([1, 2, 3, 4])\n```\n\n## \n`yield``next()``yield``yield``return``next()`\n\n``` py\n>>> def foo():\n        print \"begin\"\n        for i in range(3):\n            print \"before yield\", i\n            yield i\n            print \"after yield\", i\n        print \"end\"\n\n>>> f = foo()\n>>> f.next()\nbegin\nbefore yield 0\n0\n>>> f.next()\nafter yield 0\nbefore yield 1\n1\n>>> f.next()\nafter yield 1\nbefore yield 2\n2\n>>> f.next()\nafter yield 2\nend\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nStopIteration\n>>>\n```\n\n### \n`[]``()`\n\n``` py\nfor i in (x**2 for x in [1,2,3,4]):\n    print i\n# print 1 4 9 16\n```\n\n\n\n10`take()``n``x`$[0, \\infty]$`break`\n\n``` py\ndef integer(start, end=None):\n    \"\"\"Generate integer sequence [start, end)\n       If `end` is not given, then [start, \\infty]\n    \"\"\"\n    i = start\n    while True:\n        if end is not None and i == end:\n            raise StopIteration\n        yield i\n        i += 1\n\ndef take(n, g):\n    i = 0\n    while True:\n        if i < n:\n            yield g.next()\n            i += 1\n        else:\n            raise StopIteration\n\n#  x>y>z10, 6, 810, 8, 6\ntup = ((x,y,z) for x in integer(0) for y in integer(0, x) for z in integer(0, y) if x*x==y*y+z*z)\nlist(take(10, tup))\n```\n\n### Problem 2\nWrite a program that takes one or more filenames as arguments and prints all the lines which are longer than 40 characters.\n\n``` py\ndef readfiles(filenames):\n    for f in filenames:\n        for line in open(f):\n            yield line\n\ndef grep(lines):\n    return (line for line in lines if len(line)>40)\n\ndef printlines(lines):\n    for line in lines:\n        print line,\n\ndef main(filenames):\n    lines = readfiles(filenames)\n    lines = grep(lines)\n    printlines(lines)\n```\n\n### Problem 3\nWrite a function `findfiles` that recursively descends the directory tree for the specified directory and generates paths of all the files in the tree.\n\n`get_all_file()`SO[](http://stackoverflow.com/questions/248830/python-using-a-recursive-algorithm-as-a-generator\n)\n\n``` py\nimport os\n\ndef generate_all_file(root):\n    for item in os.listdir(root):\n        item = os.path.join(root, item)\n        if os.path.isfile(item):\n            yield os.path.abspath(item)\n        else:\n            for item in generate_all_file(item):\n                yield item\n\ndef findfiles(root):\n    for item in generate_all_file(root):\n        print item\n```\n\n### Problem 4\nWrite a function to compute the number of python files (.py extension) in a specified directory recursively.\n\n``` py\ndef generate_all_py_file(root):\n    return (file for file in generate_all_file(root) if os.path.splitext(file)[-1] == '.py')\n\nprint len(list(generate_all_py_file('./')))\n```\n\n### Problem 5\nWrite a function to compute the total number of lines of code in all python files in the specified directory recursively.\n\n``` py\ndef generate_all_line(root):\n    return (line for f in generate_all_py_file(root) for line in open(f))\nprint len(list(generate_all_line('./')))\n```\n\n### Problem 6\nWrite a function to compute the total number of lines of code, ignoring empty and comment lines, in all python files in the specified directory recursively.\n\n``` py\ndef generate_all_no_empty_and_comment_line(root):\n    return (line for line in generate_all_line(root) if not (line=='' or line.startswith('#')))\n\nprint len(list(generate_all_no_empty_and_comment_line('./')))\n```\n\n### Problem 7\nWrite a program `split.py`, that takes an integer `n` and a `filename` as command line arguments and splits the `file` into multiple small files with each having `n` lines.\n\n``` py\ndef get_numbered_line(filename):\n    i = 0\n    for line in open(filename):\n        yield i, line\n        i += 1\n\ndef split(file_name, n):\n    i = 0\n    f = open('output-%d.txt' %i, 'w')\n    for idx, line in get_numbered_line(file_name):\n        f.write(line)\n        if (idx+1) % n == 0:\n            f.close()\n            i += 1\n            f = open('output-%d.txt' %i, 'w')\n\n    f.close()\n```\n\n### Problem 9\nThe built-in function `enumerate` takes an `iteratable` and returns an `iterator` over pairs ``(index, value)`` for each value in the source.\n\nWrite a function `my_enumerate` that works like `enumerate`.\n\n``` py\ndef my_enumerate(iterable):\n    i = 0\n    seq = iter(iterable)\n    while True:\n        val = seq.next()\n        yield i, val\n        i += 1\n```\n","source":"_posts/python-iter-generator.md","raw":"---\ntitle: Python\ndate: 2017-04-21 15:53:23\ntags:\n     - python\n---\nSTLPythonPython/[Iterators & Generators](http://anandology.com/python-practice-book/iterators.html)\n\n<!-- more -->\n\n## \n`for`\n\n``` py\nfor i in range(100):\n    # do something 100 times\n```\n\nPythonIterable Object`key`\n\n`list()``tuple()`\n\n``` py\nlist({'x':1, 'y':2})  # => ['x', 'y']\n```\n\n`list``str``for x in XXX`\n\nPython`iter()``next()``iter()``__iter__()``next()`Python3`__next__()`\n\n`yrange_iter``yrange``yrange``__iter__()``iter(yrange object)``yrange_iter`\n\n``` py\n# Version 1.0 \nclass yrange_iter(object):\n    def __init__(self, yrange):\n        self.n = yrange.n\n        self.i = 0\n    def next(self):\n        v = self.i\n        self.i += 1\n        return v\n\nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        return yrange_iter(self)\n\nprint type(iter(yrange(5))) # <class '__main__.yrange_iter'>\n```\n\n`next()`\n\n``` py\nIn [3]: yiter = iter(yrange(5))\n\nIn [4]: yiter.next()\nOut[4]: 0\n\nIn [5]: yiter.next()\nOut[5]: 1\n\nIn [6]: yiter.next()\nOut[6]: 2\n```\n\n`yrange_iter``yrange.__iter__()``yrange``__iter__()``next()`\n\n``` py\n# Version2.0 \nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        self.i = 0\n        return self\n    def next(self):\n        v = self.i\n        self.i += 1\n        return v\n\nIn [8]: yiter = iter(yrange(5))\n\nIn [9]: yiter.next()\nOut[9]: 0\n\nIn [10]: yiter.next()\nOut[10]: 1\n\nIn [11]: yiter.next()\nOut[11]: 2\n```\n\n`self.n`010\n\nPython`StopIteration`\n\n``` py\n# Version3.0 \nclass yrange(object):\n    def __init__(self, n):\n        self.n = n\n    def __iter__(self):\n        self.i = 0\n        return self\n    def next(self):\n        if self.i == self.n:\n            raise StopIteration\n        v = self.i\n        self.i += 1\n        return v\n\nfor i in yrange(5):\n    print i\n```\n\n### Problem 1\nWrite an iterator class `reverse_iter`, that takes a `list` and iterates it from the reverse direction.\n\n``` py\nclass reverse_iter(object):\n    def __init__(self, alist):\n        self.container = alist\n        self.i = len(alist)\n\n    def next(self):\n        if self.i == 0:\n            raise StopIteration\n        self.i -= 1\n        return self.container[self.i]\nit = reverse_iter([1, 2, 3, 4])\n```\n\n## \n`yield``next()``yield``yield``return``next()`\n\n``` py\n>>> def foo():\n        print \"begin\"\n        for i in range(3):\n            print \"before yield\", i\n            yield i\n            print \"after yield\", i\n        print \"end\"\n\n>>> f = foo()\n>>> f.next()\nbegin\nbefore yield 0\n0\n>>> f.next()\nafter yield 0\nbefore yield 1\n1\n>>> f.next()\nafter yield 1\nbefore yield 2\n2\n>>> f.next()\nafter yield 2\nend\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nStopIteration\n>>>\n```\n\n### \n`[]``()`\n\n``` py\nfor i in (x**2 for x in [1,2,3,4]):\n    print i\n# print 1 4 9 16\n```\n\n\n\n10`take()``n``x`$[0, \\infty]$`break`\n\n``` py\ndef integer(start, end=None):\n    \"\"\"Generate integer sequence [start, end)\n       If `end` is not given, then [start, \\infty]\n    \"\"\"\n    i = start\n    while True:\n        if end is not None and i == end:\n            raise StopIteration\n        yield i\n        i += 1\n\ndef take(n, g):\n    i = 0\n    while True:\n        if i < n:\n            yield g.next()\n            i += 1\n        else:\n            raise StopIteration\n\n#  x>y>z10, 6, 810, 8, 6\ntup = ((x,y,z) for x in integer(0) for y in integer(0, x) for z in integer(0, y) if x*x==y*y+z*z)\nlist(take(10, tup))\n```\n\n### Problem 2\nWrite a program that takes one or more filenames as arguments and prints all the lines which are longer than 40 characters.\n\n``` py\ndef readfiles(filenames):\n    for f in filenames:\n        for line in open(f):\n            yield line\n\ndef grep(lines):\n    return (line for line in lines if len(line)>40)\n\ndef printlines(lines):\n    for line in lines:\n        print line,\n\ndef main(filenames):\n    lines = readfiles(filenames)\n    lines = grep(lines)\n    printlines(lines)\n```\n\n### Problem 3\nWrite a function `findfiles` that recursively descends the directory tree for the specified directory and generates paths of all the files in the tree.\n\n`get_all_file()`SO[](http://stackoverflow.com/questions/248830/python-using-a-recursive-algorithm-as-a-generator\n)\n\n``` py\nimport os\n\ndef generate_all_file(root):\n    for item in os.listdir(root):\n        item = os.path.join(root, item)\n        if os.path.isfile(item):\n            yield os.path.abspath(item)\n        else:\n            for item in generate_all_file(item):\n                yield item\n\ndef findfiles(root):\n    for item in generate_all_file(root):\n        print item\n```\n\n### Problem 4\nWrite a function to compute the number of python files (.py extension) in a specified directory recursively.\n\n``` py\ndef generate_all_py_file(root):\n    return (file for file in generate_all_file(root) if os.path.splitext(file)[-1] == '.py')\n\nprint len(list(generate_all_py_file('./')))\n```\n\n### Problem 5\nWrite a function to compute the total number of lines of code in all python files in the specified directory recursively.\n\n``` py\ndef generate_all_line(root):\n    return (line for f in generate_all_py_file(root) for line in open(f))\nprint len(list(generate_all_line('./')))\n```\n\n### Problem 6\nWrite a function to compute the total number of lines of code, ignoring empty and comment lines, in all python files in the specified directory recursively.\n\n``` py\ndef generate_all_no_empty_and_comment_line(root):\n    return (line for line in generate_all_line(root) if not (line=='' or line.startswith('#')))\n\nprint len(list(generate_all_no_empty_and_comment_line('./')))\n```\n\n### Problem 7\nWrite a program `split.py`, that takes an integer `n` and a `filename` as command line arguments and splits the `file` into multiple small files with each having `n` lines.\n\n``` py\ndef get_numbered_line(filename):\n    i = 0\n    for line in open(filename):\n        yield i, line\n        i += 1\n\ndef split(file_name, n):\n    i = 0\n    f = open('output-%d.txt' %i, 'w')\n    for idx, line in get_numbered_line(file_name):\n        f.write(line)\n        if (idx+1) % n == 0:\n            f.close()\n            i += 1\n            f = open('output-%d.txt' %i, 'w')\n\n    f.close()\n```\n\n### Problem 9\nThe built-in function `enumerate` takes an `iteratable` and returns an `iterator` over pairs ``(index, value)`` for each value in the source.\n\nWrite a function `my_enumerate` that works like `enumerate`.\n\n``` py\ndef my_enumerate(iterable):\n    i = 0\n    seq = iter(iterable)\n    while True:\n        val = seq.next()\n        yield i, val\n        i += 1\n```\n","slug":"python-iter-generator","published":1,"updated":"2018-10-27T07:16:52.413Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8nx003kae7b80c4ps9h","content":"<p>STLPythonPython/<a href=\"http://anandology.com/python-practice-book/iterators.html\" target=\"_blank\" rel=\"external\">Iterators &amp; Generators</a></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>for</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</div><div class=\"line\">    <span class=\"comment\"># do something 100 times</span></div></pre></td></tr></table></figure>\n<p>PythonIterable Object<code>key</code></p>\n<p><code>list()</code><code>tuple()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">list(&#123;<span class=\"string\">'x'</span>:<span class=\"number\">1</span>, <span class=\"string\">'y'</span>:<span class=\"number\">2</span>&#125;)  <span class=\"comment\"># =&gt; ['x', 'y']</span></div></pre></td></tr></table></figure>\n<p><code>list</code><code>str</code><code>for x in XXX</code></p>\n<p>Python<code>iter()</code><code>next()</code><code>iter()</code><code>__iter__()</code><code>next()</code>Python3<code>__next__()</code></p>\n<p><code>yrange_iter</code><code>yrange</code><code>yrange</code><code>__iter__()</code><code>iter(yrange object)</code><code>yrange_iter</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version 1.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange_iter</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, yrange)</span>:</span></div><div class=\"line\">        self.n = yrange.n</div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> yrange_iter(self)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> type(iter(yrange(<span class=\"number\">5</span>))) <span class=\"comment\"># &lt;class '__main__.yrange_iter'&gt;</span></div></pre></td></tr></table></figure>\n<p><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">In [<span class=\"number\">3</span>]: yiter = iter(yrange(<span class=\"number\">5</span>))</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">4</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">4</span>]: <span class=\"number\">0</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">5</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">5</span>]: <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">6</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">6</span>]: <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p><code>yrange_iter</code><code>yrange.__iter__()</code><code>yrange</code><code>__iter__()</code><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version2.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">8</span>]: yiter = iter(yrange(<span class=\"number\">5</span>))</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">9</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">9</span>]: <span class=\"number\">0</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">10</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">10</span>]: <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">11</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">11</span>]: <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p><code>self.n</code>010</p>\n<p>Python<code>StopIteration</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version3.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.i == self.n:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> yrange(<span class=\"number\">5</span>):</div><div class=\"line\">    <span class=\"keyword\">print</span> i</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-1\"><a href=\"#Problem-1\" class=\"headerlink\" title=\"Problem 1\"></a>Problem 1</h3><p>Write an iterator class <code>reverse_iter</code>, that takes a <code>list</code> and iterates it from the reverse direction.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">reverse_iter</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, alist)</span>:</span></div><div class=\"line\">        self.container = alist</div><div class=\"line\">        self.i = len(alist)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.i == <span class=\"number\">0</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        self.i -= <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self.container[self.i]</div><div class=\"line\">it = reverse_iter([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>])</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>yield</code><code>next()</code><code>yield</code><code>yield</code><code>return</code><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">()</span>:</span></div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"begin\"</span></div><div class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">3</span>):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"before yield\"</span>, i</div><div class=\"line\">            <span class=\"keyword\">yield</span> i</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"after yield\"</span>, i</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"end\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f = foo()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">begin</div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">0</span></div><div class=\"line\"><span class=\"number\">0</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">0</span></div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">1</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">1</span></div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">2</span></div><div class=\"line\"><span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">2</span></div><div class=\"line\">end</div><div class=\"line\">Traceback (most recent call last):</div><div class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</div><div class=\"line\">StopIteration</div><div class=\"line\">&gt;&gt;&gt;</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>[]</code><code>()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> (x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]):</div><div class=\"line\">    <span class=\"keyword\">print</span> i</div><div class=\"line\"><span class=\"comment\"># print 1 4 9 16</span></div></pre></td></tr></table></figure>\n<p></p>\n<p>10<code>take()</code><code>n</code><code>x</code>$[0, \\infty]$<code>break</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">integer</span><span class=\"params\">(start, end=None)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"Generate integer sequence [start, end)</span></div><div class=\"line\">       If `end` is not given, then [start, \\infty]</div><div class=\"line\">    \"\"\"</div><div class=\"line\">    i = start</div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        <span class=\"keyword\">if</span> end <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span> <span class=\"keyword\">and</span> i == end:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        <span class=\"keyword\">yield</span> i</div><div class=\"line\">        i += <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">take</span><span class=\"params\">(n, g)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        <span class=\"keyword\">if</span> i &lt; n:</div><div class=\"line\">            <span class=\"keyword\">yield</span> g.next()</div><div class=\"line\">            i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#  x&gt;y&gt;z10, 6, 810, 8, 6</span></div><div class=\"line\">tup = ((x,y,z) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>) <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>, x) <span class=\"keyword\">for</span> z <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>, y) <span class=\"keyword\">if</span> x*x==y*y+z*z)</div><div class=\"line\">list(take(<span class=\"number\">10</span>, tup))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-2\"><a href=\"#Problem-2\" class=\"headerlink\" title=\"Problem 2\"></a>Problem 2</h3><p>Write a program that takes one or more filenames as arguments and prints all the lines which are longer than 40 characters.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readfiles</span><span class=\"params\">(filenames)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> filenames:</div><div class=\"line\">        <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(f):</div><div class=\"line\">            <span class=\"keyword\">yield</span> line</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(lines)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines <span class=\"keyword\">if</span> len(line)&gt;<span class=\"number\">40</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printlines</span><span class=\"params\">(lines)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines:</div><div class=\"line\">        <span class=\"keyword\">print</span> line,</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(filenames)</span>:</span></div><div class=\"line\">    lines = readfiles(filenames)</div><div class=\"line\">    lines = grep(lines)</div><div class=\"line\">    printlines(lines)</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-3\"><a href=\"#Problem-3\" class=\"headerlink\" title=\"Problem 3\"></a>Problem 3</h3><p>Write a function <code>findfiles</code> that recursively descends the directory tree for the specified directory and generates paths of all the files in the tree.</p>\n<p><code>get_all_file()</code>SO<a href=\"http://stackoverflow.com/questions/248830/python-using-a-recursive-algorithm-as-a-generator\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> os</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_file</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> os.listdir(root):</div><div class=\"line\">        item = os.path.join(root, item)</div><div class=\"line\">        <span class=\"keyword\">if</span> os.path.isfile(item):</div><div class=\"line\">            <span class=\"keyword\">yield</span> os.path.abspath(item)</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> generate_all_file(item):</div><div class=\"line\">                <span class=\"keyword\">yield</span> item</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">findfiles</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> generate_all_file(root):</div><div class=\"line\">        <span class=\"keyword\">print</span> item</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-4\"><a href=\"#Problem-4\" class=\"headerlink\" title=\"Problem 4\"></a>Problem 4</h3><p>Write a function to compute the number of python files (.py extension) in a specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_py_file</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (file <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> generate_all_file(root) <span class=\"keyword\">if</span> os.path.splitext(file)[<span class=\"number\">-1</span>] == <span class=\"string\">'.py'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_py_file(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-5\"><a href=\"#Problem-5\" class=\"headerlink\" title=\"Problem 5\"></a>Problem 5</h3><p>Write a function to compute the total number of lines of code in all python files in the specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_line</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> generate_all_py_file(root) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(f))</div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_line(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-6\"><a href=\"#Problem-6\" class=\"headerlink\" title=\"Problem 6\"></a>Problem 6</h3><p>Write a function to compute the total number of lines of code, ignoring empty and comment lines, in all python files in the specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_no_empty_and_comment_line</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> generate_all_line(root) <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> (line==<span class=\"string\">''</span> <span class=\"keyword\">or</span> line.startswith(<span class=\"string\">'#'</span>)))</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_no_empty_and_comment_line(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-7\"><a href=\"#Problem-7\" class=\"headerlink\" title=\"Problem 7\"></a>Problem 7</h3><p>Write a program <code>split.py</code>, that takes an integer <code>n</code> and a <code>filename</code> as command line arguments and splits the <code>file</code> into multiple small files with each having <code>n</code> lines.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_numbered_line</span><span class=\"params\">(filename)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(filename):</div><div class=\"line\">        <span class=\"keyword\">yield</span> i, line</div><div class=\"line\">        i += <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">split</span><span class=\"params\">(file_name, n)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    f = open(<span class=\"string\">'output-%d.txt'</span> %i, <span class=\"string\">'w'</span>)</div><div class=\"line\">    <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> get_numbered_line(file_name):</div><div class=\"line\">        f.write(line)</div><div class=\"line\">        <span class=\"keyword\">if</span> (idx+<span class=\"number\">1</span>) % n == <span class=\"number\">0</span>:</div><div class=\"line\">            f.close()</div><div class=\"line\">            i += <span class=\"number\">1</span></div><div class=\"line\">            f = open(<span class=\"string\">'output-%d.txt'</span> %i, <span class=\"string\">'w'</span>)</div><div class=\"line\"></div><div class=\"line\">    f.close()</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-9\"><a href=\"#Problem-9\" class=\"headerlink\" title=\"Problem 9\"></a>Problem 9</h3><p>The built-in function <code>enumerate</code> takes an <code>iteratable</code> and returns an <code>iterator</code> over pairs <code>(index, value)</code> for each value in the source.</p>\n<p>Write a function <code>my_enumerate</code> that works like <code>enumerate</code>.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">my_enumerate</span><span class=\"params\">(iterable)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    seq = iter(iterable)</div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        val = seq.next()</div><div class=\"line\">        <span class=\"keyword\">yield</span> i, val</div><div class=\"line\">        i += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n","excerpt":"<p>STLPythonPython/<a href=\"http://anandology.com/python-practice-book/iterators.html\">Iterators &amp; Generators</a></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>for</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">100</span>):</div><div class=\"line\">    <span class=\"comment\"># do something 100 times</span></div></pre></td></tr></table></figure>\n<p>PythonIterable Object<code>key</code></p>\n<p><code>list()</code><code>tuple()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">list(&#123;<span class=\"string\">'x'</span>:<span class=\"number\">1</span>, <span class=\"string\">'y'</span>:<span class=\"number\">2</span>&#125;)  <span class=\"comment\"># =&gt; ['x', 'y']</span></div></pre></td></tr></table></figure>\n<p><code>list</code><code>str</code><code>for x in XXX</code></p>\n<p>Python<code>iter()</code><code>next()</code><code>iter()</code><code>__iter__()</code><code>next()</code>Python3<code>__next__()</code></p>\n<p><code>yrange_iter</code><code>yrange</code><code>yrange</code><code>__iter__()</code><code>iter(yrange object)</code><code>yrange_iter</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version 1.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange_iter</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, yrange)</span>:</span></div><div class=\"line\">        self.n = yrange.n</div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> yrange_iter(self)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> type(iter(yrange(<span class=\"number\">5</span>))) <span class=\"comment\"># &lt;class '__main__.yrange_iter'&gt;</span></div></pre></td></tr></table></figure>\n<p><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">In [<span class=\"number\">3</span>]: yiter = iter(yrange(<span class=\"number\">5</span>))</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">4</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">4</span>]: <span class=\"number\">0</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">5</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">5</span>]: <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">6</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">6</span>]: <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p><code>yrange_iter</code><code>yrange.__iter__()</code><code>yrange</code><code>__iter__()</code><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version2.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">8</span>]: yiter = iter(yrange(<span class=\"number\">5</span>))</div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">9</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">9</span>]: <span class=\"number\">0</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">10</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">10</span>]: <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">In [<span class=\"number\">11</span>]: yiter.next()</div><div class=\"line\">Out[<span class=\"number\">11</span>]: <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p><code>self.n</code>010</p>\n<p>Python<code>StopIteration</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Version3.0 </span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">yrange</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, n)</span>:</span></div><div class=\"line\">        self.n = n</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__iter__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.i = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.i == self.n:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        v = self.i</div><div class=\"line\">        self.i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> v</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> yrange(<span class=\"number\">5</span>):</div><div class=\"line\">    <span class=\"keyword\">print</span> i</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-1\"><a href=\"#Problem-1\" class=\"headerlink\" title=\"Problem 1\"></a>Problem 1</h3><p>Write an iterator class <code>reverse_iter</code>, that takes a <code>list</code> and iterates it from the reverse direction.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">reverse_iter</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, alist)</span>:</span></div><div class=\"line\">        self.container = alist</div><div class=\"line\">        self.i = len(alist)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">next</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> self.i == <span class=\"number\">0</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        self.i -= <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">return</span> self.container[self.i]</div><div class=\"line\">it = reverse_iter([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>])</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>yield</code><code>next()</code><code>yield</code><code>yield</code><code>return</code><code>next()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">foo</span><span class=\"params\">()</span>:</span></div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"begin\"</span></div><div class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">3</span>):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"before yield\"</span>, i</div><div class=\"line\">            <span class=\"keyword\">yield</span> i</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">\"after yield\"</span>, i</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">\"end\"</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f = foo()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">begin</div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">0</span></div><div class=\"line\"><span class=\"number\">0</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">0</span></div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">1</span></div><div class=\"line\"><span class=\"number\">1</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">1</span></div><div class=\"line\">before <span class=\"keyword\">yield</span> <span class=\"number\">2</span></div><div class=\"line\"><span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>f.next()</div><div class=\"line\">after <span class=\"keyword\">yield</span> <span class=\"number\">2</span></div><div class=\"line\">end</div><div class=\"line\">Traceback (most recent call last):</div><div class=\"line\">  File <span class=\"string\">\"&lt;stdin&gt;\"</span>, line <span class=\"number\">1</span>, <span class=\"keyword\">in</span> &lt;module&gt;</div><div class=\"line\">StopIteration</div><div class=\"line\">&gt;&gt;&gt;</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>[]</code><code>()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> (x**<span class=\"number\">2</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> [<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>]):</div><div class=\"line\">    <span class=\"keyword\">print</span> i</div><div class=\"line\"><span class=\"comment\"># print 1 4 9 16</span></div></pre></td></tr></table></figure>\n<p></p>\n<p>10<code>take()</code><code>n</code><code>x</code>$[0, \\infty]$<code>break</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">integer</span><span class=\"params\">(start, end=None)</span>:</span></div><div class=\"line\">    <span class=\"string\">\"\"\"Generate integer sequence [start, end)</div><div class=\"line\">       If `end` is not given, then [start, \\infty]</div><div class=\"line\">    \"\"\"</span></div><div class=\"line\">    i = start</div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        <span class=\"keyword\">if</span> end <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"keyword\">None</span> <span class=\"keyword\">and</span> i == end:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\">        <span class=\"keyword\">yield</span> i</div><div class=\"line\">        i += <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">take</span><span class=\"params\">(n, g)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        <span class=\"keyword\">if</span> i &lt; n:</div><div class=\"line\">            <span class=\"keyword\">yield</span> g.next()</div><div class=\"line\">            i += <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> StopIteration</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#  x&gt;y&gt;z10, 6, 810, 8, 6</span></div><div class=\"line\">tup = ((x,y,z) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>) <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>, x) <span class=\"keyword\">for</span> z <span class=\"keyword\">in</span> integer(<span class=\"number\">0</span>, y) <span class=\"keyword\">if</span> x*x==y*y+z*z)</div><div class=\"line\">list(take(<span class=\"number\">10</span>, tup))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-2\"><a href=\"#Problem-2\" class=\"headerlink\" title=\"Problem 2\"></a>Problem 2</h3><p>Write a program that takes one or more filenames as arguments and prints all the lines which are longer than 40 characters.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">readfiles</span><span class=\"params\">(filenames)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> filenames:</div><div class=\"line\">        <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(f):</div><div class=\"line\">            <span class=\"keyword\">yield</span> line</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">grep</span><span class=\"params\">(lines)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines <span class=\"keyword\">if</span> len(line)&gt;<span class=\"number\">40</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">printlines</span><span class=\"params\">(lines)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines:</div><div class=\"line\">        <span class=\"keyword\">print</span> line,</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span><span class=\"params\">(filenames)</span>:</span></div><div class=\"line\">    lines = readfiles(filenames)</div><div class=\"line\">    lines = grep(lines)</div><div class=\"line\">    printlines(lines)</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-3\"><a href=\"#Problem-3\" class=\"headerlink\" title=\"Problem 3\"></a>Problem 3</h3><p>Write a function <code>findfiles</code> that recursively descends the directory tree for the specified directory and generates paths of all the files in the tree.</p>\n<p><code>get_all_file()</code>SO<a href=\"http://stackoverflow.com/questions/248830/python-using-a-recursive-algorithm-as-a-generator\"></a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> os</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_file</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> os.listdir(root):</div><div class=\"line\">        item = os.path.join(root, item)</div><div class=\"line\">        <span class=\"keyword\">if</span> os.path.isfile(item):</div><div class=\"line\">            <span class=\"keyword\">yield</span> os.path.abspath(item)</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> generate_all_file(item):</div><div class=\"line\">                <span class=\"keyword\">yield</span> item</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">findfiles</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> generate_all_file(root):</div><div class=\"line\">        <span class=\"keyword\">print</span> item</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-4\"><a href=\"#Problem-4\" class=\"headerlink\" title=\"Problem 4\"></a>Problem 4</h3><p>Write a function to compute the number of python files (.py extension) in a specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_py_file</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (file <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> generate_all_file(root) <span class=\"keyword\">if</span> os.path.splitext(file)[<span class=\"number\">-1</span>] == <span class=\"string\">'.py'</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_py_file(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-5\"><a href=\"#Problem-5\" class=\"headerlink\" title=\"Problem 5\"></a>Problem 5</h3><p>Write a function to compute the total number of lines of code in all python files in the specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_line</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> generate_all_py_file(root) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(f))</div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_line(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-6\"><a href=\"#Problem-6\" class=\"headerlink\" title=\"Problem 6\"></a>Problem 6</h3><p>Write a function to compute the total number of lines of code, ignoring empty and comment lines, in all python files in the specified directory recursively.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_all_no_empty_and_comment_line</span><span class=\"params\">(root)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> (line <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> generate_all_line(root) <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> (line==<span class=\"string\">''</span> <span class=\"keyword\">or</span> line.startswith(<span class=\"string\">'#'</span>)))</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">print</span> len(list(generate_all_no_empty_and_comment_line(<span class=\"string\">'./'</span>)))</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-7\"><a href=\"#Problem-7\" class=\"headerlink\" title=\"Problem 7\"></a>Problem 7</h3><p>Write a program <code>split.py</code>, that takes an integer <code>n</code> and a <code>filename</code> as command line arguments and splits the <code>file</code> into multiple small files with each having <code>n</code> lines.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_numbered_line</span><span class=\"params\">(filename)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> open(filename):</div><div class=\"line\">        <span class=\"keyword\">yield</span> i, line</div><div class=\"line\">        i += <span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">split</span><span class=\"params\">(file_name, n)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    f = open(<span class=\"string\">'output-%d.txt'</span> %i, <span class=\"string\">'w'</span>)</div><div class=\"line\">    <span class=\"keyword\">for</span> idx, line <span class=\"keyword\">in</span> get_numbered_line(file_name):</div><div class=\"line\">        f.write(line)</div><div class=\"line\">        <span class=\"keyword\">if</span> (idx+<span class=\"number\">1</span>) % n == <span class=\"number\">0</span>:</div><div class=\"line\">            f.close()</div><div class=\"line\">            i += <span class=\"number\">1</span></div><div class=\"line\">            f = open(<span class=\"string\">'output-%d.txt'</span> %i, <span class=\"string\">'w'</span>)</div><div class=\"line\"></div><div class=\"line\">    f.close()</div></pre></td></tr></table></figure>\n<h3 id=\"Problem-9\"><a href=\"#Problem-9\" class=\"headerlink\" title=\"Problem 9\"></a>Problem 9</h3><p>The built-in function <code>enumerate</code> takes an <code>iteratable</code> and returns an <code>iterator</code> over pairs <code>(index, value)</code> for each value in the source.</p>\n<p>Write a function <code>my_enumerate</code> that works like <code>enumerate</code>.</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">my_enumerate</span><span class=\"params\">(iterable)</span>:</span></div><div class=\"line\">    i = <span class=\"number\">0</span></div><div class=\"line\">    seq = iter(iterable)</div><div class=\"line\">    <span class=\"keyword\">while</span> <span class=\"keyword\">True</span>:</div><div class=\"line\">        val = seq.next()</div><div class=\"line\">        <span class=\"keyword\">yield</span> i, val</div><div class=\"line\">        i += <span class=\"number\">1</span></div></pre></td></tr></table></figure>"},{"title":"PyTorch 0.4.0 Migration Guide","date":"2018-04-27T02:49:31.000Z","_content":"PyTorch0.4.0API[](http://pytorch.org/2018/04/22/0_4_0-migration-guide.html)\n\n- `Tensor``Variable``autograd``requires_grad`\n- Numpy`Tensor`\n- `device`cpugpu\n\n<!-- more -->\n## \n0.4.0PyTorchbug fixes\n\n- `Tensors`  `Variables` merge\n- 0Tensorscalar\n-  `volatile` \n- `dtypes`, `devices`,  Numpy  Tensor\n- \n\n\n\n## `Tensor`  `Variable` \nPyTorch`Tensor``numpy``ndarray``Variable``Variable``Tensor`warpping\n\n``` py\nfor data, target in data_loader:\n    ## \n    data, target = Variable(data), Variable(target)\n    loss = criterion(model(data), target)\n```\n### `Tensor``type()`\n`type()``Tensor`data typeFloatTensorLongTensor`x.type()``isinstance()`\n\n``` py\n>>> x = torch.DoubleTensor([1, 1, 1])\n>>> print(type(x))  #  torch.DoubleTensor\n\"<class 'torch.Tensor'>\"\n>>> print(x.type())  # OK: 'torch.DoubleTensor'\n'torch.DoubleTensor'\n>>> print(isinstance(x, torch.DoubleTensor))  # OK: True\nTrue\n```\n\n### `autograd`\n`Tensor``Variable`\n\n`requires_grad`, `autograd`,`Tensor``Variable``Tensor``autograd`input`requires_grad==True`\n\n``` py\n>>> x = torch.ones(1)  ## requires_grad = False\n>>> x.requires_grad\nFalse\n>>> y = torch.ones(1)  ## yrequires_gradFalse\n>>> z = x + y\n>>> ## zrequires_gradFalse\n>>> z.requires_grad\nFalse\n>>> ## zError\n>>> z.backward()\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n>>>\n>>> ##  requires_grad=True Tensor\n>>> w = torch.ones(1, requires_grad=True)\n>>> w.requires_grad\nTrue\n>>> ## requires_grad=False\n>>> total = w + z\n>>> ## wtotal\n>>> total.requires_grad\nTrue\n>>> ## bp\n>>> total.backward()\n>>> w.grad\ntensor([ 1.])\n>>> ##  x y z require gradgrad == None\n>>> z.grad == x.grad == y.grad == None\nTrue\n```\n\n###  `requires_grad` \n`my_tensor.requires_grad_()``_`in-place\n\n``` py\n>>> existing_tensor.requires_grad_()\n>>> existing_tensor.requires_grad\nTrue\n>>> my_tensor = torch.zeros(3, 4, requires_grad=True)\n>>> my_tensor.requires_grad\nTrue\n```\n\n### `.data`What about .data?\n`Variable``x.data``Tensor`merge`y = x.data``y``x`data`x``requires_grad``False`\n\n`.data``x.data``aotograd``x.detach()``x`dataTensor`requires_grad=False``x`bp\n\nHowever, .data can be unsafe in some cases. Any changes on x.data wouldnt be tracked by autograd, and the computed gradients would be incorrect if x is needed in a backward pass. A safer alternative is to use x.detach(), which also returns a Tensor that shares data with requires_grad=False, but will have its in-place changes reported by autograd if x is needed in backward.\n\n## 0(scalar)Tensor\nTensor vector1D Tensorpython numberVariable vector`size(1,)`vector!reduction function`torch.sum``torch.max`\n\nscalar0D Tensor`torch.tensor()` \n\n``` py\n>>> torch.tensor(3.1416)         # scalar\ntensor(3.1416)\n>>> torch.tensor(3.1416).size()  # scalar  0D\ntorch.Size([])\n>>> torch.tensor([3]).size()     # 1D\ntorch.Size([1])\n>>>\n>>> vector = torch.arange(2, 6)  # 1Dvector\n>>> vector\ntensor([ 2.,  3.,  4.,  5.])\n>>> vector.size()\ntorch.Size([4])\n>>> vector[3]                    # 1Dvectorindexingscalar\ntensor(5.)\n>>> vector[3].item()             # .item()python number\n5.0\n>>> mysum = torch.tensor([2, 3]).sum()\n>>> mysum\ntensor(5)\n>>> mysum.size()\ntorch.Size([])\n```\n\n### losses\n`total_loss += loss.data[0]``loss``(1,)``Tensor``Variable``loss`0Dscalarscalarindexing`loss.item()`python number\n\npython number`autograd` `total_loss += loss.item()`\n\n## `volatile`\n`volatile` `volatile=True``Variable` `autograd``torch.no_grad()``torch.set_grad_enable(grad_mode)`\n\n``` py\n>>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():    #  torch,no_grad()track\n...     y = x * 2\n>>> y.requires_grad\nFalse\n>>>\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):   # inferencetrack\n...     y = x * 2\n>>> y.requires_grad\nFalse\n>>> torch.set_grad_enabled(True)  # with\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n```\n\n## `dtypes`, `devices` NumPy\n\"tensor type\"data type`float``double`device typecpugpulayoutdensesparse`torch.cuda.sparse.DoubleTensor`data type`double`GPUsparsetensor\n\n`torch.dtype``torch.device``torch.layout`Numpy\n\n### `torch.dtype`\n\n `torch.dtypes` (data types) tensor types`x.dtype`\n<table>\n   <tr>\n      <td>data type</td>\n      <td>torch.dtype</td>\n      <td>Tensor types</td>\n   </tr>\n   <tr>\n      <td>32-bit floating point</td>\n      <td>torch.float32ortorch.float</td>\n      <td>torch.*.FloatTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit floating point</td>\n      <td>torch.float64ortorch.double</td>\n      <td>torch.*.DoubleTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit floating point</td>\n      <td>torch.float16ortorch.half</td>\n      <td>torch.*.HalfTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (unsigned)</td>\n      <td>torch.uint8</td>\n      <td>torch.*.ByteTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (signed)</td>\n      <td>torch.int8</td>\n      <td>torch.*.CharTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit integer (signed)</td>\n      <td>torch.int16ortorch.short</td>\n      <td>torch.*.ShortTensor</td>\n   </tr>\n   <tr>\n      <td>32-bit integer (signed)</td>\n      <td>torch.int32ortorch.int</td>\n      <td>torch.*.IntTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit integer (signed)</td>\n      <td>torch.int64ortorch.long</td>\n      <td>torch.*.LongTensor</td>\n   </tr>\n</table>\n\n### `torch.device`\n`torch.device`device typecpucudaid`torch.device('{device_type}')``torch.device('{device_type}:{device_ordinal}')` \n\n`device ordinal`device`torch.device('cuda')``torch.device('cuda:X')``X``torch.cuda.current_device()`\n\n`x.device`\n\n### `torch.layout`\n`torch.layout``Tensor`data layout `torch.strided` (dense)  `torch.sparse_coo` (COOGtensor)\n\n`x.layout`\n\n### `Tensor`Numpy\n`dtype``device``layout``requires_grad``Tensor`\n\n``` py\n>>> device = torch.device(\"cuda:1\") \n>>> x = torch.randn(3, 3, dtype=torch.float64, device=device)\ntensor([[-0.6344,  0.8562, -1.2758],\n        [ 0.8414,  1.7962,  1.0589],\n        [-0.1369, -1.0462, -0.4373]], dtype=torch.float64, device='cuda:1')\n>>> x.requires_grad  # default is False\nFalse\n>>> x = torch.zeros(3, requires_grad=True)\n>>> x.requires_grad\nTrue\n```\n\n### `torch.tensor(data, ...)`\n`torch.tensor``Tesnor`\"array-like\"value copy`Tensor``numpy.array``torch.*Tensor`0DTensorscalar`dtype`dataPython List`Tensor`\n\n``` py\n>>> cuda = torch.device(\"cuda\")\n>>> torch.tensor([[1], [2], [3]], dtype=torch.half, device=cuda)\ntensor([[ 1],\n        [ 2],\n        [ 3]], device='cuda:0')\n>>> torch.tensor(1)               # scalar\ntensor(1)\n>>> torch.tensor([1, 2.3]).dtype  # type inferece\ntorch.float32\n>>> torch.tensor([1, 2]).dtype    # type inferece\ntorch.int64\n```\n`Tensor``torch.*_like``tensor.new_*`\n\n- `torch.*_like`input tensor tensor\n``` py\n>>> x = torch.randn(3, dtype=torch.float64)\n>>> torch.zeros_like(x)\ntensor([ 0.,  0.,  0.], dtype=torch.float64)\n>>> torch.zeros_like(x, dtype=torch.int)\ntensor([ 0,  0,  0], dtype=torch.int32)\n```\n\n- `tensor.new_*`shape\n``` py\n>>> x = torch.randn(3, dtype=torch.float64)\n>>> x.new_ones(2)\ntensor([ 1.,  1.], dtype=torch.float64)\n>>> x.new_ones(4, dtype=torch.int)\ntensor([ 1,  1,  1,  1], dtype=torch.int32)\n```\n\nshape`tuple``torch.zeros((2, 3))`Numpy`torch.zeros(2, 3)`\n\n<table>\n   <tr>\n      <td>Name</td>\n      <td>ReturnedTensor</td>\n      <td>torch.*_likevariant</td>\n      <td>tensor.new_*variant</td>\n   </tr>\n   <tr>\n      <td>torch.empty</td>\n      <td>unintialized memory</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.zeros</td>\n      <td>all zeros</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.ones</td>\n      <td>all ones</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.full</td>\n      <td>filled with a given value</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.rand</td>\n      <td>i.i.d. continuousUniform[0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randn</td>\n      <td>i.i.d.Normal(0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randint</td>\n      <td>i.i.d. discrete Uniform in given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randperm</td>\n      <td>random permutation of{0, 1, ..., n - 1}</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.tensor</td>\n      <td>copied from existing data (list, NumPyndarray, etc.)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.from_numpy*</td>\n      <td>from NumPyndarray(sharing storage without copying)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.arange,torch.range and torch.linspace</td>\n      <td>uniformly spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.logspace</td>\n      <td>logarithmically spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.eye</td>\n      <td>identity matrix</td>\n      <td></td>\n      <td></td>\n   </tr>\n</table>\n\n`torch.from_numpy`NumPy `ndarray`\n\n## device-agnostic code\n\n\n- `Tensor``device``torch.device``get_device`CUDA tensor\n- `x.to()``Tensor``Module`devices`x.cpu()``x.cuda()`\n\n\n\n``` py\n# device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## \n\n# TensorModule\n# devicecopy\ninput = data.to(device)\nmodel = MyModule(...).to(device)\n```\n\n## `nn.Module`submoduleparameterbuffer\n`module.add_module(name, value)`, `module.add_parameter(name, value)`  `module.add_buffer(name, value)``.``state_dict`load`state_dict`\n\n## \ncode snippet0.3.10.4.0\n\n### 0.3.1 version\n``` py\n  model = MyRNN()\n  if use_cuda:\n      model = model.cuda()\n\n  # train\n  total_loss = 0\n  for input, target in train_loader:\n      input, target = Variable(input), Variable(target)\n      hidden = Variable(torch.zeros(*h_shape))  # init hidden\n      if use_cuda:\n          input, target, hidden = input.cuda(), target.cuda(), hidden.cuda()\n      ...  # get loss and optimize\n      total_loss += loss.data[0]\n\n  # evaluate\n  for input, target in test_loader:\n      input = Variable(input, volatile=True)\n      if use_cuda:\n          ...\n      ...\n```\n\n### 0.4.0 version\n``` py\n  # torch.device object used throughout this script\n  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n  model = MyRNN().to(device)\n\n  # train\n  total_loss = 0\n  for input, target in train_loader:\n      input, target = input.to(device), target.to(device)\n      hidden = input.new_zeros(*h_shape)  # has the same device & dtype as `input`\n      ...  # get loss and optimize\n      total_loss += loss.item()           # get Python number from 1-element Tensor\n\n  # evaluate\n  with torch.no_grad():                   # operations inside don't track history\n      for input, target in test_loader:\n          ...\n```\n\n## \n\n- [Release Note](https://github.com/pytorch/pytorch/releases/tag/v0.4.0)\n- [Documentation](http://pytorch.org/docs/stable/index.html)","source":"_posts/pytorch-040-migration-guide.md","raw":"---\ntitle: PyTorch 0.4.0 Migration Guide\ndate: 2018-04-27 10:49:31\ntags:\n     - pytorch\n---\nPyTorch0.4.0API[](http://pytorch.org/2018/04/22/0_4_0-migration-guide.html)\n\n- `Tensor``Variable``autograd``requires_grad`\n- Numpy`Tensor`\n- `device`cpugpu\n\n<!-- more -->\n## \n0.4.0PyTorchbug fixes\n\n- `Tensors`  `Variables` merge\n- 0Tensorscalar\n-  `volatile` \n- `dtypes`, `devices`,  Numpy  Tensor\n- \n\n\n\n## `Tensor`  `Variable` \nPyTorch`Tensor``numpy``ndarray``Variable``Variable``Tensor`warpping\n\n``` py\nfor data, target in data_loader:\n    ## \n    data, target = Variable(data), Variable(target)\n    loss = criterion(model(data), target)\n```\n### `Tensor``type()`\n`type()``Tensor`data typeFloatTensorLongTensor`x.type()``isinstance()`\n\n``` py\n>>> x = torch.DoubleTensor([1, 1, 1])\n>>> print(type(x))  #  torch.DoubleTensor\n\"<class 'torch.Tensor'>\"\n>>> print(x.type())  # OK: 'torch.DoubleTensor'\n'torch.DoubleTensor'\n>>> print(isinstance(x, torch.DoubleTensor))  # OK: True\nTrue\n```\n\n### `autograd`\n`Tensor``Variable`\n\n`requires_grad`, `autograd`,`Tensor``Variable``Tensor``autograd`input`requires_grad==True`\n\n``` py\n>>> x = torch.ones(1)  ## requires_grad = False\n>>> x.requires_grad\nFalse\n>>> y = torch.ones(1)  ## yrequires_gradFalse\n>>> z = x + y\n>>> ## zrequires_gradFalse\n>>> z.requires_grad\nFalse\n>>> ## zError\n>>> z.backward()\nRuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n>>>\n>>> ##  requires_grad=True Tensor\n>>> w = torch.ones(1, requires_grad=True)\n>>> w.requires_grad\nTrue\n>>> ## requires_grad=False\n>>> total = w + z\n>>> ## wtotal\n>>> total.requires_grad\nTrue\n>>> ## bp\n>>> total.backward()\n>>> w.grad\ntensor([ 1.])\n>>> ##  x y z require gradgrad == None\n>>> z.grad == x.grad == y.grad == None\nTrue\n```\n\n###  `requires_grad` \n`my_tensor.requires_grad_()``_`in-place\n\n``` py\n>>> existing_tensor.requires_grad_()\n>>> existing_tensor.requires_grad\nTrue\n>>> my_tensor = torch.zeros(3, 4, requires_grad=True)\n>>> my_tensor.requires_grad\nTrue\n```\n\n### `.data`What about .data?\n`Variable``x.data``Tensor`merge`y = x.data``y``x`data`x``requires_grad``False`\n\n`.data``x.data``aotograd``x.detach()``x`dataTensor`requires_grad=False``x`bp\n\nHowever, .data can be unsafe in some cases. Any changes on x.data wouldnt be tracked by autograd, and the computed gradients would be incorrect if x is needed in a backward pass. A safer alternative is to use x.detach(), which also returns a Tensor that shares data with requires_grad=False, but will have its in-place changes reported by autograd if x is needed in backward.\n\n## 0(scalar)Tensor\nTensor vector1D Tensorpython numberVariable vector`size(1,)`vector!reduction function`torch.sum``torch.max`\n\nscalar0D Tensor`torch.tensor()` \n\n``` py\n>>> torch.tensor(3.1416)         # scalar\ntensor(3.1416)\n>>> torch.tensor(3.1416).size()  # scalar  0D\ntorch.Size([])\n>>> torch.tensor([3]).size()     # 1D\ntorch.Size([1])\n>>>\n>>> vector = torch.arange(2, 6)  # 1Dvector\n>>> vector\ntensor([ 2.,  3.,  4.,  5.])\n>>> vector.size()\ntorch.Size([4])\n>>> vector[3]                    # 1Dvectorindexingscalar\ntensor(5.)\n>>> vector[3].item()             # .item()python number\n5.0\n>>> mysum = torch.tensor([2, 3]).sum()\n>>> mysum\ntensor(5)\n>>> mysum.size()\ntorch.Size([])\n```\n\n### losses\n`total_loss += loss.data[0]``loss``(1,)``Tensor``Variable``loss`0Dscalarscalarindexing`loss.item()`python number\n\npython number`autograd` `total_loss += loss.item()`\n\n## `volatile`\n`volatile` `volatile=True``Variable` `autograd``torch.no_grad()``torch.set_grad_enable(grad_mode)`\n\n``` py\n>>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():    #  torch,no_grad()track\n...     y = x * 2\n>>> y.requires_grad\nFalse\n>>>\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):   # inferencetrack\n...     y = x * 2\n>>> y.requires_grad\nFalse\n>>> torch.set_grad_enabled(True)  # with\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n```\n\n## `dtypes`, `devices` NumPy\n\"tensor type\"data type`float``double`device typecpugpulayoutdensesparse`torch.cuda.sparse.DoubleTensor`data type`double`GPUsparsetensor\n\n`torch.dtype``torch.device``torch.layout`Numpy\n\n### `torch.dtype`\n\n `torch.dtypes` (data types) tensor types`x.dtype`\n<table>\n   <tr>\n      <td>data type</td>\n      <td>torch.dtype</td>\n      <td>Tensor types</td>\n   </tr>\n   <tr>\n      <td>32-bit floating point</td>\n      <td>torch.float32ortorch.float</td>\n      <td>torch.*.FloatTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit floating point</td>\n      <td>torch.float64ortorch.double</td>\n      <td>torch.*.DoubleTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit floating point</td>\n      <td>torch.float16ortorch.half</td>\n      <td>torch.*.HalfTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (unsigned)</td>\n      <td>torch.uint8</td>\n      <td>torch.*.ByteTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (signed)</td>\n      <td>torch.int8</td>\n      <td>torch.*.CharTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit integer (signed)</td>\n      <td>torch.int16ortorch.short</td>\n      <td>torch.*.ShortTensor</td>\n   </tr>\n   <tr>\n      <td>32-bit integer (signed)</td>\n      <td>torch.int32ortorch.int</td>\n      <td>torch.*.IntTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit integer (signed)</td>\n      <td>torch.int64ortorch.long</td>\n      <td>torch.*.LongTensor</td>\n   </tr>\n</table>\n\n### `torch.device`\n`torch.device`device typecpucudaid`torch.device('{device_type}')``torch.device('{device_type}:{device_ordinal}')` \n\n`device ordinal`device`torch.device('cuda')``torch.device('cuda:X')``X``torch.cuda.current_device()`\n\n`x.device`\n\n### `torch.layout`\n`torch.layout``Tensor`data layout `torch.strided` (dense)  `torch.sparse_coo` (COOGtensor)\n\n`x.layout`\n\n### `Tensor`Numpy\n`dtype``device``layout``requires_grad``Tensor`\n\n``` py\n>>> device = torch.device(\"cuda:1\") \n>>> x = torch.randn(3, 3, dtype=torch.float64, device=device)\ntensor([[-0.6344,  0.8562, -1.2758],\n        [ 0.8414,  1.7962,  1.0589],\n        [-0.1369, -1.0462, -0.4373]], dtype=torch.float64, device='cuda:1')\n>>> x.requires_grad  # default is False\nFalse\n>>> x = torch.zeros(3, requires_grad=True)\n>>> x.requires_grad\nTrue\n```\n\n### `torch.tensor(data, ...)`\n`torch.tensor``Tesnor`\"array-like\"value copy`Tensor``numpy.array``torch.*Tensor`0DTensorscalar`dtype`dataPython List`Tensor`\n\n``` py\n>>> cuda = torch.device(\"cuda\")\n>>> torch.tensor([[1], [2], [3]], dtype=torch.half, device=cuda)\ntensor([[ 1],\n        [ 2],\n        [ 3]], device='cuda:0')\n>>> torch.tensor(1)               # scalar\ntensor(1)\n>>> torch.tensor([1, 2.3]).dtype  # type inferece\ntorch.float32\n>>> torch.tensor([1, 2]).dtype    # type inferece\ntorch.int64\n```\n`Tensor``torch.*_like``tensor.new_*`\n\n- `torch.*_like`input tensor tensor\n``` py\n>>> x = torch.randn(3, dtype=torch.float64)\n>>> torch.zeros_like(x)\ntensor([ 0.,  0.,  0.], dtype=torch.float64)\n>>> torch.zeros_like(x, dtype=torch.int)\ntensor([ 0,  0,  0], dtype=torch.int32)\n```\n\n- `tensor.new_*`shape\n``` py\n>>> x = torch.randn(3, dtype=torch.float64)\n>>> x.new_ones(2)\ntensor([ 1.,  1.], dtype=torch.float64)\n>>> x.new_ones(4, dtype=torch.int)\ntensor([ 1,  1,  1,  1], dtype=torch.int32)\n```\n\nshape`tuple``torch.zeros((2, 3))`Numpy`torch.zeros(2, 3)`\n\n<table>\n   <tr>\n      <td>Name</td>\n      <td>ReturnedTensor</td>\n      <td>torch.*_likevariant</td>\n      <td>tensor.new_*variant</td>\n   </tr>\n   <tr>\n      <td>torch.empty</td>\n      <td>unintialized memory</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.zeros</td>\n      <td>all zeros</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.ones</td>\n      <td>all ones</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.full</td>\n      <td>filled with a given value</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.rand</td>\n      <td>i.i.d. continuousUniform[0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randn</td>\n      <td>i.i.d.Normal(0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randint</td>\n      <td>i.i.d. discrete Uniform in given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randperm</td>\n      <td>random permutation of{0, 1, ..., n - 1}</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.tensor</td>\n      <td>copied from existing data (list, NumPyndarray, etc.)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.from_numpy*</td>\n      <td>from NumPyndarray(sharing storage without copying)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.arange,torch.range and torch.linspace</td>\n      <td>uniformly spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.logspace</td>\n      <td>logarithmically spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.eye</td>\n      <td>identity matrix</td>\n      <td></td>\n      <td></td>\n   </tr>\n</table>\n\n`torch.from_numpy`NumPy `ndarray`\n\n## device-agnostic code\n\n\n- `Tensor``device``torch.device``get_device`CUDA tensor\n- `x.to()``Tensor``Module`devices`x.cpu()``x.cuda()`\n\n\n\n``` py\n# device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n## \n\n# TensorModule\n# devicecopy\ninput = data.to(device)\nmodel = MyModule(...).to(device)\n```\n\n## `nn.Module`submoduleparameterbuffer\n`module.add_module(name, value)`, `module.add_parameter(name, value)`  `module.add_buffer(name, value)``.``state_dict`load`state_dict`\n\n## \ncode snippet0.3.10.4.0\n\n### 0.3.1 version\n``` py\n  model = MyRNN()\n  if use_cuda:\n      model = model.cuda()\n\n  # train\n  total_loss = 0\n  for input, target in train_loader:\n      input, target = Variable(input), Variable(target)\n      hidden = Variable(torch.zeros(*h_shape))  # init hidden\n      if use_cuda:\n          input, target, hidden = input.cuda(), target.cuda(), hidden.cuda()\n      ...  # get loss and optimize\n      total_loss += loss.data[0]\n\n  # evaluate\n  for input, target in test_loader:\n      input = Variable(input, volatile=True)\n      if use_cuda:\n          ...\n      ...\n```\n\n### 0.4.0 version\n``` py\n  # torch.device object used throughout this script\n  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n  model = MyRNN().to(device)\n\n  # train\n  total_loss = 0\n  for input, target in train_loader:\n      input, target = input.to(device), target.to(device)\n      hidden = input.new_zeros(*h_shape)  # has the same device & dtype as `input`\n      ...  # get loss and optimize\n      total_loss += loss.item()           # get Python number from 1-element Tensor\n\n  # evaluate\n  with torch.no_grad():                   # operations inside don't track history\n      for input, target in test_loader:\n          ...\n```\n\n## \n\n- [Release Note](https://github.com/pytorch/pytorch/releases/tag/v0.4.0)\n- [Documentation](http://pytorch.org/docs/stable/index.html)","slug":"pytorch-040-migration-guide","published":1,"updated":"2018-10-27T07:16:52.414Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8o0003mae7bp6yeh3em","content":"<p>PyTorch0.4.0API<a href=\"http://pytorch.org/2018/04/22/0_4_0-migration-guide.html\" target=\"_blank\" rel=\"external\"></a></p>\n<ul>\n<li><code>Tensor</code><code>Variable</code><code>autograd</code><code>requires_grad</code></li>\n<li>Numpy<code>Tensor</code></li>\n<li><code>device</code>cpugpu</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>0.4.0PyTorchbug fixes</p>\n<ul>\n<li><code>Tensors</code>  <code>Variables</code> merge</li>\n<li>0Tensorscalar</li>\n<li> <code>volatile</code> </li>\n<li><code>dtypes</code>, <code>devices</code>,  Numpy  Tensor</li>\n<li></li>\n</ul>\n<p></p>\n<h2 id=\"Tensor--Variable-\"><a href=\"#Tensor--Variable-\" class=\"headerlink\" title=\"Tensor  Variable \"></a><code>Tensor</code>  <code>Variable</code> </h2><p>PyTorch<code>Tensor</code><code>numpy</code><code>ndarray</code><code>Variable</code><code>Variable</code><code>Tensor</code>warpping</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> data, target <span class=\"keyword\">in</span> data_loader:</div><div class=\"line\">    <span class=\"comment\">## </span></div><div class=\"line\">    data, target = Variable(data), Variable(target)</div><div class=\"line\">    loss = criterion(model(data), target)</div></pre></td></tr></table></figure>\n<h3 id=\"Tensortype\"><a href=\"#Tensortype\" class=\"headerlink\" title=\"Tensortype()\"></a><code>Tensor</code><code>type()</code></h3><p><code>type()</code><code>Tensor</code>data typeFloatTensorLongTensor<code>x.type()</code><code>isinstance()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.DoubleTensor([<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(type(x))  <span class=\"comment\">#  torch.DoubleTensor</span></div><div class=\"line\"><span class=\"string\">\"&lt;class 'torch.Tensor'&gt;\"</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(x.type())  <span class=\"comment\"># OK: 'torch.DoubleTensor'</span></div><div class=\"line\"><span class=\"string\">'torch.DoubleTensor'</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(isinstance(x, torch.DoubleTensor))  <span class=\"comment\"># OK: True</span></div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"autograd\"><a href=\"#autograd\" class=\"headerlink\" title=\"autograd\"></a><code>autograd</code></h3><p><code>Tensor</code><code>Variable</code></p>\n<p><code>requires_grad</code>, <code>autograd</code>,<code>Tensor</code><code>Variable</code><code>Tensor</code><code>autograd</code>input<code>requires_grad==True</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.ones(<span class=\"number\">1</span>)  <span class=\"comment\">## requires_grad = False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = torch.ones(<span class=\"number\">1</span>)  <span class=\"comment\">## yrequires_gradFalse</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x + y</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## zrequires_gradFalse</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## zError</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.backward()</div><div class=\"line\">RuntimeError: element <span class=\"number\">0</span> of tensors does <span class=\"keyword\">not</span> require grad <span class=\"keyword\">and</span> does <span class=\"keyword\">not</span> have a grad_fn</div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">##  requires_grad=True Tensor</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w = torch.ones(<span class=\"number\">1</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## requires_grad=False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total = w + z</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## wtotal</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## bp</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total.backward()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w.grad</div><div class=\"line\">tensor([ <span class=\"number\">1.</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">##  x y z require gradgrad == None</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.grad == x.grad == y.grad == <span class=\"keyword\">None</span></div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"-requires-grad-\"><a href=\"#-requires-grad-\" class=\"headerlink\" title=\" requires_grad \"></a> <code>requires_grad</code> </h3><p><code>my_tensor.requires_grad_()</code><code>_</code>in-place</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>existing_tensor.requires_grad_()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>existing_tensor.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_tensor = torch.zeros(<span class=\"number\">3</span>, <span class=\"number\">4</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_tensor.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"dataWhat-about-data\"><a href=\"#dataWhat-about-data\" class=\"headerlink\" title=\".dataWhat about .data?\"></a><code>.data</code>What about .data?</h3><p><code>Variable</code><code>x.data</code><code>Tensor</code>merge<code>y = x.data</code><code>y</code><code>x</code>data<code>x</code><code>requires_grad</code><code>False</code></p>\n<p><code>.data</code><code>x.data</code><code>aotograd</code><code>x.detach()</code><code>x</code>dataTensor<code>requires_grad=False</code><code>x</code>bp</p>\n<p>However, .data can be unsafe in some cases. Any changes on x.data wouldnt be tracked by autograd, and the computed gradients would be incorrect if x is needed in a backward pass. A safer alternative is to use x.detach(), which also returns a Tensor that shares data with requires_grad=False, but will have its in-place changes reported by autograd if x is needed in backward.</p>\n<h2 id=\"0-scalar-Tensor\"><a href=\"#0-scalar-Tensor\" class=\"headerlink\" title=\"0(scalar)Tensor\"></a>0(scalar)Tensor</h2><p>Tensor vector1D Tensorpython numberVariable vector<code>size(1,)</code>vector!reduction function<code>torch.sum</code><code>torch.max</code></p>\n<p>scalar0D Tensor<code>torch.tensor()</code> </p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">3.1416</span>)         <span class=\"comment\"># scalar</span></div><div class=\"line\">tensor(<span class=\"number\">3.1416</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">3.1416</span>).size()  <span class=\"comment\"># scalar  0D</span></div><div class=\"line\">torch.Size([])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">3</span>]).size()     <span class=\"comment\"># 1D</span></div><div class=\"line\">torch.Size([<span class=\"number\">1</span>])</div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector = torch.arange(<span class=\"number\">2</span>, <span class=\"number\">6</span>)  <span class=\"comment\"># 1Dvector</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector</div><div class=\"line\">tensor([ <span class=\"number\">2.</span>,  <span class=\"number\">3.</span>,  <span class=\"number\">4.</span>,  <span class=\"number\">5.</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector.size()</div><div class=\"line\">torch.Size([<span class=\"number\">4</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector[<span class=\"number\">3</span>]                    <span class=\"comment\"># 1Dvectorindexingscalar</span></div><div class=\"line\">tensor(<span class=\"number\">5.</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector[<span class=\"number\">3</span>].item()             <span class=\"comment\"># .item()python number</span></div><div class=\"line\"><span class=\"number\">5.0</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum = torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">3</span>]).sum()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum</div><div class=\"line\">tensor(<span class=\"number\">5</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum.size()</div><div class=\"line\">torch.Size([])</div></pre></td></tr></table></figure>\n<h3 id=\"losses\"><a href=\"#losses\" class=\"headerlink\" title=\"losses\"></a>losses</h3><p><code>total_loss += loss.data[0]</code><code>loss</code><code>(1,)</code><code>Tensor</code><code>Variable</code><code>loss</code>0Dscalarscalarindexing<code>loss.item()</code>python number</p>\n<p>python number<code>autograd</code> <code>total_loss += loss.item()</code></p>\n<h2 id=\"volatile\"><a href=\"#volatile\" class=\"headerlink\" title=\"volatile\"></a><code>volatile</code></h2><p><code>volatile</code> <code>volatile=True</code><code>Variable</code> <code>autograd</code><code>torch.no_grad()</code><code>torch.set_grad_enable(grad_mode)</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">with</span> torch.no_grad():    <span class=\"comment\">#  torch,no_grad()track</span></div><div class=\"line\"><span class=\"meta\">... </span>    y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>is_train = <span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">with</span> torch.set_grad_enabled(is_train):   <span class=\"comment\"># inferencetrack</span></div><div class=\"line\"><span class=\"meta\">... </span>    y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class=\"keyword\">True</span>)  <span class=\"comment\"># with</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class=\"keyword\">False</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div></pre></td></tr></table></figure>\n<h2 id=\"dtypes-devices-NumPy\"><a href=\"#dtypes-devices-NumPy\" class=\"headerlink\" title=\"dtypes, devices NumPy\"></a><code>dtypes</code>, <code>devices</code> NumPy</h2><p>tensor typedata type<code>float</code><code>double</code>device typecpugpulayoutdensesparse<code>torch.cuda.sparse.DoubleTensor</code>data type<code>double</code>GPUsparsetensor</p>\n<p><code>torch.dtype</code><code>torch.device</code><code>torch.layout</code>Numpy</p>\n<h3 id=\"torch-dtype\"><a href=\"#torch-dtype\" class=\"headerlink\" title=\"torch.dtype\"></a><code>torch.dtype</code></h3><p> <code>torch.dtypes</code> (data types) tensor types<code>x.dtype</code></p>\n<table>\n   <tr>\n      <td>data type</td>\n      <td>torch.dtype</td>\n      <td>Tensor types</td>\n   </tr>\n   <tr>\n      <td>32-bit floating point</td>\n      <td>torch.float32 or torch.float</td>\n      <td>torch.*.FloatTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit floating point</td>\n      <td>torch.float64 or torch.double</td>\n      <td>torch.*.DoubleTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit floating point</td>\n      <td>torch.float16 or torch.half</td>\n      <td>torch.*.HalfTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (unsigned)</td>\n      <td>torch.uint8</td>\n      <td>torch.*.ByteTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (signed)</td>\n      <td>torch.int8</td>\n      <td>torch.*.CharTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit integer (signed)</td>\n      <td>torch.int16 or torch.short</td>\n      <td>torch.*.ShortTensor</td>\n   </tr>\n   <tr>\n      <td>32-bit integer (signed)</td>\n      <td>torch.int32 or torch.int</td>\n      <td>torch.*.IntTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit integer (signed)</td>\n      <td>torch.int64 or torch.long</td>\n      <td>torch.*.LongTensor</td>\n   </tr>\n</table>\n\n<h3 id=\"torch-device\"><a href=\"#torch-device\" class=\"headerlink\" title=\"torch.device\"></a><code>torch.device</code></h3><p><code>torch.device</code>device typecpucudaid<code>torch.device(&#39;{device_type}&#39;)</code><code>torch.device(&#39;{device_type}:{device_ordinal}&#39;)</code> </p>\n<p><code>device ordinal</code>device<code>torch.device(&#39;cuda&#39;)</code><code>torch.device(&#39;cuda:X&#39;)</code><code>X</code><code>torch.cuda.current_device()</code></p>\n<p><code>x.device</code></p>\n<h3 id=\"torch-layout\"><a href=\"#torch-layout\" class=\"headerlink\" title=\"torch.layout\"></a><code>torch.layout</code></h3><p><code>torch.layout</code><code>Tensor</code>data layout <code>torch.strided</code> (dense)  <code>torch.sparse_coo</code> (COOGtensor)</p>\n<p><code>x.layout</code></p>\n<h3 id=\"TensorNumpy\"><a href=\"#TensorNumpy\" class=\"headerlink\" title=\"TensorNumpy\"></a><code>Tensor</code>Numpy</h3><p><code>dtype</code><code>device</code><code>layout</code><code>requires_grad</code><code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>device = torch.device(<span class=\"string\">\"cuda:1\"</span>) </div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, <span class=\"number\">3</span>, dtype=torch.float64, device=device)</div><div class=\"line\">tensor([[<span class=\"number\">-0.6344</span>,  <span class=\"number\">0.8562</span>, <span class=\"number\">-1.2758</span>],</div><div class=\"line\">        [ <span class=\"number\">0.8414</span>,  <span class=\"number\">1.7962</span>,  <span class=\"number\">1.0589</span>],</div><div class=\"line\">        [<span class=\"number\">-0.1369</span>, <span class=\"number\">-1.0462</span>, <span class=\"number\">-0.4373</span>]], dtype=torch.float64, device=<span class=\"string\">'cuda:1'</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad  <span class=\"comment\"># default is False</span></div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.zeros(<span class=\"number\">3</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"torch-tensor-data\"><a href=\"#torch-tensor-data\" class=\"headerlink\" title=\"torch.tensor(data, ...)\"></a><code>torch.tensor(data, ...)</code></h3><p><code>torch.tensor</code><code>Tesnor</code>array-likevalue copy<code>Tensor</code><code>numpy.array</code><code>torch.*Tensor</code>0DTensorscalar<code>dtype</code>dataPython List<code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>cuda = torch.device(<span class=\"string\">\"cuda\"</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([[<span class=\"number\">1</span>], [<span class=\"number\">2</span>], [<span class=\"number\">3</span>]], dtype=torch.half, device=cuda)</div><div class=\"line\">tensor([[ <span class=\"number\">1</span>],</div><div class=\"line\">        [ <span class=\"number\">2</span>],</div><div class=\"line\">        [ <span class=\"number\">3</span>]], device=<span class=\"string\">'cuda:0'</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">1</span>)               <span class=\"comment\"># scalar</span></div><div class=\"line\">tensor(<span class=\"number\">1</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2.3</span>]).dtype  <span class=\"comment\"># type inferece</span></div><div class=\"line\">torch.float32</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>]).dtype    <span class=\"comment\"># type inferece</span></div><div class=\"line\">torch.int64</div></pre></td></tr></table></figure>\n<p><code>Tensor</code><code>torch.*_like</code><code>tensor.new_*</code></p>\n<ul>\n<li><p><code>torch.*_like</code>input tensor tensor</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.zeros_like(x)</div><div class=\"line\">tensor([ <span class=\"number\">0.</span>,  <span class=\"number\">0.</span>,  <span class=\"number\">0.</span>], dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.zeros_like(x, dtype=torch.int)</div><div class=\"line\">tensor([ <span class=\"number\">0</span>,  <span class=\"number\">0</span>,  <span class=\"number\">0</span>], dtype=torch.int32)</div></pre></td></tr></table></figure>\n</li>\n<li><p><code>tensor.new_*</code>shape</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.new_ones(<span class=\"number\">2</span>)</div><div class=\"line\">tensor([ <span class=\"number\">1.</span>,  <span class=\"number\">1.</span>], dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.new_ones(<span class=\"number\">4</span>, dtype=torch.int)</div><div class=\"line\">tensor([ <span class=\"number\">1</span>,  <span class=\"number\">1</span>,  <span class=\"number\">1</span>,  <span class=\"number\">1</span>], dtype=torch.int32)</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>shape<code>tuple</code><code>torch.zeros((2, 3))</code>Numpy<code>torch.zeros(2, 3)</code></p>\n<table>\n   <tr>\n      <td>Name</td>\n      <td>Returned Tensor</td>\n      <td>torch.*_likevariant</td>\n      <td>tensor.new_*variant</td>\n   </tr>\n   <tr>\n      <td>torch.empty</td>\n      <td>unintialized memory</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.zeros</td>\n      <td>all zeros</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.ones</td>\n      <td>all ones</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.full</td>\n      <td>filled with a given value</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.rand</td>\n      <td>i.i.d. continuous Uniform[0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randn</td>\n      <td>i.i.d. Normal(0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randint</td>\n      <td>i.i.d. discrete Uniform in given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randperm</td>\n      <td>random permutation of {0, 1, ..., n - 1}</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.tensor</td>\n      <td>copied from existing data (list, NumPy ndarray, etc.)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.from_numpy*</td>\n      <td>from NumPy ndarray (sharing storage without copying)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.arange, torch.range and torch.linspace</td>\n      <td>uniformly spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.logspace</td>\n      <td>logarithmically spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.eye</td>\n      <td>identity matrix</td>\n      <td></td>\n      <td></td>\n   </tr>\n</table>\n\n<p><code>torch.from_numpy</code>NumPy <code>ndarray</code></p>\n<h2 id=\"device-agnostic-code\"><a href=\"#device-agnostic-code\" class=\"headerlink\" title=\"device-agnostic code\"></a>device-agnostic code</h2><p></p>\n<ul>\n<li><code>Tensor</code><code>device</code><code>torch.device</code><code>get_device</code>CUDA tensor</li>\n<li><code>x.to()</code><code>Tensor</code><code>Module</code>devices<code>x.cpu()</code><code>x.cuda()</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># device</span></div><div class=\"line\">device = torch.device(<span class=\"string\">\"cuda:0\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># TensorModule</span></div><div class=\"line\"><span class=\"comment\"># devicecopy</span></div><div class=\"line\">input = data.to(device)</div><div class=\"line\">model = MyModule(...).to(device)</div></pre></td></tr></table></figure>\n<h2 id=\"nn-Modulesubmoduleparameterbuffer\"><a href=\"#nn-Modulesubmoduleparameterbuffer\" class=\"headerlink\" title=\"nn.Modulesubmoduleparameterbuffer\"></a><code>nn.Module</code>submoduleparameterbuffer</h2><p><code>module.add_module(name, value)</code>, <code>module.add_parameter(name, value)</code>  <code>module.add_buffer(name, value)</code><code>.</code><code>state_dict</code>load<code>state_dict</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>code snippet0.3.10.4.0</p>\n<h3 id=\"0-3-1-version\"><a href=\"#0-3-1-version\" class=\"headerlink\" title=\"0.3.1 version\"></a>0.3.1 version</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">model = MyRNN()</div><div class=\"line\"><span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">    model = model.cuda()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># train</span></div><div class=\"line\">total_loss = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> train_loader:</div><div class=\"line\">    input, target = Variable(input), Variable(target)</div><div class=\"line\">    hidden = Variable(torch.zeros(*h_shape))  <span class=\"comment\"># init hidden</span></div><div class=\"line\">    <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">        input, target, hidden = input.cuda(), target.cuda(), hidden.cuda()</div><div class=\"line\">    ...  <span class=\"comment\"># get loss and optimize</span></div><div class=\"line\">    total_loss += loss.data[<span class=\"number\">0</span>]</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># evaluate</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> test_loader:</div><div class=\"line\">    input = Variable(input, volatile=<span class=\"keyword\">True</span>)</div><div class=\"line\">    <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">        ...</div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<h3 id=\"0-4-0-version\"><a href=\"#0-4-0-version\" class=\"headerlink\" title=\"0.4.0 version\"></a>0.4.0 version</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># torch.device object used throughout this script</span></div><div class=\"line\">device = torch.device(<span class=\"string\">\"cuda\"</span> <span class=\"keyword\">if</span> use_cuda <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</div><div class=\"line\"></div><div class=\"line\">model = MyRNN().to(device)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># train</span></div><div class=\"line\">total_loss = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> train_loader:</div><div class=\"line\">    input, target = input.to(device), target.to(device)</div><div class=\"line\">    hidden = input.new_zeros(*h_shape)  <span class=\"comment\"># has the same device &amp; dtype as `input`</span></div><div class=\"line\">    ...  <span class=\"comment\"># get loss and optimize</span></div><div class=\"line\">    total_loss += loss.item()           <span class=\"comment\"># get Python number from 1-element Tensor</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># evaluate</span></div><div class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():                   <span class=\"comment\"># operations inside don't track history</span></div><div class=\"line\">    <span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> test_loader:</div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"https://github.com/pytorch/pytorch/releases/tag/v0.4.0\" target=\"_blank\" rel=\"external\">Release Note</a></li>\n<li><a href=\"http://pytorch.org/docs/stable/index.html\" target=\"_blank\" rel=\"external\">Documentation</a></li>\n</ul>\n","excerpt":"<p>PyTorch0.4.0API<a href=\"http://pytorch.org/2018/04/22/0_4_0-migration-guide.html\"></a></p>\n<ul>\n<li><code>Tensor</code><code>Variable</code><code>autograd</code><code>requires_grad</code></li>\n<li>Numpy<code>Tensor</code></li>\n<li><code>device</code>cpugpu</li>\n</ul>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>0.4.0PyTorchbug fixes</p>\n<ul>\n<li><code>Tensors</code>  <code>Variables</code> merge</li>\n<li>0Tensorscalar</li>\n<li> <code>volatile</code> </li>\n<li><code>dtypes</code>, <code>devices</code>,  Numpy  Tensor</li>\n<li></li>\n</ul>\n<p></p>\n<h2 id=\"Tensor--Variable-\"><a href=\"#Tensor--Variable-\" class=\"headerlink\" title=\"Tensor  Variable \"></a><code>Tensor</code>  <code>Variable</code> </h2><p>PyTorch<code>Tensor</code><code>numpy</code><code>ndarray</code><code>Variable</code><code>Variable</code><code>Tensor</code>warpping</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> data, target <span class=\"keyword\">in</span> data_loader:</div><div class=\"line\">    <span class=\"comment\">## </span></div><div class=\"line\">    data, target = Variable(data), Variable(target)</div><div class=\"line\">    loss = criterion(model(data), target)</div></pre></td></tr></table></figure>\n<h3 id=\"Tensortype\"><a href=\"#Tensortype\" class=\"headerlink\" title=\"Tensortype()\"></a><code>Tensor</code><code>type()</code></h3><p><code>type()</code><code>Tensor</code>data typeFloatTensorLongTensor<code>x.type()</code><code>isinstance()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.DoubleTensor([<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(type(x))  <span class=\"comment\">#  torch.DoubleTensor</span></div><div class=\"line\"><span class=\"string\">\"&lt;class 'torch.Tensor'&gt;\"</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(x.type())  <span class=\"comment\"># OK: 'torch.DoubleTensor'</span></div><div class=\"line\"><span class=\"string\">'torch.DoubleTensor'</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>print(isinstance(x, torch.DoubleTensor))  <span class=\"comment\"># OK: True</span></div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"autograd\"><a href=\"#autograd\" class=\"headerlink\" title=\"autograd\"></a><code>autograd</code></h3><p><code>Tensor</code><code>Variable</code></p>\n<p><code>requires_grad</code>, <code>autograd</code>,<code>Tensor</code><code>Variable</code><code>Tensor</code><code>autograd</code>input<code>requires_grad==True</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.ones(<span class=\"number\">1</span>)  <span class=\"comment\">## requires_grad = False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = torch.ones(<span class=\"number\">1</span>)  <span class=\"comment\">## yrequires_gradFalse</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z = x + y</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## zrequires_gradFalse</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## zError</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.backward()</div><div class=\"line\">RuntimeError: element <span class=\"number\">0</span> of tensors does <span class=\"keyword\">not</span> require grad <span class=\"keyword\">and</span> does <span class=\"keyword\">not</span> have a grad_fn</div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">##  requires_grad=True Tensor</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w = torch.ones(<span class=\"number\">1</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## requires_grad=False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total = w + z</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## wtotal</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">## bp</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>total.backward()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>w.grad</div><div class=\"line\">tensor([ <span class=\"number\">1.</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"comment\">##  x y z require gradgrad == None</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>z.grad == x.grad == y.grad == <span class=\"keyword\">None</span></div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"-requires-grad-\"><a href=\"#-requires-grad-\" class=\"headerlink\" title=\" requires_grad \"></a> <code>requires_grad</code> </h3><p><code>my_tensor.requires_grad_()</code><code>_</code>in-place</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>existing_tensor.requires_grad_()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>existing_tensor.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_tensor = torch.zeros(<span class=\"number\">3</span>, <span class=\"number\">4</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>my_tensor.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"dataWhat-about-data\"><a href=\"#dataWhat-about-data\" class=\"headerlink\" title=\".dataWhat about .data?\"></a><code>.data</code>What about .data?</h3><p><code>Variable</code><code>x.data</code><code>Tensor</code>merge<code>y = x.data</code><code>y</code><code>x</code>data<code>x</code><code>requires_grad</code><code>False</code></p>\n<p><code>.data</code><code>x.data</code><code>aotograd</code><code>x.detach()</code><code>x</code>dataTensor<code>requires_grad=False</code><code>x</code>bp</p>\n<p>However, .data can be unsafe in some cases. Any changes on x.data wouldnt be tracked by autograd, and the computed gradients would be incorrect if x is needed in a backward pass. A safer alternative is to use x.detach(), which also returns a Tensor that shares data with requires_grad=False, but will have its in-place changes reported by autograd if x is needed in backward.</p>\n<h2 id=\"0-scalar-Tensor\"><a href=\"#0-scalar-Tensor\" class=\"headerlink\" title=\"0(scalar)Tensor\"></a>0(scalar)Tensor</h2><p>Tensor vector1D Tensorpython numberVariable vector<code>size(1,)</code>vector!reduction function<code>torch.sum</code><code>torch.max</code></p>\n<p>scalar0D Tensor<code>torch.tensor()</code> </p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">3.1416</span>)         <span class=\"comment\"># scalar</span></div><div class=\"line\">tensor(<span class=\"number\">3.1416</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">3.1416</span>).size()  <span class=\"comment\"># scalar  0D</span></div><div class=\"line\">torch.Size([])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">3</span>]).size()     <span class=\"comment\"># 1D</span></div><div class=\"line\">torch.Size([<span class=\"number\">1</span>])</div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector = torch.arange(<span class=\"number\">2</span>, <span class=\"number\">6</span>)  <span class=\"comment\"># 1Dvector</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector</div><div class=\"line\">tensor([ <span class=\"number\">2.</span>,  <span class=\"number\">3.</span>,  <span class=\"number\">4.</span>,  <span class=\"number\">5.</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector.size()</div><div class=\"line\">torch.Size([<span class=\"number\">4</span>])</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector[<span class=\"number\">3</span>]                    <span class=\"comment\"># 1Dvectorindexingscalar</span></div><div class=\"line\">tensor(<span class=\"number\">5.</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>vector[<span class=\"number\">3</span>].item()             <span class=\"comment\"># .item()python number</span></div><div class=\"line\"><span class=\"number\">5.0</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum = torch.tensor([<span class=\"number\">2</span>, <span class=\"number\">3</span>]).sum()</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum</div><div class=\"line\">tensor(<span class=\"number\">5</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>mysum.size()</div><div class=\"line\">torch.Size([])</div></pre></td></tr></table></figure>\n<h3 id=\"losses\"><a href=\"#losses\" class=\"headerlink\" title=\"losses\"></a>losses</h3><p><code>total_loss += loss.data[0]</code><code>loss</code><code>(1,)</code><code>Tensor</code><code>Variable</code><code>loss</code>0Dscalarscalarindexing<code>loss.item()</code>python number</p>\n<p>python number<code>autograd</code> <code>total_loss += loss.item()</code></p>\n<h2 id=\"volatile\"><a href=\"#volatile\" class=\"headerlink\" title=\"volatile\"></a><code>volatile</code></h2><p><code>volatile</code> <code>volatile=True</code><code>Variable</code> <code>autograd</code><code>torch.no_grad()</code><code>torch.set_grad_enable(grad_mode)</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.zeros(<span class=\"number\">1</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">with</span> torch.no_grad():    <span class=\"comment\">#  torch,no_grad()track</span></div><div class=\"line\"><span class=\"meta\">... </span>    y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\">&gt;&gt;&gt;</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>is_train = <span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span><span class=\"keyword\">with</span> torch.set_grad_enabled(is_train):   <span class=\"comment\"># inferencetrack</span></div><div class=\"line\"><span class=\"meta\">... </span>    y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class=\"keyword\">True</span>)  <span class=\"comment\"># with</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.set_grad_enabled(<span class=\"keyword\">False</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>y.requires_grad</div><div class=\"line\"><span class=\"keyword\">False</span></div></pre></td></tr></table></figure>\n<h2 id=\"dtypes-devices-NumPy\"><a href=\"#dtypes-devices-NumPy\" class=\"headerlink\" title=\"dtypes, devices NumPy\"></a><code>dtypes</code>, <code>devices</code> NumPy</h2><p>tensor typedata type<code>float</code><code>double</code>device typecpugpulayoutdensesparse<code>torch.cuda.sparse.DoubleTensor</code>data type<code>double</code>GPUsparsetensor</p>\n<p><code>torch.dtype</code><code>torch.device</code><code>torch.layout</code>Numpy</p>\n<h3 id=\"torch-dtype\"><a href=\"#torch-dtype\" class=\"headerlink\" title=\"torch.dtype\"></a><code>torch.dtype</code></h3><p> <code>torch.dtypes</code> (data types) tensor types<code>x.dtype</code></p>\n<table>\n   <tr>\n      <td>data type</td>\n      <td>torch.dtype</td>\n      <td>Tensor types</td>\n   </tr>\n   <tr>\n      <td>32-bit floating point</td>\n      <td>torch.float32 or torch.float</td>\n      <td>torch.*.FloatTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit floating point</td>\n      <td>torch.float64 or torch.double</td>\n      <td>torch.*.DoubleTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit floating point</td>\n      <td>torch.float16 or torch.half</td>\n      <td>torch.*.HalfTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (unsigned)</td>\n      <td>torch.uint8</td>\n      <td>torch.*.ByteTensor</td>\n   </tr>\n   <tr>\n      <td>8-bit integer (signed)</td>\n      <td>torch.int8</td>\n      <td>torch.*.CharTensor</td>\n   </tr>\n   <tr>\n      <td>16-bit integer (signed)</td>\n      <td>torch.int16 or torch.short</td>\n      <td>torch.*.ShortTensor</td>\n   </tr>\n   <tr>\n      <td>32-bit integer (signed)</td>\n      <td>torch.int32 or torch.int</td>\n      <td>torch.*.IntTensor</td>\n   </tr>\n   <tr>\n      <td>64-bit integer (signed)</td>\n      <td>torch.int64 or torch.long</td>\n      <td>torch.*.LongTensor</td>\n   </tr>\n</table>\n\n<h3 id=\"torch-device\"><a href=\"#torch-device\" class=\"headerlink\" title=\"torch.device\"></a><code>torch.device</code></h3><p><code>torch.device</code>device typecpucudaid<code>torch.device(&#39;{device_type}&#39;)</code><code>torch.device(&#39;{device_type}:{device_ordinal}&#39;)</code> </p>\n<p><code>device ordinal</code>device<code>torch.device(&#39;cuda&#39;)</code><code>torch.device(&#39;cuda:X&#39;)</code><code>X</code><code>torch.cuda.current_device()</code></p>\n<p><code>x.device</code></p>\n<h3 id=\"torch-layout\"><a href=\"#torch-layout\" class=\"headerlink\" title=\"torch.layout\"></a><code>torch.layout</code></h3><p><code>torch.layout</code><code>Tensor</code>data layout <code>torch.strided</code> (dense)  <code>torch.sparse_coo</code> (COOGtensor)</p>\n<p><code>x.layout</code></p>\n<h3 id=\"TensorNumpy\"><a href=\"#TensorNumpy\" class=\"headerlink\" title=\"TensorNumpy\"></a><code>Tensor</code>Numpy</h3><p><code>dtype</code><code>device</code><code>layout</code><code>requires_grad</code><code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>device = torch.device(<span class=\"string\">\"cuda:1\"</span>) </div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, <span class=\"number\">3</span>, dtype=torch.float64, device=device)</div><div class=\"line\">tensor([[<span class=\"number\">-0.6344</span>,  <span class=\"number\">0.8562</span>, <span class=\"number\">-1.2758</span>],</div><div class=\"line\">        [ <span class=\"number\">0.8414</span>,  <span class=\"number\">1.7962</span>,  <span class=\"number\">1.0589</span>],</div><div class=\"line\">        [<span class=\"number\">-0.1369</span>, <span class=\"number\">-1.0462</span>, <span class=\"number\">-0.4373</span>]], dtype=torch.float64, device=<span class=\"string\">'cuda:1'</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad  <span class=\"comment\"># default is False</span></div><div class=\"line\"><span class=\"keyword\">False</span></div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.zeros(<span class=\"number\">3</span>, requires_grad=<span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.requires_grad</div><div class=\"line\"><span class=\"keyword\">True</span></div></pre></td></tr></table></figure>\n<h3 id=\"torch-tensor-data\"><a href=\"#torch-tensor-data\" class=\"headerlink\" title=\"torch.tensor(data, ...)\"></a><code>torch.tensor(data, ...)</code></h3><p><code>torch.tensor</code><code>Tesnor</code>array-likevalue copy<code>Tensor</code><code>numpy.array</code><code>torch.*Tensor</code>0DTensorscalar<code>dtype</code>dataPython List<code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>cuda = torch.device(<span class=\"string\">\"cuda\"</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([[<span class=\"number\">1</span>], [<span class=\"number\">2</span>], [<span class=\"number\">3</span>]], dtype=torch.half, device=cuda)</div><div class=\"line\">tensor([[ <span class=\"number\">1</span>],</div><div class=\"line\">        [ <span class=\"number\">2</span>],</div><div class=\"line\">        [ <span class=\"number\">3</span>]], device=<span class=\"string\">'cuda:0'</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor(<span class=\"number\">1</span>)               <span class=\"comment\"># scalar</span></div><div class=\"line\">tensor(<span class=\"number\">1</span>)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2.3</span>]).dtype  <span class=\"comment\"># type inferece</span></div><div class=\"line\">torch.float32</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.tensor([<span class=\"number\">1</span>, <span class=\"number\">2</span>]).dtype    <span class=\"comment\"># type inferece</span></div><div class=\"line\">torch.int64</div></pre></td></tr></table></figure>\n<p><code>Tensor</code><code>torch.*_like</code><code>tensor.new_*</code></p>\n<ul>\n<li><p><code>torch.*_like</code>input tensor tensor</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.zeros_like(x)</div><div class=\"line\">tensor([ <span class=\"number\">0.</span>,  <span class=\"number\">0.</span>,  <span class=\"number\">0.</span>], dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>torch.zeros_like(x, dtype=torch.int)</div><div class=\"line\">tensor([ <span class=\"number\">0</span>,  <span class=\"number\">0</span>,  <span class=\"number\">0</span>], dtype=torch.int32)</div></pre></td></tr></table></figure>\n</li>\n<li><p><code>tensor.new_*</code>shape</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = torch.randn(<span class=\"number\">3</span>, dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.new_ones(<span class=\"number\">2</span>)</div><div class=\"line\">tensor([ <span class=\"number\">1.</span>,  <span class=\"number\">1.</span>], dtype=torch.float64)</div><div class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x.new_ones(<span class=\"number\">4</span>, dtype=torch.int)</div><div class=\"line\">tensor([ <span class=\"number\">1</span>,  <span class=\"number\">1</span>,  <span class=\"number\">1</span>,  <span class=\"number\">1</span>], dtype=torch.int32)</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>shape<code>tuple</code><code>torch.zeros((2, 3))</code>Numpy<code>torch.zeros(2, 3)</code></p>\n<table>\n   <tr>\n      <td>Name</td>\n      <td>Returned Tensor</td>\n      <td>torch.*_likevariant</td>\n      <td>tensor.new_*variant</td>\n   </tr>\n   <tr>\n      <td>torch.empty</td>\n      <td>unintialized memory</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.zeros</td>\n      <td>all zeros</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.ones</td>\n      <td>all ones</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.full</td>\n      <td>filled with a given value</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.rand</td>\n      <td>i.i.d. continuous Uniform[0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randn</td>\n      <td>i.i.d. Normal(0, 1)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randint</td>\n      <td>i.i.d. discrete Uniform in given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.randperm</td>\n      <td>random permutation of {0, 1, ..., n - 1}</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.tensor</td>\n      <td>copied from existing data (list, NumPy ndarray, etc.)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.from_numpy*</td>\n      <td>from NumPy ndarray (sharing storage without copying)</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.arange, torch.range and torch.linspace</td>\n      <td>uniformly spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.logspace</td>\n      <td>logarithmically spaced values in a given range</td>\n      <td></td>\n      <td></td>\n   </tr>\n   <tr>\n      <td>torch.eye</td>\n      <td>identity matrix</td>\n      <td></td>\n      <td></td>\n   </tr>\n</table>\n\n<p><code>torch.from_numpy</code>NumPy <code>ndarray</code></p>\n<h2 id=\"device-agnostic-code\"><a href=\"#device-agnostic-code\" class=\"headerlink\" title=\"device-agnostic code\"></a>device-agnostic code</h2><p></p>\n<ul>\n<li><code>Tensor</code><code>device</code><code>torch.device</code><code>get_device</code>CUDA tensor</li>\n<li><code>x.to()</code><code>Tensor</code><code>Module</code>devices<code>x.cpu()</code><code>x.cuda()</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># device</span></div><div class=\"line\">device = torch.device(<span class=\"string\">\"cuda:0\"</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">## </span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># TensorModule</span></div><div class=\"line\"><span class=\"comment\"># devicecopy</span></div><div class=\"line\">input = data.to(device)</div><div class=\"line\">model = MyModule(...).to(device)</div></pre></td></tr></table></figure>\n<h2 id=\"nn-Modulesubmoduleparameterbuffer\"><a href=\"#nn-Modulesubmoduleparameterbuffer\" class=\"headerlink\" title=\"nn.Modulesubmoduleparameterbuffer\"></a><code>nn.Module</code>submoduleparameterbuffer</h2><p><code>module.add_module(name, value)</code>, <code>module.add_parameter(name, value)</code>  <code>module.add_buffer(name, value)</code><code>.</code><code>state_dict</code>load<code>state_dict</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>code snippet0.3.10.4.0</p>\n<h3 id=\"0-3-1-version\"><a href=\"#0-3-1-version\" class=\"headerlink\" title=\"0.3.1 version\"></a>0.3.1 version</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">model = MyRNN()</div><div class=\"line\"><span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">    model = model.cuda()</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># train</span></div><div class=\"line\">total_loss = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> train_loader:</div><div class=\"line\">    input, target = Variable(input), Variable(target)</div><div class=\"line\">    hidden = Variable(torch.zeros(*h_shape))  <span class=\"comment\"># init hidden</span></div><div class=\"line\">    <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">        input, target, hidden = input.cuda(), target.cuda(), hidden.cuda()</div><div class=\"line\">    ...  <span class=\"comment\"># get loss and optimize</span></div><div class=\"line\">    total_loss += loss.data[<span class=\"number\">0</span>]</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># evaluate</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> test_loader:</div><div class=\"line\">    input = Variable(input, volatile=<span class=\"keyword\">True</span>)</div><div class=\"line\">    <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">        ...</div><div class=\"line\">    ...</div></pre></td></tr></table></figure>\n<h3 id=\"0-4-0-version\"><a href=\"#0-4-0-version\" class=\"headerlink\" title=\"0.4.0 version\"></a>0.4.0 version</h3><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># torch.device object used throughout this script</span></div><div class=\"line\">device = torch.device(<span class=\"string\">\"cuda\"</span> <span class=\"keyword\">if</span> use_cuda <span class=\"keyword\">else</span> <span class=\"string\">\"cpu\"</span>)</div><div class=\"line\"></div><div class=\"line\">model = MyRNN().to(device)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># train</span></div><div class=\"line\">total_loss = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> train_loader:</div><div class=\"line\">    input, target = input.to(device), target.to(device)</div><div class=\"line\">    hidden = input.new_zeros(*h_shape)  <span class=\"comment\"># has the same device &amp; dtype as `input`</span></div><div class=\"line\">    ...  <span class=\"comment\"># get loss and optimize</span></div><div class=\"line\">    total_loss += loss.item()           <span class=\"comment\"># get Python number from 1-element Tensor</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># evaluate</span></div><div class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():                   <span class=\"comment\"># operations inside don't track history</span></div><div class=\"line\">    <span class=\"keyword\">for</span> input, target <span class=\"keyword\">in</span> test_loader:</div><div class=\"line\">        ...</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><a href=\"https://github.com/pytorch/pytorch/releases/tag/v0.4.0\">Release Note</a></li>\n<li><a href=\"http://pytorch.org/docs/stable/index.html\">Documentation</a></li>\n</ul>"},{"title":"Residual Net - Identity Mapping in Deep Residual Networks","date":"2017-03-07T08:16:48.000Z","_content":"He KaimingResidualNetIdentity MappingIdentity MappingIdentity Mapping\n<!-- more -->\n\n## \nCVPR best paper$x\\_l$$x\\_{l+1}$$l$$\\mathcal{F}$\n$$y_l = h(x_l) + \\mathcal{F}(x_l, W_l)$$\n$$x_{l+1} = f(y_l)$$\n\n$f(x)$ReLU$h(x)$Identity Mapping\n$$h(x_l) = x_l$$\n\n\n![BNReLU](/img/residualnet_improved_structure.png)\n\nBNReLUpre-activationpost-activation\n\n$x\\_l$BNReLUBN-ReLU-conv$y\\_l$$x\\_l$$x\\_{l+1}$\n\n1001CIFAR-10/100error\n\n\n## Identity Mapping: Why Always me?\nIdentity Mapping\n\n\n\n$$x_{l+1} = x_l + \\mathcal{F}(x_l, W_l)$$\n\n\n\n$$x_L = x_l +\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i)$$\n\n\n\n- $L$$x_L$$x_l$j$\\mathcal{F}$\n- $x\\_L=x\\_0+\\sum\\_{i=0}^{L-1}\\mathcal{F}(x\\_i, W\\_i)$$x\\_L$$x\\_l$$x\\_L = \\prod\\_{i=0}^{L-1}W\\_ix\\_0$\n\nbp\n$$\\frac{\\partial \\epsilon}{\\partial x_l} = \\frac{\\partial \\epsilon} {\\partial x_L}\\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial \\epsilon}{\\partial x_L}(1+\\frac{\\partial}{\\partial x_l}\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i))$$\n\nshortcut$x_l$-1\n\nIdentity Mapping$\\lambda$$\\lambda^k$vanish\n\nIdentity Mapping\n\n## \nPyTorch164ResNetCIFAR10[Gist Code: ResNet-164 training experiment on CIFAR10 using PyTorch](https://gist.github.com/xmfbit/67c407e34cbaf56e7820f09e774e56d8)\n\n[DMLC/tensorboard](https://github.com/dmlc/tensorboard)$30K$$0.1$\n![](/img/resnet-164layer-cifar10-training.jpg)\n![](/img/resnet-164layer-cifar10-testing.jpg)\n","source":"_posts/residualnet-paper2-identitymapping.md","raw":"---\ntitle: Residual Net - Identity Mapping in Deep Residual Networks\ndate: 2017-03-07 16:16:48\ntags:\n    - paper\n    - deep learning\n---\nHe KaimingResidualNetIdentity MappingIdentity MappingIdentity Mapping\n<!-- more -->\n\n## \nCVPR best paper$x\\_l$$x\\_{l+1}$$l$$\\mathcal{F}$\n$$y_l = h(x_l) + \\mathcal{F}(x_l, W_l)$$\n$$x_{l+1} = f(y_l)$$\n\n$f(x)$ReLU$h(x)$Identity Mapping\n$$h(x_l) = x_l$$\n\n\n![BNReLU](/img/residualnet_improved_structure.png)\n\nBNReLUpre-activationpost-activation\n\n$x\\_l$BNReLUBN-ReLU-conv$y\\_l$$x\\_l$$x\\_{l+1}$\n\n1001CIFAR-10/100error\n\n\n## Identity Mapping: Why Always me?\nIdentity Mapping\n\n\n\n$$x_{l+1} = x_l + \\mathcal{F}(x_l, W_l)$$\n\n\n\n$$x_L = x_l +\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i)$$\n\n\n\n- $L$$x_L$$x_l$j$\\mathcal{F}$\n- $x\\_L=x\\_0+\\sum\\_{i=0}^{L-1}\\mathcal{F}(x\\_i, W\\_i)$$x\\_L$$x\\_l$$x\\_L = \\prod\\_{i=0}^{L-1}W\\_ix\\_0$\n\nbp\n$$\\frac{\\partial \\epsilon}{\\partial x_l} = \\frac{\\partial \\epsilon} {\\partial x_L}\\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial \\epsilon}{\\partial x_L}(1+\\frac{\\partial}{\\partial x_l}\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i))$$\n\nshortcut$x_l$-1\n\nIdentity Mapping$\\lambda$$\\lambda^k$vanish\n\nIdentity Mapping\n\n## \nPyTorch164ResNetCIFAR10[Gist Code: ResNet-164 training experiment on CIFAR10 using PyTorch](https://gist.github.com/xmfbit/67c407e34cbaf56e7820f09e774e56d8)\n\n[DMLC/tensorboard](https://github.com/dmlc/tensorboard)$30K$$0.1$\n![](/img/resnet-164layer-cifar10-training.jpg)\n![](/img/resnet-164layer-cifar10-testing.jpg)\n","slug":"residualnet-paper2-identitymapping","published":1,"updated":"2018-10-27T07:16:52.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8o3003pae7bxei90rvh","content":"<p>He KaimingResidualNetIdentity MappingIdentity MappingIdentity Mapping<br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CVPR best paper$x_l$$x_{l+1}$$l$$\\mathcal{F}$</p>\n<script type=\"math/tex; mode=display\">y_l = h(x_l) + \\mathcal{F}(x_l, W_l)</script><script type=\"math/tex; mode=display\">x_{l+1} = f(y_l)</script><p>$f(x)$ReLU$h(x)$Identity Mapping</p>\n<script type=\"math/tex; mode=display\">h(x_l) = x_l</script><p><br><img src=\"/img/residualnet_improved_structure.png\" alt=\"BNReLU\"></p>\n<p>BNReLUpre-activationpost-activation</p>\n<p>$x_l$BNReLUBN-ReLU-conv$y_l$$x_l$$x_{l+1}$</p>\n<p>1001CIFAR-10/100error</p>\n<h2 id=\"Identity-Mapping-Why-Always-me\"><a href=\"#Identity-Mapping-Why-Always-me\" class=\"headerlink\" title=\"Identity Mapping: Why Always me?\"></a>Identity Mapping: Why Always me?</h2><p>Identity Mapping</p>\n<p></p>\n<script type=\"math/tex; mode=display\">x_{l+1} = x_l + \\mathcal{F}(x_l, W_l)</script><p></p>\n<script type=\"math/tex; mode=display\">x_L = x_l +\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i)</script><p></p>\n<ul>\n<li>$L$$x_L$$x_l$j$\\mathcal{F}$</li>\n<li>$x_L=x_0+\\sum_{i=0}^{L-1}\\mathcal{F}(x_i, W_i)$$x_L$$x_l$$x_L = \\prod_{i=0}^{L-1}W_ix_0$</li>\n</ul>\n<p>bp</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial \\epsilon}{\\partial x_l} = \\frac{\\partial \\epsilon} {\\partial x_L}\\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial \\epsilon}{\\partial x_L}(1+\\frac{\\partial}{\\partial x_l}\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i))</script><p>shortcut$x_l$-1</p>\n<p>Identity Mapping$\\lambda$$\\lambda^k$vanish</p>\n<p>Identity Mapping</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorch164ResNetCIFAR10<a href=\"https://gist.github.com/xmfbit/67c407e34cbaf56e7820f09e774e56d8\" target=\"_blank\" rel=\"external\">Gist Code: ResNet-164 training experiment on CIFAR10 using PyTorch</a></p>\n<p><a href=\"https://github.com/dmlc/tensorboard\" target=\"_blank\" rel=\"external\">DMLC/tensorboard</a>$30K$$0.1$<br><img src=\"/img/resnet-164layer-cifar10-training.jpg\" alt=\"\"><br><img src=\"/img/resnet-164layer-cifar10-testing.jpg\" alt=\"\"></p>\n","excerpt":"<p>He KaimingResidualNetIdentity MappingIdentity MappingIdentity Mapping<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>CVPR best paper$x_l$$x_{l+1}$$l$$\\mathcal{F}$</p>\n<script type=\"math/tex; mode=display\">y_l = h(x_l) + \\mathcal{F}(x_l, W_l)</script><script type=\"math/tex; mode=display\">x_{l+1} = f(y_l)</script><p>$f(x)$ReLU$h(x)$Identity Mapping</p>\n<script type=\"math/tex; mode=display\">h(x_l) = x_l</script><p><br><img src=\"/img/residualnet_improved_structure.png\" alt=\"BNReLU\"></p>\n<p>BNReLUpre-activationpost-activation</p>\n<p>$x_l$BNReLUBN-ReLU-conv$y_l$$x_l$$x_{l+1}$</p>\n<p>1001CIFAR-10/100error</p>\n<h2 id=\"Identity-Mapping-Why-Always-me\"><a href=\"#Identity-Mapping-Why-Always-me\" class=\"headerlink\" title=\"Identity Mapping: Why Always me?\"></a>Identity Mapping: Why Always me?</h2><p>Identity Mapping</p>\n<p></p>\n<script type=\"math/tex; mode=display\">x_{l+1} = x_l + \\mathcal{F}(x_l, W_l)</script><p></p>\n<script type=\"math/tex; mode=display\">x_L = x_l +\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i)</script><p></p>\n<ul>\n<li>$L$$x_L$$x_l$j$\\mathcal{F}$</li>\n<li>$x_L=x_0+\\sum_{i=0}^{L-1}\\mathcal{F}(x_i, W_i)$$x_L$$x_l$$x_L = \\prod_{i=0}^{L-1}W_ix_0$</li>\n</ul>\n<p>bp</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial \\epsilon}{\\partial x_l} = \\frac{\\partial \\epsilon} {\\partial x_L}\\frac{\\partial x_L}{\\partial x_l} = \\frac{\\partial \\epsilon}{\\partial x_L}(1+\\frac{\\partial}{\\partial x_l}\\sum_{i=l}^{L-1}\\mathcal{F}(x_i, W_i))</script><p>shortcut$x_l$-1</p>\n<p>Identity Mapping$\\lambda$$\\lambda^k$vanish</p>\n<p>Identity Mapping</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorch164ResNetCIFAR10<a href=\"https://gist.github.com/xmfbit/67c407e34cbaf56e7820f09e774e56d8\">Gist Code: ResNet-164 training experiment on CIFAR10 using PyTorch</a></p>\n<p><a href=\"https://github.com/dmlc/tensorboard\">DMLC/tensorboard</a>$30K$$0.1$<br><img src=\"/img/resnet-164layer-cifar10-training.jpg\" alt=\"\"><br><img src=\"/img/resnet-164layer-cifar10-testing.jpg\" alt=\"\"></p>"},{"title":"toy demo - PyTorch + MNIST","date":"2017-03-04T14:37:44.000Z","_content":"PyTorchMNISTMLPCNN\n![MNIST](/img/mnist_example.png)\n<!-- more -->\n\n## MNIST\nPyTorchMNISTCIFARCOCO`MNIST``torchvision.datasets``download``True``root`\n\nRGBaugmentation`torchvision.transforms``transforms.Compose()``ToTensor`PILTensorRGB`[0, 255]``[0, 1]` `Normalize`MNIST1`tuple`\n\n`DataLoader``for`\n\n``` py\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# use cuda or not\nuse_cuda = torch.cuda.is_available()\n\ntrans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n\ntrain_set = dset.MNIST(root=root, train=True, transform=trans, download=download)\ntest_set = dset.MNIST(root=root, train=False, transform=trans)\n\nbatch_size = 128\n\ntrain_loader = torch.utils.data.DataLoader(\n                 dataset=train_set,\n                 batch_size=batch_size,\n                 shuffle=True)\ntest_loader = torch.utils.data.DataLoader(\n                dataset=test_set,\n                batch_size=batch_size,\n                shuffle=False)\n\n```\n\n## \n`torch.nn`MLP`nn.Linear``y = wx+b``x``y`\n\n``` py\nclass MLPNet(nn.Module):\n    def __init__(self):\n        super(MLPNet, self).__init__()\n        self.fc1 = nn.Linear(28*28, 500)\n        self.fc2 = nn.Linear(500, 256)\n        self.fc3 = nn.Linear(256, 10)\n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```\nPyTorch`forward``nn.functionals``nn``nn.functionals`\n\n``` py\n# With square kernels and equal stride\nfilters = autograd.Variable(torch.randn(8,4,3,3))\ninputs = autograd.Variable(torch.randn(1,4,5,5))\nF.conv2d(inputs, filters, padding=1)\n```\n\nLeNet\n\n``` py\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```\n\n## \n\n`SGD``optim.SGD``Parameter``lr``momentum`\n\n``` py\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n```\n\n\n\n``` py\n## training\nmodel = LeNet()\n\nif use_cuda:\n    model = model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nceriation = nn.CrossEntropyLoss()\n\nfor epoch in xrange(10):\n    # trainning\n    ave_loss = 0\n    for batch_idx, (x, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        if use_cuda:\n            x, target = x.cuda(), target.cuda()\n        x, target = Variable(x), Variable(target)\n        out = model(x)\n        loss = ceriation(out, target)\n        ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n        loss.backward()\n        optimizer.step()\n        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n            print '==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n                epoch, batch_idx+1, ave_loss)\n    # testing\n    correct_cnt, ave_loss = 0, 0\n    total_cnt = 0\n    for batch_idx, (x, target) in enumerate(test_loader):\n        if use_cuda:\n            x, targe = x.cuda(), target.cuda()\n        x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n        out = model(x)\n        loss = ceriation(out, target)\n        _, pred_label = torch.max(out.data, 1)\n        total_cnt += x.data.size()[0]\n        correct_cnt += (pred_label == target.data).sum()\n        # smooth average\n        ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n        \n        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n            print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n                epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)\n\n```\n\n[](http://pytorch.org/docs/notes/serialization.html#recommend-saving-models)\n``` py\ntorch.save(model.state_dict(), PATH)   #\nthe_model = TheModelClass(*args, **kwargs)\nthe_model.load_state_dict(torch.load(PATH))  #\n```\n\n[PyTorch MNIST demo](https://gist.github.com/xmfbit/b27cdbff68870418bdb8cefa86a2d558)\n","source":"_posts/pytorch-mnist-example.md","raw":"---\ntitle: toy demo - PyTorch + MNIST\ndate: 2017-03-04 22:37:44\ntags:\n     - pytorch\n---\nPyTorchMNISTMLPCNN\n![MNIST](/img/mnist_example.png)\n<!-- more -->\n\n## MNIST\nPyTorchMNISTCIFARCOCO`MNIST``torchvision.datasets``download``True``root`\n\nRGBaugmentation`torchvision.transforms``transforms.Compose()``ToTensor`PILTensorRGB`[0, 255]``[0, 1]` `Normalize`MNIST1`tuple`\n\n`DataLoader``for`\n\n``` py\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# use cuda or not\nuse_cuda = torch.cuda.is_available()\n\ntrans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n\ntrain_set = dset.MNIST(root=root, train=True, transform=trans, download=download)\ntest_set = dset.MNIST(root=root, train=False, transform=trans)\n\nbatch_size = 128\n\ntrain_loader = torch.utils.data.DataLoader(\n                 dataset=train_set,\n                 batch_size=batch_size,\n                 shuffle=True)\ntest_loader = torch.utils.data.DataLoader(\n                dataset=test_set,\n                batch_size=batch_size,\n                shuffle=False)\n\n```\n\n## \n`torch.nn`MLP`nn.Linear``y = wx+b``x``y`\n\n``` py\nclass MLPNet(nn.Module):\n    def __init__(self):\n        super(MLPNet, self).__init__()\n        self.fc1 = nn.Linear(28*28, 500)\n        self.fc2 = nn.Linear(500, 256)\n        self.fc3 = nn.Linear(256, 10)\n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```\nPyTorch`forward``nn.functionals``nn``nn.functionals`\n\n``` py\n# With square kernels and equal stride\nfilters = autograd.Variable(torch.randn(8,4,3,3))\ninputs = autograd.Variable(torch.randn(1,4,5,5))\nF.conv2d(inputs, filters, padding=1)\n```\n\nLeNet\n\n``` py\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n```\n\n## \n\n`SGD``optim.SGD``Parameter``lr``momentum`\n\n``` py\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n```\n\n\n\n``` py\n## training\nmodel = LeNet()\n\nif use_cuda:\n    model = model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nceriation = nn.CrossEntropyLoss()\n\nfor epoch in xrange(10):\n    # trainning\n    ave_loss = 0\n    for batch_idx, (x, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        if use_cuda:\n            x, target = x.cuda(), target.cuda()\n        x, target = Variable(x), Variable(target)\n        out = model(x)\n        loss = ceriation(out, target)\n        ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n        loss.backward()\n        optimizer.step()\n        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n            print '==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n                epoch, batch_idx+1, ave_loss)\n    # testing\n    correct_cnt, ave_loss = 0, 0\n    total_cnt = 0\n    for batch_idx, (x, target) in enumerate(test_loader):\n        if use_cuda:\n            x, targe = x.cuda(), target.cuda()\n        x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n        out = model(x)\n        loss = ceriation(out, target)\n        _, pred_label = torch.max(out.data, 1)\n        total_cnt += x.data.size()[0]\n        correct_cnt += (pred_label == target.data).sum()\n        # smooth average\n        ave_loss = ave_loss * 0.9 + loss.data[0] * 0.1\n        \n        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n            print '==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n                epoch, batch_idx+1, ave_loss, correct_cnt * 1.0 / total_cnt)\n\n```\n\n[](http://pytorch.org/docs/notes/serialization.html#recommend-saving-models)\n``` py\ntorch.save(model.state_dict(), PATH)   #\nthe_model = TheModelClass(*args, **kwargs)\nthe_model.load_state_dict(torch.load(PATH))  #\n```\n\n[PyTorch MNIST demo](https://gist.github.com/xmfbit/b27cdbff68870418bdb8cefa86a2d558)\n","slug":"pytorch-mnist-example","published":1,"updated":"2018-10-27T07:16:52.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8o6003rae7b8ptocjcp","content":"<p>PyTorchMNISTMLPCNN<br><img src=\"/img/mnist_example.png\" alt=\"MNIST\"><br><a id=\"more\"></a></p>\n<h2 id=\"MNIST\"><a href=\"#MNIST\" class=\"headerlink\" title=\"MNIST\"></a>MNIST</h2><p>PyTorchMNISTCIFARCOCO<code>MNIST</code><code>torchvision.datasets</code><code>download</code><code>True</code><code>root</code></p>\n<p>RGBaugmentation<code>torchvision.transforms</code><code>transforms.Compose()</code><code>ToTensor</code>PILTensorRGB<code>[0, 255]</code><code>[0, 1]</code> <code>Normalize</code>MNIST1<code>tuple</code></p>\n<p><code>DataLoader</code><code>for</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</div><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> dset</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</div><div class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># use cuda or not</span></div><div class=\"line\">use_cuda = torch.cuda.is_available()</div><div class=\"line\"></div><div class=\"line\">trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class=\"number\">0.5</span>,), (<span class=\"number\">1.0</span>,))])</div><div class=\"line\"></div><div class=\"line\">train_set = dset.MNIST(root=root, train=<span class=\"keyword\">True</span>, transform=trans, download=download)</div><div class=\"line\">test_set = dset.MNIST(root=root, train=<span class=\"keyword\">False</span>, transform=trans)</div><div class=\"line\"></div><div class=\"line\">batch_size = <span class=\"number\">128</span></div><div class=\"line\"></div><div class=\"line\">train_loader = torch.utils.data.DataLoader(</div><div class=\"line\">                 dataset=train_set,</div><div class=\"line\">                 batch_size=batch_size,</div><div class=\"line\">                 shuffle=<span class=\"keyword\">True</span>)</div><div class=\"line\">test_loader = torch.utils.data.DataLoader(</div><div class=\"line\">                dataset=test_set,</div><div class=\"line\">                batch_size=batch_size,</div><div class=\"line\">                shuffle=<span class=\"keyword\">False</span>)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>torch.nn</code>MLP<code>nn.Linear</code><code>y = wx+b</code><code>x</code><code>y</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MLPNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MLPNet, self).__init__()</div><div class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">500</span>)</div><div class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">500</span>, <span class=\"number\">256</span>)</div><div class=\"line\">        self.fc3 = nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">28</span>*<span class=\"number\">28</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div></pre></td></tr></table></figure>\n<p>PyTorch<code>forward</code><code>nn.functionals</code><code>nn</code><code>nn.functionals</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># With square kernels and equal stride</span></div><div class=\"line\">filters = autograd.Variable(torch.randn(<span class=\"number\">8</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>))</div><div class=\"line\">inputs = autograd.Variable(torch.randn(<span class=\"number\">1</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">5</span>))</div><div class=\"line\">F.conv2d(inputs, filters, padding=<span class=\"number\">1</span>)</div></pre></td></tr></table></figure>\n<p>LeNet</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LeNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(LeNet, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">20</span>, <span class=\"number\">50</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</div><div class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">4</span>*<span class=\"number\">4</span>*<span class=\"number\">50</span>, <span class=\"number\">500</span>)</div><div class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">500</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = F.relu(self.conv1(x))</div><div class=\"line\">        x = F.max_pool2d(x, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</div><div class=\"line\">        x = F.relu(self.conv2(x))</div><div class=\"line\">        x = F.max_pool2d(x, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">4</span>*<span class=\"number\">4</span>*<span class=\"number\">50</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = self.fc2(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SGD</code><code>optim.SGD</code><code>Parameter</code><code>lr</code><code>momentum</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">optimizer = optim.SGD(model.parameters(), lr=<span class=\"number\">0.01</span>, momentum=<span class=\"number\">0.9</span>)</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## training</span></div><div class=\"line\">model = LeNet()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">    model = model.cuda()</div><div class=\"line\"></div><div class=\"line\">optimizer = optim.SGD(model.parameters(), lr=<span class=\"number\">0.01</span>, momentum=<span class=\"number\">0.9</span>)</div><div class=\"line\"></div><div class=\"line\">ceriation = nn.CrossEntropyLoss()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> xrange(<span class=\"number\">10</span>):</div><div class=\"line\">    <span class=\"comment\"># trainning</span></div><div class=\"line\">    ave_loss = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> batch_idx, (x, target) <span class=\"keyword\">in</span> enumerate(train_loader):</div><div class=\"line\">        optimizer.zero_grad()</div><div class=\"line\">        <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">            x, target = x.cuda(), target.cuda()</div><div class=\"line\">        x, target = Variable(x), Variable(target)</div><div class=\"line\">        out = model(x)</div><div class=\"line\">        loss = ceriation(out, target)</div><div class=\"line\">        ave_loss = ave_loss * <span class=\"number\">0.9</span> + loss.data[<span class=\"number\">0</span>] * <span class=\"number\">0.1</span></div><div class=\"line\">        loss.backward()</div><div class=\"line\">        optimizer.step()</div><div class=\"line\">        <span class=\"keyword\">if</span> (batch_idx+<span class=\"number\">1</span>) % <span class=\"number\">100</span> == <span class=\"number\">0</span> <span class=\"keyword\">or</span> (batch_idx+<span class=\"number\">1</span>) == len(train_loader):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">'==&gt;&gt;&gt; epoch: &#123;&#125;, batch index: &#123;&#125;, train loss: &#123;:.6f&#125;'</span>.format(</div><div class=\"line\">                epoch, batch_idx+<span class=\"number\">1</span>, ave_loss)</div><div class=\"line\">    <span class=\"comment\"># testing</span></div><div class=\"line\">    correct_cnt, ave_loss = <span class=\"number\">0</span>, <span class=\"number\">0</span></div><div class=\"line\">    total_cnt = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> batch_idx, (x, target) <span class=\"keyword\">in</span> enumerate(test_loader):</div><div class=\"line\">        <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">            x, targe = x.cuda(), target.cuda()</div><div class=\"line\">        x, target = Variable(x, volatile=<span class=\"keyword\">True</span>), Variable(target, volatile=<span class=\"keyword\">True</span>)</div><div class=\"line\">        out = model(x)</div><div class=\"line\">        loss = ceriation(out, target)</div><div class=\"line\">        _, pred_label = torch.max(out.data, <span class=\"number\">1</span>)</div><div class=\"line\">        total_cnt += x.data.size()[<span class=\"number\">0</span>]</div><div class=\"line\">        correct_cnt += (pred_label == target.data).sum()</div><div class=\"line\">        <span class=\"comment\"># smooth average</span></div><div class=\"line\">        ave_loss = ave_loss * <span class=\"number\">0.9</span> + loss.data[<span class=\"number\">0</span>] * <span class=\"number\">0.1</span></div><div class=\"line\">        </div><div class=\"line\">        <span class=\"keyword\">if</span>(batch_idx+<span class=\"number\">1</span>) % <span class=\"number\">100</span> == <span class=\"number\">0</span> <span class=\"keyword\">or</span> (batch_idx+<span class=\"number\">1</span>) == len(test_loader):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">'==&gt;&gt;&gt; epoch: &#123;&#125;, batch index: &#123;&#125;, test loss: &#123;:.6f&#125;, acc: &#123;:.3f&#125;'</span>.format(</div><div class=\"line\">                epoch, batch_idx+<span class=\"number\">1</span>, ave_loss, correct_cnt * <span class=\"number\">1.0</span> / total_cnt)</div></pre></td></tr></table></figure>\n<p><a href=\"http://pytorch.org/docs/notes/serialization.html#recommend-saving-models\" target=\"_blank\" rel=\"external\"></a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">torch.save(model.state_dict(), PATH)   <span class=\"comment\">#</span></div><div class=\"line\">the_model = TheModelClass(*args, **kwargs)</div><div class=\"line\">the_model.load_state_dict(torch.load(PATH))  <span class=\"comment\">#</span></div></pre></td></tr></table></figure></p>\n<p><a href=\"https://gist.github.com/xmfbit/b27cdbff68870418bdb8cefa86a2d558\" target=\"_blank\" rel=\"external\">PyTorch MNIST demo</a></p>\n","excerpt":"<p>PyTorchMNISTMLPCNN<br><img src=\"/img/mnist_example.png\" alt=\"MNIST\"><br>","more":"</p>\n<h2 id=\"MNIST\"><a href=\"#MNIST\" class=\"headerlink\" title=\"MNIST\"></a>MNIST</h2><p>PyTorchMNISTCIFARCOCO<code>MNIST</code><code>torchvision.datasets</code><code>download</code><code>True</code><code>root</code></p>\n<p>RGBaugmentation<code>torchvision.transforms</code><code>transforms.Compose()</code><code>ToTensor</code>PILTensorRGB<code>[0, 255]</code><code>[0, 1]</code> <code>Normalize</code>MNIST1<code>tuple</code></p>\n<p><code>DataLoader</code><code>for</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</div><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> dset</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms</div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</div><div class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># use cuda or not</span></div><div class=\"line\">use_cuda = torch.cuda.is_available()</div><div class=\"line\"></div><div class=\"line\">trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class=\"number\">0.5</span>,), (<span class=\"number\">1.0</span>,))])</div><div class=\"line\"></div><div class=\"line\">train_set = dset.MNIST(root=root, train=<span class=\"keyword\">True</span>, transform=trans, download=download)</div><div class=\"line\">test_set = dset.MNIST(root=root, train=<span class=\"keyword\">False</span>, transform=trans)</div><div class=\"line\"></div><div class=\"line\">batch_size = <span class=\"number\">128</span></div><div class=\"line\"></div><div class=\"line\">train_loader = torch.utils.data.DataLoader(</div><div class=\"line\">                 dataset=train_set,</div><div class=\"line\">                 batch_size=batch_size,</div><div class=\"line\">                 shuffle=<span class=\"keyword\">True</span>)</div><div class=\"line\">test_loader = torch.utils.data.DataLoader(</div><div class=\"line\">                dataset=test_set,</div><div class=\"line\">                batch_size=batch_size,</div><div class=\"line\">                shuffle=<span class=\"keyword\">False</span>)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>torch.nn</code>MLP<code>nn.Linear</code><code>y = wx+b</code><code>x</code><code>y</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MLPNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(MLPNet, self).__init__()</div><div class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">28</span>*<span class=\"number\">28</span>, <span class=\"number\">500</span>)</div><div class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">500</span>, <span class=\"number\">256</span>)</div><div class=\"line\">        self.fc3 = nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>)</div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">28</span>*<span class=\"number\">28</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div></pre></td></tr></table></figure>\n<p>PyTorch<code>forward</code><code>nn.functionals</code><code>nn</code><code>nn.functionals</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># With square kernels and equal stride</span></div><div class=\"line\">filters = autograd.Variable(torch.randn(<span class=\"number\">8</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>))</div><div class=\"line\">inputs = autograd.Variable(torch.randn(<span class=\"number\">1</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">5</span>))</div><div class=\"line\">F.conv2d(inputs, filters, padding=<span class=\"number\">1</span>)</div></pre></td></tr></table></figure>\n<p>LeNet</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LeNet</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(LeNet, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">20</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">20</span>, <span class=\"number\">50</span>, <span class=\"number\">5</span>, <span class=\"number\">1</span>)</div><div class=\"line\">        self.fc1 = nn.Linear(<span class=\"number\">4</span>*<span class=\"number\">4</span>*<span class=\"number\">50</span>, <span class=\"number\">500</span>)</div><div class=\"line\">        self.fc2 = nn.Linear(<span class=\"number\">500</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = F.relu(self.conv1(x))</div><div class=\"line\">        x = F.max_pool2d(x, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</div><div class=\"line\">        x = F.relu(self.conv2(x))</div><div class=\"line\">        x = F.max_pool2d(x, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">4</span>*<span class=\"number\">4</span>*<span class=\"number\">50</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = self.fc2(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>SGD</code><code>optim.SGD</code><code>Parameter</code><code>lr</code><code>momentum</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">optimizer = optim.SGD(model.parameters(), lr=<span class=\"number\">0.01</span>, momentum=<span class=\"number\">0.9</span>)</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">## training</span></div><div class=\"line\">model = LeNet()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">    model = model.cuda()</div><div class=\"line\"></div><div class=\"line\">optimizer = optim.SGD(model.parameters(), lr=<span class=\"number\">0.01</span>, momentum=<span class=\"number\">0.9</span>)</div><div class=\"line\"></div><div class=\"line\">ceriation = nn.CrossEntropyLoss()</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> xrange(<span class=\"number\">10</span>):</div><div class=\"line\">    <span class=\"comment\"># trainning</span></div><div class=\"line\">    ave_loss = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> batch_idx, (x, target) <span class=\"keyword\">in</span> enumerate(train_loader):</div><div class=\"line\">        optimizer.zero_grad()</div><div class=\"line\">        <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">            x, target = x.cuda(), target.cuda()</div><div class=\"line\">        x, target = Variable(x), Variable(target)</div><div class=\"line\">        out = model(x)</div><div class=\"line\">        loss = ceriation(out, target)</div><div class=\"line\">        ave_loss = ave_loss * <span class=\"number\">0.9</span> + loss.data[<span class=\"number\">0</span>] * <span class=\"number\">0.1</span></div><div class=\"line\">        loss.backward()</div><div class=\"line\">        optimizer.step()</div><div class=\"line\">        <span class=\"keyword\">if</span> (batch_idx+<span class=\"number\">1</span>) % <span class=\"number\">100</span> == <span class=\"number\">0</span> <span class=\"keyword\">or</span> (batch_idx+<span class=\"number\">1</span>) == len(train_loader):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">'==&gt;&gt;&gt; epoch: &#123;&#125;, batch index: &#123;&#125;, train loss: &#123;:.6f&#125;'</span>.format(</div><div class=\"line\">                epoch, batch_idx+<span class=\"number\">1</span>, ave_loss)</div><div class=\"line\">    <span class=\"comment\"># testing</span></div><div class=\"line\">    correct_cnt, ave_loss = <span class=\"number\">0</span>, <span class=\"number\">0</span></div><div class=\"line\">    total_cnt = <span class=\"number\">0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> batch_idx, (x, target) <span class=\"keyword\">in</span> enumerate(test_loader):</div><div class=\"line\">        <span class=\"keyword\">if</span> use_cuda:</div><div class=\"line\">            x, targe = x.cuda(), target.cuda()</div><div class=\"line\">        x, target = Variable(x, volatile=<span class=\"keyword\">True</span>), Variable(target, volatile=<span class=\"keyword\">True</span>)</div><div class=\"line\">        out = model(x)</div><div class=\"line\">        loss = ceriation(out, target)</div><div class=\"line\">        _, pred_label = torch.max(out.data, <span class=\"number\">1</span>)</div><div class=\"line\">        total_cnt += x.data.size()[<span class=\"number\">0</span>]</div><div class=\"line\">        correct_cnt += (pred_label == target.data).sum()</div><div class=\"line\">        <span class=\"comment\"># smooth average</span></div><div class=\"line\">        ave_loss = ave_loss * <span class=\"number\">0.9</span> + loss.data[<span class=\"number\">0</span>] * <span class=\"number\">0.1</span></div><div class=\"line\">        </div><div class=\"line\">        <span class=\"keyword\">if</span>(batch_idx+<span class=\"number\">1</span>) % <span class=\"number\">100</span> == <span class=\"number\">0</span> <span class=\"keyword\">or</span> (batch_idx+<span class=\"number\">1</span>) == len(test_loader):</div><div class=\"line\">            <span class=\"keyword\">print</span> <span class=\"string\">'==&gt;&gt;&gt; epoch: &#123;&#125;, batch index: &#123;&#125;, test loss: &#123;:.6f&#125;, acc: &#123;:.3f&#125;'</span>.format(</div><div class=\"line\">                epoch, batch_idx+<span class=\"number\">1</span>, ave_loss, correct_cnt * <span class=\"number\">1.0</span> / total_cnt)</div></pre></td></tr></table></figure>\n<p><a href=\"http://pytorch.org/docs/notes/serialization.html#recommend-saving-models\"></a><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">torch.save(model.state_dict(), PATH)   <span class=\"comment\">#</span></div><div class=\"line\">the_model = TheModelClass(*args, **kwargs)</div><div class=\"line\">the_model.load_state_dict(torch.load(PATH))  <span class=\"comment\">#</span></div></pre></td></tr></table></figure></p>\n<p><a href=\"https://gist.github.com/xmfbit/b27cdbff68870418bdb8cefa86a2d558\">PyTorch MNIST demo</a></p>"},{"title":"Residual Net - Deep Residual Learning for Image Recongnition","date":"2017-03-05T14:12:21.000Z","_content":"Residuel NetMSRA HeKaimingImageNetCVPRbest paperstate of the arDeep Residual Learning for Image Recongnition\n![ResidualNet Unit](/img/residualnet_unit.png)\n<!-- more -->\n\n##  -> \nImageNetLeNetAlexNetVGG NetGoogLeNet\n\nlayer\n>  Is learning better networks as easy as stacking more layers?\n\nbpBN\n\nCIFAR-105620\n![](/img/residualnet_deepnet_problem.png)\n\n5620shadow netIdentity Mapping\n\n\n## \nIdentity Mapping\n![](/img/residualnet_unit.png)\n\n$\\mathcal{H}(x)$$\\mathcal{F}(x) = \\mathcal{H}(x) - x$$\\mathcal{F}(x)$$0$\n\n$1000$\n\n## \n$\\mathcal{H}$$\\mathcal{F}$Residual Learning\n\n$\\mathcal{H}$\n\n$W_i$$\\mathcal{F}$\n\n$$y = \\mathcal{F(x,\\lbrace W_i\\rbrace)}+x$$\n\n$\\mathcal{F}(x)$$x$$x$$W_s$$W_s$Identity Mapping\n\nbottleneck$\\mathcal{F}$\n\n## ImageNet\n\n\nImageNet\n\n1834plain34\n\n![](/img/residualnet_comparison_with_plainnet.png)\n\n18\n\n\n- Azero-padding\n- B\n- CIdentity Mapping\n\nA<B<CC\n\n## Bottleneck\nBottleneck$1\\times 1$channel$1\\times 1$channel$3\\times 3$$1\\times 1$\n\n![Bottleneck](/img/residualnet_bottleneck_unit.png)\n\n50101152\n\n## \nPascal VOCCOCOResidual NetMSRAR-FCN\n","source":"_posts/residualnet-paper.md","raw":"---\ntitle: Residual Net - Deep Residual Learning for Image Recongnition\ndate: 2017-03-05 22:12:21\ntags:\n    - paper\n    - deep learning\n---\nResiduel NetMSRA HeKaimingImageNetCVPRbest paperstate of the arDeep Residual Learning for Image Recongnition\n![ResidualNet Unit](/img/residualnet_unit.png)\n<!-- more -->\n\n##  -> \nImageNetLeNetAlexNetVGG NetGoogLeNet\n\nlayer\n>  Is learning better networks as easy as stacking more layers?\n\nbpBN\n\nCIFAR-105620\n![](/img/residualnet_deepnet_problem.png)\n\n5620shadow netIdentity Mapping\n\n\n## \nIdentity Mapping\n![](/img/residualnet_unit.png)\n\n$\\mathcal{H}(x)$$\\mathcal{F}(x) = \\mathcal{H}(x) - x$$\\mathcal{F}(x)$$0$\n\n$1000$\n\n## \n$\\mathcal{H}$$\\mathcal{F}$Residual Learning\n\n$\\mathcal{H}$\n\n$W_i$$\\mathcal{F}$\n\n$$y = \\mathcal{F(x,\\lbrace W_i\\rbrace)}+x$$\n\n$\\mathcal{F}(x)$$x$$x$$W_s$$W_s$Identity Mapping\n\nbottleneck$\\mathcal{F}$\n\n## ImageNet\n\n\nImageNet\n\n1834plain34\n\n![](/img/residualnet_comparison_with_plainnet.png)\n\n18\n\n\n- Azero-padding\n- B\n- CIdentity Mapping\n\nA<B<CC\n\n## Bottleneck\nBottleneck$1\\times 1$channel$1\\times 1$channel$3\\times 3$$1\\times 1$\n\n![Bottleneck](/img/residualnet_bottleneck_unit.png)\n\n50101152\n\n## \nPascal VOCCOCOResidual NetMSRAR-FCN\n","slug":"residualnet-paper","published":1,"updated":"2018-10-27T07:16:52.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8oa003uae7bg5evygxs","content":"<p>Residuel NetMSRA HeKaimingImageNetCVPRbest paperstate of the arDeep Residual Learning for Image Recongnition<br><img src=\"/img/residualnet_unit.png\" alt=\"ResidualNet Unit\"><br><a id=\"more\"></a></p>\n<h2 id=\"-gt-\"><a href=\"#-gt-\" class=\"headerlink\" title=\" -&gt; \"></a> -&gt; </h2><p>ImageNetLeNetAlexNetVGG NetGoogLeNet</p>\n<p>layer</p>\n<blockquote>\n<p> Is learning better networks as easy as stacking more layers?</p>\n</blockquote>\n<p>bpBN</p>\n<p>CIFAR-105620<br><img src=\"/img/residualnet_deepnet_problem.png\" alt=\"\"></p>\n<p>5620shadow netIdentity Mapping</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Identity Mapping<br><img src=\"/img/residualnet_unit.png\" alt=\"\"></p>\n<p>$\\mathcal{H}(x)$$\\mathcal{F}(x) = \\mathcal{H}(x) - x$$\\mathcal{F}(x)$$0$</p>\n<p>$1000$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathcal{H}$$\\mathcal{F}$Residual Learning</p>\n<p>$\\mathcal{H}$</p>\n<p>$W_i$$\\mathcal{F}$</p>\n<script type=\"math/tex; mode=display\">y = \\mathcal{F(x,\\lbrace W_i\\rbrace)}+x</script><p>$\\mathcal{F}(x)$$x$$x$$W_s$$W_s$Identity Mapping</p>\n<p>bottleneck$\\mathcal{F}$</p>\n<h2 id=\"ImageNet\"><a href=\"#ImageNet\" class=\"headerlink\" title=\"ImageNet\"></a>ImageNet</h2><p></p>\n<p>ImageNet</p>\n<p>1834plain34</p>\n<p><img src=\"/img/residualnet_comparison_with_plainnet.png\" alt=\"\"></p>\n<p>18</p>\n<p></p>\n<ul>\n<li>Azero-padding</li>\n<li>B</li>\n<li>CIdentity Mapping</li>\n</ul>\n<p>A&lt;B&lt;CC</p>\n<h2 id=\"Bottleneck\"><a href=\"#Bottleneck\" class=\"headerlink\" title=\"Bottleneck\"></a>Bottleneck</h2><p>Bottleneck$1\\times 1$channel$1\\times 1$channel$3\\times 3$$1\\times 1$</p>\n<p><img src=\"/img/residualnet_bottleneck_unit.png\" alt=\"Bottleneck\"></p>\n<p>50101152</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Pascal VOCCOCOResidual NetMSRAR-FCN</p>\n","excerpt":"<p>Residuel NetMSRA HeKaimingImageNetCVPRbest paperstate of the arDeep Residual Learning for Image Recongnition<br><img src=\"/img/residualnet_unit.png\" alt=\"ResidualNet Unit\"><br>","more":"</p>\n<h2 id=\"-gt-\"><a href=\"#-gt-\" class=\"headerlink\" title=\" -&gt; \"></a> -&gt; </h2><p>ImageNetLeNetAlexNetVGG NetGoogLeNet</p>\n<p>layer</p>\n<blockquote>\n<p> Is learning better networks as easy as stacking more layers?</p>\n</blockquote>\n<p>bpBN</p>\n<p>CIFAR-105620<br><img src=\"/img/residualnet_deepnet_problem.png\" alt=\"\"></p>\n<p>5620shadow netIdentity Mapping</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Identity Mapping<br><img src=\"/img/residualnet_unit.png\" alt=\"\"></p>\n<p>$\\mathcal{H}(x)$$\\mathcal{F}(x) = \\mathcal{H}(x) - x$$\\mathcal{F}(x)$$0$</p>\n<p>$1000$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\mathcal{H}$$\\mathcal{F}$Residual Learning</p>\n<p>$\\mathcal{H}$</p>\n<p>$W_i$$\\mathcal{F}$</p>\n<script type=\"math/tex; mode=display\">y = \\mathcal{F(x,\\lbrace W_i\\rbrace)}+x</script><p>$\\mathcal{F}(x)$$x$$x$$W_s$$W_s$Identity Mapping</p>\n<p>bottleneck$\\mathcal{F}$</p>\n<h2 id=\"ImageNet\"><a href=\"#ImageNet\" class=\"headerlink\" title=\"ImageNet\"></a>ImageNet</h2><p></p>\n<p>ImageNet</p>\n<p>1834plain34</p>\n<p><img src=\"/img/residualnet_comparison_with_plainnet.png\" alt=\"\"></p>\n<p>18</p>\n<p></p>\n<ul>\n<li>Azero-padding</li>\n<li>B</li>\n<li>CIdentity Mapping</li>\n</ul>\n<p>A&lt;B&lt;CC</p>\n<h2 id=\"Bottleneck\"><a href=\"#Bottleneck\" class=\"headerlink\" title=\"Bottleneck\"></a>Bottleneck</h2><p>Bottleneck$1\\times 1$channel$1\\times 1$channel$3\\times 3$$1\\times 1$</p>\n<p><img src=\"/img/residualnet_bottleneck_unit.png\" alt=\"Bottleneck\"></p>\n<p>50101152</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Pascal VOCCOCOResidual NetMSRAR-FCN</p>"},{"title":"JupyterNotebookPython","date":"2018-04-09T05:44:04.000Z","_content":"PythonPythonAnacondaenvJupyter NotebookPython KernelJupyter Notebook\n<!-- more -->\n## conda\nAnaconda`conda create -n your_env_name python=your_python_version``source activate your_env_name`python\n\nipythonJupyter NotebookPython kernelnotebook\n\n## \n[Conda environments not showing up in Jupyter Notebook](https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook).\n\n`nb_conda_kernels`\n``` bash\nconda install nb_conda_kernels\n```\n\nNotebook`New`\n![kernel](/img/set-env-in-notebook-choose-kernel.png)\n\nnotebook`Kernel -> choose kernel -> your env kernel`\n![notebookkernel](/img/set-env-in-notebook-change-kernel.png)\n\n`nb_conda_kernels`GitHub[nb_conda_kernels](https://github.com/Anaconda-Platform/nb_conda_kernels)","source":"_posts/set-env-in-jupyternotebook.md","raw":"---\ntitle: JupyterNotebookPython\ndate: 2018-04-09 13:44:04\ntags:\n    - python\n    - tool\n---\nPythonPythonAnacondaenvJupyter NotebookPython KernelJupyter Notebook\n<!-- more -->\n## conda\nAnaconda`conda create -n your_env_name python=your_python_version``source activate your_env_name`python\n\nipythonJupyter NotebookPython kernelnotebook\n\n## \n[Conda environments not showing up in Jupyter Notebook](https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook).\n\n`nb_conda_kernels`\n``` bash\nconda install nb_conda_kernels\n```\n\nNotebook`New`\n![kernel](/img/set-env-in-notebook-choose-kernel.png)\n\nnotebook`Kernel -> choose kernel -> your env kernel`\n![notebookkernel](/img/set-env-in-notebook-change-kernel.png)\n\n`nb_conda_kernels`GitHub[nb_conda_kernels](https://github.com/Anaconda-Platform/nb_conda_kernels)","slug":"set-env-in-jupyternotebook","published":1,"updated":"2018-10-27T07:16:52.417Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8om003vae7bhe61as6j","content":"<p>PythonPythonAnacondaenvJupyter NotebookPython KernelJupyter Notebook<br><a id=\"more\"></a></p>\n<h2 id=\"conda\"><a href=\"#conda\" class=\"headerlink\" title=\"conda\"></a>conda</h2><p>Anaconda<code>conda create -n your_env_name python=your_python_version</code><code>source activate your_env_name</code>python</p>\n<p>ipythonJupyter NotebookPython kernelnotebook</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook\" target=\"_blank\" rel=\"external\">Conda environments not showing up in Jupyter Notebook</a>.</p>\n<p><code>nb_conda_kernels</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">conda install nb_conda_kernels</div></pre></td></tr></table></figure></p>\n<p>Notebook<code>New</code><br><img src=\"/img/set-env-in-notebook-choose-kernel.png\" alt=\"kernel\"></p>\n<p>notebook<code>Kernel -&gt; choose kernel -&gt; your env kernel</code><br><img src=\"/img/set-env-in-notebook-change-kernel.png\" alt=\"notebookkernel\"></p>\n<p><code>nb_conda_kernels</code>GitHub<a href=\"https://github.com/Anaconda-Platform/nb_conda_kernels\" target=\"_blank\" rel=\"external\">nb_conda_kernels</a></p>\n","excerpt":"<p>PythonPythonAnacondaenvJupyter NotebookPython KernelJupyter Notebook<br>","more":"</p>\n<h2 id=\"conda\"><a href=\"#conda\" class=\"headerlink\" title=\"conda\"></a>conda</h2><p>Anaconda<code>conda create -n your_env_name python=your_python_version</code><code>source activate your_env_name</code>python</p>\n<p>ipythonJupyter NotebookPython kernelnotebook</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook\">Conda environments not showing up in Jupyter Notebook</a>.</p>\n<p><code>nb_conda_kernels</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">conda install nb_conda_kernels</div></pre></td></tr></table></figure></p>\n<p>Notebook<code>New</code><br><img src=\"/img/set-env-in-notebook-choose-kernel.png\" alt=\"kernel\"></p>\n<p>notebook<code>Kernel -&gt; choose kernel -&gt; your env kernel</code><br><img src=\"/img/set-env-in-notebook-change-kernel.png\" alt=\"notebookkernel\"></p>\n<p><code>nb_conda_kernels</code>GitHub<a href=\"https://github.com/Anaconda-Platform/nb_conda_kernels\">nb_conda_kernels</a></p>"},{"title":"PyTorch","date":"2017-02-25T11:23:39.000Z","_content":"PyTorchjupyter notebook[GitHub repo](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb)\n![PyTorch Logo](/img/pytorch_logo.png)\n\n<!-- more -->\n## PyTorch\n[PyTorch](https://github.com/pytorch/pytorch)TorchPyTorchPythonPython firstGPU`numpy`PyTorch\n\nPyTorchCaffe`prototxt`PyTorchPyTorchopAutoGrad\n\n## Tensors\n`Tensor``numpy`PyTorchGPUPyTorch`Tensor``numpy``array`\n\n`Tensor(shape)``tensor`\n\n``` py\nx = torch.Tensor(5, 3)  # construct a 5x3 matrix, uninitialized\n# \ny = torch.rand(5, 3)    # construct a randomly initialized matrix\n# sizetensorshapetorch.Size  tuple\nx.size()                # out: torch.Size([5, 3])\n```\n\nPyTorch`op`\n\n``` py\n# addition: syntax 1\nx + y                  # out: [torch.FloatTensor of size 5x3]\n\n# addition: syntax 2\ntorch.add(x, y)        # torchop\n\n# addition: giving an output tensor\nresult = torch.Tensor(5, 3)  # size\ntorch.add(x, y, out=result)  # result\n\n# \nout = x + y                  # size\n\n# torchop\n# addition: in-place\ny.add_(x)              # xy\n# : x.copy_(y), x.t_().\n```\n\nPyTorch`numpy`\n\n``` py\n# standard numpy-like indexing with all bells and whistles\nx[:,1]                 # out: [torch.FloatTensor of size 5]\n```\n\n`op`PyTorch[](http://pytorch.org/docs/torch.html)\n\n`Tensor``numpy`\n\n``` py\n# Tensor  np.array\na = torch.ones(5)    # out: [torch.FloatTensor of size 5]\n#  numpy\nb = a.numpy()        # out: array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)\n# ab\na.add_(1)\nprint(a)\nprint(b)             # a b2\n\n# np.array Tensor\nimport numpy as np\na = np.ones(5)\n# torch.from_numpy\nb = torch.from_numpy(a)  # out: [torch.DoubleTensor of size 5]\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)            # a b2\n```\n\nPyTorchGPU`.cuda()`GPU\n\n``` py\n# let us run this cell only if CUDA is available\nif torch.cuda.is_available():\n    print('cuda is avaliable')\n    x = x.cuda()\n    y = y.cuda()\n    x + y          # GPU\n```\n\n## Neural Network\n`Tensor`[](http://pytorch.org/docs/autograd.html)\n\n`autograd.Variable``Tensor``.backward()``Variable``Variable``data``Tensor``grad``Variable`\n\n`Variable``Function``Variable``creator``Function``creator``None`\n\n`Variable``loss``backward()``Variable``Variable`shape`Tensor`\n\n``` py\nfrom torch.autograd import Variable\nx = Variable(torch.ones(2, 2), requires_grad = True)\nx     # x 2x2Tensor\n\"\"\"\nVariable containing:\n 1  1\n 1  1\n[torch.FloatTensor of size 2x2]\n\"\"\"\n# Variable\n# y was created as a result of an operation,\n# so it has a creator\ny = x + 2\ny.creator    # out: <torch.autograd._functions.basic_ops.AddConstant at 0x7fa1cc158c08>\n\nz = y * y * 3  \nout = z.mean()   # out: Variable containing: 27 [torch.FloatTensor of size 1]\n\n# let's backprop now\nout.backward()  #  out.backward(torch.Tensor([1.0]))\n\n# print gradients d(out)/dx\nx.grad\n\"\"\"\nVariable containing:\n 4.5000  4.5000\n 4.5000  4.5000\n[torch.FloatTensor of size 2x2]\n\"\"\"\n```\n\n`Tensor`\n``` py\n# TensorVariable\nx = torch.randn(3)\nx = Variable(x, requires_grad = True)\n#  op\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\n#  dy/dx\ngradients = torch.FloatTensor([0.1, 1.0, 0.0001])\ny.backward(gradients)\nx.grad\n\"\"\"\nVariable containing:\n  204.8000\n 2048.0000\n    0.2048\n[torch.FloatTensor of size 3]\n\"\"\"\n```\n\nNN`Variable`PyTorch`torch.nn``layer` `nn.Module``forward(input)``output``conv``max-pooling``fc`CNN\n\n``` py\nimport torch.nn as nn                 # nn\nimport torch.nn.functional as F       # poolingrelufunctional\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # input1x32x32conv-pooling-conv-pooling16x5x5\n        # fc 16x5x5\n        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n        self.fc2   = nn.Linear(120, 84)\n        self.fc3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # \n        #  backward\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n        x = x.view(-1, self.num_flat_features(x))  # \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:] # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n# Net\nnet = Net()\nnet     # \n\"\"\"\nNet (\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear (400 -> 120)\n  (fc2): Linear (120 -> 84)\n  (fc3): Linear (84 -> 10)\n)\n\"\"\"\n```\n\n\n\n``` py\nparams = list(net.parameters())\nprint(len(params))      # out: 10, 55bias\nprint(params[0].size())  # conv1's weight out: torch.Size([6, 1, 5, 5])\nprint(params[1].size())  # conv1's bias, out: torch.Size([6])\n```\n\n\n\n``` py\ninput = Variable(torch.randn(1, 1, 32, 32))\nout = net(input)         # ()\nnet.zero_grad()          # bpgrad buffer\nout.backward(torch.randn(1, 10))\n```\n\n`torch.nn`mini-batch`input.unsqueeze(0)`4-D`Tensor`\n\n## \ntargetoutputloss`torch.nn`[loss](http://pytorch.org/docs/nn.html#loss-functions)\n\n``` py\noutput = net(input)\ntarget = Variable(torch.range(1, 10))  # a dummy target, for example\n# \ncriterion = nn.MSELoss()\nloss = criterion(output, target)\nloss\n\"\"\"\nVariable containing:\n 38.6049\n[torch.FloatTensor of size 1]\n\"\"\"\n```\n\n\n\n```\ninput -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n```\n\n`previous_functions``Function`\n\n```\n# For illustration, let us follow a few steps backward\nprint(loss.creator) # MSELoss\nprint(loss.creator.previous_functions[0][0]) # Linear\nprint(loss.creator.previous_functions[0][0].previous_functions[0][0]) # ReLU\n\"\"\"\n<torch.nn._functions.thnn.auto.MSELoss object at 0x7fa18011db40>\n<torch.nn._functions.linear.Linear object at 0x7fa18011da78>\n<torch.nn._functions.thnn.auto.Threshold object at 0x7fa18011d9b0>\n\"\"\"\n```\n\n\n\n``` py\n# now we shall call loss.backward(), and have a look at conv1's bias gradients before and after the backward.\nnet.zero_grad() # zeroes the gradient buffers of all parameters\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\nloss.backward()\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)\n```\n\n\n\n``` py\nlearning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)\n```\n\n`torch.optim`SGD, Nesterov-SGD, Adam, RMSProp, etc\n\n``` py\nimport torch.optim as optim\n# create your optimizer\noptimizer = optim.SGD(net.parameters(), lr = 0.01)\n# in your training loop:\noptimizer.zero_grad() # zero the gradient buffers\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step() # Does the update\n```\n\n## \nPyTorchPython`np.array`OpenCVvisionPyTorch`torchvision`Imagenet, CIFAR10, MNIST, etcCIFAR\n\n``` py\nimport torchvision\nimport torchvision.transforms as transforms\n\n# The output of torchvision datasets are PILImage images of range [0, 1].\n# We transform them to Tensors of normalized range [-1, 1]\n# Compose: Composes several transforms together.\n# see http://pytorch.org/docs/torchvision/transforms.html?highlight=transforms\ntransform=transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                             ])   # torchvision.transforms.Normalize(mean, std)\n# CIFAR10                             \ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n# DataLoader\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n# Testtrain = False\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                          shuffle=False, num_workers=2)\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```\n\nCNN`conv`3loss\n\n``` py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool  = nn.MaxPool2d(2,2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1   = nn.Linear(16*5*5, 120)\n        self.fc2   = nn.Linear(120, 84)\n        self.fc3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16*5*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n# use a Classification Cross-Entropy loss\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\nloop overdatasetmini-batch2000mini-batchloss\n\n``` py\nfor epoch in range(2): # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs\n        inputs, labels = data\n\n        # wrap them in Variable\n        inputs, labels = Variable(inputs), Variable(labels)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()        \n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.data[0]\n        if i % 2000 == 1999: # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n            running_loss = 0.0\nprint('Finished Training')\n```\n\nmini-batch4`testloader`\n\n``` py\ndataiter = iter(testloader)\nimages, labels = dataiter.next()   # imagelabel\noutputs = net(Variable(images))\n\n# the outputs are energies for the 10 classes.\n# Higher the energy for a class, the more the network\n# thinks that the image is of the particular class\n# So, let's get the index of the highest energy\n_, predicted = torch.max(outputs.data, 1)   # channeltop-1\n\nprint('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))\n```\n\n\n\n``` py\ncorrect = 0\ntotal = 0\nfor data in testloader:     # test mini-batch\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n```\n\n\n\n``` py\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nfor data in testloader:\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    c = (predicted == labels).squeeze()\n    for i in range(4):\n        label = labels[i]\n        class_correct[label] += c[i]\n        class_total[label] += 1\n```\n\nCPUGPU`.cuda()`\n\n``` py\nnet.cuda()\n```\n\n`images``label`GPU\n\n``` py\ninputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n```\n## \n[](https://github.com/pytorch/examples)\n[](https://github.com/pytorch/tutorials)\n","source":"_posts/pytorch-tutor-01.md","raw":"---\ntitle: PyTorch\ndate: 2017-02-25 19:23:39\ntags:\n    - pytorch\n---\nPyTorchjupyter notebook[GitHub repo](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb)\n![PyTorch Logo](/img/pytorch_logo.png)\n\n<!-- more -->\n## PyTorch\n[PyTorch](https://github.com/pytorch/pytorch)TorchPyTorchPythonPython firstGPU`numpy`PyTorch\n\nPyTorchCaffe`prototxt`PyTorchPyTorchopAutoGrad\n\n## Tensors\n`Tensor``numpy`PyTorchGPUPyTorch`Tensor``numpy``array`\n\n`Tensor(shape)``tensor`\n\n``` py\nx = torch.Tensor(5, 3)  # construct a 5x3 matrix, uninitialized\n# \ny = torch.rand(5, 3)    # construct a randomly initialized matrix\n# sizetensorshapetorch.Size  tuple\nx.size()                # out: torch.Size([5, 3])\n```\n\nPyTorch`op`\n\n``` py\n# addition: syntax 1\nx + y                  # out: [torch.FloatTensor of size 5x3]\n\n# addition: syntax 2\ntorch.add(x, y)        # torchop\n\n# addition: giving an output tensor\nresult = torch.Tensor(5, 3)  # size\ntorch.add(x, y, out=result)  # result\n\n# \nout = x + y                  # size\n\n# torchop\n# addition: in-place\ny.add_(x)              # xy\n# : x.copy_(y), x.t_().\n```\n\nPyTorch`numpy`\n\n``` py\n# standard numpy-like indexing with all bells and whistles\nx[:,1]                 # out: [torch.FloatTensor of size 5]\n```\n\n`op`PyTorch[](http://pytorch.org/docs/torch.html)\n\n`Tensor``numpy`\n\n``` py\n# Tensor  np.array\na = torch.ones(5)    # out: [torch.FloatTensor of size 5]\n#  numpy\nb = a.numpy()        # out: array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)\n# ab\na.add_(1)\nprint(a)\nprint(b)             # a b2\n\n# np.array Tensor\nimport numpy as np\na = np.ones(5)\n# torch.from_numpy\nb = torch.from_numpy(a)  # out: [torch.DoubleTensor of size 5]\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)            # a b2\n```\n\nPyTorchGPU`.cuda()`GPU\n\n``` py\n# let us run this cell only if CUDA is available\nif torch.cuda.is_available():\n    print('cuda is avaliable')\n    x = x.cuda()\n    y = y.cuda()\n    x + y          # GPU\n```\n\n## Neural Network\n`Tensor`[](http://pytorch.org/docs/autograd.html)\n\n`autograd.Variable``Tensor``.backward()``Variable``Variable``data``Tensor``grad``Variable`\n\n`Variable``Function``Variable``creator``Function``creator``None`\n\n`Variable``loss``backward()``Variable``Variable`shape`Tensor`\n\n``` py\nfrom torch.autograd import Variable\nx = Variable(torch.ones(2, 2), requires_grad = True)\nx     # x 2x2Tensor\n\"\"\"\nVariable containing:\n 1  1\n 1  1\n[torch.FloatTensor of size 2x2]\n\"\"\"\n# Variable\n# y was created as a result of an operation,\n# so it has a creator\ny = x + 2\ny.creator    # out: <torch.autograd._functions.basic_ops.AddConstant at 0x7fa1cc158c08>\n\nz = y * y * 3  \nout = z.mean()   # out: Variable containing: 27 [torch.FloatTensor of size 1]\n\n# let's backprop now\nout.backward()  #  out.backward(torch.Tensor([1.0]))\n\n# print gradients d(out)/dx\nx.grad\n\"\"\"\nVariable containing:\n 4.5000  4.5000\n 4.5000  4.5000\n[torch.FloatTensor of size 2x2]\n\"\"\"\n```\n\n`Tensor`\n``` py\n# TensorVariable\nx = torch.randn(3)\nx = Variable(x, requires_grad = True)\n#  op\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\n#  dy/dx\ngradients = torch.FloatTensor([0.1, 1.0, 0.0001])\ny.backward(gradients)\nx.grad\n\"\"\"\nVariable containing:\n  204.8000\n 2048.0000\n    0.2048\n[torch.FloatTensor of size 3]\n\"\"\"\n```\n\nNN`Variable`PyTorch`torch.nn``layer` `nn.Module``forward(input)``output``conv``max-pooling``fc`CNN\n\n``` py\nimport torch.nn as nn                 # nn\nimport torch.nn.functional as F       # poolingrelufunctional\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # input1x32x32conv-pooling-conv-pooling16x5x5\n        # fc 16x5x5\n        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n        self.fc2   = nn.Linear(120, 84)\n        self.fc3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # \n        #  backward\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n        x = x.view(-1, self.num_flat_features(x))  # \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:] # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n# Net\nnet = Net()\nnet     # \n\"\"\"\nNet (\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear (400 -> 120)\n  (fc2): Linear (120 -> 84)\n  (fc3): Linear (84 -> 10)\n)\n\"\"\"\n```\n\n\n\n``` py\nparams = list(net.parameters())\nprint(len(params))      # out: 10, 55bias\nprint(params[0].size())  # conv1's weight out: torch.Size([6, 1, 5, 5])\nprint(params[1].size())  # conv1's bias, out: torch.Size([6])\n```\n\n\n\n``` py\ninput = Variable(torch.randn(1, 1, 32, 32))\nout = net(input)         # ()\nnet.zero_grad()          # bpgrad buffer\nout.backward(torch.randn(1, 10))\n```\n\n`torch.nn`mini-batch`input.unsqueeze(0)`4-D`Tensor`\n\n## \ntargetoutputloss`torch.nn`[loss](http://pytorch.org/docs/nn.html#loss-functions)\n\n``` py\noutput = net(input)\ntarget = Variable(torch.range(1, 10))  # a dummy target, for example\n# \ncriterion = nn.MSELoss()\nloss = criterion(output, target)\nloss\n\"\"\"\nVariable containing:\n 38.6049\n[torch.FloatTensor of size 1]\n\"\"\"\n```\n\n\n\n```\ninput -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n```\n\n`previous_functions``Function`\n\n```\n# For illustration, let us follow a few steps backward\nprint(loss.creator) # MSELoss\nprint(loss.creator.previous_functions[0][0]) # Linear\nprint(loss.creator.previous_functions[0][0].previous_functions[0][0]) # ReLU\n\"\"\"\n<torch.nn._functions.thnn.auto.MSELoss object at 0x7fa18011db40>\n<torch.nn._functions.linear.Linear object at 0x7fa18011da78>\n<torch.nn._functions.thnn.auto.Threshold object at 0x7fa18011d9b0>\n\"\"\"\n```\n\n\n\n``` py\n# now we shall call loss.backward(), and have a look at conv1's bias gradients before and after the backward.\nnet.zero_grad() # zeroes the gradient buffers of all parameters\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\nloss.backward()\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)\n```\n\n\n\n``` py\nlearning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)\n```\n\n`torch.optim`SGD, Nesterov-SGD, Adam, RMSProp, etc\n\n``` py\nimport torch.optim as optim\n# create your optimizer\noptimizer = optim.SGD(net.parameters(), lr = 0.01)\n# in your training loop:\noptimizer.zero_grad() # zero the gradient buffers\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step() # Does the update\n```\n\n## \nPyTorchPython`np.array`OpenCVvisionPyTorch`torchvision`Imagenet, CIFAR10, MNIST, etcCIFAR\n\n``` py\nimport torchvision\nimport torchvision.transforms as transforms\n\n# The output of torchvision datasets are PILImage images of range [0, 1].\n# We transform them to Tensors of normalized range [-1, 1]\n# Compose: Composes several transforms together.\n# see http://pytorch.org/docs/torchvision/transforms.html?highlight=transforms\ntransform=transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                             ])   # torchvision.transforms.Normalize(mean, std)\n# CIFAR10                             \ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n# DataLoader\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n# Testtrain = False\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                          shuffle=False, num_workers=2)\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```\n\nCNN`conv`3loss\n\n``` py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool  = nn.MaxPool2d(2,2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1   = nn.Linear(16*5*5, 120)\n        self.fc2   = nn.Linear(120, 84)\n        self.fc3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16*5*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n# use a Classification Cross-Entropy loss\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```\n\nloop overdatasetmini-batch2000mini-batchloss\n\n``` py\nfor epoch in range(2): # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs\n        inputs, labels = data\n\n        # wrap them in Variable\n        inputs, labels = Variable(inputs), Variable(labels)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()        \n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.data[0]\n        if i % 2000 == 1999: # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 2000))\n            running_loss = 0.0\nprint('Finished Training')\n```\n\nmini-batch4`testloader`\n\n``` py\ndataiter = iter(testloader)\nimages, labels = dataiter.next()   # imagelabel\noutputs = net(Variable(images))\n\n# the outputs are energies for the 10 classes.\n# Higher the energy for a class, the more the network\n# thinks that the image is of the particular class\n# So, let's get the index of the highest energy\n_, predicted = torch.max(outputs.data, 1)   # channeltop-1\n\nprint('Predicted: ', ' '.join('%5s'% classes[predicted[j][0]] for j in range(4)))\n```\n\n\n\n``` py\ncorrect = 0\ntotal = 0\nfor data in testloader:     # test mini-batch\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n```\n\n\n\n``` py\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nfor data in testloader:\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    c = (predicted == labels).squeeze()\n    for i in range(4):\n        label = labels[i]\n        class_correct[label] += c[i]\n        class_total[label] += 1\n```\n\nCPUGPU`.cuda()`\n\n``` py\nnet.cuda()\n```\n\n`images``label`GPU\n\n``` py\ninputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n```\n## \n[](https://github.com/pytorch/examples)\n[](https://github.com/pytorch/tutorials)\n","slug":"pytorch-tutor-01","published":1,"updated":"2018-10-27T07:16:52.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8os003xae7bmaehiowo","content":"<p>PyTorchjupyter notebook<a href=\"https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb\" target=\"_blank\" rel=\"external\">GitHub repo</a><br><img src=\"/img/pytorch_logo.png\" alt=\"PyTorch Logo\"></p>\n<a id=\"more\"></a>\n<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><p><a href=\"https://github.com/pytorch/pytorch\" target=\"_blank\" rel=\"external\">PyTorch</a>TorchPyTorchPythonPython firstGPU<code>numpy</code>PyTorch</p>\n<p>PyTorchCaffe<code>prototxt</code>PyTorchPyTorchopAutoGrad</p>\n<h2 id=\"Tensors\"><a href=\"#Tensors\" class=\"headerlink\" title=\"Tensors\"></a>Tensors</h2><p><code>Tensor</code><code>numpy</code>PyTorchGPUPyTorch<code>Tensor</code><code>numpy</code><code>array</code></p>\n<p><code>Tensor(shape)</code><code>tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">x = torch.Tensor(<span class=\"number\">5</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># construct a 5x3 matrix, uninitialized</span></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)    <span class=\"comment\"># construct a randomly initialized matrix</span></div><div class=\"line\"><span class=\"comment\"># sizetensorshapetorch.Size  tuple</span></div><div class=\"line\">x.size()                <span class=\"comment\"># out: torch.Size([5, 3])</span></div></pre></td></tr></table></figure>\n<p>PyTorch<code>op</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># addition: syntax 1</span></div><div class=\"line\">x + y                  <span class=\"comment\"># out: [torch.FloatTensor of size 5x3]</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># addition: syntax 2</span></div><div class=\"line\">torch.add(x, y)        <span class=\"comment\"># torchop</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># addition: giving an output tensor</span></div><div class=\"line\">result = torch.Tensor(<span class=\"number\">5</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># size</span></div><div class=\"line\">torch.add(x, y, out=result)  <span class=\"comment\"># result</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">out = x + y                  <span class=\"comment\"># size</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># torchop</span></div><div class=\"line\"><span class=\"comment\"># addition: in-place</span></div><div class=\"line\">y.add_(x)              <span class=\"comment\"># xy</span></div><div class=\"line\"><span class=\"comment\"># : x.copy_(y), x.t_().</span></div></pre></td></tr></table></figure>\n<p>PyTorch<code>numpy</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># standard numpy-like indexing with all bells and whistles</span></div><div class=\"line\">x[:,<span class=\"number\">1</span>]                 <span class=\"comment\"># out: [torch.FloatTensor of size 5]</span></div></pre></td></tr></table></figure>\n<p><code>op</code>PyTorch<a href=\"http://pytorch.org/docs/torch.html\" target=\"_blank\" rel=\"external\"></a></p>\n<p><code>Tensor</code><code>numpy</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Tensor  np.array</span></div><div class=\"line\">a = torch.ones(<span class=\"number\">5</span>)    <span class=\"comment\"># out: [torch.FloatTensor of size 5]</span></div><div class=\"line\"><span class=\"comment\">#  numpy</span></div><div class=\"line\">b = a.numpy()        <span class=\"comment\"># out: array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)</span></div><div class=\"line\"><span class=\"comment\"># ab</span></div><div class=\"line\">a.add_(<span class=\"number\">1</span>)</div><div class=\"line\">print(a)</div><div class=\"line\">print(b)             <span class=\"comment\"># a b2</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># np.array Tensor</span></div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\">a = np.ones(<span class=\"number\">5</span>)</div><div class=\"line\"><span class=\"comment\"># torch.from_numpy</span></div><div class=\"line\">b = torch.from_numpy(a)  <span class=\"comment\"># out: [torch.DoubleTensor of size 5]</span></div><div class=\"line\">np.add(a, <span class=\"number\">1</span>, out=a)</div><div class=\"line\">print(a)</div><div class=\"line\">print(b)            <span class=\"comment\"># a b2</span></div></pre></td></tr></table></figure>\n<p>PyTorchGPU<code>.cuda()</code>GPU</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># let us run this cell only if CUDA is available</span></div><div class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</div><div class=\"line\">    print(<span class=\"string\">'cuda is avaliable'</span>)</div><div class=\"line\">    x = x.cuda()</div><div class=\"line\">    y = y.cuda()</div><div class=\"line\">    x + y          <span class=\"comment\"># GPU</span></div></pre></td></tr></table></figure>\n<h2 id=\"Neural-Network\"><a href=\"#Neural-Network\" class=\"headerlink\" title=\"Neural Network\"></a>Neural Network</h2><p><code>Tensor</code><a href=\"http://pytorch.org/docs/autograd.html\" target=\"_blank\" rel=\"external\"></a></p>\n<p><code>autograd.Variable</code><code>Tensor</code><code>.backward()</code><code>Variable</code><code>Variable</code><code>data</code><code>Tensor</code><code>grad</code><code>Variable</code></p>\n<p><code>Variable</code><code>Function</code><code>Variable</code><code>creator</code><code>Function</code><code>creator</code><code>None</code></p>\n<p><code>Variable</code><code>loss</code><code>backward()</code><code>Variable</code><code>Variable</code>shape<code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\">x = Variable(torch.ones(<span class=\"number\">2</span>, <span class=\"number\">2</span>), requires_grad = <span class=\"keyword\">True</span>)</div><div class=\"line\">x     <span class=\"comment\"># x 2x2Tensor</span></div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">Variable containing:</div><div class=\"line\"> 1  1</div><div class=\"line\"> 1  1</div><div class=\"line\">[torch.FloatTensor of size 2x2]</div><div class=\"line\">\"\"\"</div><div class=\"line\"><span class=\"comment\"># Variable</span></div><div class=\"line\"><span class=\"comment\"># y was created as a result of an operation,</span></div><div class=\"line\"><span class=\"comment\"># so it has a creator</span></div><div class=\"line\">y = x + <span class=\"number\">2</span></div><div class=\"line\">y.creator    <span class=\"comment\"># out: &lt;torch.autograd._functions.basic_ops.AddConstant at 0x7fa1cc158c08&gt;</span></div><div class=\"line\"></div><div class=\"line\">z = y * y * <span class=\"number\">3</span>  </div><div class=\"line\">out = z.mean()   <span class=\"comment\"># out: Variable containing: 27 [torch.FloatTensor of size 1]</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># let's backprop now</span></div><div class=\"line\">out.backward()  <span class=\"comment\">#  out.backward(torch.Tensor([1.0]))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># print gradients d(out)/dx</span></div><div class=\"line\">x.grad</div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">Variable containing:</div><div class=\"line\"> 4.5000  4.5000</div><div class=\"line\"> 4.5000  4.5000</div><div class=\"line\">[torch.FloatTensor of size 2x2]</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p><code>Tensor</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TensorVariable</span></div><div class=\"line\">x = torch.randn(<span class=\"number\">3</span>)</div><div class=\"line\">x = Variable(x, requires_grad = <span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"comment\">#  op</span></div><div class=\"line\">y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"keyword\">while</span> y.data.norm() &lt; <span class=\"number\">1000</span>:</div><div class=\"line\">    y = y * <span class=\"number\">2</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#  dy/dx</span></div><div class=\"line\">gradients = torch.FloatTensor([<span class=\"number\">0.1</span>, <span class=\"number\">1.0</span>, <span class=\"number\">0.0001</span>])</div><div class=\"line\">y.backward(gradients)</div><div class=\"line\">x.grad</div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">Variable containing:</div><div class=\"line\">  204.8000</div><div class=\"line\"> 2048.0000</div><div class=\"line\">    0.2048</div><div class=\"line\">[torch.FloatTensor of size 3]</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure></p>\n<p>NN<code>Variable</code>PyTorch<code>torch.nn</code><code>layer</code> <code>nn.Module</code><code>forward(input)</code><code>output</code><code>conv</code><code>max-pooling</code><code>fc</code>CNN</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn                 <span class=\"comment\"># nn</span></div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F       <span class=\"comment\"># poolingrelufunctional</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(Net, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>) <span class=\"comment\"># 1 input image channel, 6 output channels, 5x5 square convolution kernel</span></div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        <span class=\"comment\"># input1x32x32conv-pooling-conv-pooling16x5x5</span></div><div class=\"line\">        <span class=\"comment\"># fc 16x5x5</span></div><div class=\"line\">        self.fc1   = nn.Linear(<span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>, <span class=\"number\">120</span>) <span class=\"comment\"># an affine operation: y = Wx + b</span></div><div class=\"line\">        self.fc2   = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</div><div class=\"line\">        self.fc3   = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># </span></div><div class=\"line\">        <span class=\"comment\">#  backward</span></div><div class=\"line\">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class=\"number\">2</span>, <span class=\"number\">2</span>)) <span class=\"comment\"># Max pooling over a (2, 2) window</span></div><div class=\"line\">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class=\"number\">2</span>) <span class=\"comment\"># If the size is a square you can only specify a single number</span></div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, self.num_flat_features(x))  <span class=\"comment\"># </span></div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">num_flat_features</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        size = x.size()[<span class=\"number\">1</span>:] <span class=\"comment\"># all dimensions except the batch dimension</span></div><div class=\"line\">        num_features = <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> size:</div><div class=\"line\">            num_features *= s</div><div class=\"line\">        <span class=\"keyword\">return</span> num_features</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Net</span></div><div class=\"line\">net = Net()</div><div class=\"line\">net     <span class=\"comment\"># </span></div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">Net (</div><div class=\"line\">  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))</div><div class=\"line\">  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))</div><div class=\"line\">  (fc1): Linear (400 -&gt; 120)</div><div class=\"line\">  (fc2): Linear (120 -&gt; 84)</div><div class=\"line\">  (fc3): Linear (84 -&gt; 10)</div><div class=\"line\">)</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">params = list(net.parameters())</div><div class=\"line\">print(len(params))      <span class=\"comment\"># out: 10, 55bias</span></div><div class=\"line\">print(params[<span class=\"number\">0</span>].size())  <span class=\"comment\"># conv1's weight out: torch.Size([6, 1, 5, 5])</span></div><div class=\"line\">print(params[<span class=\"number\">1</span>].size())  <span class=\"comment\"># conv1's bias, out: torch.Size([6])</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">input = Variable(torch.randn(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>))</div><div class=\"line\">out = net(input)         <span class=\"comment\"># ()</span></div><div class=\"line\">net.zero_grad()          <span class=\"comment\"># bpgrad buffer</span></div><div class=\"line\">out.backward(torch.randn(<span class=\"number\">1</span>, <span class=\"number\">10</span>))</div></pre></td></tr></table></figure>\n<p><code>torch.nn</code>mini-batch<code>input.unsqueeze(0)</code>4-D<code>Tensor</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>targetoutputloss<code>torch.nn</code><a href=\"http://pytorch.org/docs/nn.html#loss-functions\" target=\"_blank\" rel=\"external\">loss</a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">output = net(input)</div><div class=\"line\">target = Variable(torch.range(<span class=\"number\">1</span>, <span class=\"number\">10</span>))  <span class=\"comment\"># a dummy target, for example</span></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">criterion = nn.MSELoss()</div><div class=\"line\">loss = criterion(output, target)</div><div class=\"line\">loss</div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">Variable containing:</div><div class=\"line\"> 38.6049</div><div class=\"line\">[torch.FloatTensor of size 1]</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d  </div><div class=\"line\">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</div><div class=\"line\">      -&gt; MSELoss</div><div class=\"line\">      -&gt; loss</div></pre></td></tr></table></figure>\n<p><code>previous_functions</code><code>Function</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"># For illustration, let us follow a few steps backward</div><div class=\"line\">print(loss.creator) # MSELoss</div><div class=\"line\">print(loss.creator.previous_functions[0][0]) # Linear</div><div class=\"line\">print(loss.creator.previous_functions[0][0].previous_functions[0][0]) # ReLU</div><div class=\"line\">&quot;&quot;&quot;</div><div class=\"line\">&lt;torch.nn._functions.thnn.auto.MSELoss object at 0x7fa18011db40&gt;</div><div class=\"line\">&lt;torch.nn._functions.linear.Linear object at 0x7fa18011da78&gt;</div><div class=\"line\">&lt;torch.nn._functions.thnn.auto.Threshold object at 0x7fa18011d9b0&gt;</div><div class=\"line\">&quot;&quot;&quot;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># now we shall call loss.backward(), and have a look at conv1's bias gradients before and after the backward.</span></div><div class=\"line\">net.zero_grad() <span class=\"comment\"># zeroes the gradient buffers of all parameters</span></div><div class=\"line\">print(<span class=\"string\">'conv1.bias.grad before backward'</span>)</div><div class=\"line\">print(net.conv1.bias.grad)</div><div class=\"line\">loss.backward()</div><div class=\"line\">print(<span class=\"string\">'conv1.bias.grad after backward'</span>)</div><div class=\"line\">print(net.conv1.bias.grad)</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">learning_rate = <span class=\"number\">0.01</span></div><div class=\"line\"><span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> net.parameters():</div><div class=\"line\">    f.data.sub_(f.grad.data * learning_rate)</div></pre></td></tr></table></figure>\n<p><code>torch.optim</code>SGD, Nesterov-SGD, Adam, RMSProp, etc</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</div><div class=\"line\"><span class=\"comment\"># create your optimizer</span></div><div class=\"line\">optimizer = optim.SGD(net.parameters(), lr = <span class=\"number\">0.01</span>)</div><div class=\"line\"><span class=\"comment\"># in your training loop:</span></div><div class=\"line\">optimizer.zero_grad() <span class=\"comment\"># zero the gradient buffers</span></div><div class=\"line\">output = net(input)</div><div class=\"line\">loss = criterion(output, target)</div><div class=\"line\">loss.backward()</div><div class=\"line\">optimizer.step() <span class=\"comment\"># Does the update</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorchPython<code>np.array</code>OpenCVvisionPyTorch<code>torchvision</code>Imagenet, CIFAR10, MNIST, etcCIFAR</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torchvision</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># The output of torchvision datasets are PILImage images of range [0, 1].</span></div><div class=\"line\"><span class=\"comment\"># We transform them to Tensors of normalized range [-1, 1]</span></div><div class=\"line\"><span class=\"comment\"># Compose: Composes several transforms together.</span></div><div class=\"line\"><span class=\"comment\"># see http://pytorch.org/docs/torchvision/transforms.html?highlight=transforms</span></div><div class=\"line\">transform=transforms.Compose([transforms.ToTensor(),</div><div class=\"line\">                              transforms.Normalize((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>)),</div><div class=\"line\">                             ])   <span class=\"comment\"># torchvision.transforms.Normalize(mean, std)</span></div><div class=\"line\"><span class=\"comment\"># CIFAR10                             </span></div><div class=\"line\">trainset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">True</span>, download=<span class=\"keyword\">True</span>, transform=transform)</div><div class=\"line\"><span class=\"comment\"># DataLoader</span></div><div class=\"line\">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class=\"number\">4</span>,</div><div class=\"line\">                                          shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">2</span>)</div><div class=\"line\"><span class=\"comment\"># Testtrain = False</span></div><div class=\"line\">testset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">False</span>, download=<span class=\"keyword\">True</span>, transform=transform)</div><div class=\"line\">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class=\"number\">4</span>,</div><div class=\"line\">                                          shuffle=<span class=\"keyword\">False</span>, num_workers=<span class=\"number\">2</span>)</div><div class=\"line\">classes = (<span class=\"string\">'plane'</span>, <span class=\"string\">'car'</span>, <span class=\"string\">'bird'</span>, <span class=\"string\">'cat'</span>,</div><div class=\"line\">           <span class=\"string\">'deer'</span>, <span class=\"string\">'dog'</span>, <span class=\"string\">'frog'</span>, <span class=\"string\">'horse'</span>, <span class=\"string\">'ship'</span>, <span class=\"string\">'truck'</span>)</div></pre></td></tr></table></figure>\n<p>CNN<code>conv</code>3loss</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(Net, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        self.pool  = nn.MaxPool2d(<span class=\"number\">2</span>,<span class=\"number\">2</span>)</div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        self.fc1   = nn.Linear(<span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>, <span class=\"number\">120</span>)</div><div class=\"line\">        self.fc2   = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</div><div class=\"line\">        self.fc3   = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = self.pool(F.relu(self.conv1(x)))</div><div class=\"line\">        x = self.pool(F.relu(self.conv2(x)))</div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div><div class=\"line\"></div><div class=\"line\">net = Net()</div><div class=\"line\"><span class=\"comment\"># use a Classification Cross-Entropy loss</span></div><div class=\"line\">criterion = nn.CrossEntropyLoss()</div><div class=\"line\">optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.001</span>, momentum=<span class=\"number\">0.9</span>)</div></pre></td></tr></table></figure>\n<p>loop overdatasetmini-batch2000mini-batchloss</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>): <span class=\"comment\"># loop over the dataset multiple times</span></div><div class=\"line\"></div><div class=\"line\">    running_loss = <span class=\"number\">0.0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> i, data <span class=\"keyword\">in</span> enumerate(trainloader, <span class=\"number\">0</span>):</div><div class=\"line\">        <span class=\"comment\"># get the inputs</span></div><div class=\"line\">        inputs, labels = data</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># wrap them in Variable</span></div><div class=\"line\">        inputs, labels = Variable(inputs), Variable(labels)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># zero the parameter gradients</span></div><div class=\"line\">        optimizer.zero_grad()</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># forward + backward + optimize</span></div><div class=\"line\">        outputs = net(inputs)</div><div class=\"line\">        loss = criterion(outputs, labels)</div><div class=\"line\">        loss.backward()        </div><div class=\"line\">        optimizer.step()</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># print statistics</span></div><div class=\"line\">        running_loss += loss.data[<span class=\"number\">0</span>]</div><div class=\"line\">        <span class=\"keyword\">if</span> i % <span class=\"number\">2000</span> == <span class=\"number\">1999</span>: <span class=\"comment\"># print every 2000 mini-batches</span></div><div class=\"line\">            print(<span class=\"string\">'[%d, %5d] loss: %.3f'</span> % (epoch+<span class=\"number\">1</span>, i+<span class=\"number\">1</span>, running_loss / <span class=\"number\">2000</span>))</div><div class=\"line\">            running_loss = <span class=\"number\">0.0</span></div><div class=\"line\">print(<span class=\"string\">'Finished Training'</span>)</div></pre></td></tr></table></figure>\n<p>mini-batch4<code>testloader</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">dataiter = iter(testloader)</div><div class=\"line\">images, labels = dataiter.next()   <span class=\"comment\"># imagelabel</span></div><div class=\"line\">outputs = net(Variable(images))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># the outputs are energies for the 10 classes.</span></div><div class=\"line\"><span class=\"comment\"># Higher the energy for a class, the more the network</span></div><div class=\"line\"><span class=\"comment\"># thinks that the image is of the particular class</span></div><div class=\"line\"><span class=\"comment\"># So, let's get the index of the highest energy</span></div><div class=\"line\">_, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)   <span class=\"comment\"># channeltop-1</span></div><div class=\"line\"></div><div class=\"line\">print(<span class=\"string\">'Predicted: '</span>, <span class=\"string\">' '</span>.join(<span class=\"string\">'%5s'</span>% classes[predicted[j][<span class=\"number\">0</span>]] <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)))</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">correct = <span class=\"number\">0</span></div><div class=\"line\">total = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:     <span class=\"comment\"># test mini-batch</span></div><div class=\"line\">    images, labels = data</div><div class=\"line\">    outputs = net(Variable(images))</div><div class=\"line\">    _, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)</div><div class=\"line\">    total += labels.size(<span class=\"number\">0</span>)</div><div class=\"line\">    correct += (predicted == labels).sum()</div><div class=\"line\"></div><div class=\"line\">print(<span class=\"string\">'Accuracy of the network on the 10000 test images: %d %%'</span> % (<span class=\"number\">100</span> * correct / total))</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">class_correct = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</div><div class=\"line\">class_total = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</div><div class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:</div><div class=\"line\">    images, labels = data</div><div class=\"line\">    outputs = net(Variable(images))</div><div class=\"line\">    _, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)</div><div class=\"line\">    c = (predicted == labels).squeeze()</div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>):</div><div class=\"line\">        label = labels[i]</div><div class=\"line\">        class_correct[label] += c[i]</div><div class=\"line\">        class_total[label] += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p>CPUGPU<code>.cuda()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">net.cuda()</div></pre></td></tr></table></figure>\n<p><code>images</code><code>label</code>GPU</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://github.com/pytorch/examples\" target=\"_blank\" rel=\"external\"></a><br><a href=\"https://github.com/pytorch/tutorials\" target=\"_blank\" rel=\"external\"></a></p>\n","excerpt":"<p>PyTorchjupyter notebook<a href=\"https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb\">GitHub repo</a><br><img src=\"/img/pytorch_logo.png\" alt=\"PyTorch Logo\"></p>","more":"<h2 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch\"></a>PyTorch</h2><p><a href=\"https://github.com/pytorch/pytorch\">PyTorch</a>TorchPyTorchPythonPython firstGPU<code>numpy</code>PyTorch</p>\n<p>PyTorchCaffe<code>prototxt</code>PyTorchPyTorchopAutoGrad</p>\n<h2 id=\"Tensors\"><a href=\"#Tensors\" class=\"headerlink\" title=\"Tensors\"></a>Tensors</h2><p><code>Tensor</code><code>numpy</code>PyTorchGPUPyTorch<code>Tensor</code><code>numpy</code><code>array</code></p>\n<p><code>Tensor(shape)</code><code>tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">x = torch.Tensor(<span class=\"number\">5</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># construct a 5x3 matrix, uninitialized</span></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)    <span class=\"comment\"># construct a randomly initialized matrix</span></div><div class=\"line\"><span class=\"comment\"># sizetensorshapetorch.Size  tuple</span></div><div class=\"line\">x.size()                <span class=\"comment\"># out: torch.Size([5, 3])</span></div></pre></td></tr></table></figure>\n<p>PyTorch<code>op</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># addition: syntax 1</span></div><div class=\"line\">x + y                  <span class=\"comment\"># out: [torch.FloatTensor of size 5x3]</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># addition: syntax 2</span></div><div class=\"line\">torch.add(x, y)        <span class=\"comment\"># torchop</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># addition: giving an output tensor</span></div><div class=\"line\">result = torch.Tensor(<span class=\"number\">5</span>, <span class=\"number\">3</span>)  <span class=\"comment\"># size</span></div><div class=\"line\">torch.add(x, y, out=result)  <span class=\"comment\"># result</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">out = x + y                  <span class=\"comment\"># size</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># torchop</span></div><div class=\"line\"><span class=\"comment\"># addition: in-place</span></div><div class=\"line\">y.add_(x)              <span class=\"comment\"># xy</span></div><div class=\"line\"><span class=\"comment\"># : x.copy_(y), x.t_().</span></div></pre></td></tr></table></figure>\n<p>PyTorch<code>numpy</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># standard numpy-like indexing with all bells and whistles</span></div><div class=\"line\">x[:,<span class=\"number\">1</span>]                 <span class=\"comment\"># out: [torch.FloatTensor of size 5]</span></div></pre></td></tr></table></figure>\n<p><code>op</code>PyTorch<a href=\"http://pytorch.org/docs/torch.html\"></a></p>\n<p><code>Tensor</code><code>numpy</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># Tensor  np.array</span></div><div class=\"line\">a = torch.ones(<span class=\"number\">5</span>)    <span class=\"comment\"># out: [torch.FloatTensor of size 5]</span></div><div class=\"line\"><span class=\"comment\">#  numpy</span></div><div class=\"line\">b = a.numpy()        <span class=\"comment\"># out: array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)</span></div><div class=\"line\"><span class=\"comment\"># ab</span></div><div class=\"line\">a.add_(<span class=\"number\">1</span>)</div><div class=\"line\">print(a)</div><div class=\"line\">print(b)             <span class=\"comment\"># a b2</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># np.array Tensor</span></div><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\">a = np.ones(<span class=\"number\">5</span>)</div><div class=\"line\"><span class=\"comment\"># torch.from_numpy</span></div><div class=\"line\">b = torch.from_numpy(a)  <span class=\"comment\"># out: [torch.DoubleTensor of size 5]</span></div><div class=\"line\">np.add(a, <span class=\"number\">1</span>, out=a)</div><div class=\"line\">print(a)</div><div class=\"line\">print(b)            <span class=\"comment\"># a b2</span></div></pre></td></tr></table></figure>\n<p>PyTorchGPU<code>.cuda()</code>GPU</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># let us run this cell only if CUDA is available</span></div><div class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</div><div class=\"line\">    print(<span class=\"string\">'cuda is avaliable'</span>)</div><div class=\"line\">    x = x.cuda()</div><div class=\"line\">    y = y.cuda()</div><div class=\"line\">    x + y          <span class=\"comment\"># GPU</span></div></pre></td></tr></table></figure>\n<h2 id=\"Neural-Network\"><a href=\"#Neural-Network\" class=\"headerlink\" title=\"Neural Network\"></a>Neural Network</h2><p><code>Tensor</code><a href=\"http://pytorch.org/docs/autograd.html\"></a></p>\n<p><code>autograd.Variable</code><code>Tensor</code><code>.backward()</code><code>Variable</code><code>Variable</code><code>data</code><code>Tensor</code><code>grad</code><code>Variable</code></p>\n<p><code>Variable</code><code>Function</code><code>Variable</code><code>creator</code><code>Function</code><code>creator</code><code>None</code></p>\n<p><code>Variable</code><code>loss</code><code>backward()</code><code>Variable</code><code>Variable</code>shape<code>Tensor</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</div><div class=\"line\">x = Variable(torch.ones(<span class=\"number\">2</span>, <span class=\"number\">2</span>), requires_grad = <span class=\"keyword\">True</span>)</div><div class=\"line\">x     <span class=\"comment\"># x 2x2Tensor</span></div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">Variable containing:</div><div class=\"line\"> 1  1</div><div class=\"line\"> 1  1</div><div class=\"line\">[torch.FloatTensor of size 2x2]</div><div class=\"line\">\"\"\"</span></div><div class=\"line\"><span class=\"comment\"># Variable</span></div><div class=\"line\"><span class=\"comment\"># y was created as a result of an operation,</span></div><div class=\"line\"><span class=\"comment\"># so it has a creator</span></div><div class=\"line\">y = x + <span class=\"number\">2</span></div><div class=\"line\">y.creator    <span class=\"comment\"># out: &lt;torch.autograd._functions.basic_ops.AddConstant at 0x7fa1cc158c08&gt;</span></div><div class=\"line\"></div><div class=\"line\">z = y * y * <span class=\"number\">3</span>  </div><div class=\"line\">out = z.mean()   <span class=\"comment\"># out: Variable containing: 27 [torch.FloatTensor of size 1]</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># let's backprop now</span></div><div class=\"line\">out.backward()  <span class=\"comment\">#  out.backward(torch.Tensor([1.0]))</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># print gradients d(out)/dx</span></div><div class=\"line\">x.grad</div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">Variable containing:</div><div class=\"line\"> 4.5000  4.5000</div><div class=\"line\"> 4.5000  4.5000</div><div class=\"line\">[torch.FloatTensor of size 2x2]</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p><code>Tensor</code><br><figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># TensorVariable</span></div><div class=\"line\">x = torch.randn(<span class=\"number\">3</span>)</div><div class=\"line\">x = Variable(x, requires_grad = <span class=\"keyword\">True</span>)</div><div class=\"line\"><span class=\"comment\">#  op</span></div><div class=\"line\">y = x * <span class=\"number\">2</span></div><div class=\"line\"><span class=\"keyword\">while</span> y.data.norm() &lt; <span class=\"number\">1000</span>:</div><div class=\"line\">    y = y * <span class=\"number\">2</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">#  dy/dx</span></div><div class=\"line\">gradients = torch.FloatTensor([<span class=\"number\">0.1</span>, <span class=\"number\">1.0</span>, <span class=\"number\">0.0001</span>])</div><div class=\"line\">y.backward(gradients)</div><div class=\"line\">x.grad</div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">Variable containing:</div><div class=\"line\">  204.8000</div><div class=\"line\"> 2048.0000</div><div class=\"line\">    0.2048</div><div class=\"line\">[torch.FloatTensor of size 3]</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure></p>\n<p>NN<code>Variable</code>PyTorch<code>torch.nn</code><code>layer</code> <code>nn.Module</code><code>forward(input)</code><code>output</code><code>conv</code><code>max-pooling</code><code>fc</code>CNN</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn                 <span class=\"comment\"># nn</span></div><div class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F       <span class=\"comment\"># poolingrelufunctional</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(Net, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>) <span class=\"comment\"># 1 input image channel, 6 output channels, 5x5 square convolution kernel</span></div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        <span class=\"comment\"># input1x32x32conv-pooling-conv-pooling16x5x5</span></div><div class=\"line\">        <span class=\"comment\"># fc 16x5x5</span></div><div class=\"line\">        self.fc1   = nn.Linear(<span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>, <span class=\"number\">120</span>) <span class=\"comment\"># an affine operation: y = Wx + b</span></div><div class=\"line\">        self.fc2   = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</div><div class=\"line\">        self.fc3   = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># </span></div><div class=\"line\">        <span class=\"comment\">#  backward</span></div><div class=\"line\">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class=\"number\">2</span>, <span class=\"number\">2</span>)) <span class=\"comment\"># Max pooling over a (2, 2) window</span></div><div class=\"line\">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class=\"number\">2</span>) <span class=\"comment\"># If the size is a square you can only specify a single number</span></div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, self.num_flat_features(x))  <span class=\"comment\"># </span></div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">num_flat_features</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        size = x.size()[<span class=\"number\">1</span>:] <span class=\"comment\"># all dimensions except the batch dimension</span></div><div class=\"line\">        num_features = <span class=\"number\">1</span></div><div class=\"line\">        <span class=\"keyword\">for</span> s <span class=\"keyword\">in</span> size:</div><div class=\"line\">            num_features *= s</div><div class=\"line\">        <span class=\"keyword\">return</span> num_features</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># Net</span></div><div class=\"line\">net = Net()</div><div class=\"line\">net     <span class=\"comment\"># </span></div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">Net (</div><div class=\"line\">  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))</div><div class=\"line\">  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))</div><div class=\"line\">  (fc1): Linear (400 -&gt; 120)</div><div class=\"line\">  (fc2): Linear (120 -&gt; 84)</div><div class=\"line\">  (fc3): Linear (84 -&gt; 10)</div><div class=\"line\">)</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">params = list(net.parameters())</div><div class=\"line\">print(len(params))      <span class=\"comment\"># out: 10, 55bias</span></div><div class=\"line\">print(params[<span class=\"number\">0</span>].size())  <span class=\"comment\"># conv1's weight out: torch.Size([6, 1, 5, 5])</span></div><div class=\"line\">print(params[<span class=\"number\">1</span>].size())  <span class=\"comment\"># conv1's bias, out: torch.Size([6])</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">input = Variable(torch.randn(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>))</div><div class=\"line\">out = net(input)         <span class=\"comment\"># ()</span></div><div class=\"line\">net.zero_grad()          <span class=\"comment\"># bpgrad buffer</span></div><div class=\"line\">out.backward(torch.randn(<span class=\"number\">1</span>, <span class=\"number\">10</span>))</div></pre></td></tr></table></figure>\n<p><code>torch.nn</code>mini-batch<code>input.unsqueeze(0)</code>4-D<code>Tensor</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>targetoutputloss<code>torch.nn</code><a href=\"http://pytorch.org/docs/nn.html#loss-functions\">loss</a></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">output = net(input)</div><div class=\"line\">target = Variable(torch.range(<span class=\"number\">1</span>, <span class=\"number\">10</span>))  <span class=\"comment\"># a dummy target, for example</span></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">criterion = nn.MSELoss()</div><div class=\"line\">loss = criterion(output, target)</div><div class=\"line\">loss</div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">Variable containing:</div><div class=\"line\"> 38.6049</div><div class=\"line\">[torch.FloatTensor of size 1]</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d  </div><div class=\"line\">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</div><div class=\"line\">      -&gt; MSELoss</div><div class=\"line\">      -&gt; loss</div></pre></td></tr></table></figure>\n<p><code>previous_functions</code><code>Function</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"># For illustration, let us follow a few steps backward</div><div class=\"line\">print(loss.creator) # MSELoss</div><div class=\"line\">print(loss.creator.previous_functions[0][0]) # Linear</div><div class=\"line\">print(loss.creator.previous_functions[0][0].previous_functions[0][0]) # ReLU</div><div class=\"line\">&quot;&quot;&quot;</div><div class=\"line\">&lt;torch.nn._functions.thnn.auto.MSELoss object at 0x7fa18011db40&gt;</div><div class=\"line\">&lt;torch.nn._functions.linear.Linear object at 0x7fa18011da78&gt;</div><div class=\"line\">&lt;torch.nn._functions.thnn.auto.Threshold object at 0x7fa18011d9b0&gt;</div><div class=\"line\">&quot;&quot;&quot;</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># now we shall call loss.backward(), and have a look at conv1's bias gradients before and after the backward.</span></div><div class=\"line\">net.zero_grad() <span class=\"comment\"># zeroes the gradient buffers of all parameters</span></div><div class=\"line\">print(<span class=\"string\">'conv1.bias.grad before backward'</span>)</div><div class=\"line\">print(net.conv1.bias.grad)</div><div class=\"line\">loss.backward()</div><div class=\"line\">print(<span class=\"string\">'conv1.bias.grad after backward'</span>)</div><div class=\"line\">print(net.conv1.bias.grad)</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">learning_rate = <span class=\"number\">0.01</span></div><div class=\"line\"><span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> net.parameters():</div><div class=\"line\">    f.data.sub_(f.grad.data * learning_rate)</div></pre></td></tr></table></figure>\n<p><code>torch.optim</code>SGD, Nesterov-SGD, Adam, RMSProp, etc</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</div><div class=\"line\"><span class=\"comment\"># create your optimizer</span></div><div class=\"line\">optimizer = optim.SGD(net.parameters(), lr = <span class=\"number\">0.01</span>)</div><div class=\"line\"><span class=\"comment\"># in your training loop:</span></div><div class=\"line\">optimizer.zero_grad() <span class=\"comment\"># zero the gradient buffers</span></div><div class=\"line\">output = net(input)</div><div class=\"line\">loss = criterion(output, target)</div><div class=\"line\">loss.backward()</div><div class=\"line\">optimizer.step() <span class=\"comment\"># Does the update</span></div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>PyTorchPython<code>np.array</code>OpenCVvisionPyTorch<code>torchvision</code>Imagenet, CIFAR10, MNIST, etcCIFAR</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> torchvision</div><div class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span> transforms</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># The output of torchvision datasets are PILImage images of range [0, 1].</span></div><div class=\"line\"><span class=\"comment\"># We transform them to Tensors of normalized range [-1, 1]</span></div><div class=\"line\"><span class=\"comment\"># Compose: Composes several transforms together.</span></div><div class=\"line\"><span class=\"comment\"># see http://pytorch.org/docs/torchvision/transforms.html?highlight=transforms</span></div><div class=\"line\">transform=transforms.Compose([transforms.ToTensor(),</div><div class=\"line\">                              transforms.Normalize((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>)),</div><div class=\"line\">                             ])   <span class=\"comment\"># torchvision.transforms.Normalize(mean, std)</span></div><div class=\"line\"><span class=\"comment\"># CIFAR10                             </span></div><div class=\"line\">trainset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">True</span>, download=<span class=\"keyword\">True</span>, transform=transform)</div><div class=\"line\"><span class=\"comment\"># DataLoader</span></div><div class=\"line\">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class=\"number\">4</span>,</div><div class=\"line\">                                          shuffle=<span class=\"keyword\">True</span>, num_workers=<span class=\"number\">2</span>)</div><div class=\"line\"><span class=\"comment\"># Testtrain = False</span></div><div class=\"line\">testset = torchvision.datasets.CIFAR10(root=<span class=\"string\">'./data'</span>, train=<span class=\"keyword\">False</span>, download=<span class=\"keyword\">True</span>, transform=transform)</div><div class=\"line\">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class=\"number\">4</span>,</div><div class=\"line\">                                          shuffle=<span class=\"keyword\">False</span>, num_workers=<span class=\"number\">2</span>)</div><div class=\"line\">classes = (<span class=\"string\">'plane'</span>, <span class=\"string\">'car'</span>, <span class=\"string\">'bird'</span>, <span class=\"string\">'cat'</span>,</div><div class=\"line\">           <span class=\"string\">'deer'</span>, <span class=\"string\">'dog'</span>, <span class=\"string\">'frog'</span>, <span class=\"string\">'horse'</span>, <span class=\"string\">'ship'</span>, <span class=\"string\">'truck'</span>)</div></pre></td></tr></table></figure>\n<p>CNN<code>conv</code>3loss</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Net</span><span class=\"params\">(nn.Module)</span>:</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        super(Net, self).__init__()</div><div class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">6</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        self.pool  = nn.MaxPool2d(<span class=\"number\">2</span>,<span class=\"number\">2</span>)</div><div class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">6</span>, <span class=\"number\">16</span>, <span class=\"number\">5</span>)</div><div class=\"line\">        self.fc1   = nn.Linear(<span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>, <span class=\"number\">120</span>)</div><div class=\"line\">        self.fc2   = nn.Linear(<span class=\"number\">120</span>, <span class=\"number\">84</span>)</div><div class=\"line\">        self.fc3   = nn.Linear(<span class=\"number\">84</span>, <span class=\"number\">10</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></div><div class=\"line\">        x = self.pool(F.relu(self.conv1(x)))</div><div class=\"line\">        x = self.pool(F.relu(self.conv2(x)))</div><div class=\"line\">        x = x.view(<span class=\"number\">-1</span>, <span class=\"number\">16</span>*<span class=\"number\">5</span>*<span class=\"number\">5</span>)</div><div class=\"line\">        x = F.relu(self.fc1(x))</div><div class=\"line\">        x = F.relu(self.fc2(x))</div><div class=\"line\">        x = self.fc3(x)</div><div class=\"line\">        <span class=\"keyword\">return</span> x</div><div class=\"line\"></div><div class=\"line\">net = Net()</div><div class=\"line\"><span class=\"comment\"># use a Classification Cross-Entropy loss</span></div><div class=\"line\">criterion = nn.CrossEntropyLoss()</div><div class=\"line\">optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.001</span>, momentum=<span class=\"number\">0.9</span>)</div></pre></td></tr></table></figure>\n<p>loop overdatasetmini-batch2000mini-batchloss</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>): <span class=\"comment\"># loop over the dataset multiple times</span></div><div class=\"line\"></div><div class=\"line\">    running_loss = <span class=\"number\">0.0</span></div><div class=\"line\">    <span class=\"keyword\">for</span> i, data <span class=\"keyword\">in</span> enumerate(trainloader, <span class=\"number\">0</span>):</div><div class=\"line\">        <span class=\"comment\"># get the inputs</span></div><div class=\"line\">        inputs, labels = data</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># wrap them in Variable</span></div><div class=\"line\">        inputs, labels = Variable(inputs), Variable(labels)</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># zero the parameter gradients</span></div><div class=\"line\">        optimizer.zero_grad()</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># forward + backward + optimize</span></div><div class=\"line\">        outputs = net(inputs)</div><div class=\"line\">        loss = criterion(outputs, labels)</div><div class=\"line\">        loss.backward()        </div><div class=\"line\">        optimizer.step()</div><div class=\"line\"></div><div class=\"line\">        <span class=\"comment\"># print statistics</span></div><div class=\"line\">        running_loss += loss.data[<span class=\"number\">0</span>]</div><div class=\"line\">        <span class=\"keyword\">if</span> i % <span class=\"number\">2000</span> == <span class=\"number\">1999</span>: <span class=\"comment\"># print every 2000 mini-batches</span></div><div class=\"line\">            print(<span class=\"string\">'[%d, %5d] loss: %.3f'</span> % (epoch+<span class=\"number\">1</span>, i+<span class=\"number\">1</span>, running_loss / <span class=\"number\">2000</span>))</div><div class=\"line\">            running_loss = <span class=\"number\">0.0</span></div><div class=\"line\">print(<span class=\"string\">'Finished Training'</span>)</div></pre></td></tr></table></figure>\n<p>mini-batch4<code>testloader</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">dataiter = iter(testloader)</div><div class=\"line\">images, labels = dataiter.next()   <span class=\"comment\"># imagelabel</span></div><div class=\"line\">outputs = net(Variable(images))</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># the outputs are energies for the 10 classes.</span></div><div class=\"line\"><span class=\"comment\"># Higher the energy for a class, the more the network</span></div><div class=\"line\"><span class=\"comment\"># thinks that the image is of the particular class</span></div><div class=\"line\"><span class=\"comment\"># So, let's get the index of the highest energy</span></div><div class=\"line\">_, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)   <span class=\"comment\"># channeltop-1</span></div><div class=\"line\"></div><div class=\"line\">print(<span class=\"string\">'Predicted: '</span>, <span class=\"string\">' '</span>.join(<span class=\"string\">'%5s'</span>% classes[predicted[j][<span class=\"number\">0</span>]] <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>)))</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">correct = <span class=\"number\">0</span></div><div class=\"line\">total = <span class=\"number\">0</span></div><div class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:     <span class=\"comment\"># test mini-batch</span></div><div class=\"line\">    images, labels = data</div><div class=\"line\">    outputs = net(Variable(images))</div><div class=\"line\">    _, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)</div><div class=\"line\">    total += labels.size(<span class=\"number\">0</span>)</div><div class=\"line\">    correct += (predicted == labels).sum()</div><div class=\"line\"></div><div class=\"line\">print(<span class=\"string\">'Accuracy of the network on the 10000 test images: %d %%'</span> % (<span class=\"number\">100</span> * correct / total))</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">class_correct = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</div><div class=\"line\">class_total = list(<span class=\"number\">0.</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>))</div><div class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> testloader:</div><div class=\"line\">    images, labels = data</div><div class=\"line\">    outputs = net(Variable(images))</div><div class=\"line\">    _, predicted = torch.max(outputs.data, <span class=\"number\">1</span>)</div><div class=\"line\">    c = (predicted == labels).squeeze()</div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>):</div><div class=\"line\">        label = labels[i]</div><div class=\"line\">        class_correct[label] += c[i]</div><div class=\"line\">        class_total[label] += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p>CPUGPU<code>.cuda()</code></p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">net.cuda()</div></pre></td></tr></table></figure>\n<p><code>images</code><code>label</code>GPU</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://github.com/pytorch/examples\"></a><br><a href=\"https://github.com/pytorch/tutorials\"></a></p>"},{"title":"shell","date":"2017-11-10T05:06:30.000Z","_content":"shell[Linux Shell Scripting Tutorial, A Beginner's handbook](http://www.freeos.com/guides/lsst/)\n![Bash Logo](/img/shell-programming-bash-logo.png)\n<!-- more -->\n\n## \n\nshell\n\nshell\n\n`$``echo``echo $var``var`\n\n### \n\nLinux`HOME`,`PATH``PATH`\n![](/img/shell-programming-system-variables.jpg)\n\n### \n\n\n\n``` bash\n# \nname=value\n#  n=10\n```\n\n### \n`local`111, 222, 111.\n```bash\n#! /bin/sh\nnum=111 # \nfunc1()\n{\n  local num=222 # \n  echo $num\n}\n\necho \"before---$num\"\nfunc1\necho \"after---$num\"\n```\n\n### \n\n`expr`\n\n``` bash\n# \nexpr 1 + 3\n# *\nexpr 10 \\* 2\n```\n\n### \\`\\`\"\"\n\n\\`\\`TAB\"\"\n\n``` bash\na=`expr 10 \\* 3`\n# output: 3\necho $a\n# output: a\necho a\n# output: expr 10 \\* 3\na=\"expr 10 \\* 3\"\necho $a\n```\n\n\"\"''\n\n``` bash\na=1\necho \"$a\"  #  1\necho '$a'  #  $a\n```\n\n### \n\n`read var1, var2, ...`\n\n``` bash\n# input a=1\nread a\n# ouptut: 2\necho `expr $a + 1`\n```\n\n## \n\n### \n\nbash`0``$?`\n\n``` bash\n# echo ecoh\necoh \"hello\"\n# output: (127)\necho $?\n# output: 0\necho $?\n```\n\n### \n\n`*`,`?``[...]`\n\n`*``?``[...]`\n![](/img/shell-programming-wild-cards.jpg)\n\n`[...]`\n\n- `-``[a-z]``a``z`\n- `^``!``[!a-p]``a``p`\n\n### \n\n`>``<``ls -l > a.txt``a.txt`\n\n`>>`\n\n`<``>``tr group1 group2``group1``group2`\n\n``` bash\ntr \"[a-z]\" \"A-Z\" < ori.txt > out.txt\n```\n\n`ori.txt``out.txt`\n\n### pipeline\n\n`|`\n\n``` bash\ncat ori.txt | tr \"[a-z]\" \"A-Z\"\n```\n\n`ori.txt`\n\n### Filter\n\nFilterFilter\n\n``` bash\nsort < names.txt | uniq > u_names.txt\n```\n\n`uniq`Filter`names.txt``u_names.txt`\n\n## \n\n### if \n\nbash`if`MATLAB`end`\n\n``` bash\nif condition\nthen \nXXX\nfi\n```\n\n`else`\n``` bash\nif condition\nthen\n    do something\nelif condition\nthen\n    do something\nelse\n    do something\nfi\n```\n\n`test`\n\n`if test op1 oprator op2``op1``op2``operator``-gt``-eq`\n\n`if [ op1 operator op2 ]``[]`\n\n\n![](/img/shell-programming-if-operators.jpg)\n\n\n![](/img/bash-programming-comparing-string.jpg)\n\n12`[]`\n``` bash\n#! /bin/bash\na=1\nif [ $1=$a ]\nthen\n    echo \"you input 1\"\nelif [ $1=2 ]\nthen\n    echo \"you input 2\"\nelse\n    echo \"you input $1\"\nfi\n```\n\n\n","source":"_posts/shell-programming.md","raw":"---\ntitle: shell\ndate: 2017-11-10 13:06:30\ntags:\n    - linux\n    - shell\n---\nshell[Linux Shell Scripting Tutorial, A Beginner's handbook](http://www.freeos.com/guides/lsst/)\n![Bash Logo](/img/shell-programming-bash-logo.png)\n<!-- more -->\n\n## \n\nshell\n\nshell\n\n`$``echo``echo $var``var`\n\n### \n\nLinux`HOME`,`PATH``PATH`\n![](/img/shell-programming-system-variables.jpg)\n\n### \n\n\n\n``` bash\n# \nname=value\n#  n=10\n```\n\n### \n`local`111, 222, 111.\n```bash\n#! /bin/sh\nnum=111 # \nfunc1()\n{\n  local num=222 # \n  echo $num\n}\n\necho \"before---$num\"\nfunc1\necho \"after---$num\"\n```\n\n### \n\n`expr`\n\n``` bash\n# \nexpr 1 + 3\n# *\nexpr 10 \\* 2\n```\n\n### \\`\\`\"\"\n\n\\`\\`TAB\"\"\n\n``` bash\na=`expr 10 \\* 3`\n# output: 3\necho $a\n# output: a\necho a\n# output: expr 10 \\* 3\na=\"expr 10 \\* 3\"\necho $a\n```\n\n\"\"''\n\n``` bash\na=1\necho \"$a\"  #  1\necho '$a'  #  $a\n```\n\n### \n\n`read var1, var2, ...`\n\n``` bash\n# input a=1\nread a\n# ouptut: 2\necho `expr $a + 1`\n```\n\n## \n\n### \n\nbash`0``$?`\n\n``` bash\n# echo ecoh\necoh \"hello\"\n# output: (127)\necho $?\n# output: 0\necho $?\n```\n\n### \n\n`*`,`?``[...]`\n\n`*``?``[...]`\n![](/img/shell-programming-wild-cards.jpg)\n\n`[...]`\n\n- `-``[a-z]``a``z`\n- `^``!``[!a-p]``a``p`\n\n### \n\n`>``<``ls -l > a.txt``a.txt`\n\n`>>`\n\n`<``>``tr group1 group2``group1``group2`\n\n``` bash\ntr \"[a-z]\" \"A-Z\" < ori.txt > out.txt\n```\n\n`ori.txt``out.txt`\n\n### pipeline\n\n`|`\n\n``` bash\ncat ori.txt | tr \"[a-z]\" \"A-Z\"\n```\n\n`ori.txt`\n\n### Filter\n\nFilterFilter\n\n``` bash\nsort < names.txt | uniq > u_names.txt\n```\n\n`uniq`Filter`names.txt``u_names.txt`\n\n## \n\n### if \n\nbash`if`MATLAB`end`\n\n``` bash\nif condition\nthen \nXXX\nfi\n```\n\n`else`\n``` bash\nif condition\nthen\n    do something\nelif condition\nthen\n    do something\nelse\n    do something\nfi\n```\n\n`test`\n\n`if test op1 oprator op2``op1``op2``operator``-gt``-eq`\n\n`if [ op1 operator op2 ]``[]`\n\n\n![](/img/shell-programming-if-operators.jpg)\n\n\n![](/img/bash-programming-comparing-string.jpg)\n\n12`[]`\n``` bash\n#! /bin/bash\na=1\nif [ $1=$a ]\nthen\n    echo \"you input 1\"\nelif [ $1=2 ]\nthen\n    echo \"you input 2\"\nelse\n    echo \"you input $1\"\nfi\n```\n\n\n","slug":"shell-programming","published":1,"updated":"2018-10-27T07:16:52.417Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ou003zae7b3fivnp8w","content":"<p>shell<a href=\"http://www.freeos.com/guides/lsst/\" target=\"_blank\" rel=\"external\">Linux Shell Scripting Tutorial, A Beginners handbook</a><br><img src=\"/img/shell-programming-bash-logo.png\" alt=\"Bash Logo\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>shell</p>\n<p>shell</p>\n<p><code>$</code><code>echo</code><code>echo $var</code><code>var</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Linux<code>HOME</code>,<code>PATH</code><code>PATH</code><br><img src=\"/img/shell-programming-system-variables.jpg\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">name=value</div><div class=\"line\"><span class=\"comment\">#  n=10</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>local</code>111, 222, 111.<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">num=111 <span class=\"comment\"># </span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">func1</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"built_in\">local</span> num=222 <span class=\"comment\"># </span></div><div class=\"line\">  <span class=\"built_in\">echo</span> <span class=\"variable\">$num</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"before---<span class=\"variable\">$num</span>\"</span></div><div class=\"line\">func1</div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"after---<span class=\"variable\">$num</span>\"</span></div></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>expr</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">expr 1 + 3</div><div class=\"line\"><span class=\"comment\"># *</span></div><div class=\"line\">expr 10 \\* 2</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"``\"></a>``</h3><p>``TAB</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">a=`expr 10 \\* 3`</div><div class=\"line\"><span class=\"comment\"># output: 3</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$a</span></div><div class=\"line\"><span class=\"comment\"># output: a</span></div><div class=\"line\"><span class=\"built_in\">echo</span> a</div><div class=\"line\"><span class=\"comment\"># output: expr 10 \\* 3</span></div><div class=\"line\">a=<span class=\"string\">\"expr 10 \\* 3\"</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$a</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">a=1</div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"<span class=\"variable\">$a</span>\"</span>  <span class=\"comment\">#  1</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'$a'</span>  <span class=\"comment\">#  $a</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>read var1, var2, ...</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># input a=1</span></div><div class=\"line\"><span class=\"built_in\">read</span> a</div><div class=\"line\"><span class=\"comment\"># ouptut: 2</span></div><div class=\"line\"><span class=\"built_in\">echo</span> `expr <span class=\"variable\">$a</span> + 1`</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>bash<code>0</code><code>$?</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># echo ecoh</span></div><div class=\"line\">ecoh <span class=\"string\">\"hello\"</span></div><div class=\"line\"><span class=\"comment\"># output: (127)</span></div><div class=\"line\"><span class=\"built_in\">echo</span> $?</div><div class=\"line\"><span class=\"comment\"># output: 0</span></div><div class=\"line\"><span class=\"built_in\">echo</span> $?</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>*</code>,<code>?</code><code>[...]</code></p>\n<p><code>*</code><code>?</code><code>[...]</code><br><img src=\"/img/shell-programming-wild-cards.jpg\" alt=\"\"></p>\n<p><code>[...]</code></p>\n<ul>\n<li><code>-</code><code>[a-z]</code><code>a</code><code>z</code></li>\n<li><code>^</code><code>!</code><code>[!a-p]</code><code>a</code><code>p</code></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>&gt;</code><code>&lt;</code><code>ls -l &gt; a.txt</code><code>a.txt</code></p>\n<p><code>&gt;&gt;</code></p>\n<p><code>&lt;</code><code>&gt;</code><code>tr group1 group2</code><code>group1</code><code>group2</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">tr <span class=\"string\">\"[a-z]\"</span> <span class=\"string\">\"A-Z\"</span> &lt; ori.txt &gt; out.txt</div></pre></td></tr></table></figure>\n<p><code>ori.txt</code><code>out.txt</code></p>\n<h3 id=\"pipeline\"><a href=\"#pipeline\" class=\"headerlink\" title=\"pipeline\"></a>pipeline</h3><p><code>|</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat ori.txt | tr <span class=\"string\">\"[a-z]\"</span> <span class=\"string\">\"A-Z\"</span></div></pre></td></tr></table></figure>\n<p><code>ori.txt</code></p>\n<h3 id=\"Filter\"><a href=\"#Filter\" class=\"headerlink\" title=\"Filter\"></a>Filter</h3><p>FilterFilter</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort &lt; names.txt | uniq &gt; u_names.txt</div></pre></td></tr></table></figure>\n<p><code>uniq</code>Filter<code>names.txt</code><code>u_names.txt</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"if-\"><a href=\"#if-\" class=\"headerlink\" title=\"if \"></a>if </h3><p>bash<code>if</code>MATLAB<code>end</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span> </div><div class=\"line\">XXX</div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p><code>else</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">elif</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure></p>\n<p><code>test</code></p>\n<p><code>if test op1 oprator op2</code><code>op1</code><code>op2</code><code>operator</code><code>-gt</code><code>-eq</code></p>\n<p><code>if [ op1 operator op2 ]</code><code>[]</code><br></p>\n<p><img src=\"/img/shell-programming-if-operators.jpg\" alt=\"\"></p>\n<p><br><img src=\"/img/bash-programming-comparing-string.jpg\" alt=\"\"></p>\n<p>12<code>[]</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/bash</span></div><div class=\"line\">a=1</div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$1</span>=<span class=\"variable\">$a</span> ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 1\"</span></div><div class=\"line\"><span class=\"keyword\">elif</span> [ <span class=\"variable\">$1</span>=2 ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 2\"</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input <span class=\"variable\">$1</span>\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure></p>\n","excerpt":"<p>shell<a href=\"http://www.freeos.com/guides/lsst/\">Linux Shell Scripting Tutorial, A Beginners handbook</a><br><img src=\"/img/shell-programming-bash-logo.png\" alt=\"Bash Logo\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>shell</p>\n<p>shell</p>\n<p><code>$</code><code>echo</code><code>echo $var</code><code>var</code></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Linux<code>HOME</code>,<code>PATH</code><code>PATH</code><br><img src=\"/img/shell-programming-system-variables.jpg\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">name=value</div><div class=\"line\"><span class=\"comment\">#  n=10</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>local</code>111, 222, 111.<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/sh</span></div><div class=\"line\">num=111 <span class=\"comment\"># </span></div><div class=\"line\"><span class=\"function\"><span class=\"title\">func1</span></span>()</div><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"built_in\">local</span> num=222 <span class=\"comment\"># </span></div><div class=\"line\">  <span class=\"built_in\">echo</span> <span class=\"variable\">$num</span></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"before---<span class=\"variable\">$num</span>\"</span></div><div class=\"line\">func1</div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"after---<span class=\"variable\">$num</span>\"</span></div></pre></td></tr></table></figure></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>expr</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">expr 1 + 3</div><div class=\"line\"><span class=\"comment\"># *</span></div><div class=\"line\">expr 10 \\* 2</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"``\"></a>``</h3><p>``TAB</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">a=`expr 10 \\* 3`</div><div class=\"line\"><span class=\"comment\"># output: 3</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$a</span></div><div class=\"line\"><span class=\"comment\"># output: a</span></div><div class=\"line\"><span class=\"built_in\">echo</span> a</div><div class=\"line\"><span class=\"comment\"># output: expr 10 \\* 3</span></div><div class=\"line\">a=<span class=\"string\">\"expr 10 \\* 3\"</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"variable\">$a</span></div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">a=1</div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">\"<span class=\"variable\">$a</span>\"</span>  <span class=\"comment\">#  1</span></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'$a'</span>  <span class=\"comment\">#  $a</span></div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>read var1, var2, ...</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># input a=1</span></div><div class=\"line\"><span class=\"built_in\">read</span> a</div><div class=\"line\"><span class=\"comment\"># ouptut: 2</span></div><div class=\"line\"><span class=\"built_in\">echo</span> `expr <span class=\"variable\">$a</span> + 1`</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>bash<code>0</code><code>$?</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># echo ecoh</span></div><div class=\"line\">ecoh <span class=\"string\">\"hello\"</span></div><div class=\"line\"><span class=\"comment\"># output: (127)</span></div><div class=\"line\"><span class=\"built_in\">echo</span> $?</div><div class=\"line\"><span class=\"comment\"># output: 0</span></div><div class=\"line\"><span class=\"built_in\">echo</span> $?</div></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>*</code>,<code>?</code><code>[...]</code></p>\n<p><code>*</code><code>?</code><code>[...]</code><br><img src=\"/img/shell-programming-wild-cards.jpg\" alt=\"\"></p>\n<p><code>[...]</code></p>\n<ul>\n<li><code>-</code><code>[a-z]</code><code>a</code><code>z</code></li>\n<li><code>^</code><code>!</code><code>[!a-p]</code><code>a</code><code>p</code></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>&gt;</code><code>&lt;</code><code>ls -l &gt; a.txt</code><code>a.txt</code></p>\n<p><code>&gt;&gt;</code></p>\n<p><code>&lt;</code><code>&gt;</code><code>tr group1 group2</code><code>group1</code><code>group2</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">tr <span class=\"string\">\"[a-z]\"</span> <span class=\"string\">\"A-Z\"</span> &lt; ori.txt &gt; out.txt</div></pre></td></tr></table></figure>\n<p><code>ori.txt</code><code>out.txt</code></p>\n<h3 id=\"pipeline\"><a href=\"#pipeline\" class=\"headerlink\" title=\"pipeline\"></a>pipeline</h3><p><code>|</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">cat ori.txt | tr <span class=\"string\">\"[a-z]\"</span> <span class=\"string\">\"A-Z\"</span></div></pre></td></tr></table></figure>\n<p><code>ori.txt</code></p>\n<h3 id=\"Filter\"><a href=\"#Filter\" class=\"headerlink\" title=\"Filter\"></a>Filter</h3><p>FilterFilter</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">sort &lt; names.txt | uniq &gt; u_names.txt</div></pre></td></tr></table></figure>\n<p><code>uniq</code>Filter<code>names.txt</code><code>u_names.txt</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"if-\"><a href=\"#if-\" class=\"headerlink\" title=\"if \"></a>if </h3><p>bash<code>if</code>MATLAB<code>end</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span> </div><div class=\"line\">XXX</div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure>\n<p><code>else</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">elif</span> condition</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"keyword\">do</span> something</div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure></p>\n<p><code>test</code></p>\n<p><code>if test op1 oprator op2</code><code>op1</code><code>op2</code><code>operator</code><code>-gt</code><code>-eq</code></p>\n<p><code>if [ op1 operator op2 ]</code><code>[]</code><br></p>\n<p><img src=\"/img/shell-programming-if-operators.jpg\" alt=\"\"></p>\n<p><br><img src=\"/img/bash-programming-comparing-string.jpg\" alt=\"\"></p>\n<p>12<code>[]</code><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#! /bin/bash</span></div><div class=\"line\">a=1</div><div class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$1</span>=<span class=\"variable\">$a</span> ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 1\"</span></div><div class=\"line\"><span class=\"keyword\">elif</span> [ <span class=\"variable\">$1</span>=2 ]</div><div class=\"line\"><span class=\"keyword\">then</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input 2\"</span></div><div class=\"line\"><span class=\"keyword\">else</span></div><div class=\"line\">    <span class=\"built_in\">echo</span> <span class=\"string\">\"you input <span class=\"variable\">$1</span>\"</span></div><div class=\"line\"><span class=\"keyword\">fi</span></div></pre></td></tr></table></figure></p>"},{"title":"Silver RL - DP Planning","date":"2017-06-06T08:57:49.000Z","_content":"MDPlectureMDPplanning\n<!-- more -->\n\n## \n\n\n- \n- \n\nMDP$S$$s$$s^\\prime$$s^\\prime$\n\n## \n$v_\\pi(s)$\n\n$$v_{k+1}(s) = \\sum_{a\\in \\mathcal{A}}\\pi(a|s)(R_s^a+\\gamma\\sum_{s^\\prime \\in \\mathcal{S}} P_{ss^\\prime}^av_k(s^\\prime))$$\n\n$s\\in \\mathcal{S}$$v(s^\\prime)$$v_{k+1}(s)$\n\n$4\\times 4$$0$$15$$0$$15$$0$$-1$$\\pi$$0.25$$v_\\pi(s)$\n![Demo](/img/silver_rl_dp_policy_evaluating_demo.png)\n\nPython\n\n``` py\nimport numpy as np\n\nv = [0 for _ in xrange(16)]\nline1 = range(1, 4)\nline4 = range(12, 15)\ncol1 = [4, 8, 12]\ncol4 = [3, 7, 11]\n\n\n# the environment simulator\ndef get_new_loc(idx, action):\n    if idx == 0 or idx == 15:\n        ret = idx\n        reward = 0\n        return ret, reward\n\n    if action == 0:\n        # up\n        if idx in line1:\n            ret = idx\n        else:\n            ret = idx-4\n    elif action == 1:\n        # down\n        if idx in line4:\n            ret = idx\n        else:\n            ret = idx+4\n    elif action == 2:\n        # left\n        if idx in col1:\n            ret = idx\n        else:\n            ret = idx-1\n    elif action == 3:\n        # right\n        if idx in col4:\n            ret = idx\n        else:\n            ret = idx+1\n\n    reward = -1\n    return ret, reward\n\n\ngamma = 1.\n\nK = [1, 2, 3, 10, 100]\nfor k in xrange(1, 101):\n    # in each iteration, update v(s) via:\n    # v(s) = \\sum_a \\pi(a|s) + \\gamma \\sum_s^\\prime P_{ss^\\prime}^a v(s^\\prime)\n    v_aux = v[:]\n    for i in xrange(16):\n        v_aux[i] = 0.\n        for action in range(4):\n            j, r = get_new_loc(i, action)\n            v_aux[i] += 0.25*(r+gamma*v[j])\n    v = v_aux\n    if k in K:\n        print 'k = {} '.format(k),\n        print ', '.join(map(lambda x: '{:.1f}'.format(x), v))\n\n```\n\n## \n$s$$Q(s,a)$\n$$\\pi^\\prime = arg\\max_{a\\in \\mathcal{A}}q_\\pi(s,a)$$\n\n\n![](/img/silver_rl_dp_policy_evaluating_demo_result.png)\n\n$1$$0$$1$$q(s,a)$\n\n\n![work](/img/silver_rl_dp_improve_policy_greedily_proof.png)\n\n\n![](/img/silver_rl_dp_improve_policy_greedily_proof_2.png)\n\n## \nwork$s$$s$$s^\\prime$$s^\\prime$$s$\n$$v^\\ast(s) = \\max_{a\\in \\mathcal{A}}R_s^a+\\gamma\\sum_{s^\\prime\\in \\mathcal{S}}P_{ss^\\prime}^av^\\ast(s^\\prime)$$\n\n\n![](/img/silver_rl_dp_value_iteration_demo.png)\n\n$1$$1$$0$$s^\\prime=0$$-1$reward\n\n-$a$-$q(s,a)$\n\n## DP\n$s^\\prime$$s$\n![](/img/silver_rl_dp_synchronous_value_iteration.png)\n\n![](/img/silver_rl_dp_synchronous_dp_algorithms.png)\n\n\n\n### in-place DP\nDP$v_{\\text{new}}(s^\\orime)$$v(s)$\n![](/img/silver_rl_dp_inplace_value_iteration.png)\n\n### Prioritized Sweeping\n\n$$|\\max\\_{a\\in A}(R\\_s^a+\\gamma\\sum\\_{s^\\prime\\in S}P\\_{ss^\\prime}^a v(s^\\prime)-v(s)|$$\n\n\n![](/img/silver_rl_dp_detailed_prioritized_dp.png)\n### DP\nexperience\n![DP](/img/silver_rl_dp_realtime_dp.png)\n","source":"_posts/silver-rl-dp.md","raw":"---\ntitle: Silver RL - DP Planning\ndate: 2017-06-06 16:57:49\ntags:\n     - reinforcement learning\n---\nMDPlectureMDPplanning\n<!-- more -->\n\n## \n\n\n- \n- \n\nMDP$S$$s$$s^\\prime$$s^\\prime$\n\n## \n$v_\\pi(s)$\n\n$$v_{k+1}(s) = \\sum_{a\\in \\mathcal{A}}\\pi(a|s)(R_s^a+\\gamma\\sum_{s^\\prime \\in \\mathcal{S}} P_{ss^\\prime}^av_k(s^\\prime))$$\n\n$s\\in \\mathcal{S}$$v(s^\\prime)$$v_{k+1}(s)$\n\n$4\\times 4$$0$$15$$0$$15$$0$$-1$$\\pi$$0.25$$v_\\pi(s)$\n![Demo](/img/silver_rl_dp_policy_evaluating_demo.png)\n\nPython\n\n``` py\nimport numpy as np\n\nv = [0 for _ in xrange(16)]\nline1 = range(1, 4)\nline4 = range(12, 15)\ncol1 = [4, 8, 12]\ncol4 = [3, 7, 11]\n\n\n# the environment simulator\ndef get_new_loc(idx, action):\n    if idx == 0 or idx == 15:\n        ret = idx\n        reward = 0\n        return ret, reward\n\n    if action == 0:\n        # up\n        if idx in line1:\n            ret = idx\n        else:\n            ret = idx-4\n    elif action == 1:\n        # down\n        if idx in line4:\n            ret = idx\n        else:\n            ret = idx+4\n    elif action == 2:\n        # left\n        if idx in col1:\n            ret = idx\n        else:\n            ret = idx-1\n    elif action == 3:\n        # right\n        if idx in col4:\n            ret = idx\n        else:\n            ret = idx+1\n\n    reward = -1\n    return ret, reward\n\n\ngamma = 1.\n\nK = [1, 2, 3, 10, 100]\nfor k in xrange(1, 101):\n    # in each iteration, update v(s) via:\n    # v(s) = \\sum_a \\pi(a|s) + \\gamma \\sum_s^\\prime P_{ss^\\prime}^a v(s^\\prime)\n    v_aux = v[:]\n    for i in xrange(16):\n        v_aux[i] = 0.\n        for action in range(4):\n            j, r = get_new_loc(i, action)\n            v_aux[i] += 0.25*(r+gamma*v[j])\n    v = v_aux\n    if k in K:\n        print 'k = {} '.format(k),\n        print ', '.join(map(lambda x: '{:.1f}'.format(x), v))\n\n```\n\n## \n$s$$Q(s,a)$\n$$\\pi^\\prime = arg\\max_{a\\in \\mathcal{A}}q_\\pi(s,a)$$\n\n\n![](/img/silver_rl_dp_policy_evaluating_demo_result.png)\n\n$1$$0$$1$$q(s,a)$\n\n\n![work](/img/silver_rl_dp_improve_policy_greedily_proof.png)\n\n\n![](/img/silver_rl_dp_improve_policy_greedily_proof_2.png)\n\n## \nwork$s$$s$$s^\\prime$$s^\\prime$$s$\n$$v^\\ast(s) = \\max_{a\\in \\mathcal{A}}R_s^a+\\gamma\\sum_{s^\\prime\\in \\mathcal{S}}P_{ss^\\prime}^av^\\ast(s^\\prime)$$\n\n\n![](/img/silver_rl_dp_value_iteration_demo.png)\n\n$1$$1$$0$$s^\\prime=0$$-1$reward\n\n-$a$-$q(s,a)$\n\n## DP\n$s^\\prime$$s$\n![](/img/silver_rl_dp_synchronous_value_iteration.png)\n\n![](/img/silver_rl_dp_synchronous_dp_algorithms.png)\n\n\n\n### in-place DP\nDP$v_{\\text{new}}(s^\\orime)$$v(s)$\n![](/img/silver_rl_dp_inplace_value_iteration.png)\n\n### Prioritized Sweeping\n\n$$|\\max\\_{a\\in A}(R\\_s^a+\\gamma\\sum\\_{s^\\prime\\in S}P\\_{ss^\\prime}^a v(s^\\prime)-v(s)|$$\n\n\n![](/img/silver_rl_dp_detailed_prioritized_dp.png)\n### DP\nexperience\n![DP](/img/silver_rl_dp_realtime_dp.png)\n","slug":"silver-rl-dp","published":1,"updated":"2018-10-27T07:16:52.418Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8ow0041ae7bfr77xarj","content":"<p>MDPlectureMDPplanning<br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>MDP$S$$s$$s^\\prime$$s^\\prime$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$v_\\pi(s)$</p>\n<script type=\"math/tex; mode=display\">v_{k+1}(s) = \\sum_{a\\in \\mathcal{A}}\\pi(a|s)(R_s^a+\\gamma\\sum_{s^\\prime \\in \\mathcal{S}} P_{ss^\\prime}^av_k(s^\\prime))</script><p>$s\\in \\mathcal{S}$$v(s^\\prime)$$v_{k+1}(s)$</p>\n<p>$4\\times 4$$0$$15$$0$$15$$0$$-1$$\\pi$$0.25$$v_\\pi(s)$<br><img src=\"/img/silver_rl_dp_policy_evaluating_demo.png\" alt=\"Demo\"></p>\n<p>Python</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\"></div><div class=\"line\">v = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> xrange(<span class=\"number\">16</span>)]</div><div class=\"line\">line1 = range(<span class=\"number\">1</span>, <span class=\"number\">4</span>)</div><div class=\"line\">line4 = range(<span class=\"number\">12</span>, <span class=\"number\">15</span>)</div><div class=\"line\">col1 = [<span class=\"number\">4</span>, <span class=\"number\">8</span>, <span class=\"number\">12</span>]</div><div class=\"line\">col4 = [<span class=\"number\">3</span>, <span class=\"number\">7</span>, <span class=\"number\">11</span>]</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># the environment simulator</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_new_loc</span><span class=\"params\">(idx, action)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> idx == <span class=\"number\">0</span> <span class=\"keyword\">or</span> idx == <span class=\"number\">15</span>:</div><div class=\"line\">        ret = idx</div><div class=\"line\">        reward = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> ret, reward</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> action == <span class=\"number\">0</span>:</div><div class=\"line\">        <span class=\"comment\"># up</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> line1:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx<span class=\"number\">-4</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">1</span>:</div><div class=\"line\">        <span class=\"comment\"># down</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> line4:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx+<span class=\"number\">4</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">2</span>:</div><div class=\"line\">        <span class=\"comment\"># left</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> col1:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx<span class=\"number\">-1</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">3</span>:</div><div class=\"line\">        <span class=\"comment\"># right</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> col4:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx+<span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">    reward = <span class=\"number\">-1</span></div><div class=\"line\">    <span class=\"keyword\">return</span> ret, reward</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">gamma = <span class=\"number\">1.</span></div><div class=\"line\"></div><div class=\"line\">K = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>]</div><div class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> xrange(<span class=\"number\">1</span>, <span class=\"number\">101</span>):</div><div class=\"line\">    <span class=\"comment\"># in each iteration, update v(s) via:</span></div><div class=\"line\">    <span class=\"comment\"># v(s) = \\sum_a \\pi(a|s) + \\gamma \\sum_s^\\prime P_&#123;ss^\\prime&#125;^a v(s^\\prime)</span></div><div class=\"line\">    v_aux = v[:]</div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> xrange(<span class=\"number\">16</span>):</div><div class=\"line\">        v_aux[i] = <span class=\"number\">0.</span></div><div class=\"line\">        <span class=\"keyword\">for</span> action <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>):</div><div class=\"line\">            j, r = get_new_loc(i, action)</div><div class=\"line\">            v_aux[i] += <span class=\"number\">0.25</span>*(r+gamma*v[j])</div><div class=\"line\">    v = v_aux</div><div class=\"line\">    <span class=\"keyword\">if</span> k <span class=\"keyword\">in</span> K:</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'k = &#123;&#125; '</span>.format(k),</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">', '</span>.join(map(<span class=\"keyword\">lambda</span> x: <span class=\"string\">'&#123;:.1f&#125;'</span>.format(x), v))</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$s$$Q(s,a)$</p>\n<script type=\"math/tex; mode=display\">\\pi^\\prime = arg\\max_{a\\in \\mathcal{A}}q_\\pi(s,a)</script><p><br><img src=\"/img/silver_rl_dp_policy_evaluating_demo_result.png\" alt=\"\"></p>\n<p>$1$$0$$1$$q(s,a)$</p>\n<p><br><img src=\"/img/silver_rl_dp_improve_policy_greedily_proof.png\" alt=\"work\"></p>\n<p><br><img src=\"/img/silver_rl_dp_improve_policy_greedily_proof_2.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>work$s$$s$$s^\\prime$$s^\\prime$$s$</p>\n<script type=\"math/tex; mode=display\">v^\\ast(s) = \\max_{a\\in \\mathcal{A}}R_s^a+\\gamma\\sum_{s^\\prime\\in \\mathcal{S}}P_{ss^\\prime}^av^\\ast(s^\\prime)</script><p><br><img src=\"/img/silver_rl_dp_value_iteration_demo.png\" alt=\"\"></p>\n<p>$1$$1$$0$$s^\\prime=0$$-1$reward</p>\n<p>-$a$-$q(s,a)$</p>\n<h2 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h2><p>$s^\\prime$$s$<br><img src=\"/img/silver_rl_dp_synchronous_value_iteration.png\" alt=\"\"><br><br><img src=\"/img/silver_rl_dp_synchronous_dp_algorithms.png\" alt=\"\"></p>\n<p></p>\n<h3 id=\"in-place-DP\"><a href=\"#in-place-DP\" class=\"headerlink\" title=\"in-place DP\"></a>in-place DP</h3><p>DP$v_{\\text{new}}(s^\\orime)$$v(s)$<br><img src=\"/img/silver_rl_dp_inplace_value_iteration.png\" alt=\"\"></p>\n<h3 id=\"Prioritized-Sweeping\"><a href=\"#Prioritized-Sweeping\" class=\"headerlink\" title=\"Prioritized Sweeping\"></a>Prioritized Sweeping</h3><p></p>\n<script type=\"math/tex; mode=display\">|\\max\\_{a\\in A}(R\\_s^a+\\gamma\\sum\\_{s^\\prime\\in S}P\\_{ss^\\prime}^a v(s^\\prime)-v(s)|</script><p><br><img src=\"/img/silver_rl_dp_detailed_prioritized_dp.png\" alt=\"\"></p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p>experience<br><img src=\"/img/silver_rl_dp_realtime_dp.png\" alt=\"DP\"></p>\n","excerpt":"<p>MDPlectureMDPplanning<br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>MDP$S$$s$$s^\\prime$$s^\\prime$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$v_\\pi(s)$</p>\n<script type=\"math/tex; mode=display\">v_{k+1}(s) = \\sum_{a\\in \\mathcal{A}}\\pi(a|s)(R_s^a+\\gamma\\sum_{s^\\prime \\in \\mathcal{S}} P_{ss^\\prime}^av_k(s^\\prime))</script><p>$s\\in \\mathcal{S}$$v(s^\\prime)$$v_{k+1}(s)$</p>\n<p>$4\\times 4$$0$$15$$0$$15$$0$$-1$$\\pi$$0.25$$v_\\pi(s)$<br><img src=\"/img/silver_rl_dp_policy_evaluating_demo.png\" alt=\"Demo\"></p>\n<p>Python</p>\n<figure class=\"highlight py\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</div><div class=\"line\"></div><div class=\"line\">v = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> xrange(<span class=\"number\">16</span>)]</div><div class=\"line\">line1 = range(<span class=\"number\">1</span>, <span class=\"number\">4</span>)</div><div class=\"line\">line4 = range(<span class=\"number\">12</span>, <span class=\"number\">15</span>)</div><div class=\"line\">col1 = [<span class=\"number\">4</span>, <span class=\"number\">8</span>, <span class=\"number\">12</span>]</div><div class=\"line\">col4 = [<span class=\"number\">3</span>, <span class=\"number\">7</span>, <span class=\"number\">11</span>]</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># the environment simulator</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_new_loc</span><span class=\"params\">(idx, action)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> idx == <span class=\"number\">0</span> <span class=\"keyword\">or</span> idx == <span class=\"number\">15</span>:</div><div class=\"line\">        ret = idx</div><div class=\"line\">        reward = <span class=\"number\">0</span></div><div class=\"line\">        <span class=\"keyword\">return</span> ret, reward</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> action == <span class=\"number\">0</span>:</div><div class=\"line\">        <span class=\"comment\"># up</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> line1:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx<span class=\"number\">-4</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">1</span>:</div><div class=\"line\">        <span class=\"comment\"># down</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> line4:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx+<span class=\"number\">4</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">2</span>:</div><div class=\"line\">        <span class=\"comment\"># left</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> col1:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx<span class=\"number\">-1</span></div><div class=\"line\">    <span class=\"keyword\">elif</span> action == <span class=\"number\">3</span>:</div><div class=\"line\">        <span class=\"comment\"># right</span></div><div class=\"line\">        <span class=\"keyword\">if</span> idx <span class=\"keyword\">in</span> col4:</div><div class=\"line\">            ret = idx</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            ret = idx+<span class=\"number\">1</span></div><div class=\"line\"></div><div class=\"line\">    reward = <span class=\"number\">-1</span></div><div class=\"line\">    <span class=\"keyword\">return</span> ret, reward</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">gamma = <span class=\"number\">1.</span></div><div class=\"line\"></div><div class=\"line\">K = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">10</span>, <span class=\"number\">100</span>]</div><div class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> xrange(<span class=\"number\">1</span>, <span class=\"number\">101</span>):</div><div class=\"line\">    <span class=\"comment\"># in each iteration, update v(s) via:</span></div><div class=\"line\">    <span class=\"comment\"># v(s) = \\sum_a \\pi(a|s) + \\gamma \\sum_s^\\prime P_&#123;ss^\\prime&#125;^a v(s^\\prime)</span></div><div class=\"line\">    v_aux = v[:]</div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> xrange(<span class=\"number\">16</span>):</div><div class=\"line\">        v_aux[i] = <span class=\"number\">0.</span></div><div class=\"line\">        <span class=\"keyword\">for</span> action <span class=\"keyword\">in</span> range(<span class=\"number\">4</span>):</div><div class=\"line\">            j, r = get_new_loc(i, action)</div><div class=\"line\">            v_aux[i] += <span class=\"number\">0.25</span>*(r+gamma*v[j])</div><div class=\"line\">    v = v_aux</div><div class=\"line\">    <span class=\"keyword\">if</span> k <span class=\"keyword\">in</span> K:</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">'k = &#123;&#125; '</span>.format(k),</div><div class=\"line\">        <span class=\"keyword\">print</span> <span class=\"string\">', '</span>.join(map(<span class=\"keyword\">lambda</span> x: <span class=\"string\">'&#123;:.1f&#125;'</span>.format(x), v))</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$s$$Q(s,a)$</p>\n<script type=\"math/tex; mode=display\">\\pi^\\prime = arg\\max_{a\\in \\mathcal{A}}q_\\pi(s,a)</script><p><br><img src=\"/img/silver_rl_dp_policy_evaluating_demo_result.png\" alt=\"\"></p>\n<p>$1$$0$$1$$q(s,a)$</p>\n<p><br><img src=\"/img/silver_rl_dp_improve_policy_greedily_proof.png\" alt=\"work\"></p>\n<p><br><img src=\"/img/silver_rl_dp_improve_policy_greedily_proof_2.png\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>work$s$$s$$s^\\prime$$s^\\prime$$s$</p>\n<script type=\"math/tex; mode=display\">v^\\ast(s) = \\max_{a\\in \\mathcal{A}}R_s^a+\\gamma\\sum_{s^\\prime\\in \\mathcal{S}}P_{ss^\\prime}^av^\\ast(s^\\prime)</script><p><br><img src=\"/img/silver_rl_dp_value_iteration_demo.png\" alt=\"\"></p>\n<p>$1$$1$$0$$s^\\prime=0$$-1$reward</p>\n<p>-$a$-$q(s,a)$</p>\n<h2 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h2><p>$s^\\prime$$s$<br><img src=\"/img/silver_rl_dp_synchronous_value_iteration.png\" alt=\"\"><br><br><img src=\"/img/silver_rl_dp_synchronous_dp_algorithms.png\" alt=\"\"></p>\n<p></p>\n<h3 id=\"in-place-DP\"><a href=\"#in-place-DP\" class=\"headerlink\" title=\"in-place DP\"></a>in-place DP</h3><p>DP$v_{\\text{new}}(s^\\orime)$$v(s)$<br><img src=\"/img/silver_rl_dp_inplace_value_iteration.png\" alt=\"\"></p>\n<h3 id=\"Prioritized-Sweeping\"><a href=\"#Prioritized-Sweeping\" class=\"headerlink\" title=\"Prioritized Sweeping\"></a>Prioritized Sweeping</h3><p></p>\n<script type=\"math/tex; mode=display\">|\\max\\_{a\\in A}(R\\_s^a+\\gamma\\sum\\_{s^\\prime\\in S}P\\_{ss^\\prime}^a v(s^\\prime)-v(s)|</script><p><br><img src=\"/img/silver_rl_dp_detailed_prioritized_dp.png\" alt=\"\"></p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p>experience<br><img src=\"/img/silver_rl_dp_realtime_dp.png\" alt=\"DP\"></p>"},{"title":"Silver RL - MDP","date":"2017-05-31T05:03:31.000Z","_content":"SilverUCLslide-MDP\n![MDP](/img/silver_rl_mdp.png)\n<!-- more -->\n\n## \nStateMarkov\n\n$$P[S_{t+1}|S_t] = P[S_{t+1}|S_1, \\dots, S_t]$$\n\nState Transition Probability\n$$P_{ss^\\prime} = P[S_{t+1}=s^\\prime|S_t=s]$$\n\n$P_{i,j}$$t$$i$$t+1$$j$$1$\n\n\n\n## \n$(S, P)$\n- $S$\n- $P$\n\n## \nMarkov reward processreward$(S, P, R, \\gamma)$\n- $R$$R\\_s = E[R\\_{t+1}|S\\_t=s]$$s$\n- $\\gamma$discount$\\gamma \\in [0,1]$\n\nReturn\n$$G_t = R_{t+1}+\\gamma R_{t+2}+... = \\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}$$\n\n\n- \n- \n- \n- \n- $\\gamma=1$\n\n## \nValue function$s$\n$$v(s) = E[G_t|S_t=s]$$\n\n$R_{t+1}$\n![](/img/silver_mdp_value_function.png)\n\n\n$$\\begin{aligned}\nE[G_{t+1}|S_t = s]  &= \\sum_{s^\\prime\\in S}E[G_{t+1}|S_{t+1}=s^\\prime]P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=\\sum_{s^\\prime}v(S_{t+1}=s^\\prime)P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=E[v(S_{t+1})|S_t=s]\n\\end{aligned}$$\n\n$s$$s^\\prime$$r$$s^\\prime$$t$$s$\n![](/img/silver_rl_bellman_equation_figure.png)\n\n$s$\n$$v(s) = R_s + \\gamma\\sum_{s^\\prime \\in S}P_{ss^\\prime}v(s^\\prime)$$\n\n\n$$v = R+\\gamma Pv$$\n![bellman](/img/silver_rl_bellman_equation_matrix.png)\n\n\n![Bellman](/img/silver_rl_bellman_equation_solution.png)\n\n$n$$\\mathcal{O}(n^3)$$n$\n-  DP\n- Monte-Carlo evaluation\n- Temporal Difference Learning\n\n## \nMDPenvMDP$(S,A,P,R,\\gamma)$\n- $A$\n- $P\\_{ss^\\prime}^a = P(S\\_{t+1}=s^\\prime|S\\_t=s, A\\_t=a)$\n- $R\\_{s}^a = E[R\\_{t+1}|S\\_t=s, A\\_t=a]$\n\n### \nPolicy$\\pi$\n$$\\pi(a|s)=P(A_t=a|S_t=s)$$\n\nMDP\n\nMDP$\\pi$$S_1,S_2,\\dots$$(S, P^\\pi)$$\\pi$$P$$\\pi$$S_1,R_1,\\dots$$(S, P^\\pi, R^\\pi, \\gamma)$\n$$\\begin{aligned}\nP_{ss^\\prime}^\\pi &= \\sum_{a\\in A}\\pi(a|s)P_{ss^\\prime}^a\\\\\nR_s^\\pi &=\\sum_{a\\in A}\\pi(a|s)R_s^a\n\\end{aligned}$$\n\n### \nMDP$v_\\pi(s)$$s$$\\pi$\n$$v_\\pi(s) = E_\\pi[G_t|S_t=s]$$\n\n-action-value function$q_\\pi(s,a)$$s$$a$$\\pi$\n$$q_\\pi(s,a) = E_\\pi[G_t|S_t=s,A_t=a]$$\n\n### \n\n![Q](/img/silver_rl_mdp_vq_relationship.png)\n\n$t$$s$$v(s)$$q(s,a)$$q(s,a)$$t+1$$s^\\prime$$v(s^\\prime)$\n![Q](/img/silver_rl_mdp_vq_relationship2.png)\n\n$v(s)$$v(s^\\prime)$\n![](/img/silver_rl_mdp_vv_relationship.png)\n\nQ\n![Q](/img/silver_rl_mdp_qq_relationship.png)\n\n\n$$v_\\pi = R^\\pi + \\gamma P^\\pi v_\\pi$$\n\n$$v_\\pi = (1-\\gamma P^\\pi)^{-1}R^\\pi$$\n\n\n$$v_\\pi(s) = E_\\pi[R_{t+1} + \\gamma v_\\pi(sS_{t+1})]$$\n\n\n### \n$v_\\pi(s)$\n$$v_\\ast(s) = \\max_\\pi v_\\pi(s)$$\n\nQ\n$$q_\\ast(s,a) = \\max_\\pi q_\\pi(s,a)$$\n\n$\\pi$\n$$\\pi > \\pi^\\prime \\quad \\text{if} \\quad v_\\pi(s) > v_{\\pi^\\prime}(s), \\forall s$$\n\nQstraight forward\n\n![](/img/silver_rl_mdp_optimal_policy.png)\n\n![](/img/silver_rl_mdp_optimal_vq_relationship.png)\n![](/img/silver_rl_mdp_optimal_vq_relationship2.png)\n![](/img/silver_rl_mdp_optimal_vv_relationship.png)\n![](/img/silver_rl_mdp_optimal_qq_relationship.png)\n\n\n- Value Iteration\n- Policy Iteration\n- Q Learning\n- Sarsa\n","source":"_posts/silver-rl-mdp.md","raw":"---\ntitle: Silver RL - MDP\ndate: 2017-05-31 13:03:31\ntags:\n    - reinforcement learning\n---\nSilverUCLslide-MDP\n![MDP](/img/silver_rl_mdp.png)\n<!-- more -->\n\n## \nStateMarkov\n\n$$P[S_{t+1}|S_t] = P[S_{t+1}|S_1, \\dots, S_t]$$\n\nState Transition Probability\n$$P_{ss^\\prime} = P[S_{t+1}=s^\\prime|S_t=s]$$\n\n$P_{i,j}$$t$$i$$t+1$$j$$1$\n\n\n\n## \n$(S, P)$\n- $S$\n- $P$\n\n## \nMarkov reward processreward$(S, P, R, \\gamma)$\n- $R$$R\\_s = E[R\\_{t+1}|S\\_t=s]$$s$\n- $\\gamma$discount$\\gamma \\in [0,1]$\n\nReturn\n$$G_t = R_{t+1}+\\gamma R_{t+2}+... = \\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}$$\n\n\n- \n- \n- \n- \n- $\\gamma=1$\n\n## \nValue function$s$\n$$v(s) = E[G_t|S_t=s]$$\n\n$R_{t+1}$\n![](/img/silver_mdp_value_function.png)\n\n\n$$\\begin{aligned}\nE[G_{t+1}|S_t = s]  &= \\sum_{s^\\prime\\in S}E[G_{t+1}|S_{t+1}=s^\\prime]P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=\\sum_{s^\\prime}v(S_{t+1}=s^\\prime)P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=E[v(S_{t+1})|S_t=s]\n\\end{aligned}$$\n\n$s$$s^\\prime$$r$$s^\\prime$$t$$s$\n![](/img/silver_rl_bellman_equation_figure.png)\n\n$s$\n$$v(s) = R_s + \\gamma\\sum_{s^\\prime \\in S}P_{ss^\\prime}v(s^\\prime)$$\n\n\n$$v = R+\\gamma Pv$$\n![bellman](/img/silver_rl_bellman_equation_matrix.png)\n\n\n![Bellman](/img/silver_rl_bellman_equation_solution.png)\n\n$n$$\\mathcal{O}(n^3)$$n$\n-  DP\n- Monte-Carlo evaluation\n- Temporal Difference Learning\n\n## \nMDPenvMDP$(S,A,P,R,\\gamma)$\n- $A$\n- $P\\_{ss^\\prime}^a = P(S\\_{t+1}=s^\\prime|S\\_t=s, A\\_t=a)$\n- $R\\_{s}^a = E[R\\_{t+1}|S\\_t=s, A\\_t=a]$\n\n### \nPolicy$\\pi$\n$$\\pi(a|s)=P(A_t=a|S_t=s)$$\n\nMDP\n\nMDP$\\pi$$S_1,S_2,\\dots$$(S, P^\\pi)$$\\pi$$P$$\\pi$$S_1,R_1,\\dots$$(S, P^\\pi, R^\\pi, \\gamma)$\n$$\\begin{aligned}\nP_{ss^\\prime}^\\pi &= \\sum_{a\\in A}\\pi(a|s)P_{ss^\\prime}^a\\\\\nR_s^\\pi &=\\sum_{a\\in A}\\pi(a|s)R_s^a\n\\end{aligned}$$\n\n### \nMDP$v_\\pi(s)$$s$$\\pi$\n$$v_\\pi(s) = E_\\pi[G_t|S_t=s]$$\n\n-action-value function$q_\\pi(s,a)$$s$$a$$\\pi$\n$$q_\\pi(s,a) = E_\\pi[G_t|S_t=s,A_t=a]$$\n\n### \n\n![Q](/img/silver_rl_mdp_vq_relationship.png)\n\n$t$$s$$v(s)$$q(s,a)$$q(s,a)$$t+1$$s^\\prime$$v(s^\\prime)$\n![Q](/img/silver_rl_mdp_vq_relationship2.png)\n\n$v(s)$$v(s^\\prime)$\n![](/img/silver_rl_mdp_vv_relationship.png)\n\nQ\n![Q](/img/silver_rl_mdp_qq_relationship.png)\n\n\n$$v_\\pi = R^\\pi + \\gamma P^\\pi v_\\pi$$\n\n$$v_\\pi = (1-\\gamma P^\\pi)^{-1}R^\\pi$$\n\n\n$$v_\\pi(s) = E_\\pi[R_{t+1} + \\gamma v_\\pi(sS_{t+1})]$$\n\n\n### \n$v_\\pi(s)$\n$$v_\\ast(s) = \\max_\\pi v_\\pi(s)$$\n\nQ\n$$q_\\ast(s,a) = \\max_\\pi q_\\pi(s,a)$$\n\n$\\pi$\n$$\\pi > \\pi^\\prime \\quad \\text{if} \\quad v_\\pi(s) > v_{\\pi^\\prime}(s), \\forall s$$\n\nQstraight forward\n\n![](/img/silver_rl_mdp_optimal_policy.png)\n\n![](/img/silver_rl_mdp_optimal_vq_relationship.png)\n![](/img/silver_rl_mdp_optimal_vq_relationship2.png)\n![](/img/silver_rl_mdp_optimal_vv_relationship.png)\n![](/img/silver_rl_mdp_optimal_qq_relationship.png)\n\n\n- Value Iteration\n- Policy Iteration\n- Q Learning\n- Sarsa\n","slug":"silver-rl-mdp","published":1,"updated":"2018-10-27T07:16:52.418Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8oz0044ae7b2tw23tyz","content":"<p>SilverUCLslide-MDP<br><img src=\"/img/silver_rl_mdp.png\" alt=\"MDP\"><br><a id=\"more\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>StateMarkov</p>\n<script type=\"math/tex; mode=display\">P[S_{t+1}|S_t] = P[S_{t+1}|S_1, \\dots, S_t]</script><p>State Transition Probability</p>\n<script type=\"math/tex; mode=display\">P_{ss^\\prime} = P[S_{t+1}=s^\\prime|S_t=s]</script><p>$P_{i,j}$$t$$i$$t+1$$j$$1$</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$(S, P)$</p>\n<ul>\n<li>$S$</li>\n<li>$P$</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Markov reward processreward$(S, P, R, \\gamma)$</p>\n<ul>\n<li>$R$$R_s = E[R_{t+1}|S_t=s]$$s$</li>\n<li>$\\gamma$discount$\\gamma \\in [0,1]$</li>\n</ul>\n<p>Return</p>\n<script type=\"math/tex; mode=display\">G_t = R_{t+1}+\\gamma R_{t+2}+... = \\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}</script><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li>$\\gamma=1$</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Value function$s$</p>\n<script type=\"math/tex; mode=display\">v(s) = E[G_t|S_t=s]</script><p>$R_{t+1}$<br><img src=\"/img/silver_mdp_value_function.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\nE[G_{t+1}|S_t = s]  &= \\sum_{s^\\prime\\in S}E[G_{t+1}|S_{t+1}=s^\\prime]P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=\\sum_{s^\\prime}v(S_{t+1}=s^\\prime)P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=E[v(S_{t+1})|S_t=s]\n\\end{aligned}</script><p>$s$$s^\\prime$$r$$s^\\prime$$t$$s$<br><img src=\"/img/silver_rl_bellman_equation_figure.png\" alt=\"\"></p>\n<p>$s$</p>\n<script type=\"math/tex; mode=display\">v(s) = R_s + \\gamma\\sum_{s^\\prime \\in S}P_{ss^\\prime}v(s^\\prime)</script><p></p>\n<script type=\"math/tex; mode=display\">v = R+\\gamma Pv</script><p><img src=\"/img/silver_rl_bellman_equation_matrix.png\" alt=\"bellman\"></p>\n<p><br><img src=\"/img/silver_rl_bellman_equation_solution.png\" alt=\"Bellman\"></p>\n<p>$n$$\\mathcal{O}(n^3)$$n$</p>\n<ul>\n<li> DP</li>\n<li>Monte-Carlo evaluation</li>\n<li>Temporal Difference Learning</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MDPenvMDP$(S,A,P,R,\\gamma)$</p>\n<ul>\n<li>$A$</li>\n<li>$P_{ss^\\prime}^a = P(S_{t+1}=s^\\prime|S_t=s, A_t=a)$</li>\n<li>$R_{s}^a = E[R_{t+1}|S_t=s, A_t=a]$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Policy$\\pi$</p>\n<script type=\"math/tex; mode=display\">\\pi(a|s)=P(A_t=a|S_t=s)</script><p>MDP</p>\n<p>MDP$\\pi$$S_1,S_2,\\dots$$(S, P^\\pi)$$\\pi$$P$$\\pi$$S_1,R_1,\\dots$$(S, P^\\pi, R^\\pi, \\gamma)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\nP_{ss^\\prime}^\\pi &= \\sum_{a\\in A}\\pi(a|s)P_{ss^\\prime}^a\\\\\nR_s^\\pi &=\\sum_{a\\in A}\\pi(a|s)R_s^a\n\\end{aligned}</script><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>MDP$v_\\pi(s)$$s$$\\pi$</p>\n<script type=\"math/tex; mode=display\">v_\\pi(s) = E_\\pi[G_t|S_t=s]</script><p>-action-value function$q_\\pi(s,a)$$s$$a$$\\pi$</p>\n<script type=\"math/tex; mode=display\">q_\\pi(s,a) = E_\\pi[G_t|S_t=s,A_t=a]</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><img src=\"/img/silver_rl_mdp_vq_relationship.png\" alt=\"Q\"></p>\n<p>$t$$s$$v(s)$$q(s,a)$$q(s,a)$$t+1$$s^\\prime$$v(s^\\prime)$<br><img src=\"/img/silver_rl_mdp_vq_relationship2.png\" alt=\"Q\"></p>\n<p>$v(s)$$v(s^\\prime)$<br><img src=\"/img/silver_rl_mdp_vv_relationship.png\" alt=\"\"></p>\n<p>Q<br><img src=\"/img/silver_rl_mdp_qq_relationship.png\" alt=\"Q\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">v_\\pi = R^\\pi + \\gamma P^\\pi v_\\pi</script><p></p>\n<script type=\"math/tex; mode=display\">v_\\pi = (1-\\gamma P^\\pi)^{-1}R^\\pi</script><p></p>\n<script type=\"math/tex; mode=display\">v_\\pi(s) = E_\\pi[R_{t+1} + \\gamma v_\\pi(sS_{t+1})]</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$v_\\pi(s)$</p>\n<script type=\"math/tex; mode=display\">v_\\ast(s) = \\max_\\pi v_\\pi(s)</script><p>Q</p>\n<script type=\"math/tex; mode=display\">q_\\ast(s,a) = \\max_\\pi q_\\pi(s,a)</script><p>$\\pi$</p>\n<script type=\"math/tex; mode=display\">\\pi > \\pi^\\prime \\quad \\text{if} \\quad v_\\pi(s) > v_{\\pi^\\prime}(s), \\forall s</script><p>Qstraight forward</p>\n<p><img src=\"/img/silver_rl_mdp_optimal_policy.png\" alt=\"\"><br><br><img src=\"/img/silver_rl_mdp_optimal_vq_relationship.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_vq_relationship2.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_vv_relationship.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_qq_relationship.png\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>Value Iteration</li>\n<li>Policy Iteration</li>\n<li>Q Learning</li>\n<li>Sarsa</li>\n</ul>\n","excerpt":"<p>SilverUCLslide-MDP<br><img src=\"/img/silver_rl_mdp.png\" alt=\"MDP\"><br>","more":"</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>StateMarkov</p>\n<script type=\"math/tex; mode=display\">P[S_{t+1}|S_t] = P[S_{t+1}|S_1, \\dots, S_t]</script><p>State Transition Probability</p>\n<script type=\"math/tex; mode=display\">P_{ss^\\prime} = P[S_{t+1}=s^\\prime|S_t=s]</script><p>$P_{i,j}$$t$$i$$t+1$$j$$1$</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$(S, P)$</p>\n<ul>\n<li>$S$</li>\n<li>$P$</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Markov reward processreward$(S, P, R, \\gamma)$</p>\n<ul>\n<li>$R$$R_s = E[R_{t+1}|S_t=s]$$s$</li>\n<li>$\\gamma$discount$\\gamma \\in [0,1]$</li>\n</ul>\n<p>Return</p>\n<script type=\"math/tex; mode=display\">G_t = R_{t+1}+\\gamma R_{t+2}+... = \\sum_{k=0}^{\\infty}\\gamma^kR_{t+k+1}</script><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li>$\\gamma=1$</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Value function$s$</p>\n<script type=\"math/tex; mode=display\">v(s) = E[G_t|S_t=s]</script><p>$R_{t+1}$<br><img src=\"/img/silver_mdp_value_function.png\" alt=\"\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\nE[G_{t+1}|S_t = s]  &= \\sum_{s^\\prime\\in S}E[G_{t+1}|S_{t+1}=s^\\prime]P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=\\sum_{s^\\prime}v(S_{t+1}=s^\\prime)P(S_{t+1}=s^\\prime|S_t=s)\\\\\n&=E[v(S_{t+1})|S_t=s]\n\\end{aligned}</script><p>$s$$s^\\prime$$r$$s^\\prime$$t$$s$<br><img src=\"/img/silver_rl_bellman_equation_figure.png\" alt=\"\"></p>\n<p>$s$</p>\n<script type=\"math/tex; mode=display\">v(s) = R_s + \\gamma\\sum_{s^\\prime \\in S}P_{ss^\\prime}v(s^\\prime)</script><p></p>\n<script type=\"math/tex; mode=display\">v = R+\\gamma Pv</script><p><img src=\"/img/silver_rl_bellman_equation_matrix.png\" alt=\"bellman\"></p>\n<p><br><img src=\"/img/silver_rl_bellman_equation_solution.png\" alt=\"Bellman\"></p>\n<p>$n$$\\mathcal{O}(n^3)$$n$</p>\n<ul>\n<li> DP</li>\n<li>Monte-Carlo evaluation</li>\n<li>Temporal Difference Learning</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>MDPenvMDP$(S,A,P,R,\\gamma)$</p>\n<ul>\n<li>$A$</li>\n<li>$P_{ss^\\prime}^a = P(S_{t+1}=s^\\prime|S_t=s, A_t=a)$</li>\n<li>$R_{s}^a = E[R_{t+1}|S_t=s, A_t=a]$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Policy$\\pi$</p>\n<script type=\"math/tex; mode=display\">\\pi(a|s)=P(A_t=a|S_t=s)</script><p>MDP</p>\n<p>MDP$\\pi$$S_1,S_2,\\dots$$(S, P^\\pi)$$\\pi$$P$$\\pi$$S_1,R_1,\\dots$$(S, P^\\pi, R^\\pi, \\gamma)$</p>\n<script type=\"math/tex; mode=display\">\\begin{aligned}\nP_{ss^\\prime}^\\pi &= \\sum_{a\\in A}\\pi(a|s)P_{ss^\\prime}^a\\\\\nR_s^\\pi &=\\sum_{a\\in A}\\pi(a|s)R_s^a\n\\end{aligned}</script><h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>MDP$v_\\pi(s)$$s$$\\pi$</p>\n<script type=\"math/tex; mode=display\">v_\\pi(s) = E_\\pi[G_t|S_t=s]</script><p>-action-value function$q_\\pi(s,a)$$s$$a$$\\pi$</p>\n<script type=\"math/tex; mode=display\">q_\\pi(s,a) = E_\\pi[G_t|S_t=s,A_t=a]</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><br><img src=\"/img/silver_rl_mdp_vq_relationship.png\" alt=\"Q\"></p>\n<p>$t$$s$$v(s)$$q(s,a)$$q(s,a)$$t+1$$s^\\prime$$v(s^\\prime)$<br><img src=\"/img/silver_rl_mdp_vq_relationship2.png\" alt=\"Q\"></p>\n<p>$v(s)$$v(s^\\prime)$<br><img src=\"/img/silver_rl_mdp_vv_relationship.png\" alt=\"\"></p>\n<p>Q<br><img src=\"/img/silver_rl_mdp_qq_relationship.png\" alt=\"Q\"></p>\n<p></p>\n<script type=\"math/tex; mode=display\">v_\\pi = R^\\pi + \\gamma P^\\pi v_\\pi</script><p></p>\n<script type=\"math/tex; mode=display\">v_\\pi = (1-\\gamma P^\\pi)^{-1}R^\\pi</script><p></p>\n<script type=\"math/tex; mode=display\">v_\\pi(s) = E_\\pi[R_{t+1} + \\gamma v_\\pi(sS_{t+1})]</script><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$v_\\pi(s)$</p>\n<script type=\"math/tex; mode=display\">v_\\ast(s) = \\max_\\pi v_\\pi(s)</script><p>Q</p>\n<script type=\"math/tex; mode=display\">q_\\ast(s,a) = \\max_\\pi q_\\pi(s,a)</script><p>$\\pi$</p>\n<script type=\"math/tex; mode=display\">\\pi > \\pi^\\prime \\quad \\text{if} \\quad v_\\pi(s) > v_{\\pi^\\prime}(s), \\forall s</script><p>Qstraight forward</p>\n<p><img src=\"/img/silver_rl_mdp_optimal_policy.png\" alt=\"\"><br><br><img src=\"/img/silver_rl_mdp_optimal_vq_relationship.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_vq_relationship2.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_vv_relationship.png\" alt=\"\"><br><img src=\"/img/silver_rl_mdp_optimal_qq_relationship.png\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>Value Iteration</li>\n<li>Policy Iteration</li>\n<li>Q Learning</li>\n<li>Sarsa</li>\n</ul>"},{"title":"WindowsDoxygen","date":"2016-12-16T11:00:00.000Z","_content":"\nDoxygen \n\n![Doxygen](/img/doxygen_picture.png)\n<!-- more -->\n##  Doxygen\n\nDoxygen Windows[Doxygen](http://www.doxygen.nl/)Windows\n\n\n\n``` bash\ndoxygen --help\n```\n\n\n\n\n\n\n``` bash\ndoxygen -g doxygen_filename\n```\n\ndoxygen\n\n\n\n``` bash\ndoxygen doxygen_filename\n```\n\n\n\n\n\n##  HTML \n\nVisual StudioVSVSGB2312\n\n Doxygen  INPUT_ENCODING  GB2312\n\n HTML \n\n## Latex \n\n Latex  Latex CTEX\n\nDoxygenLatexmakemakepdf\n\nrefman.latex CJKutf8 `\\begin{document}`\n\n``` latex\n\\begin{document}\n\\begin{CJK}{UTF8}{gbsn}\n```\n\nCJK\n\n `\\end{document)`\n``` latex\n\\end{CJK}\n\\end{document}\n```\n\nmake\n","source":"_posts/use-doxygen.md","raw":"---\ntitle: WindowsDoxygen\ndate: 2016-12-16 19:00:00\ntags:\n    - tool\n    - doxygen\n---\n\nDoxygen \n\n![Doxygen](/img/doxygen_picture.png)\n<!-- more -->\n##  Doxygen\n\nDoxygen Windows[Doxygen](http://www.doxygen.nl/)Windows\n\n\n\n``` bash\ndoxygen --help\n```\n\n\n\n\n\n\n``` bash\ndoxygen -g doxygen_filename\n```\n\ndoxygen\n\n\n\n``` bash\ndoxygen doxygen_filename\n```\n\n\n\n\n\n##  HTML \n\nVisual StudioVSVSGB2312\n\n Doxygen  INPUT_ENCODING  GB2312\n\n HTML \n\n## Latex \n\n Latex  Latex CTEX\n\nDoxygenLatexmakemakepdf\n\nrefman.latex CJKutf8 `\\begin{document}`\n\n``` latex\n\\begin{document}\n\\begin{CJK}{UTF8}{gbsn}\n```\n\nCJK\n\n `\\end{document)`\n``` latex\n\\end{CJK}\n\\end{document}\n```\n\nmake\n","slug":"use-doxygen","published":1,"updated":"2018-10-27T07:16:52.419Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8p10046ae7bmd4pfs4y","content":"<p>Doxygen </p>\n<p><img src=\"/img/doxygen_picture.png\" alt=\"Doxygen\"><br><a id=\"more\"></a></p>\n<h2 id=\"-Doxygen\"><a href=\"#-Doxygen\" class=\"headerlink\" title=\" Doxygen\"></a> Doxygen</h2><p>Doxygen Windows<a href=\"http://www.doxygen.nl/\" target=\"_blank\" rel=\"external\">Doxygen</a>Windows</p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen --help</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen -g doxygen_filename</div></pre></td></tr></table></figure>\n<p>doxygen</p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen doxygen_filename</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<h2 id=\"-HTML-\"><a href=\"#-HTML-\" class=\"headerlink\" title=\" HTML \"></a> HTML </h2><p>Visual StudioVSVSGB2312</p>\n<p> Doxygen  INPUT_ENCODING  GB2312</p>\n<p> HTML </p>\n<h2 id=\"Latex-\"><a href=\"#Latex-\" class=\"headerlink\" title=\"Latex \"></a>Latex </h2><p> Latex  Latex CTEX</p>\n<p>DoxygenLatexmakemakepdf</p>\n<p>refman.latex CJKutf8 <code>\\begin{document}</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\begin&#123;document&#125;</div><div class=\"line\">\\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gbsn&#125;</div></pre></td></tr></table></figure>\n<p>CJK</p>\n<p> <code>\\end{document)</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\end&#123;CJK&#125;</div><div class=\"line\">\\end&#123;document&#125;</div></pre></td></tr></table></figure></p>\n<p>make</p>\n","excerpt":"<p>Doxygen </p>\n<p><img src=\"/img/doxygen_picture.png\" alt=\"Doxygen\"><br>","more":"</p>\n<h2 id=\"-Doxygen\"><a href=\"#-Doxygen\" class=\"headerlink\" title=\" Doxygen\"></a> Doxygen</h2><p>Doxygen Windows<a href=\"http://www.doxygen.nl/\">Doxygen</a>Windows</p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen --help</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen -g doxygen_filename</div></pre></td></tr></table></figure>\n<p>doxygen</p>\n<p></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">doxygen doxygen_filename</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n<h2 id=\"-HTML-\"><a href=\"#-HTML-\" class=\"headerlink\" title=\" HTML \"></a> HTML </h2><p>Visual StudioVSVSGB2312</p>\n<p> Doxygen  INPUT_ENCODING  GB2312</p>\n<p> HTML </p>\n<h2 id=\"Latex-\"><a href=\"#Latex-\" class=\"headerlink\" title=\"Latex \"></a>Latex </h2><p> Latex  Latex CTEX</p>\n<p>DoxygenLatexmakemakepdf</p>\n<p>refman.latex CJKutf8 <code>\\begin{document}</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\begin&#123;document&#125;</div><div class=\"line\">\\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gbsn&#125;</div></pre></td></tr></table></figure>\n<p>CJK</p>\n<p> <code>\\end{document)</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\end&#123;CJK&#125;</div><div class=\"line\">\\end&#123;document&#125;</div></pre></td></tr></table></figure></p>\n<p>make</p>"},{"title":"Ubuntu/Mac ","date":"2017-10-22T12:12:09.000Z","_content":"UbuntuMacOSDocumentGitHubREADME\n<!-- more -->\n\n## zshOh-my-zsh\n\nBashzshbash[oh-my-zsh](https://github.com/robbyrussell/oh-my-zsh)zsh\n\noh-my-zshoh-my-zsh`colored-man-pages``man`\n![cp man](/img/useful_tools_colored_man_pages.jpg)\n\n## autojump\n\n[autojump](https://github.com/wting/autojump)\n\n(Mac: Finder)\n```\n# path\njo path\n```\n\n## tldr\n\n[tldr](https://github.com/tldr-pages/tldr) (too long don't read)bashLinuxtldr\n\n`tar`\n\n``` bash\ntldr tar\n# output\ntar\n\nArchiving utility.\nOften combined with a compression method, such as gzip or bzip.\n\n- Create an archive from files:\n    tar cf target.tar file1 file2 file3\n\n- Create a gzipped archive:\n    tar czf target.tar.gz file1 file2 file3\n\n- Extract an archive in a target folder:\n    tar xf source.tar -C folder\n\n- Extract a gzipped archive in the current directory:\n    tar xzf source.tar.gz\n\n- Extract a bzipped archive in the current directory:\n    tar xjf source.tar.bz2\n\n- Create a compressed archive, using archive suffix to determine the compression program:\n    tar caf target.tar.xz file1 file2 file3\n\n- List the contents of a tar file:\n    tar tvf source.tar\n```\n\ntldrpythontldr[tldr-py](https://github.com/lord63/tldr.py)\n\n## tmux\n\nSSHSSHSessiontmuxdetachSSHtmuxSSHtmuxguake\n\nUbuntu14.04`apt-get`tmux[oh-my-tmux](https://github.com/gpakosz/.tmux)tmux>=2.1GitHub[tmux](https://github.com/tmux/tmux)Ubuntu16.04tmux\n\n## guake\n\n[guake](https://github.com/Guake/guake)UbuntuF12F11\n\n## Dash/Zeal\n\nDashMacAPIUbuntuWindowsZealZealDashMac[](https://xmfbit.github.io/2017/08/26/doc2dash-usage/)Zeal\n\n## sshfs\n\nsshfs`rm`\n\n## Alfred/Mutate\n\nAlfredMac\nip\n\n[Mutate](https://github.com/qdore/Mutate)Ubuntupython/shell\n\n## Mos\nMacMac[Mos](https://github.com/Caldis/Mos)\n\n>  MacOS ,  | A lightweight tool used to smooth scrolling and set scroll direction independently for your mouse on MacOS http://mos.caldis.me\n\n[Release](https://github.com/Caldis/Mos/releases/)\n``` bash\nbrew cask install mos\n```","source":"_posts/useful-tools-list.md","raw":"---\ntitle: Ubuntu/Mac \ndate: 2017-10-22 20:12:09\ntags:\n---\nUbuntuMacOSDocumentGitHubREADME\n<!-- more -->\n\n## zshOh-my-zsh\n\nBashzshbash[oh-my-zsh](https://github.com/robbyrussell/oh-my-zsh)zsh\n\noh-my-zshoh-my-zsh`colored-man-pages``man`\n![cp man](/img/useful_tools_colored_man_pages.jpg)\n\n## autojump\n\n[autojump](https://github.com/wting/autojump)\n\n(Mac: Finder)\n```\n# path\njo path\n```\n\n## tldr\n\n[tldr](https://github.com/tldr-pages/tldr) (too long don't read)bashLinuxtldr\n\n`tar`\n\n``` bash\ntldr tar\n# output\ntar\n\nArchiving utility.\nOften combined with a compression method, such as gzip or bzip.\n\n- Create an archive from files:\n    tar cf target.tar file1 file2 file3\n\n- Create a gzipped archive:\n    tar czf target.tar.gz file1 file2 file3\n\n- Extract an archive in a target folder:\n    tar xf source.tar -C folder\n\n- Extract a gzipped archive in the current directory:\n    tar xzf source.tar.gz\n\n- Extract a bzipped archive in the current directory:\n    tar xjf source.tar.bz2\n\n- Create a compressed archive, using archive suffix to determine the compression program:\n    tar caf target.tar.xz file1 file2 file3\n\n- List the contents of a tar file:\n    tar tvf source.tar\n```\n\ntldrpythontldr[tldr-py](https://github.com/lord63/tldr.py)\n\n## tmux\n\nSSHSSHSessiontmuxdetachSSHtmuxSSHtmuxguake\n\nUbuntu14.04`apt-get`tmux[oh-my-tmux](https://github.com/gpakosz/.tmux)tmux>=2.1GitHub[tmux](https://github.com/tmux/tmux)Ubuntu16.04tmux\n\n## guake\n\n[guake](https://github.com/Guake/guake)UbuntuF12F11\n\n## Dash/Zeal\n\nDashMacAPIUbuntuWindowsZealZealDashMac[](https://xmfbit.github.io/2017/08/26/doc2dash-usage/)Zeal\n\n## sshfs\n\nsshfs`rm`\n\n## Alfred/Mutate\n\nAlfredMac\nip\n\n[Mutate](https://github.com/qdore/Mutate)Ubuntupython/shell\n\n## Mos\nMacMac[Mos](https://github.com/Caldis/Mos)\n\n>  MacOS ,  | A lightweight tool used to smooth scrolling and set scroll direction independently for your mouse on MacOS http://mos.caldis.me\n\n[Release](https://github.com/Caldis/Mos/releases/)\n``` bash\nbrew cask install mos\n```","slug":"useful-tools-list","published":1,"updated":"2018-10-27T07:16:52.420Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8p40049ae7b2bm00kg6","content":"<p>UbuntuMacOSDocumentGitHubREADME<br><a id=\"more\"></a></p>\n<h2 id=\"zshOh-my-zsh\"><a href=\"#zshOh-my-zsh\" class=\"headerlink\" title=\"zshOh-my-zsh\"></a>zshOh-my-zsh</h2><p>Bashzshbash<a href=\"https://github.com/robbyrussell/oh-my-zsh\" target=\"_blank\" rel=\"external\">oh-my-zsh</a>zsh</p>\n<p>oh-my-zshoh-my-zsh<code>colored-man-pages</code><code>man</code><br><img src=\"/img/useful_tools_colored_man_pages.jpg\" alt=\"cp man\"></p>\n<h2 id=\"autojump\"><a href=\"#autojump\" class=\"headerlink\" title=\"autojump\"></a>autojump</h2><p><a href=\"https://github.com/wting/autojump\" target=\"_blank\" rel=\"external\">autojump</a></p>\n<p>(Mac: Finder)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># path</div><div class=\"line\">jo path</div></pre></td></tr></table></figure></p>\n<h2 id=\"tldr\"><a href=\"#tldr\" class=\"headerlink\" title=\"tldr\"></a>tldr</h2><p><a href=\"https://github.com/tldr-pages/tldr\" target=\"_blank\" rel=\"external\">tldr</a> (too long dont read)bashLinuxtldr</p>\n<p><code>tar</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">tldr tar</div><div class=\"line\"><span class=\"comment\"># output</span></div><div class=\"line\">tar</div><div class=\"line\"></div><div class=\"line\">Archiving utility.</div><div class=\"line\">Often combined with a compression method, such as gzip or bzip.</div><div class=\"line\"></div><div class=\"line\">- Create an archive from files:</div><div class=\"line\">    tar cf target.tar file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- Create a gzipped archive:</div><div class=\"line\">    tar czf target.tar.gz file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- Extract an archive <span class=\"keyword\">in</span> a target folder:</div><div class=\"line\">    tar xf source.tar -C folder</div><div class=\"line\"></div><div class=\"line\">- Extract a gzipped archive <span class=\"keyword\">in</span> the current directory:</div><div class=\"line\">    tar xzf source.tar.gz</div><div class=\"line\"></div><div class=\"line\">- Extract a bzipped archive <span class=\"keyword\">in</span> the current directory:</div><div class=\"line\">    tar xjf source.tar.bz2</div><div class=\"line\"></div><div class=\"line\">- Create a compressed archive, using archive suffix to determine the compression program:</div><div class=\"line\">    tar caf target.tar.xz file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- List the contents of a tar file:</div><div class=\"line\">    tar tvf source.tar</div></pre></td></tr></table></figure>\n<p>tldrpythontldr<a href=\"https://github.com/lord63/tldr.py\" target=\"_blank\" rel=\"external\">tldr-py</a></p>\n<h2 id=\"tmux\"><a href=\"#tmux\" class=\"headerlink\" title=\"tmux\"></a>tmux</h2><p>SSHSSHSessiontmuxdetachSSHtmuxSSHtmuxguake</p>\n<p>Ubuntu14.04<code>apt-get</code>tmux<a href=\"https://github.com/gpakosz/.tmux\" target=\"_blank\" rel=\"external\">oh-my-tmux</a>tmux&gt;=2.1GitHub<a href=\"https://github.com/tmux/tmux\" target=\"_blank\" rel=\"external\">tmux</a>Ubuntu16.04tmux</p>\n<h2 id=\"guake\"><a href=\"#guake\" class=\"headerlink\" title=\"guake\"></a>guake</h2><p><a href=\"https://github.com/Guake/guake\" target=\"_blank\" rel=\"external\">guake</a>UbuntuF12F11</p>\n<h2 id=\"Dash-Zeal\"><a href=\"#Dash-Zeal\" class=\"headerlink\" title=\"Dash/Zeal\"></a>Dash/Zeal</h2><p>DashMacAPIUbuntuWindowsZealZealDashMac<a href=\"https://xmfbit.github.io/2017/08/26/doc2dash-usage/\"></a>Zeal</p>\n<h2 id=\"sshfs\"><a href=\"#sshfs\" class=\"headerlink\" title=\"sshfs\"></a>sshfs</h2><p>sshfs<code>rm</code></p>\n<h2 id=\"Alfred-Mutate\"><a href=\"#Alfred-Mutate\" class=\"headerlink\" title=\"Alfred/Mutate\"></a>Alfred/Mutate</h2><p>AlfredMac<br>ip</p>\n<p><a href=\"https://github.com/qdore/Mutate\" target=\"_blank\" rel=\"external\">Mutate</a>Ubuntupython/shell</p>\n<h2 id=\"Mos\"><a href=\"#Mos\" class=\"headerlink\" title=\"Mos\"></a>Mos</h2><p>MacMac<a href=\"https://github.com/Caldis/Mos\" target=\"_blank\" rel=\"external\">Mos</a></p>\n<blockquote>\n<p> MacOS ,  | A lightweight tool used to smooth scrolling and set scroll direction independently for your mouse on MacOS <a href=\"http://mos.caldis.me\" target=\"_blank\" rel=\"external\">http://mos.caldis.me</a></p>\n</blockquote>\n<p><a href=\"https://github.com/Caldis/Mos/releases/\" target=\"_blank\" rel=\"external\">Release</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">brew cask install mos</div></pre></td></tr></table></figure></p>\n","excerpt":"<p>UbuntuMacOSDocumentGitHubREADME<br>","more":"</p>\n<h2 id=\"zshOh-my-zsh\"><a href=\"#zshOh-my-zsh\" class=\"headerlink\" title=\"zshOh-my-zsh\"></a>zshOh-my-zsh</h2><p>Bashzshbash<a href=\"https://github.com/robbyrussell/oh-my-zsh\">oh-my-zsh</a>zsh</p>\n<p>oh-my-zshoh-my-zsh<code>colored-man-pages</code><code>man</code><br><img src=\"/img/useful_tools_colored_man_pages.jpg\" alt=\"cp man\"></p>\n<h2 id=\"autojump\"><a href=\"#autojump\" class=\"headerlink\" title=\"autojump\"></a>autojump</h2><p><a href=\"https://github.com/wting/autojump\">autojump</a></p>\n<p>(Mac: Finder)<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># path</div><div class=\"line\">jo path</div></pre></td></tr></table></figure></p>\n<h2 id=\"tldr\"><a href=\"#tldr\" class=\"headerlink\" title=\"tldr\"></a>tldr</h2><p><a href=\"https://github.com/tldr-pages/tldr\">tldr</a> (too long dont read)bashLinuxtldr</p>\n<p><code>tar</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\">tldr tar</div><div class=\"line\"><span class=\"comment\"># output</span></div><div class=\"line\">tar</div><div class=\"line\"></div><div class=\"line\">Archiving utility.</div><div class=\"line\">Often combined with a compression method, such as gzip or bzip.</div><div class=\"line\"></div><div class=\"line\">- Create an archive from files:</div><div class=\"line\">    tar cf target.tar file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- Create a gzipped archive:</div><div class=\"line\">    tar czf target.tar.gz file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- Extract an archive <span class=\"keyword\">in</span> a target folder:</div><div class=\"line\">    tar xf source.tar -C folder</div><div class=\"line\"></div><div class=\"line\">- Extract a gzipped archive <span class=\"keyword\">in</span> the current directory:</div><div class=\"line\">    tar xzf source.tar.gz</div><div class=\"line\"></div><div class=\"line\">- Extract a bzipped archive <span class=\"keyword\">in</span> the current directory:</div><div class=\"line\">    tar xjf source.tar.bz2</div><div class=\"line\"></div><div class=\"line\">- Create a compressed archive, using archive suffix to determine the compression program:</div><div class=\"line\">    tar caf target.tar.xz file1 file2 file3</div><div class=\"line\"></div><div class=\"line\">- List the contents of a tar file:</div><div class=\"line\">    tar tvf source.tar</div></pre></td></tr></table></figure>\n<p>tldrpythontldr<a href=\"https://github.com/lord63/tldr.py\">tldr-py</a></p>\n<h2 id=\"tmux\"><a href=\"#tmux\" class=\"headerlink\" title=\"tmux\"></a>tmux</h2><p>SSHSSHSessiontmuxdetachSSHtmuxSSHtmuxguake</p>\n<p>Ubuntu14.04<code>apt-get</code>tmux<a href=\"https://github.com/gpakosz/.tmux\">oh-my-tmux</a>tmux&gt;=2.1GitHub<a href=\"https://github.com/tmux/tmux\">tmux</a>Ubuntu16.04tmux</p>\n<h2 id=\"guake\"><a href=\"#guake\" class=\"headerlink\" title=\"guake\"></a>guake</h2><p><a href=\"https://github.com/Guake/guake\">guake</a>UbuntuF12F11</p>\n<h2 id=\"Dash-Zeal\"><a href=\"#Dash-Zeal\" class=\"headerlink\" title=\"Dash/Zeal\"></a>Dash/Zeal</h2><p>DashMacAPIUbuntuWindowsZealZealDashMac<a href=\"https://xmfbit.github.io/2017/08/26/doc2dash-usage/\"></a>Zeal</p>\n<h2 id=\"sshfs\"><a href=\"#sshfs\" class=\"headerlink\" title=\"sshfs\"></a>sshfs</h2><p>sshfs<code>rm</code></p>\n<h2 id=\"Alfred-Mutate\"><a href=\"#Alfred-Mutate\" class=\"headerlink\" title=\"Alfred/Mutate\"></a>Alfred/Mutate</h2><p>AlfredMac<br>ip</p>\n<p><a href=\"https://github.com/qdore/Mutate\">Mutate</a>Ubuntupython/shell</p>\n<h2 id=\"Mos\"><a href=\"#Mos\" class=\"headerlink\" title=\"Mos\"></a>Mos</h2><p>MacMac<a href=\"https://github.com/Caldis/Mos\">Mos</a></p>\n<blockquote>\n<p> MacOS ,  | A lightweight tool used to smooth scrolling and set scroll direction independently for your mouse on MacOS <a href=\"http://mos.caldis.me\">http://mos.caldis.me</a></p>\n</blockquote>\n<p><a href=\"https://github.com/Caldis/Mos/releases/\">Release</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">brew cask install mos</div></pre></td></tr></table></figure></p>"},{"title":"Ubuntu Cannot Mount exfat","date":"2017-05-04T10:36:29.000Z","_content":"1TBWindowsMacOSexfatUbuntu14.04`unable to mount`\n![Ubuntu Exfat](/img/ubuntu_exfat.png)\n\n<!-- more -->\n\n## \n[](https://askubuntu.com/questions/531919/ubuntu-14-04-cant-mount-exfat-external-hard-disk)\n\n```\n$ sudo -i  # root\n# apt-get update\n# apt-get install --reinstall exfat-fuse exfat-utils\n# mkdir -p /media/user/exfat\n# chmod -Rf 777 /media/user/exfat\n# fdisk -l\n```\n\n\n\n3sNTFSMacNTFS\n","source":"_posts/ubuntu-cannot-mount-exfat-disk.md","raw":"---\ntitle: Ubuntu Cannot Mount exfat\ndate: 2017-05-04 18:36:29\ntags:\n    - tool\n---\n1TBWindowsMacOSexfatUbuntu14.04`unable to mount`\n![Ubuntu Exfat](/img/ubuntu_exfat.png)\n\n<!-- more -->\n\n## \n[](https://askubuntu.com/questions/531919/ubuntu-14-04-cant-mount-exfat-external-hard-disk)\n\n```\n$ sudo -i  # root\n# apt-get update\n# apt-get install --reinstall exfat-fuse exfat-utils\n# mkdir -p /media/user/exfat\n# chmod -Rf 777 /media/user/exfat\n# fdisk -l\n```\n\n\n\n3sNTFSMacNTFS\n","slug":"ubuntu-cannot-mount-exfat-disk","published":1,"updated":"2018-10-27T07:16:52.418Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8p6004bae7baoicr9jh","content":"<p>1TBWindowsMacOSexfatUbuntu14.04<code>unable to mount</code><br><img src=\"/img/ubuntu_exfat.png\" alt=\"Ubuntu Exfat\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://askubuntu.com/questions/531919/ubuntu-14-04-cant-mount-exfat-external-hard-disk\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo -i  # root</div><div class=\"line\"># apt-get update</div><div class=\"line\"># apt-get install --reinstall exfat-fuse exfat-utils</div><div class=\"line\"># mkdir -p /media/user/exfat</div><div class=\"line\"># chmod -Rf 777 /media/user/exfat</div><div class=\"line\"># fdisk -l</div></pre></td></tr></table></figure>\n<p></p>\n<p>3sNTFSMacNTFS</p>\n","excerpt":"<p>1TBWindowsMacOSexfatUbuntu14.04<code>unable to mount</code><br><img src=\"/img/ubuntu_exfat.png\" alt=\"Ubuntu Exfat\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://askubuntu.com/questions/531919/ubuntu-14-04-cant-mount-exfat-external-hard-disk\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo -i  # root</div><div class=\"line\"># apt-get update</div><div class=\"line\"># apt-get install --reinstall exfat-fuse exfat-utils</div><div class=\"line\"># mkdir -p /media/user/exfat</div><div class=\"line\"># chmod -Rf 777 /media/user/exfat</div><div class=\"line\"># fdisk -l</div></pre></td></tr></table></figure>\n<p></p>\n<p>3sNTFSMacNTFS</p>"},{"title":"B","date":"2017-02-05T11:16:32.000Z","_content":"B[](http://www.bilibili.com/video/av6731067/index_1.html)10\n![](/img/video_linear_alg_essential.png)\n\n<!-- more -->\n## \nBIT~\n\n****\n- \n- \n\n## \n\n\n$\\alpha_i, i = 1,2,\\dots,n$$\\mathcal{V}$$v$\n$$v = \\sum_{i=1}^{n}k_i\\alpha_i$$\n\n$\\mathcal{T}$$v$\n$$u = \\mathcal{T}(v) = \\mathcal{T}(\\sum_{i=1}^{n}k_i\\alpha_i)$$\n\n\n$$u = \\sum_{i=1}^{n}k_i\\mathcal{T}(\\alpha_i)$$\n\n$\\alpha_i$$\\mathcal{T}$$\\beta_i$\n$$u = \\sum_{i=1}^{n}k_i\\beta_i$$\n\n\n$$u = \\begin{bmatrix}\\mathcal{T}(\\alpha_1), \\mathcal{T}(\\alpha_2), \\cdots, \\mathcal{T}(\\alpha_n)\\end{bmatrix}\n\\begin{bmatrix}k_1\\\\\\\\ k_2\\\\\\\\ \\vdots\\\\\\\\ k_n\\end{bmatrix}$$\n\n\n\n$\\frac{\\pi}{4}$$i$$j$$(\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$$(-\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$\n\n$$A = \\begin{bmatrix}\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\\end{bmatrix}$$\n\n$A$\n\n## \n$A$$x = \\begin{bmatrix}-1\\\\\\\\ 0\\end{bmatrix}$$-1i+0j$$-1$$0$$k_1$$k_2$\n\n$$Ax = -1\\begin{bmatrix}\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}\\end{bmatrix} + 0\\begin{bmatrix}-\\frac{\\sqrt{2}}{2}\\\\\\\\\\frac{\\sqrt{2}}{2}\\end{bmatrix} $$\n\n\n\n$x$$Ax$$A$$A$\n\n$Ax=0$$x$\n\n\n\n\n![](/img/video_linear_alg_essential_linear_equation.png)\n\n$v$$x$\n\n## \n$i$$j$\n\n$0$\n- \n- \n\n$0$\n\n## \n\n$$\\langle v, u \\rangle = \\sum_{i=1}^{n}v_iu_i$$\n\n$u$$v$$v$\n\n$u$21$\\mathbb{R}^2$$\\mathbb{R}$$v$$u$\n","source":"_posts/video-linear-alg-essential-property.md","raw":"---\ntitle: B\ndate: 2017-02-05 19:16:32\ntags:\n    - math\n---\nB[](http://www.bilibili.com/video/av6731067/index_1.html)10\n![](/img/video_linear_alg_essential.png)\n\n<!-- more -->\n## \nBIT~\n\n****\n- \n- \n\n## \n\n\n$\\alpha_i, i = 1,2,\\dots,n$$\\mathcal{V}$$v$\n$$v = \\sum_{i=1}^{n}k_i\\alpha_i$$\n\n$\\mathcal{T}$$v$\n$$u = \\mathcal{T}(v) = \\mathcal{T}(\\sum_{i=1}^{n}k_i\\alpha_i)$$\n\n\n$$u = \\sum_{i=1}^{n}k_i\\mathcal{T}(\\alpha_i)$$\n\n$\\alpha_i$$\\mathcal{T}$$\\beta_i$\n$$u = \\sum_{i=1}^{n}k_i\\beta_i$$\n\n\n$$u = \\begin{bmatrix}\\mathcal{T}(\\alpha_1), \\mathcal{T}(\\alpha_2), \\cdots, \\mathcal{T}(\\alpha_n)\\end{bmatrix}\n\\begin{bmatrix}k_1\\\\\\\\ k_2\\\\\\\\ \\vdots\\\\\\\\ k_n\\end{bmatrix}$$\n\n\n\n$\\frac{\\pi}{4}$$i$$j$$(\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$$(-\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$\n\n$$A = \\begin{bmatrix}\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\\end{bmatrix}$$\n\n$A$\n\n## \n$A$$x = \\begin{bmatrix}-1\\\\\\\\ 0\\end{bmatrix}$$-1i+0j$$-1$$0$$k_1$$k_2$\n\n$$Ax = -1\\begin{bmatrix}\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}\\end{bmatrix} + 0\\begin{bmatrix}-\\frac{\\sqrt{2}}{2}\\\\\\\\\\frac{\\sqrt{2}}{2}\\end{bmatrix} $$\n\n\n\n$x$$Ax$$A$$A$\n\n$Ax=0$$x$\n\n\n\n\n![](/img/video_linear_alg_essential_linear_equation.png)\n\n$v$$x$\n\n## \n$i$$j$\n\n$0$\n- \n- \n\n$0$\n\n## \n\n$$\\langle v, u \\rangle = \\sum_{i=1}^{n}v_iu_i$$\n\n$u$$v$$v$\n\n$u$21$\\mathbb{R}^2$$\\mathbb{R}$$v$$u$\n","slug":"video-linear-alg-essential-property","published":1,"updated":"2018-10-27T07:16:52.420Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8pc004eae7bogmqbnd3","content":"<p>B<a href=\"http://www.bilibili.com/video/av6731067/index_1.html\" target=\"_blank\" rel=\"external\"></a>10<br><img src=\"/img/video_linear_alg_essential.png\" alt=\"\"></p>\n<a id=\"more\"></a>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>BIT~</p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>$\\alpha_i, i = 1,2,\\dots,n$$\\mathcal{V}$$v$</p>\n<script type=\"math/tex; mode=display\">v = \\sum_{i=1}^{n}k_i\\alpha_i</script><p>$\\mathcal{T}$$v$</p>\n<script type=\"math/tex; mode=display\">u = \\mathcal{T}(v) = \\mathcal{T}(\\sum_{i=1}^{n}k_i\\alpha_i)</script><p></p>\n<script type=\"math/tex; mode=display\">u = \\sum_{i=1}^{n}k_i\\mathcal{T}(\\alpha_i)</script><p>$\\alpha_i$$\\mathcal{T}$$\\beta_i$</p>\n<script type=\"math/tex; mode=display\">u = \\sum_{i=1}^{n}k_i\\beta_i</script><p></p>\n<script type=\"math/tex; mode=display\">u = \\begin{bmatrix}\\mathcal{T}(\\alpha_1), \\mathcal{T}(\\alpha_2), \\cdots, \\mathcal{T}(\\alpha_n)\\end{bmatrix}\n\\begin{bmatrix}k_1\\\\\\\\ k_2\\\\\\\\ \\vdots\\\\\\\\ k_n\\end{bmatrix}</script><p></p>\n<p>$\\frac{\\pi}{4}$$i$$j$$(\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$$(-\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$</p>\n<script type=\"math/tex; mode=display\">A = \\begin{bmatrix}\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\\end{bmatrix}</script><p>$A$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$A$$x = \\begin{bmatrix}-1\\\\ 0\\end{bmatrix}$$-1i+0j$$-1$$0$$k_1$$k_2$</p>\n<script type=\"math/tex; mode=display\">Ax = -1\\begin{bmatrix}\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}\\end{bmatrix} + 0\\begin{bmatrix}-\\frac{\\sqrt{2}}{2}\\\\\\\\\\frac{\\sqrt{2}}{2}\\end{bmatrix}</script><p></p>\n<p>$x$$Ax$$A$$A$</p>\n<p>$Ax=0$$x$</p>\n<p></p>\n<p><br><img src=\"/img/video_linear_alg_essential_linear_equation.png\" alt=\"\"></p>\n<p>$v$$x$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$i$$j$</p>\n<p>$0$</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\langle v, u \\rangle = \\sum_{i=1}^{n}v_iu_i</script><p>$u$$v$$v$</p>\n<p>$u$21$\\mathbb{R}^2$$\\mathbb{R}$$v$$u$</p>\n","excerpt":"<p>B<a href=\"http://www.bilibili.com/video/av6731067/index_1.html\"></a>10<br><img src=\"/img/video_linear_alg_essential.png\" alt=\"\"></p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>BIT~</p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>$\\alpha_i, i = 1,2,\\dots,n$$\\mathcal{V}$$v$</p>\n<script type=\"math/tex; mode=display\">v = \\sum_{i=1}^{n}k_i\\alpha_i</script><p>$\\mathcal{T}$$v$</p>\n<script type=\"math/tex; mode=display\">u = \\mathcal{T}(v) = \\mathcal{T}(\\sum_{i=1}^{n}k_i\\alpha_i)</script><p></p>\n<script type=\"math/tex; mode=display\">u = \\sum_{i=1}^{n}k_i\\mathcal{T}(\\alpha_i)</script><p>$\\alpha_i$$\\mathcal{T}$$\\beta_i$</p>\n<script type=\"math/tex; mode=display\">u = \\sum_{i=1}^{n}k_i\\beta_i</script><p></p>\n<script type=\"math/tex; mode=display\">u = \\begin{bmatrix}\\mathcal{T}(\\alpha_1), \\mathcal{T}(\\alpha_2), \\cdots, \\mathcal{T}(\\alpha_n)\\end{bmatrix}\n\\begin{bmatrix}k_1\\\\\\\\ k_2\\\\\\\\ \\vdots\\\\\\\\ k_n\\end{bmatrix}</script><p></p>\n<p>$\\frac{\\pi}{4}$$i$$j$$(\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$$(-\\frac{\\sqrt{2}}{2},\\frac{\\sqrt{2}}{2})$</p>\n<script type=\"math/tex; mode=display\">A = \\begin{bmatrix}\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}& \\frac{\\sqrt{2}}{2}\\end{bmatrix}</script><p>$A$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$A$$x = \\begin{bmatrix}-1\\\\ 0\\end{bmatrix}$$-1i+0j$$-1$$0$$k_1$$k_2$</p>\n<script type=\"math/tex; mode=display\">Ax = -1\\begin{bmatrix}\\frac{\\sqrt{2}}{2}\\\\\\\\ \\frac{\\sqrt{2}}{2}\\end{bmatrix} + 0\\begin{bmatrix}-\\frac{\\sqrt{2}}{2}\\\\\\\\\\frac{\\sqrt{2}}{2}\\end{bmatrix}</script><p></p>\n<p>$x$$Ax$$A$$A$</p>\n<p>$Ax=0$$x$</p>\n<p></p>\n<p><br><img src=\"/img/video_linear_alg_essential_linear_equation.png\" alt=\"\"></p>\n<p>$v$$x$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$i$$j$</p>\n<p>$0$</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>$0$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\\langle v, u \\rangle = \\sum_{i=1}^{n}v_iu_i</script><p>$u$$v$$v$</p>\n<p>$u$21$\\mathbb{R}^2$$\\mathbb{R}$$v$$u$</p>"},{"title":"VIMYouCompleteMeJedi","date":"2018-10-02T14:30:54.000Z","_content":"Anaconda + VIMJediYouCompleteMeVIMDracula~\n\n![VIM](/img/vim-config-demo.png)\n\n<!-- more -->\n\n## JediYouCompleteMeVim\nsshfsVSCodeVSCodessh\"CTRL+`\"vim\n\n\n\n## Vim\nVimanacondabin\n\n``` sh\n./configure --with-features=huge --enable-multibyte --enable-pythoninterp=yes --with-python-config-dir=/path/to/anaconda/bin/python-config --enable-gui=gtk2 --prefix=/path/to/anaconda\n```\n\n\n``` sh\nmake -j4 VIMRUNTIMEDIR=/path/to/anaconda/share/vim/vim81\nmake install\n```\n\nvimversion\n``` sh\nvim --version\n```\n\nVundleREADME[Vundle@Github](https://github.com/VundleVim/Vundle.vim)\n\nVundleGithubvimNormal`:PluginInstall`\n\n## Jedi\njedipython\n``` sh\npip install jedi\n```\n\nVbudle[jedi-vim](https://github.com/davidhalter/jedi-vim)`.vimrc`\n```\nlet g:jedi#force_py_version=2.7\n```\n\n## YouCompleteMe\nVundle[YouCompleteMe](https://github.com/Valloric/YouCompleteMe#ubuntu-linux-x64)\n\n`.vim/bundle/YouCompleteMe``./install.py`C++`./install.py --clang-completer`\n\nPython.h`locate Python.h``/path/to/anaconda/include/python2.7`CMakeLists.txt\n\n\n`.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/CMakeLists.txt`\n\n`.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/CMakeLists.txt`\n\n``` sh\nset( CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -I/path/to/anaconda/include/python2.7\" )\n```\n\n\n\n##  \nSO`.vimrc`[jiangmiao/auto-pairs](https://github.com/jiangmiao/auto-pairs)README\n","source":"_posts/vim-you-complete-me.md","raw":"---\ntitle: VIMYouCompleteMeJedi\ndate: 2018-10-02 22:30:54\ntags:\n    - vim\n    - tools\n---\nAnaconda + VIMJediYouCompleteMeVIMDracula~\n\n![VIM](/img/vim-config-demo.png)\n\n<!-- more -->\n\n## JediYouCompleteMeVim\nsshfsVSCodeVSCodessh\"CTRL+`\"vim\n\n\n\n## Vim\nVimanacondabin\n\n``` sh\n./configure --with-features=huge --enable-multibyte --enable-pythoninterp=yes --with-python-config-dir=/path/to/anaconda/bin/python-config --enable-gui=gtk2 --prefix=/path/to/anaconda\n```\n\n\n``` sh\nmake -j4 VIMRUNTIMEDIR=/path/to/anaconda/share/vim/vim81\nmake install\n```\n\nvimversion\n``` sh\nvim --version\n```\n\nVundleREADME[Vundle@Github](https://github.com/VundleVim/Vundle.vim)\n\nVundleGithubvimNormal`:PluginInstall`\n\n## Jedi\njedipython\n``` sh\npip install jedi\n```\n\nVbudle[jedi-vim](https://github.com/davidhalter/jedi-vim)`.vimrc`\n```\nlet g:jedi#force_py_version=2.7\n```\n\n## YouCompleteMe\nVundle[YouCompleteMe](https://github.com/Valloric/YouCompleteMe#ubuntu-linux-x64)\n\n`.vim/bundle/YouCompleteMe``./install.py`C++`./install.py --clang-completer`\n\nPython.h`locate Python.h``/path/to/anaconda/include/python2.7`CMakeLists.txt\n\n\n`.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/CMakeLists.txt`\n\n`.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/CMakeLists.txt`\n\n``` sh\nset( CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -I/path/to/anaconda/include/python2.7\" )\n```\n\n\n\n##  \nSO`.vimrc`[jiangmiao/auto-pairs](https://github.com/jiangmiao/auto-pairs)README\n","slug":"vim-you-complete-me","published":1,"updated":"2018-10-27T07:16:52.421Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8pf004gae7bknk96n5x","content":"<p>Anaconda + VIMJediYouCompleteMeVIMDracula~</p>\n<p><img src=\"/img/vim-config-demo.png\" alt=\"VIM\"></p>\n<a id=\"more\"></a>\n<h2 id=\"JediYouCompleteMeVim\"><a href=\"#JediYouCompleteMeVim\" class=\"headerlink\" title=\"JediYouCompleteMeVim\"></a>JediYouCompleteMeVim</h2><p>sshfsVSCodeVSCodesshCTRL+`vim</p>\n<p></p>\n<h2 id=\"Vim\"><a href=\"#Vim\" class=\"headerlink\" title=\"Vim\"></a>Vim</h2><p>Vimanacondabin</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure --with-features=huge --enable-multibyte --enable-pythoninterp=yes --with-python-config-dir=/path/to/anaconda/bin/python-config --enable-gui=gtk2 --prefix=/path/to/anaconda</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">make -j4 VIMRUNTIMEDIR=/path/to/anaconda/share/vim/vim81</div><div class=\"line\">make install</div></pre></td></tr></table></figure></p>\n<p>vimversion<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim --version</div></pre></td></tr></table></figure></p>\n<p>VundleREADME<a href=\"https://github.com/VundleVim/Vundle.vim\" target=\"_blank\" rel=\"external\">Vundle@Github</a></p>\n<p>VundleGithubvimNormal<code>:PluginInstall</code></p>\n<h2 id=\"Jedi\"><a href=\"#Jedi\" class=\"headerlink\" title=\"Jedi\"></a>Jedi</h2><p>jedipython<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install jedi</div></pre></td></tr></table></figure></p>\n<p>Vbudle<a href=\"https://github.com/davidhalter/jedi-vim\" target=\"_blank\" rel=\"external\">jedi-vim</a><code>.vimrc</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">let g:jedi#force_py_version=2.7</div></pre></td></tr></table></figure></p>\n<h2 id=\"YouCompleteMe\"><a href=\"#YouCompleteMe\" class=\"headerlink\" title=\"YouCompleteMe\"></a>YouCompleteMe</h2><p>Vundle<a href=\"https://github.com/Valloric/YouCompleteMe#ubuntu-linux-x64\" target=\"_blank\" rel=\"external\">YouCompleteMe</a></p>\n<p><code>.vim/bundle/YouCompleteMe</code><code>./install.py</code>C++<code>./install.py --clang-completer</code></p>\n<p>Python.h<code>locate Python.h</code><code>/path/to/anaconda/include/python2.7</code>CMakeLists.txt</p>\n<p><br><code>.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/CMakeLists.txt</code><br><br><code>.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/CMakeLists.txt</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">set</span>( CMAKE_CXX_FLAGS <span class=\"string\">\"<span class=\"variable\">$&#123;CMAKE_CXX_FLAGS&#125;</span> -I/path/to/anaconda/include/python2.7\"</span> )</div></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SO<code>.vimrc</code><a href=\"https://github.com/jiangmiao/auto-pairs\" target=\"_blank\" rel=\"external\">jiangmiao/auto-pairs</a>README</p>\n","excerpt":"<p>Anaconda + VIMJediYouCompleteMeVIMDracula~</p>\n<p><img src=\"/img/vim-config-demo.png\" alt=\"VIM\"></p>","more":"<h2 id=\"JediYouCompleteMeVim\"><a href=\"#JediYouCompleteMeVim\" class=\"headerlink\" title=\"JediYouCompleteMeVim\"></a>JediYouCompleteMeVim</h2><p>sshfsVSCodeVSCodesshCTRL+`vim</p>\n<p></p>\n<h2 id=\"Vim\"><a href=\"#Vim\" class=\"headerlink\" title=\"Vim\"></a>Vim</h2><p>Vimanacondabin</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">./configure --with-features=huge --enable-multibyte --enable-pythoninterp=yes --with-python-config-dir=/path/to/anaconda/bin/python-config --enable-gui=gtk2 --prefix=/path/to/anaconda</div></pre></td></tr></table></figure>\n<p><br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">make -j4 VIMRUNTIMEDIR=/path/to/anaconda/share/vim/vim81</div><div class=\"line\">make install</div></pre></td></tr></table></figure></p>\n<p>vimversion<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">vim --version</div></pre></td></tr></table></figure></p>\n<p>VundleREADME<a href=\"https://github.com/VundleVim/Vundle.vim\">Vundle@Github</a></p>\n<p>VundleGithubvimNormal<code>:PluginInstall</code></p>\n<h2 id=\"Jedi\"><a href=\"#Jedi\" class=\"headerlink\" title=\"Jedi\"></a>Jedi</h2><p>jedipython<br><figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">pip install jedi</div></pre></td></tr></table></figure></p>\n<p>Vbudle<a href=\"https://github.com/davidhalter/jedi-vim\">jedi-vim</a><code>.vimrc</code><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">let g:jedi#force_py_version=2.7</div></pre></td></tr></table></figure></p>\n<h2 id=\"YouCompleteMe\"><a href=\"#YouCompleteMe\" class=\"headerlink\" title=\"YouCompleteMe\"></a>YouCompleteMe</h2><p>Vundle<a href=\"https://github.com/Valloric/YouCompleteMe#ubuntu-linux-x64\">YouCompleteMe</a></p>\n<p><code>.vim/bundle/YouCompleteMe</code><code>./install.py</code>C++<code>./install.py --clang-completer</code></p>\n<p>Python.h<code>locate Python.h</code><code>/path/to/anaconda/include/python2.7</code>CMakeLists.txt</p>\n<p><br><code>.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/CMakeLists.txt</code><br><br><code>.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/CMakeLists.txt</code></p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">set</span>( CMAKE_CXX_FLAGS <span class=\"string\">\"<span class=\"variable\">$&#123;CMAKE_CXX_FLAGS&#125;</span> -I/path/to/anaconda/include/python2.7\"</span> )</div></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>SO<code>.vimrc</code><a href=\"https://github.com/jiangmiao/auto-pairs\">jiangmiao/auto-pairs</a>README</p>"},{"title":"CaffeBaidu warpctcCTC Loss","date":"2017-02-22T07:34:32.000Z","_content":"CTC(Connectionist Temporal Classification) Loss CTC LossCaffeBaidu[warp-ctc](https://github.com/baidu-research/warp-ctc)LSTM + CTC Lossdemowarp-ctc[](https://github.com/baidu-research/warp-ctc)GitHub[warpctc-caffe](https://github.com/xmfbit/warpctc-caffe)\n![CTC Loss](/img/warpctc_intro.png)\n<!-- more -->\n\n## warp-ctc\n`warp-ctc`Caffe\n\n`warp-ctc`GitHubcloneCaffe`include/caffe``src/caffe``3rdparty`warp-ctcCaffe\n\n`warp-ctc``C++11`Caffe`Makefile``C++11`[Makefile](https://github.com/xmfbit/warpctc-caffe/blob/master/Makefile)\n\nCaffe`warp-ctc`GPUCTC Loss\n\n`warp-ctc`CPU`openmp`\n\nwarp-ctcCUDA`cuh``__host__``__device__`\n\nGitHub[](https://github.com/xmfbit/warpctc-caffe/blob/master/include/caffe/3rdparty/detail/hostdevice.cuh)\n\n## CTC Loss\n`ctc_loss_layer`CTC Loss`ctc.h``warp-ctc`CTC LossAPI\n\n`ctc_loss_layer``loss_layer``warp-ctc``float``NOT_IMPLEMENTED`\n\n``` cpp\ntemplate <>\nvoid CtcLossLayer<double>::Forward_cpu(\n    const vector<Blob<double>*>& bottom, const vector<Blob<double>*>& top) {\n    NOT_IMPLEMENTED;\n}\n\ntemplate <>\nvoid CtcLossLayer<double>::Backward_cpu(const vector<Blob<double>*>& top,\n    const vector<bool>& propagate_down, const vector<Blob<double>*>& bottom) {\n    NOT_IMPLEMENTED;\n}\n```\n\n`warp-ctc`CTC Loss\n\n- `ctcOptions`CPUGPUCPUGPUCUDA stream\n- `get_workspace_size()`CPUGPU\n- `compute_ctc_loss()``loss``gradient`\n\n`gradient``blob``cpu/gpu_diff``gradient`\n\n`include/caffe/layers``src/caffe/layers/`\n\n## \n`examples/warpctc`\n\n- `Python``capycha``0-9``1``MAX_LEN`\n- `10``blank_label``blank_label``MAX_LEN`\n- time step`image data->2LSTM->fc->CTC Loss`\n- `HDF5`\n\n### \n`captcha`[](https://pypi.python.org/pypi/captcha/0.1.1)API demo`160x60``80x30`\n\n`python``h5py``HDF5`80%20%\n\n### LSTM\nCaffe`lstm_layer``lstm_layer``blob``TxNx...`image\n\nCaffeBatch`NxCxHxW`time step$x$[liuweiSSD`permute_layer`](https://github.com/weiliu89/caffe/blob/ssd/include/caffe/layers/permute_layer.hpp)`W`\n\n```\nlayer {\n    name: \"permuted_data\"\n    type: \"Permute\"\n    bottom: \"data\"\n    top: \"permuted_data\"\n    permute_param {\n        order: 3   # W\n        order: 0   # N\n        order: 1   # C\n        order: 2   # H\n    }\n}\n```\n\nLSTM`ContinuationIndicator`layertime indicator\n\n### \n50,000\n\n![train loss](/img/captcha_train_loss.png)\n\n\n\n![test accuracy](/img/captcha_test_accuracy.png)\n\n98%LSTMCTC LossCTC Loss\n\nrepo\n","source":"_posts/warpctc-caffe.md","raw":"---\ntitle: CaffeBaidu warpctcCTC Loss\ndate: 2017-02-22 15:34:32\ntags:\n     - caffe\n     - deep learning\n---\nCTC(Connectionist Temporal Classification) Loss CTC LossCaffeBaidu[warp-ctc](https://github.com/baidu-research/warp-ctc)LSTM + CTC Lossdemowarp-ctc[](https://github.com/baidu-research/warp-ctc)GitHub[warpctc-caffe](https://github.com/xmfbit/warpctc-caffe)\n![CTC Loss](/img/warpctc_intro.png)\n<!-- more -->\n\n## warp-ctc\n`warp-ctc`Caffe\n\n`warp-ctc`GitHubcloneCaffe`include/caffe``src/caffe``3rdparty`warp-ctcCaffe\n\n`warp-ctc``C++11`Caffe`Makefile``C++11`[Makefile](https://github.com/xmfbit/warpctc-caffe/blob/master/Makefile)\n\nCaffe`warp-ctc`GPUCTC Loss\n\n`warp-ctc`CPU`openmp`\n\nwarp-ctcCUDA`cuh``__host__``__device__`\n\nGitHub[](https://github.com/xmfbit/warpctc-caffe/blob/master/include/caffe/3rdparty/detail/hostdevice.cuh)\n\n## CTC Loss\n`ctc_loss_layer`CTC Loss`ctc.h``warp-ctc`CTC LossAPI\n\n`ctc_loss_layer``loss_layer``warp-ctc``float``NOT_IMPLEMENTED`\n\n``` cpp\ntemplate <>\nvoid CtcLossLayer<double>::Forward_cpu(\n    const vector<Blob<double>*>& bottom, const vector<Blob<double>*>& top) {\n    NOT_IMPLEMENTED;\n}\n\ntemplate <>\nvoid CtcLossLayer<double>::Backward_cpu(const vector<Blob<double>*>& top,\n    const vector<bool>& propagate_down, const vector<Blob<double>*>& bottom) {\n    NOT_IMPLEMENTED;\n}\n```\n\n`warp-ctc`CTC Loss\n\n- `ctcOptions`CPUGPUCPUGPUCUDA stream\n- `get_workspace_size()`CPUGPU\n- `compute_ctc_loss()``loss``gradient`\n\n`gradient``blob``cpu/gpu_diff``gradient`\n\n`include/caffe/layers``src/caffe/layers/`\n\n## \n`examples/warpctc`\n\n- `Python``capycha``0-9``1``MAX_LEN`\n- `10``blank_label``blank_label``MAX_LEN`\n- time step`image data->2LSTM->fc->CTC Loss`\n- `HDF5`\n\n### \n`captcha`[](https://pypi.python.org/pypi/captcha/0.1.1)API demo`160x60``80x30`\n\n`python``h5py``HDF5`80%20%\n\n### LSTM\nCaffe`lstm_layer``lstm_layer``blob``TxNx...`image\n\nCaffeBatch`NxCxHxW`time step$x$[liuweiSSD`permute_layer`](https://github.com/weiliu89/caffe/blob/ssd/include/caffe/layers/permute_layer.hpp)`W`\n\n```\nlayer {\n    name: \"permuted_data\"\n    type: \"Permute\"\n    bottom: \"data\"\n    top: \"permuted_data\"\n    permute_param {\n        order: 3   # W\n        order: 0   # N\n        order: 1   # C\n        order: 2   # H\n    }\n}\n```\n\nLSTM`ContinuationIndicator`layertime indicator\n\n### \n50,000\n\n![train loss](/img/captcha_train_loss.png)\n\n\n\n![test accuracy](/img/captcha_test_accuracy.png)\n\n98%LSTMCTC LossCTC Loss\n\nrepo\n","slug":"warpctc-caffe","published":1,"updated":"2018-10-27T07:16:52.421Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8pi004jae7byslmsyv2","content":"<p>CTC(Connectionist Temporal Classification) Loss CTC LossCaffeBaidu<a href=\"https://github.com/baidu-research/warp-ctc\" target=\"_blank\" rel=\"external\">warp-ctc</a>LSTM + CTC Lossdemowarp-ctc<a href=\"https://github.com/baidu-research/warp-ctc\" target=\"_blank\" rel=\"external\"></a>GitHub<a href=\"https://github.com/xmfbit/warpctc-caffe\" target=\"_blank\" rel=\"external\">warpctc-caffe</a><br><img src=\"/img/warpctc_intro.png\" alt=\"CTC Loss\"><br><a id=\"more\"></a></p>\n<h2 id=\"warp-ctc\"><a href=\"#warp-ctc\" class=\"headerlink\" title=\"warp-ctc\"></a>warp-ctc</h2><p><code>warp-ctc</code>Caffe</p>\n<p><code>warp-ctc</code>GitHubcloneCaffe<code>include/caffe</code><code>src/caffe</code><code>3rdparty</code>warp-ctcCaffe</p>\n<p><code>warp-ctc</code><code>C++11</code>Caffe<code>Makefile</code><code>C++11</code><a href=\"https://github.com/xmfbit/warpctc-caffe/blob/master/Makefile\" target=\"_blank\" rel=\"external\">Makefile</a></p>\n<p>Caffe<code>warp-ctc</code>GPUCTC Loss</p>\n<p><code>warp-ctc</code>CPU<code>openmp</code></p>\n<p>warp-ctcCUDA<code>cuh</code><code>__host__</code><code>__device__</code></p>\n<p>GitHub<a href=\"https://github.com/xmfbit/warpctc-caffe/blob/master/include/caffe/3rdparty/detail/hostdevice.cuh\" target=\"_blank\" rel=\"external\"></a></p>\n<h2 id=\"CTC-Loss\"><a href=\"#CTC-Loss\" class=\"headerlink\" title=\"CTC Loss\"></a>CTC Loss</h2><p><code>ctc_loss_layer</code>CTC Loss<code>ctc.h</code><code>warp-ctc</code>CTC LossAPI</p>\n<p><code>ctc_loss_layer</code><code>loss_layer</code><code>warp-ctc</code><code>float</code><code>NOT_IMPLEMENTED</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> CtcLossLayer&lt;<span class=\"keyword\">double</span>&gt;::Forward_cpu(</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; bottom, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">    NOT_IMPLEMENTED;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> CtcLossLayer&lt;<span class=\"keyword\">double</span>&gt;::Backward_cpu(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; top,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt;&amp; propagate_down, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; bottom) &#123;</div><div class=\"line\">    NOT_IMPLEMENTED;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>warp-ctc</code>CTC Loss</p>\n<ul>\n<li><code>ctcOptions</code>CPUGPUCPUGPUCUDA stream</li>\n<li><code>get_workspace_size()</code>CPUGPU</li>\n<li><code>compute_ctc_loss()</code><code>loss</code><code>gradient</code></li>\n</ul>\n<p><code>gradient</code><code>blob</code><code>cpu/gpu_diff</code><code>gradient</code></p>\n<p><code>include/caffe/layers</code><code>src/caffe/layers/</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>examples/warpctc</code></p>\n<ul>\n<li><code>Python</code><code>capycha</code><code>0-9</code><code>1</code><code>MAX_LEN</code></li>\n<li><code>10</code><code>blank_label</code><code>blank_label</code><code>MAX_LEN</code></li>\n<li>time step<code>image data-&gt;2LSTM-&gt;fc-&gt;CTC Loss</code></li>\n<li><code>HDF5</code></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>captcha</code><a href=\"https://pypi.python.org/pypi/captcha/0.1.1\" target=\"_blank\" rel=\"external\"></a>API demo<code>160x60</code><code>80x30</code></p>\n<p><code>python</code><code>h5py</code><code>HDF5</code>80%20%</p>\n<h3 id=\"LSTM\"><a href=\"#LSTM\" class=\"headerlink\" title=\"LSTM\"></a>LSTM</h3><p>Caffe<code>lstm_layer</code><code>lstm_layer</code><code>blob</code><code>TxNx...</code>image</p>\n<p>CaffeBatch<code>NxCxHxW</code>time step$x$<a href=\"https://github.com/weiliu89/caffe/blob/ssd/include/caffe/layers/permute_layer.hpp\" target=\"_blank\" rel=\"external\">liuweiSSD<code>permute_layer</code></a><code>W</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">    name: &quot;permuted_data&quot;</div><div class=\"line\">    type: &quot;Permute&quot;</div><div class=\"line\">    bottom: &quot;data&quot;</div><div class=\"line\">    top: &quot;permuted_data&quot;</div><div class=\"line\">    permute_param &#123;</div><div class=\"line\">        order: 3   # W</div><div class=\"line\">        order: 0   # N</div><div class=\"line\">        order: 1   # C</div><div class=\"line\">        order: 2   # H</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>LSTM<code>ContinuationIndicator</code>layertime indicator</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>50,000</p>\n<p><img src=\"/img/captcha_train_loss.png\" alt=\"train loss\"></p>\n<p></p>\n<p><img src=\"/img/captcha_test_accuracy.png\" alt=\"test accuracy\"></p>\n<p>98%LSTMCTC LossCTC Loss</p>\n<p>repo</p>\n","excerpt":"<p>CTC(Connectionist Temporal Classification) Loss CTC LossCaffeBaidu<a href=\"https://github.com/baidu-research/warp-ctc\">warp-ctc</a>LSTM + CTC Lossdemowarp-ctc<a href=\"https://github.com/baidu-research/warp-ctc\"></a>GitHub<a href=\"https://github.com/xmfbit/warpctc-caffe\">warpctc-caffe</a><br><img src=\"/img/warpctc_intro.png\" alt=\"CTC Loss\"><br>","more":"</p>\n<h2 id=\"warp-ctc\"><a href=\"#warp-ctc\" class=\"headerlink\" title=\"warp-ctc\"></a>warp-ctc</h2><p><code>warp-ctc</code>Caffe</p>\n<p><code>warp-ctc</code>GitHubcloneCaffe<code>include/caffe</code><code>src/caffe</code><code>3rdparty</code>warp-ctcCaffe</p>\n<p><code>warp-ctc</code><code>C++11</code>Caffe<code>Makefile</code><code>C++11</code><a href=\"https://github.com/xmfbit/warpctc-caffe/blob/master/Makefile\">Makefile</a></p>\n<p>Caffe<code>warp-ctc</code>GPUCTC Loss</p>\n<p><code>warp-ctc</code>CPU<code>openmp</code></p>\n<p>warp-ctcCUDA<code>cuh</code><code>__host__</code><code>__device__</code></p>\n<p>GitHub<a href=\"https://github.com/xmfbit/warpctc-caffe/blob/master/include/caffe/3rdparty/detail/hostdevice.cuh\"></a></p>\n<h2 id=\"CTC-Loss\"><a href=\"#CTC-Loss\" class=\"headerlink\" title=\"CTC Loss\"></a>CTC Loss</h2><p><code>ctc_loss_layer</code>CTC Loss<code>ctc.h</code><code>warp-ctc</code>CTC LossAPI</p>\n<p><code>ctc_loss_layer</code><code>loss_layer</code><code>warp-ctc</code><code>float</code><code>NOT_IMPLEMENTED</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> CtcLossLayer&lt;<span class=\"keyword\">double</span>&gt;::Forward_cpu(</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; bottom, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; top) &#123;</div><div class=\"line\">    NOT_IMPLEMENTED;</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">template</span> &lt;&gt;</div><div class=\"line\"><span class=\"keyword\">void</span> CtcLossLayer&lt;<span class=\"keyword\">double</span>&gt;::Backward_cpu(<span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; top,</div><div class=\"line\">    <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">bool</span>&gt;&amp; propagate_down, <span class=\"keyword\">const</span> <span class=\"built_in\">vector</span>&lt;Blob&lt;<span class=\"keyword\">double</span>&gt;*&gt;&amp; bottom) &#123;</div><div class=\"line\">    NOT_IMPLEMENTED;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>warp-ctc</code>CTC Loss</p>\n<ul>\n<li><code>ctcOptions</code>CPUGPUCPUGPUCUDA stream</li>\n<li><code>get_workspace_size()</code>CPUGPU</li>\n<li><code>compute_ctc_loss()</code><code>loss</code><code>gradient</code></li>\n</ul>\n<p><code>gradient</code><code>blob</code><code>cpu/gpu_diff</code><code>gradient</code></p>\n<p><code>include/caffe/layers</code><code>src/caffe/layers/</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>examples/warpctc</code></p>\n<ul>\n<li><code>Python</code><code>capycha</code><code>0-9</code><code>1</code><code>MAX_LEN</code></li>\n<li><code>10</code><code>blank_label</code><code>blank_label</code><code>MAX_LEN</code></li>\n<li>time step<code>image data-&gt;2LSTM-&gt;fc-&gt;CTC Loss</code></li>\n<li><code>HDF5</code></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><code>captcha</code><a href=\"https://pypi.python.org/pypi/captcha/0.1.1\"></a>API demo<code>160x60</code><code>80x30</code></p>\n<p><code>python</code><code>h5py</code><code>HDF5</code>80%20%</p>\n<h3 id=\"LSTM\"><a href=\"#LSTM\" class=\"headerlink\" title=\"LSTM\"></a>LSTM</h3><p>Caffe<code>lstm_layer</code><code>lstm_layer</code><code>blob</code><code>TxNx...</code>image</p>\n<p>CaffeBatch<code>NxCxHxW</code>time step$x$<a href=\"https://github.com/weiliu89/caffe/blob/ssd/include/caffe/layers/permute_layer.hpp\">liuweiSSD<code>permute_layer</code></a><code>W</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">layer &#123;</div><div class=\"line\">    name: &quot;permuted_data&quot;</div><div class=\"line\">    type: &quot;Permute&quot;</div><div class=\"line\">    bottom: &quot;data&quot;</div><div class=\"line\">    top: &quot;permuted_data&quot;</div><div class=\"line\">    permute_param &#123;</div><div class=\"line\">        order: 3   # W</div><div class=\"line\">        order: 0   # N</div><div class=\"line\">        order: 1   # C</div><div class=\"line\">        order: 2   # H</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>LSTM<code>ContinuationIndicator</code>layertime indicator</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>50,000</p>\n<p><img src=\"/img/captcha_train_loss.png\" alt=\"train loss\"></p>\n<p></p>\n<p><img src=\"/img/captcha_test_accuracy.png\" alt=\"test accuracy\"></p>\n<p>98%LSTMCTC LossCTC Loss</p>\n<p>repo</p>"},{"title":"YOLO","date":"2017-03-06T07:51:22.000Z","_content":"YOLODarknet\n<!-- more -->\n\n## YOLOCFG\nYOLOCaffelayerCaffeGoogleprotobufCaffeCaffeYOLOCFG\n\nCFG[CFG](https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg)\n```\n[net]\n# net\n# YOLOnet\n[conv]\n# conv\n[maxpool]\n# \n\n# layer\n```\nDarknet`[]`section\n\n##  Parser\n[parser.c](https://github.com/pjreddie/darknet/blob/master/src/parser.c)`convolutional_layer parse_convolutional(list *options, size_params params)`Darknet\n\n`list`Darknet`size_params``params`\n``` cpp\ntypedef struct size_params{\n    int batch;\n    int inputs;\n    int h;\n    int w;\n    int c;\n    int index;\n    int time_steps;\n    network net;\n} size_params;\n```\nlayer\n\n`option_find_int`\n\n~`parser.c`[option_list.c ](https://github.com/pjreddie/darknet/blob/master/src/option_list.c)\n\n``` cpp\n// l: data pointer to the list\n// key: the key to find, example: \"filters\", \"padding\"\n// def: default value\nint option_find_int(list *l, char *key, int def)\n{\n    // keyatoi\n    char *v = option_find(l, key);\n    if(v) return atoi(v);\n    // XXX_quiet\n    fprintf(stderr, \"%s: Using default '%d'\\n\", key, def);\n    // key\n    return def;\n}\n```\n\n`option_find`\n\n``` cpp\nchar *option_find(list *l, char *key)\n{\n    node *n = l->front;\n    while(n){\n        kvp *p = (kvp *)n->val;\n        if(strcmp(p->key, key) == 0){\n            p->used = 1;\n            return p->val;\n        }\n        n = n->next;\n    }\n    return 0;\n}\n```\n\n## conv\nCFG\n\n``` cpp\n    // \n    int n = option_find_int(options, \"filters\",1);\n    int size = option_find_int(options, \"size\",1);\n    int stride = option_find_int(options, \"stride\",1);\n    int pad = option_find_int_quiet(options, \"pad\",0);\n    int padding = option_find_int_quiet(options, \"padding\",0);\n    if(pad) padding = size/2;\n\t// \n    char *activation_s = option_find_str(options, \"activation\", \"logistic\");\n    ACTIVATION activation = get_activation(activation_s);\n    // batch size\n    int batch,h,w,c;\n    h = params.h;\n    w = params.w;\n    c = params.c;\n    batch=params.batch;\n    if(!(h && w && c)) error(\"Layer before convolutional layer must output image.\");\n    int batch_normalize = option_find_int_quiet(options, \"batch_normalize\", 0);\n    int binary = option_find_int_quiet(options, \"binary\", 0);\n    int xnor = option_find_int_quiet(options, \"xnor\", 0);\n    // \n    convolutional_layer layer = make_convolutional_layer(batch,h,w,c,n,size,stride,padding,activation, batch_normalize, binary, xnor, params.net.adam);\n    layer.flipped = option_find_int_quiet(options, \"flipped\", 0);\n    layer.dot = option_find_float_quiet(options, \"dot\", 0);\n```\n\nlayer\n\n## \nlayer\n\nDarknet`network parse_network_cfg(char *filename)`\n\n`read_cfg(filename)`CFGsection`[net]` section\n\n## \nDarknetlayer\n\n``` cpp\nvoid save_convolutional_weights(layer l, FILE *fp)\n{\n    if(l.binary){\n        //save_convolutional_weights_binary(l, fp);\n        //return;\n    }\n#ifdef GPU\n    if(gpu_index >= 0){\n        pull_convolutional_layer(l);\n    }\n#endif\n    int num = l.n*l.c*l.size*l.size;\n    fwrite(l.biases, sizeof(float), l.n, fp);\n    // darknetBNBN\n    if (l.batch_normalize){\n        fwrite(l.scales, sizeof(float), l.n, fp);\n        fwrite(l.rolling_mean, sizeof(float), l.n, fp);\n        fwrite(l.rolling_variance, sizeof(float), l.n, fp);\n    }\n    fwrite(l.weights, sizeof(float), num, fp);\n    if(l.adam){\n        fwrite(l.m, sizeof(float), num, fp);\n        fwrite(l.v, sizeof(float), num, fp);\n    }\n}\n```\n\n\n","source":"_posts/yolo-cfg-parser.md","raw":"---\ntitle: YOLO\ndate: 2017-03-06 15:51:22\ntags:\n     - yolo\n     - deep learning\n---\nYOLODarknet\n<!-- more -->\n\n## YOLOCFG\nYOLOCaffelayerCaffeGoogleprotobufCaffeCaffeYOLOCFG\n\nCFG[CFG](https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg)\n```\n[net]\n# net\n# YOLOnet\n[conv]\n# conv\n[maxpool]\n# \n\n# layer\n```\nDarknet`[]`section\n\n##  Parser\n[parser.c](https://github.com/pjreddie/darknet/blob/master/src/parser.c)`convolutional_layer parse_convolutional(list *options, size_params params)`Darknet\n\n`list`Darknet`size_params``params`\n``` cpp\ntypedef struct size_params{\n    int batch;\n    int inputs;\n    int h;\n    int w;\n    int c;\n    int index;\n    int time_steps;\n    network net;\n} size_params;\n```\nlayer\n\n`option_find_int`\n\n~`parser.c`[option_list.c ](https://github.com/pjreddie/darknet/blob/master/src/option_list.c)\n\n``` cpp\n// l: data pointer to the list\n// key: the key to find, example: \"filters\", \"padding\"\n// def: default value\nint option_find_int(list *l, char *key, int def)\n{\n    // keyatoi\n    char *v = option_find(l, key);\n    if(v) return atoi(v);\n    // XXX_quiet\n    fprintf(stderr, \"%s: Using default '%d'\\n\", key, def);\n    // key\n    return def;\n}\n```\n\n`option_find`\n\n``` cpp\nchar *option_find(list *l, char *key)\n{\n    node *n = l->front;\n    while(n){\n        kvp *p = (kvp *)n->val;\n        if(strcmp(p->key, key) == 0){\n            p->used = 1;\n            return p->val;\n        }\n        n = n->next;\n    }\n    return 0;\n}\n```\n\n## conv\nCFG\n\n``` cpp\n    // \n    int n = option_find_int(options, \"filters\",1);\n    int size = option_find_int(options, \"size\",1);\n    int stride = option_find_int(options, \"stride\",1);\n    int pad = option_find_int_quiet(options, \"pad\",0);\n    int padding = option_find_int_quiet(options, \"padding\",0);\n    if(pad) padding = size/2;\n\t// \n    char *activation_s = option_find_str(options, \"activation\", \"logistic\");\n    ACTIVATION activation = get_activation(activation_s);\n    // batch size\n    int batch,h,w,c;\n    h = params.h;\n    w = params.w;\n    c = params.c;\n    batch=params.batch;\n    if(!(h && w && c)) error(\"Layer before convolutional layer must output image.\");\n    int batch_normalize = option_find_int_quiet(options, \"batch_normalize\", 0);\n    int binary = option_find_int_quiet(options, \"binary\", 0);\n    int xnor = option_find_int_quiet(options, \"xnor\", 0);\n    // \n    convolutional_layer layer = make_convolutional_layer(batch,h,w,c,n,size,stride,padding,activation, batch_normalize, binary, xnor, params.net.adam);\n    layer.flipped = option_find_int_quiet(options, \"flipped\", 0);\n    layer.dot = option_find_float_quiet(options, \"dot\", 0);\n```\n\nlayer\n\n## \nlayer\n\nDarknet`network parse_network_cfg(char *filename)`\n\n`read_cfg(filename)`CFGsection`[net]` section\n\n## \nDarknetlayer\n\n``` cpp\nvoid save_convolutional_weights(layer l, FILE *fp)\n{\n    if(l.binary){\n        //save_convolutional_weights_binary(l, fp);\n        //return;\n    }\n#ifdef GPU\n    if(gpu_index >= 0){\n        pull_convolutional_layer(l);\n    }\n#endif\n    int num = l.n*l.c*l.size*l.size;\n    fwrite(l.biases, sizeof(float), l.n, fp);\n    // darknetBNBN\n    if (l.batch_normalize){\n        fwrite(l.scales, sizeof(float), l.n, fp);\n        fwrite(l.rolling_mean, sizeof(float), l.n, fp);\n        fwrite(l.rolling_variance, sizeof(float), l.n, fp);\n    }\n    fwrite(l.weights, sizeof(float), num, fp);\n    if(l.adam){\n        fwrite(l.m, sizeof(float), num, fp);\n        fwrite(l.v, sizeof(float), num, fp);\n    }\n}\n```\n\n\n","slug":"yolo-cfg-parser","published":1,"updated":"2018-10-27T07:16:52.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8pj004lae7b13xflkmn","content":"<p>YOLODarknet<br><a id=\"more\"></a></p>\n<h2 id=\"YOLOCFG\"><a href=\"#YOLOCFG\" class=\"headerlink\" title=\"YOLOCFG\"></a>YOLOCFG</h2><p>YOLOCaffelayerCaffeGoogleprotobufCaffeCaffeYOLOCFG</p>\n<p>CFG<a href=\"https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg\" target=\"_blank\" rel=\"external\">CFG</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[net]</div><div class=\"line\"># net</div><div class=\"line\"># YOLOnet</div><div class=\"line\">[conv]</div><div class=\"line\"># conv</div><div class=\"line\">[maxpool]</div><div class=\"line\"># </div><div class=\"line\"></div><div class=\"line\"># layer</div></pre></td></tr></table></figure></p>\n<p>Darknet<code>[]</code>section</p>\n<h2 id=\"-Parser\"><a href=\"#-Parser\" class=\"headerlink\" title=\" Parser\"></a> Parser</h2><p><a href=\"https://github.com/pjreddie/darknet/blob/master/src/parser.c\" target=\"_blank\" rel=\"external\">parser.c</a><code>convolutional_layer parse_convolutional(list *options, size_params params)</code>Darknet</p>\n<p><code>list</code>Darknet<code>size_params</code><code>params</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">struct</span> size_params&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> batch;</div><div class=\"line\">    <span class=\"keyword\">int</span> inputs;</div><div class=\"line\">    <span class=\"keyword\">int</span> h;</div><div class=\"line\">    <span class=\"keyword\">int</span> w;</div><div class=\"line\">    <span class=\"keyword\">int</span> c;</div><div class=\"line\">    <span class=\"keyword\">int</span> index;</div><div class=\"line\">    <span class=\"keyword\">int</span> time_steps;</div><div class=\"line\">    network net;</div><div class=\"line\">&#125; size_params;</div></pre></td></tr></table></figure></p>\n<p>layer</p>\n<p><code>option_find_int</code></p>\n<p>~<code>parser.c</code><a href=\"https://github.com/pjreddie/darknet/blob/master/src/option_list.c\" target=\"_blank\" rel=\"external\">option_list.c </a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// l: data pointer to the list</span></div><div class=\"line\"><span class=\"comment\">// key: the key to find, example: \"filters\", \"padding\"</span></div><div class=\"line\"><span class=\"comment\">// def: default value</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">option_find_int</span><span class=\"params\">(<span class=\"built_in\">list</span> *l, <span class=\"keyword\">char</span> *key, <span class=\"keyword\">int</span> def)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"comment\">// keyatoi</span></div><div class=\"line\">    <span class=\"keyword\">char</span> *v = option_find(l, key);</div><div class=\"line\">    <span class=\"keyword\">if</span>(v) <span class=\"keyword\">return</span> atoi(v);</div><div class=\"line\">    <span class=\"comment\">// XXX_quiet</span></div><div class=\"line\">    <span class=\"built_in\">fprintf</span>(<span class=\"built_in\">stderr</span>, <span class=\"string\">\"%s: Using default '%d'\\n\"</span>, key, def);</div><div class=\"line\">    <span class=\"comment\">// key</span></div><div class=\"line\">    <span class=\"keyword\">return</span> def;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>option_find</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *<span class=\"title\">option_find</span><span class=\"params\">(<span class=\"built_in\">list</span> *l, <span class=\"keyword\">char</span> *key)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    node *n = l-&gt;front;</div><div class=\"line\">    <span class=\"keyword\">while</span>(n)&#123;</div><div class=\"line\">        kvp *p = (kvp *)n-&gt;val;</div><div class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">strcmp</span>(p-&gt;key, key) == <span class=\"number\">0</span>)&#123;</div><div class=\"line\">            p-&gt;used = <span class=\"number\">1</span>;</div><div class=\"line\">            <span class=\"keyword\">return</span> p-&gt;val;</div><div class=\"line\">        &#125;</div><div class=\"line\">        n = n-&gt;next;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"conv\"><a href=\"#conv\" class=\"headerlink\" title=\"conv\"></a>conv</h2><p>CFG</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">   <span class=\"comment\">// </span></div><div class=\"line\">   <span class=\"keyword\">int</span> n = option_find_int(options, <span class=\"string\">\"filters\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> size = option_find_int(options, <span class=\"string\">\"size\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> stride = option_find_int(options, <span class=\"string\">\"stride\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> pad = option_find_int_quiet(options, <span class=\"string\">\"pad\"</span>,<span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> padding = option_find_int_quiet(options, <span class=\"string\">\"padding\"</span>,<span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">if</span>(pad) padding = size/<span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">   <span class=\"keyword\">char</span> *activation_s = option_find_str(options, <span class=\"string\">\"activation\"</span>, <span class=\"string\">\"logistic\"</span>);</div><div class=\"line\">   ACTIVATION activation = get_activation(activation_s);</div><div class=\"line\">   <span class=\"comment\">// batch size</span></div><div class=\"line\">   <span class=\"keyword\">int</span> batch,h,w,c;</div><div class=\"line\">   h = params.h;</div><div class=\"line\">   w = params.w;</div><div class=\"line\">   c = params.c;</div><div class=\"line\">   batch=params.batch;</div><div class=\"line\">   <span class=\"keyword\">if</span>(!(h &amp;&amp; w &amp;&amp; c)) error(<span class=\"string\">\"Layer before convolutional layer must output image.\"</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> batch_normalize = option_find_int_quiet(options, <span class=\"string\">\"batch_normalize\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> binary = option_find_int_quiet(options, <span class=\"string\">\"binary\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> xnor = option_find_int_quiet(options, <span class=\"string\">\"xnor\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"comment\">// </span></div><div class=\"line\">   convolutional_layer layer = make_convolutional_layer(batch,h,w,c,n,size,stride,padding,activation, batch_normalize, binary, xnor, params.net.adam);</div><div class=\"line\">   layer.flipped = option_find_int_quiet(options, <span class=\"string\">\"flipped\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   layer.dot = option_find_float_quiet(options, <span class=\"string\">\"dot\"</span>, <span class=\"number\">0</span>);</div></pre></td></tr></table></figure>\n<p>layer</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>layer</p>\n<p>Darknet<code>network parse_network_cfg(char *filename)</code></p>\n<p><code>read_cfg(filename)</code>CFGsection<code>[net]</code> section</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Darknetlayer</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">save_convolutional_weights</span><span class=\"params\">(layer l, FILE *fp)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(l.binary)&#123;</div><div class=\"line\">        <span class=\"comment\">//save_convolutional_weights_binary(l, fp);</span></div><div class=\"line\">        <span class=\"comment\">//return;</span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> GPU</span></div><div class=\"line\">    <span class=\"keyword\">if</span>(gpu_index &gt;= <span class=\"number\">0</span>)&#123;</div><div class=\"line\">        pull_convolutional_layer(l);</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">    <span class=\"keyword\">int</span> num = l.n*l.c*l.size*l.size;</div><div class=\"line\">    fwrite(l.biases, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">    <span class=\"comment\">// darknetBNBN</span></div><div class=\"line\">    <span class=\"keyword\">if</span> (l.batch_normalize)&#123;</div><div class=\"line\">        fwrite(l.scales, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">        fwrite(l.rolling_mean, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">        fwrite(l.rolling_variance, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">    &#125;</div><div class=\"line\">    fwrite(l.weights, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">    <span class=\"keyword\">if</span>(l.adam)&#123;</div><div class=\"line\">        fwrite(l.m, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">        fwrite(l.v, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>\n","excerpt":"<p>YOLODarknet<br>","more":"</p>\n<h2 id=\"YOLOCFG\"><a href=\"#YOLOCFG\" class=\"headerlink\" title=\"YOLOCFG\"></a>YOLOCFG</h2><p>YOLOCaffelayerCaffeGoogleprotobufCaffeCaffeYOLOCFG</p>\n<p>CFG<a href=\"https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg\">CFG</a><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">[net]</div><div class=\"line\"># net</div><div class=\"line\"># YOLOnet</div><div class=\"line\">[conv]</div><div class=\"line\"># conv</div><div class=\"line\">[maxpool]</div><div class=\"line\"># </div><div class=\"line\"></div><div class=\"line\"># layer</div></pre></td></tr></table></figure></p>\n<p>Darknet<code>[]</code>section</p>\n<h2 id=\"-Parser\"><a href=\"#-Parser\" class=\"headerlink\" title=\" Parser\"></a> Parser</h2><p><a href=\"https://github.com/pjreddie/darknet/blob/master/src/parser.c\">parser.c</a><code>convolutional_layer parse_convolutional(list *options, size_params params)</code>Darknet</p>\n<p><code>list</code>Darknet<code>size_params</code><code>params</code><br><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">struct</span> size_params&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> batch;</div><div class=\"line\">    <span class=\"keyword\">int</span> inputs;</div><div class=\"line\">    <span class=\"keyword\">int</span> h;</div><div class=\"line\">    <span class=\"keyword\">int</span> w;</div><div class=\"line\">    <span class=\"keyword\">int</span> c;</div><div class=\"line\">    <span class=\"keyword\">int</span> index;</div><div class=\"line\">    <span class=\"keyword\">int</span> time_steps;</div><div class=\"line\">    network net;</div><div class=\"line\">&#125; size_params;</div></pre></td></tr></table></figure></p>\n<p>layer</p>\n<p><code>option_find_int</code></p>\n<p>~<code>parser.c</code><a href=\"https://github.com/pjreddie/darknet/blob/master/src/option_list.c\">option_list.c </a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// l: data pointer to the list</span></div><div class=\"line\"><span class=\"comment\">// key: the key to find, example: \"filters\", \"padding\"</span></div><div class=\"line\"><span class=\"comment\">// def: default value</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">option_find_int</span><span class=\"params\">(<span class=\"built_in\">list</span> *l, <span class=\"keyword\">char</span> *key, <span class=\"keyword\">int</span> def)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"comment\">// keyatoi</span></div><div class=\"line\">    <span class=\"keyword\">char</span> *v = option_find(l, key);</div><div class=\"line\">    <span class=\"keyword\">if</span>(v) <span class=\"keyword\">return</span> atoi(v);</div><div class=\"line\">    <span class=\"comment\">// XXX_quiet</span></div><div class=\"line\">    <span class=\"built_in\">fprintf</span>(<span class=\"built_in\">stderr</span>, <span class=\"string\">\"%s: Using default '%d'\\n\"</span>, key, def);</div><div class=\"line\">    <span class=\"comment\">// key</span></div><div class=\"line\">    <span class=\"keyword\">return</span> def;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><code>option_find</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">char</span> *<span class=\"title\">option_find</span><span class=\"params\">(<span class=\"built_in\">list</span> *l, <span class=\"keyword\">char</span> *key)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    node *n = l-&gt;front;</div><div class=\"line\">    <span class=\"keyword\">while</span>(n)&#123;</div><div class=\"line\">        kvp *p = (kvp *)n-&gt;val;</div><div class=\"line\">        <span class=\"keyword\">if</span>(<span class=\"built_in\">strcmp</span>(p-&gt;key, key) == <span class=\"number\">0</span>)&#123;</div><div class=\"line\">            p-&gt;used = <span class=\"number\">1</span>;</div><div class=\"line\">            <span class=\"keyword\">return</span> p-&gt;val;</div><div class=\"line\">        &#125;</div><div class=\"line\">        n = n-&gt;next;</div><div class=\"line\">    &#125;</div><div class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"conv\"><a href=\"#conv\" class=\"headerlink\" title=\"conv\"></a>conv</h2><p>CFG</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">   <span class=\"comment\">// </span></div><div class=\"line\">   <span class=\"keyword\">int</span> n = option_find_int(options, <span class=\"string\">\"filters\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> size = option_find_int(options, <span class=\"string\">\"size\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> stride = option_find_int(options, <span class=\"string\">\"stride\"</span>,<span class=\"number\">1</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> pad = option_find_int_quiet(options, <span class=\"string\">\"pad\"</span>,<span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> padding = option_find_int_quiet(options, <span class=\"string\">\"padding\"</span>,<span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">if</span>(pad) padding = size/<span class=\"number\">2</span>;</div><div class=\"line\"><span class=\"comment\">// </span></div><div class=\"line\">   <span class=\"keyword\">char</span> *activation_s = option_find_str(options, <span class=\"string\">\"activation\"</span>, <span class=\"string\">\"logistic\"</span>);</div><div class=\"line\">   ACTIVATION activation = get_activation(activation_s);</div><div class=\"line\">   <span class=\"comment\">// batch size</span></div><div class=\"line\">   <span class=\"keyword\">int</span> batch,h,w,c;</div><div class=\"line\">   h = params.h;</div><div class=\"line\">   w = params.w;</div><div class=\"line\">   c = params.c;</div><div class=\"line\">   batch=params.batch;</div><div class=\"line\">   <span class=\"keyword\">if</span>(!(h &amp;&amp; w &amp;&amp; c)) error(<span class=\"string\">\"Layer before convolutional layer must output image.\"</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> batch_normalize = option_find_int_quiet(options, <span class=\"string\">\"batch_normalize\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> binary = option_find_int_quiet(options, <span class=\"string\">\"binary\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"keyword\">int</span> xnor = option_find_int_quiet(options, <span class=\"string\">\"xnor\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   <span class=\"comment\">// </span></div><div class=\"line\">   convolutional_layer layer = make_convolutional_layer(batch,h,w,c,n,size,stride,padding,activation, batch_normalize, binary, xnor, params.net.adam);</div><div class=\"line\">   layer.flipped = option_find_int_quiet(options, <span class=\"string\">\"flipped\"</span>, <span class=\"number\">0</span>);</div><div class=\"line\">   layer.dot = option_find_float_quiet(options, <span class=\"string\">\"dot\"</span>, <span class=\"number\">0</span>);</div></pre></td></tr></table></figure>\n<p>layer</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>layer</p>\n<p>Darknet<code>network parse_network_cfg(char *filename)</code></p>\n<p><code>read_cfg(filename)</code>CFGsection<code>[net]</code> section</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Darknetlayer</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">save_convolutional_weights</span><span class=\"params\">(layer l, FILE *fp)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">if</span>(l.binary)&#123;</div><div class=\"line\">        <span class=\"comment\">//save_convolutional_weights_binary(l, fp);</span></div><div class=\"line\">        <span class=\"comment\">//return;</span></div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">ifdef</span> GPU</span></div><div class=\"line\">    <span class=\"keyword\">if</span>(gpu_index &gt;= <span class=\"number\">0</span>)&#123;</div><div class=\"line\">        pull_convolutional_layer(l);</div><div class=\"line\">    &#125;</div><div class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></div><div class=\"line\">    <span class=\"keyword\">int</span> num = l.n*l.c*l.size*l.size;</div><div class=\"line\">    fwrite(l.biases, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">    <span class=\"comment\">// darknetBNBN</span></div><div class=\"line\">    <span class=\"keyword\">if</span> (l.batch_normalize)&#123;</div><div class=\"line\">        fwrite(l.scales, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">        fwrite(l.rolling_mean, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">        fwrite(l.rolling_variance, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), l.n, fp);</div><div class=\"line\">    &#125;</div><div class=\"line\">    fwrite(l.weights, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">    <span class=\"keyword\">if</span>(l.adam)&#123;</div><div class=\"line\">        fwrite(l.m, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">        fwrite(l.v, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>), num, fp);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p></p>"},{"title":"YOLO ","date":"2017-02-04T10:49:22.000Z","_content":"YOLO(**Y**ou **O**nly **L**ook **O**nce)Faster RCNNstate of the art20172YOLO[YOLO V1](https://arxiv.org/abs/1506.02640)[YOLO V2](https://arxiv.org/abs/1612.08242)YOLO V2[Darknet](http://pjreddie.com/darknet/yolo/)[GitHub]()YOLOV2\n\nUpdate@2018/04: [YOLO v3](https://pjreddie.com/darknet/yolo/)[ - YOLO v3](https://xmfbit.github.io/2018/04/01/paper-yolov3/)\n\n![YOLO V2](/img/yolo2_result.png)\n<!-- more -->\n\n## YOLO V1\nYOLO V1[\"You Only Look Once: Unitied, Real-Time Object Detection\"](https://arxiv.org/abs/1506.02640)\n\n> YOLObounding boxCNNbounding boxpipeline\n> YOLObase model45fpsmodelFast YOLO155fpsmAPState of the artYOLOlocalizationFalse PositivesYOLO\n\nHoG+SVMDPMRCNNYOLOimagebounding boxState of the artFaster RCNNFaster RCNNRPNFast RCNNproposalFast RCNNproposalYOLOYOLOtestCNN\n![YOLO V1](/img/yolo1_detection_system.png)\n\n### \n![](/img/yolo1_basic_idea.png)\n\n- image$S \\times S$grid cellimageobject boxgrid cellcellobjectresponsible for detection that objectgrid cell$B$bounding boxbounding boxbounding boxbounding boxIoUbounding box\n\n$$\\text{confidence} = P(\\text{Object})\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}$$\n\n- bounding box5$x,y,w,h$$x,y$bounding boxgrid cell$w,h$bounding box$x,y,w,h$bounded$[0,1]$grid cell$C$$P(\\text{Class}_i|\\text{Object})$$B$grid celltestbounding box\n$$\\text{confidence}\\times P(\\text{Class}_i|\\text{Object}) = P(\\text{Class}_i)\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}$$\n\n- PASCAL VOC$S = 7$, $B=2$20$C=20$$7\\times 7 \\times 30$\n\n### \nInspired by GoogLeNetinceptionsimply$1\\times 1$base model242\n![YOLO](/img/yolo1_network_arch.png)\n\nFast YOLO9filter\n\n### \nImageNet20average-poolingImageNet 100088%top-5\n\n[Ren](https://arxiv.org/abs/1504.06066)42$224\\times 224$$448 \\times 448$\n\nleaky ReLU\n$$\nf(x)=\n\\begin{cases}\nx, &\\text{if}\\ x > 0 \\\\\\\\\n0.1x, &\\text{otherwise}\n\\end{cases}\n$$\n\nloss function\n\n- loss\n- grid cellbounding boxbounding box\n$$\\lambda_{\\text{coord}} = 5\\lambda_{\\text{noobj}} = 0.5$$\n- $w$$h$boxlossbox$\\sqrt{w}$$\\sqrt{h}$\n- grid cellbounding boxtrainingbounding boxobjectbounding boxground truthIoUbounding boxno obj\n\nloss$\\mathbb{1}_i$$i$grid cell\n\n$\\mathbb{1}_{i,j}$$i$grid cell$j$bounding box\n![YOLO](/img/yolo1_loss_fun.png)\n\nlossDarknet[detection_layer.c](https://github.com/pjreddie/darknet/blob/master/src/detection_layer.c)costlossdelta\n\n``` c\nif(state.train){\n    float avg_iou = 0;\n    float avg_cat = 0;\n    float avg_allcat = 0;\n    float avg_obj = 0;\n    float avg_anyobj = 0;\n    int count = 0;\n    *(l.cost) = 0;\n    int size = l.inputs * l.batch;\n    memset(l.delta, 0, size * sizeof(float));\n    for (b = 0; b < l.batch; ++b){\n        int index = b*l.inputs;\n        // for each grid cell\n        for (i = 0; i < locations; ++i) {   // locations = S * S = 49\n            int truth_index = (b*locations + i)*(1+l.coords+l.classes);\n            int is_obj = state.truth[truth_index];\n            // for each bbox\n            for (j = 0; j < l.n; ++j) {     // l.n = B = 2\n                int p_index = index + locations*l.classes + i*l.n + j;\n                l.delta[p_index] = l.noobject_scale*(0 - l.output[p_index]);\n                // no objbboxresponsible\n                // bbox responsible for object\n                *(l.cost) += l.noobject_scale*pow(l.output[p_index], 2);  \n                avg_anyobj += l.output[p_index];\n            }\n\n            int best_index = -1;\n            float best_iou = 0;\n            float best_rmse = 20;\n            // grid cell\n            if (!is_obj){\n                continue;\n            }\n            // responsiblebounding boxloss\n            int class_index = index + i*l.classes;\n            for(j = 0; j < l.classes; ++j) {\n                l.delta[class_index+j] = l.class_scale * (state.truth[truth_index+1+j] - l.output[class_index+j]);\n                *(l.cost) += l.class_scale * pow(state.truth[truth_index+1+j] - l.output[class_index+j], 2);\n                if(state.truth[truth_index + 1 + j]) avg_cat += l.output[class_index+j];\n                avg_allcat += l.output[class_index+j];\n            }\n\n            box truth = float_to_box(state.truth + truth_index + 1 + l.classes);\n            truth.x /= l.side;\n            truth.y /= l.side;\n            // IoUbboxresponsibleindex\n            for(j = 0; j < l.n; ++j){\n                int box_index = index + locations*(l.classes + l.n) + (i*l.n + j) * l.coords;\n                box out = float_to_box(l.output + box_index);\n                out.x /= l.side;\n                out.y /= l.side;\n\n                if (l.sqrt){\n                    out.w = out.w*out.w;\n                    out.h = out.h*out.h;\n                }\n\n                float iou  = box_iou(out, truth);\n                //iou = 0;\n                float rmse = box_rmse(out, truth);\n                if(best_iou > 0 || iou > 0){\n                    if(iou > best_iou){\n                        best_iou = iou;\n                        best_index = j;\n                    }\n                }else{\n                    if(rmse < best_rmse){\n                        best_rmse = rmse;\n                        best_index = j;\n                    }\n                }\n            }\n\n            if(l.forced){\n                if(truth.w*truth.h < .1){\n                    best_index = 1;\n                }else{\n                    best_index = 0;\n                }\n            }\n            if(l.random && *(state.net.seen) < 64000){\n                best_index = rand()%l.n;\n            }\n\n            int box_index = index + locations*(l.classes + l.n) + (i*l.n + best_index) * l.coords;\n            int tbox_index = truth_index + 1 + l.classes;\n\n            box out = float_to_box(l.output + box_index);\n            out.x /= l.side;\n            out.y /= l.side;\n            if (l.sqrt) {\n                out.w = out.w*out.w;\n                out.h = out.h*out.h;\n            }\n            float iou  = box_iou(out, truth);\n\n            //printf(\"%d,\", best_index);\n            int p_index = index + locations*l.classes + i*l.n + best_index;\n            *(l.cost) -= l.noobject_scale * pow(l.output[p_index], 2);  // \n            *(l.cost) += l.object_scale * pow(1-l.output[p_index], 2);\n            avg_obj += l.output[p_index];\n            l.delta[p_index] = l.object_scale * (1.-l.output[p_index]);\n\n            if(l.rescore){\n                l.delta[p_index] = l.object_scale * (iou - l.output[p_index]);\n            }\n\n            l.delta[box_index+0] = l.coord_scale*(state.truth[tbox_index + 0] - l.output[box_index + 0]);\n            l.delta[box_index+1] = l.coord_scale*(state.truth[tbox_index + 1] - l.output[box_index + 1]);\n            l.delta[box_index+2] = l.coord_scale*(state.truth[tbox_index + 2] - l.output[box_index + 2]);\n            l.delta[box_index+3] = l.coord_scale*(state.truth[tbox_index + 3] - l.output[box_index + 3]);\n            if(l.sqrt){\n                l.delta[box_index+2] = l.coord_scale*(sqrt(state.truth[tbox_index + 2]) - l.output[box_index + 2]);\n                l.delta[box_index+3] = l.coord_scale*(sqrt(state.truth[tbox_index + 3]) - l.output[box_index + 3]);\n            }\n\n            *(l.cost) += pow(1-iou, 2);\n            avg_iou += iou;\n            ++count;\n        }\n    }\n\n```\n\n## YOLO V2\nYOLO V2V1BetterFasterStronger\n- Faster RCNNanchorK-Meansanchor\n- \n- WordTreeImageNetCOCO\n\n\n>YOLO 9000State of the art9KYOLO V1PASCAL VOCCOCOState of the artmulti-scale training method YOLO V2imagetrade-off67fpsVOC200776.8mAP40fps78.6mAPFaster RCNN with ResNetSSDCOCO detection datasetImageNet classification datasetlabeldetection datadetectionImageNetdetectionYOLO 900020044detection dataImageNet datection19.7mAPCOCO156YOLO900016.0mAPYOLO90009K\n\nBetterFasterStronger\n\n## Better\nYOLO V1mAP1356Anchor Box34527\n\n### 1BNBatch Normalization\nBatch NormalizationconvBNdrop out2%\n\n### 2High Resolution Classifier\nYOLO V1ImageNet$224\\times 224$$448\\times 448$224$448\\times 448$ImageNetfine tuning10epochclsdetection4%\n\n### 3Anchor Box\nYOLO V1CNNbounding boxFaster RCNNanchor boxbounding boxanchor box\n\nfcmax poolingfeature mapshrink$416\\times 416$448imagefeature mapcenter cellYOLO conv-poolingimage downsamplig 32feature map$416/32 = 13$\n\nYOLO V1grid cellbounding box$C$bounding box$C$YOLO V1confidence\n\nanchoraccuracyrecallgrid cell2bounding boxrecallrecallaccuracy\n\n### 4Dimension Cluster\nanchor boxanchorFaster RCNNstrideanchor9anchor boxanchor box\n\n\n- K-Means\n- IoU\n$$d(\\text{box}, \\text{centroid}) = 1-\\text{IoU}(\\text{box}, \\text{centroid})$$\n\n$k$$k = 5$$k=9$Faster RCNNanchor boxCOCOVOC$k=5$boxanchor box\n![](/img/yolo2_cluster_result.png)\n\n### 5Direct Location Prediction\nYOLO V1boxgrid cellsigmoid$[0, 1]$\n\noutputfeature mapcell$13\\times 13$bounding box$t_x$, $t_y$, $t_w$, $t_h$cell$k=5$bounding boxbounding box\n\n![bbox](/img/yolo2_bbox_location.png)\n\ngrid celloffset$(c_x, c_y)$bounding boxboxgrid cellanchor box\n![bounding box](/img/yolo2_bbox_param.png)\n\nDarknet\n\n``` cpp\n// get bounding box\n// x: data pointer of feature map\n// biases: data pointer of anchor box data\n// biases[2*n] = width of anchor box\n// biases[2*n+1] = height of anchor box\n// n: output bounding box for each cell in the feature map\n// index: output bounding box index in the cell\n// i: `cx` in the paper\n// j: 'cy' in the paper\n// (cx, cy) is the offset from the left top corner of the feature map\n// (w, h) is the size of feature map (do normalization in the code)\nbox get_region_box(float *x, float *biases, int n, int index, int i, int j, int w, int h)\n{\n    box b;\n    // i <- cx, j <- cy\n    // index + 0: tx\n    // index + 1: ty\n    // index + 2: tw\n    // index + 3: th\n    // index + 4: to   // not used here\n    // index + 5, +6, ..., +(C+4)   // confidence of P(class c|Object), not used here\n    b.x = (i + logistic_activate(x[index + 0])) / w;    // bx = cx+sigmoid(tx)\n    b.y = (j + logistic_activate(x[index + 1])) / h;    // by = cy+sigmoid(ty)\n    b.w = exp(x[index + 2]) * biases[2*n]   / w;        // bw = exp(tw) * pw\n    b.h = exp(x[index + 3]) * biases[2*n+1] / h;        // bh = exp(th) * ph\n    // Normalization[0, 1]\n    // YOLO detectionbounding box\n    return b;\n}\n```\n\nbounding boxbp\n\n``` cpp\n// truth: ground truth\n// x: data pointer of feature map\n// biases: data pointer of anchor box data\n// n, index, i, j, w, h: same meaning with `get_region_box`\n// delta: data pointer of gradient\n// scale: just a weight, given by user\nfloat delta_region_box(box truth, float *x, float *biases,\n                       int n, int index, int i, int j, int w, int h,\n                       float *delta, float scale)\n{\n    box pred = get_region_box(x, biases, n, index, i, j, w, h);\n    // get iou of the bbox and truth\n    float iou = box_iou(pred, truth);\n    // ground truth of the parameters (tx, ty, tw, th)\n    float tx = (truth.x*w - i);\n    float ty = (truth.y*h - j);\n    float tw = log(truth.w*w / biases[2*n]);\n    float th = log(truth.h*h / biases[2*n + 1]);\n    // \n    // tx\n    // loss = 1/2*(bx^hat-bx)^2, bx = cx + sigmoid(tx)\n    // d(loss)/d(tx) = -(bx^hat-bx) * d(bx)/d(tx)\n    // Darkentdeltadelta-d(loss)/d(tx)\n    // (bx^hat-bx) * d(bx)/d(tx)\n    // (bx^hat-bx)cxcell\n    // sigmoid\n    //  sigomid(tx) sigmoid(tx)\n    delta[index + 0] = scale * (tx - logistic_activate(x[index + 0]))\n                             * logistic_gradient(logistic_activate(x[index + 0]));\n\n    delta[index + 1] = scale * (ty - logistic_activate(x[index + 1]))\n                             * logistic_gradient(logistic_activate(x[index + 1]));\n    // tw  loss = 1/2(tw^hat-tw)^2bw^hat  bw\n    delta[index + 2] = scale * (tw - x[index + 2]);\n    delta[index + 3] = scale * (th - x[index + 3]);\n    return iou;\n}\n```\n\nbpbounding box$t_o$$C$bounding box$t_o$\n\n``` cpp\n// groundtruthbounding box iou\n// bounding boxresponsible for any groundtruth\n// loss = 1/2*(0-sigmoid(to))^2\n// => d(loss)/d(to) = -(0-sigmoid(to)) * d(sigmoid)/d(to)\n// outputsigmoid\n// logistic_gradient(y) dy/dx|(y=y0)logistic_gradient(y) = (1-y)*y\nl.delta[index + 4] = l.noobject_scale * ((0 - l.output[index + 4]) * logistic_gradient(l.output[index + 4]));\n// best iou > thresh, bounding boxgroundtruth0\nif (best_iou > l.thresh) {\n    l.delta[index + 4] = 0;\n}\n```\n\nlossV1MSELoss\n```\n// for each class\nfor(n = 0; n < classes; ++n){\n    // P_i = \\frac{exp^out_i}{sum of exp^out_j}\n    // SoftmaxLoss = -logP(class)\n    // SoftmaxLoss/output = -(1(n==class)-P)\n    delta[index + n] = scale * (((n == class)?1 : 0) - output[index + n]);\n    if(n == class) *avg_cat += output[index + n];\n}\n```\n\n### 6Fine-Gained Features\ntrickFaster RCNNSSDfeature mappass-through$26\\times 26$feature map\n\nhigher resolution$26\\times 26$feature map stacking$26\\times 26 \\times 512$feature map$13\\times 13$channelDarknet`reorg_layer`\n\nfeature map1%\n\n### 7Multi-Scale Training\nconvpooling\n\nepoch10$32$$32$$\\lbrace 320, 352, \\dots, 608\\rbrace$\n\nYOLO V2GPUGPUYOLO V2state of the artFaster RCNNSSDYOLO30fpsFaster RCNNYOLO V2VOC 2007\n\n![](/img/yolo2_different_methods_comparation.png)\n![](/img/yolo2_different_methods_comparation_in_table.png)\n\n### \nBetterAnchor boxrecallmAP~33%\n![](/img/yolo2_different_methods_improvement.png)\n\n## Faster\nFaster RCNNVGG-16base networkVGG-16$224\\times 224$30.69BYOLO V1VGG-16ImageNet88.0% vs 90.0%\n\nYOLO V2Darknet-19base network19VGG$3\\times 3$poolingchanneldoubleNINglobal average pooling$1\\times 1$feature mapchannelchannelBatch NormalizationDarknet-19VGG-16\n![Darknet-19](/img/yolo2_dartnet_19_structure.png)\n\nImageNet 1K$224\\times 224$$448\\times 448$fine tuning\n\n1K$3$$3\\times 3$channel$1024$$1\\times 1$channelVOC$5$box$5$$20$$5\\times(5+20)=125$YOLO V2`yolo_voc.cfg`[](https://github.com/pjreddie/darknet/blob/master/cfg/yolo.cfg)\n\n```\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=125\nactivation=linear\n```\n\npass-through\n\n## Stronger\n\n","source":"_posts/yolo-paper.md","raw":"---\ntitle: YOLO \ndate: 2017-02-04 18:49:22\ntags:\n    - paper\n    - yolo\n    - deep learning\n    - detection\n---\nYOLO(**Y**ou **O**nly **L**ook **O**nce)Faster RCNNstate of the art20172YOLO[YOLO V1](https://arxiv.org/abs/1506.02640)[YOLO V2](https://arxiv.org/abs/1612.08242)YOLO V2[Darknet](http://pjreddie.com/darknet/yolo/)[GitHub]()YOLOV2\n\nUpdate@2018/04: [YOLO v3](https://pjreddie.com/darknet/yolo/)[ - YOLO v3](https://xmfbit.github.io/2018/04/01/paper-yolov3/)\n\n![YOLO V2](/img/yolo2_result.png)\n<!-- more -->\n\n## YOLO V1\nYOLO V1[\"You Only Look Once: Unitied, Real-Time Object Detection\"](https://arxiv.org/abs/1506.02640)\n\n> YOLObounding boxCNNbounding boxpipeline\n> YOLObase model45fpsmodelFast YOLO155fpsmAPState of the artYOLOlocalizationFalse PositivesYOLO\n\nHoG+SVMDPMRCNNYOLOimagebounding boxState of the artFaster RCNNFaster RCNNRPNFast RCNNproposalFast RCNNproposalYOLOYOLOtestCNN\n![YOLO V1](/img/yolo1_detection_system.png)\n\n### \n![](/img/yolo1_basic_idea.png)\n\n- image$S \\times S$grid cellimageobject boxgrid cellcellobjectresponsible for detection that objectgrid cell$B$bounding boxbounding boxbounding boxbounding boxIoUbounding box\n\n$$\\text{confidence} = P(\\text{Object})\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}$$\n\n- bounding box5$x,y,w,h$$x,y$bounding boxgrid cell$w,h$bounding box$x,y,w,h$bounded$[0,1]$grid cell$C$$P(\\text{Class}_i|\\text{Object})$$B$grid celltestbounding box\n$$\\text{confidence}\\times P(\\text{Class}_i|\\text{Object}) = P(\\text{Class}_i)\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}$$\n\n- PASCAL VOC$S = 7$, $B=2$20$C=20$$7\\times 7 \\times 30$\n\n### \nInspired by GoogLeNetinceptionsimply$1\\times 1$base model242\n![YOLO](/img/yolo1_network_arch.png)\n\nFast YOLO9filter\n\n### \nImageNet20average-poolingImageNet 100088%top-5\n\n[Ren](https://arxiv.org/abs/1504.06066)42$224\\times 224$$448 \\times 448$\n\nleaky ReLU\n$$\nf(x)=\n\\begin{cases}\nx, &\\text{if}\\ x > 0 \\\\\\\\\n0.1x, &\\text{otherwise}\n\\end{cases}\n$$\n\nloss function\n\n- loss\n- grid cellbounding boxbounding box\n$$\\lambda_{\\text{coord}} = 5\\lambda_{\\text{noobj}} = 0.5$$\n- $w$$h$boxlossbox$\\sqrt{w}$$\\sqrt{h}$\n- grid cellbounding boxtrainingbounding boxobjectbounding boxground truthIoUbounding boxno obj\n\nloss$\\mathbb{1}_i$$i$grid cell\n\n$\\mathbb{1}_{i,j}$$i$grid cell$j$bounding box\n![YOLO](/img/yolo1_loss_fun.png)\n\nlossDarknet[detection_layer.c](https://github.com/pjreddie/darknet/blob/master/src/detection_layer.c)costlossdelta\n\n``` c\nif(state.train){\n    float avg_iou = 0;\n    float avg_cat = 0;\n    float avg_allcat = 0;\n    float avg_obj = 0;\n    float avg_anyobj = 0;\n    int count = 0;\n    *(l.cost) = 0;\n    int size = l.inputs * l.batch;\n    memset(l.delta, 0, size * sizeof(float));\n    for (b = 0; b < l.batch; ++b){\n        int index = b*l.inputs;\n        // for each grid cell\n        for (i = 0; i < locations; ++i) {   // locations = S * S = 49\n            int truth_index = (b*locations + i)*(1+l.coords+l.classes);\n            int is_obj = state.truth[truth_index];\n            // for each bbox\n            for (j = 0; j < l.n; ++j) {     // l.n = B = 2\n                int p_index = index + locations*l.classes + i*l.n + j;\n                l.delta[p_index] = l.noobject_scale*(0 - l.output[p_index]);\n                // no objbboxresponsible\n                // bbox responsible for object\n                *(l.cost) += l.noobject_scale*pow(l.output[p_index], 2);  \n                avg_anyobj += l.output[p_index];\n            }\n\n            int best_index = -1;\n            float best_iou = 0;\n            float best_rmse = 20;\n            // grid cell\n            if (!is_obj){\n                continue;\n            }\n            // responsiblebounding boxloss\n            int class_index = index + i*l.classes;\n            for(j = 0; j < l.classes; ++j) {\n                l.delta[class_index+j] = l.class_scale * (state.truth[truth_index+1+j] - l.output[class_index+j]);\n                *(l.cost) += l.class_scale * pow(state.truth[truth_index+1+j] - l.output[class_index+j], 2);\n                if(state.truth[truth_index + 1 + j]) avg_cat += l.output[class_index+j];\n                avg_allcat += l.output[class_index+j];\n            }\n\n            box truth = float_to_box(state.truth + truth_index + 1 + l.classes);\n            truth.x /= l.side;\n            truth.y /= l.side;\n            // IoUbboxresponsibleindex\n            for(j = 0; j < l.n; ++j){\n                int box_index = index + locations*(l.classes + l.n) + (i*l.n + j) * l.coords;\n                box out = float_to_box(l.output + box_index);\n                out.x /= l.side;\n                out.y /= l.side;\n\n                if (l.sqrt){\n                    out.w = out.w*out.w;\n                    out.h = out.h*out.h;\n                }\n\n                float iou  = box_iou(out, truth);\n                //iou = 0;\n                float rmse = box_rmse(out, truth);\n                if(best_iou > 0 || iou > 0){\n                    if(iou > best_iou){\n                        best_iou = iou;\n                        best_index = j;\n                    }\n                }else{\n                    if(rmse < best_rmse){\n                        best_rmse = rmse;\n                        best_index = j;\n                    }\n                }\n            }\n\n            if(l.forced){\n                if(truth.w*truth.h < .1){\n                    best_index = 1;\n                }else{\n                    best_index = 0;\n                }\n            }\n            if(l.random && *(state.net.seen) < 64000){\n                best_index = rand()%l.n;\n            }\n\n            int box_index = index + locations*(l.classes + l.n) + (i*l.n + best_index) * l.coords;\n            int tbox_index = truth_index + 1 + l.classes;\n\n            box out = float_to_box(l.output + box_index);\n            out.x /= l.side;\n            out.y /= l.side;\n            if (l.sqrt) {\n                out.w = out.w*out.w;\n                out.h = out.h*out.h;\n            }\n            float iou  = box_iou(out, truth);\n\n            //printf(\"%d,\", best_index);\n            int p_index = index + locations*l.classes + i*l.n + best_index;\n            *(l.cost) -= l.noobject_scale * pow(l.output[p_index], 2);  // \n            *(l.cost) += l.object_scale * pow(1-l.output[p_index], 2);\n            avg_obj += l.output[p_index];\n            l.delta[p_index] = l.object_scale * (1.-l.output[p_index]);\n\n            if(l.rescore){\n                l.delta[p_index] = l.object_scale * (iou - l.output[p_index]);\n            }\n\n            l.delta[box_index+0] = l.coord_scale*(state.truth[tbox_index + 0] - l.output[box_index + 0]);\n            l.delta[box_index+1] = l.coord_scale*(state.truth[tbox_index + 1] - l.output[box_index + 1]);\n            l.delta[box_index+2] = l.coord_scale*(state.truth[tbox_index + 2] - l.output[box_index + 2]);\n            l.delta[box_index+3] = l.coord_scale*(state.truth[tbox_index + 3] - l.output[box_index + 3]);\n            if(l.sqrt){\n                l.delta[box_index+2] = l.coord_scale*(sqrt(state.truth[tbox_index + 2]) - l.output[box_index + 2]);\n                l.delta[box_index+3] = l.coord_scale*(sqrt(state.truth[tbox_index + 3]) - l.output[box_index + 3]);\n            }\n\n            *(l.cost) += pow(1-iou, 2);\n            avg_iou += iou;\n            ++count;\n        }\n    }\n\n```\n\n## YOLO V2\nYOLO V2V1BetterFasterStronger\n- Faster RCNNanchorK-Meansanchor\n- \n- WordTreeImageNetCOCO\n\n\n>YOLO 9000State of the art9KYOLO V1PASCAL VOCCOCOState of the artmulti-scale training method YOLO V2imagetrade-off67fpsVOC200776.8mAP40fps78.6mAPFaster RCNN with ResNetSSDCOCO detection datasetImageNet classification datasetlabeldetection datadetectionImageNetdetectionYOLO 900020044detection dataImageNet datection19.7mAPCOCO156YOLO900016.0mAPYOLO90009K\n\nBetterFasterStronger\n\n## Better\nYOLO V1mAP1356Anchor Box34527\n\n### 1BNBatch Normalization\nBatch NormalizationconvBNdrop out2%\n\n### 2High Resolution Classifier\nYOLO V1ImageNet$224\\times 224$$448\\times 448$224$448\\times 448$ImageNetfine tuning10epochclsdetection4%\n\n### 3Anchor Box\nYOLO V1CNNbounding boxFaster RCNNanchor boxbounding boxanchor box\n\nfcmax poolingfeature mapshrink$416\\times 416$448imagefeature mapcenter cellYOLO conv-poolingimage downsamplig 32feature map$416/32 = 13$\n\nYOLO V1grid cellbounding box$C$bounding box$C$YOLO V1confidence\n\nanchoraccuracyrecallgrid cell2bounding boxrecallrecallaccuracy\n\n### 4Dimension Cluster\nanchor boxanchorFaster RCNNstrideanchor9anchor boxanchor box\n\n\n- K-Means\n- IoU\n$$d(\\text{box}, \\text{centroid}) = 1-\\text{IoU}(\\text{box}, \\text{centroid})$$\n\n$k$$k = 5$$k=9$Faster RCNNanchor boxCOCOVOC$k=5$boxanchor box\n![](/img/yolo2_cluster_result.png)\n\n### 5Direct Location Prediction\nYOLO V1boxgrid cellsigmoid$[0, 1]$\n\noutputfeature mapcell$13\\times 13$bounding box$t_x$, $t_y$, $t_w$, $t_h$cell$k=5$bounding boxbounding box\n\n![bbox](/img/yolo2_bbox_location.png)\n\ngrid celloffset$(c_x, c_y)$bounding boxboxgrid cellanchor box\n![bounding box](/img/yolo2_bbox_param.png)\n\nDarknet\n\n``` cpp\n// get bounding box\n// x: data pointer of feature map\n// biases: data pointer of anchor box data\n// biases[2*n] = width of anchor box\n// biases[2*n+1] = height of anchor box\n// n: output bounding box for each cell in the feature map\n// index: output bounding box index in the cell\n// i: `cx` in the paper\n// j: 'cy' in the paper\n// (cx, cy) is the offset from the left top corner of the feature map\n// (w, h) is the size of feature map (do normalization in the code)\nbox get_region_box(float *x, float *biases, int n, int index, int i, int j, int w, int h)\n{\n    box b;\n    // i <- cx, j <- cy\n    // index + 0: tx\n    // index + 1: ty\n    // index + 2: tw\n    // index + 3: th\n    // index + 4: to   // not used here\n    // index + 5, +6, ..., +(C+4)   // confidence of P(class c|Object), not used here\n    b.x = (i + logistic_activate(x[index + 0])) / w;    // bx = cx+sigmoid(tx)\n    b.y = (j + logistic_activate(x[index + 1])) / h;    // by = cy+sigmoid(ty)\n    b.w = exp(x[index + 2]) * biases[2*n]   / w;        // bw = exp(tw) * pw\n    b.h = exp(x[index + 3]) * biases[2*n+1] / h;        // bh = exp(th) * ph\n    // Normalization[0, 1]\n    // YOLO detectionbounding box\n    return b;\n}\n```\n\nbounding boxbp\n\n``` cpp\n// truth: ground truth\n// x: data pointer of feature map\n// biases: data pointer of anchor box data\n// n, index, i, j, w, h: same meaning with `get_region_box`\n// delta: data pointer of gradient\n// scale: just a weight, given by user\nfloat delta_region_box(box truth, float *x, float *biases,\n                       int n, int index, int i, int j, int w, int h,\n                       float *delta, float scale)\n{\n    box pred = get_region_box(x, biases, n, index, i, j, w, h);\n    // get iou of the bbox and truth\n    float iou = box_iou(pred, truth);\n    // ground truth of the parameters (tx, ty, tw, th)\n    float tx = (truth.x*w - i);\n    float ty = (truth.y*h - j);\n    float tw = log(truth.w*w / biases[2*n]);\n    float th = log(truth.h*h / biases[2*n + 1]);\n    // \n    // tx\n    // loss = 1/2*(bx^hat-bx)^2, bx = cx + sigmoid(tx)\n    // d(loss)/d(tx) = -(bx^hat-bx) * d(bx)/d(tx)\n    // Darkentdeltadelta-d(loss)/d(tx)\n    // (bx^hat-bx) * d(bx)/d(tx)\n    // (bx^hat-bx)cxcell\n    // sigmoid\n    //  sigomid(tx) sigmoid(tx)\n    delta[index + 0] = scale * (tx - logistic_activate(x[index + 0]))\n                             * logistic_gradient(logistic_activate(x[index + 0]));\n\n    delta[index + 1] = scale * (ty - logistic_activate(x[index + 1]))\n                             * logistic_gradient(logistic_activate(x[index + 1]));\n    // tw  loss = 1/2(tw^hat-tw)^2bw^hat  bw\n    delta[index + 2] = scale * (tw - x[index + 2]);\n    delta[index + 3] = scale * (th - x[index + 3]);\n    return iou;\n}\n```\n\nbpbounding box$t_o$$C$bounding box$t_o$\n\n``` cpp\n// groundtruthbounding box iou\n// bounding boxresponsible for any groundtruth\n// loss = 1/2*(0-sigmoid(to))^2\n// => d(loss)/d(to) = -(0-sigmoid(to)) * d(sigmoid)/d(to)\n// outputsigmoid\n// logistic_gradient(y) dy/dx|(y=y0)logistic_gradient(y) = (1-y)*y\nl.delta[index + 4] = l.noobject_scale * ((0 - l.output[index + 4]) * logistic_gradient(l.output[index + 4]));\n// best iou > thresh, bounding boxgroundtruth0\nif (best_iou > l.thresh) {\n    l.delta[index + 4] = 0;\n}\n```\n\nlossV1MSELoss\n```\n// for each class\nfor(n = 0; n < classes; ++n){\n    // P_i = \\frac{exp^out_i}{sum of exp^out_j}\n    // SoftmaxLoss = -logP(class)\n    // SoftmaxLoss/output = -(1(n==class)-P)\n    delta[index + n] = scale * (((n == class)?1 : 0) - output[index + n]);\n    if(n == class) *avg_cat += output[index + n];\n}\n```\n\n### 6Fine-Gained Features\ntrickFaster RCNNSSDfeature mappass-through$26\\times 26$feature map\n\nhigher resolution$26\\times 26$feature map stacking$26\\times 26 \\times 512$feature map$13\\times 13$channelDarknet`reorg_layer`\n\nfeature map1%\n\n### 7Multi-Scale Training\nconvpooling\n\nepoch10$32$$32$$\\lbrace 320, 352, \\dots, 608\\rbrace$\n\nYOLO V2GPUGPUYOLO V2state of the artFaster RCNNSSDYOLO30fpsFaster RCNNYOLO V2VOC 2007\n\n![](/img/yolo2_different_methods_comparation.png)\n![](/img/yolo2_different_methods_comparation_in_table.png)\n\n### \nBetterAnchor boxrecallmAP~33%\n![](/img/yolo2_different_methods_improvement.png)\n\n## Faster\nFaster RCNNVGG-16base networkVGG-16$224\\times 224$30.69BYOLO V1VGG-16ImageNet88.0% vs 90.0%\n\nYOLO V2Darknet-19base network19VGG$3\\times 3$poolingchanneldoubleNINglobal average pooling$1\\times 1$feature mapchannelchannelBatch NormalizationDarknet-19VGG-16\n![Darknet-19](/img/yolo2_dartnet_19_structure.png)\n\nImageNet 1K$224\\times 224$$448\\times 448$fine tuning\n\n1K$3$$3\\times 3$channel$1024$$1\\times 1$channelVOC$5$box$5$$20$$5\\times(5+20)=125$YOLO V2`yolo_voc.cfg`[](https://github.com/pjreddie/darknet/blob/master/cfg/yolo.cfg)\n\n```\n[convolutional]\nbatch_normalize=1\nsize=3\nstride=1\npad=1\nfilters=1024\nactivation=leaky\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=125\nactivation=linear\n```\n\npass-through\n\n## Stronger\n\n","slug":"yolo-paper","published":1,"updated":"2018-10-27T07:16:52.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjolov8pm004oae7b9n42zyah","content":"<p>YOLO(<strong>Y</strong>ou <strong>O</strong>nly <strong>L</strong>ook <strong>O</strong>nce)Faster RCNNstate of the art20172YOLO<a href=\"https://arxiv.org/abs/1506.02640\" target=\"_blank\" rel=\"external\">YOLO V1</a><a href=\"https://arxiv.org/abs/1612.08242\" target=\"_blank\" rel=\"external\">YOLO V2</a>YOLO V2<a href=\"http://pjreddie.com/darknet/yolo/\" target=\"_blank\" rel=\"external\">Darknet</a><a href=\"\">GitHub</a>YOLOV2</p>\n<p>Update@2018/04: <a href=\"https://pjreddie.com/darknet/yolo/\" target=\"_blank\" rel=\"external\">YOLO v3</a><a href=\"https://xmfbit.github.io/2018/04/01/paper-yolov3/\"> - YOLO v3</a></p>\n<p><img src=\"/img/yolo2_result.png\" alt=\"YOLO V2\"><br><a id=\"more\"></a></p>\n<h2 id=\"YOLO-V1\"><a href=\"#YOLO-V1\" class=\"headerlink\" title=\"YOLO V1\"></a>YOLO V1</h2><p>YOLO V1<a href=\"https://arxiv.org/abs/1506.02640\" target=\"_blank\" rel=\"external\">You Only Look Once: Unitied, Real-Time Object Detection</a></p>\n<blockquote>\n<p>YOLObounding boxCNNbounding boxpipeline<br>YOLObase model45fpsmodelFast YOLO155fpsmAPState of the artYOLOlocalizationFalse PositivesYOLO</p>\n</blockquote>\n<p>HoG+SVMDPMRCNNYOLOimagebounding boxState of the artFaster RCNNFaster RCNNRPNFast RCNNproposalFast RCNNproposalYOLOYOLOtestCNN<br><img src=\"/img/yolo1_detection_system.png\" alt=\"YOLO V1\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/yolo1_basic_idea.png\" alt=\"\"></p>\n<ul>\n<li>image$S \\times S$grid cellimageobject boxgrid cellcellobjectresponsible for detection that objectgrid cell$B$bounding boxbounding boxbounding boxbounding boxIoUbounding box</li>\n</ul>\n<script type=\"math/tex; mode=display\">\\text{confidence} = P(\\text{Object})\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}</script><ul>\n<li><p>bounding box5$x,y,w,h$$x,y$bounding boxgrid cell$w,h$bounding box$x,y,w,h$bounded$[0,1]$grid cell$C$$P(\\text{Class}_i|\\text{Object})$$B$grid celltestbounding box</p>\n<script type=\"math/tex; mode=display\">\\text{confidence}\\times P(\\text{Class}_i|\\text{Object}) = P(\\text{Class}_i)\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}</script></li>\n<li><p>PASCAL VOC$S = 7$, $B=2$20$C=20$$7\\times 7 \\times 30$</p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Inspired by GoogLeNetinceptionsimply$1\\times 1$base model242<br><img src=\"/img/yolo1_network_arch.png\" alt=\"YOLO\"></p>\n<p>Fast YOLO9filter</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ImageNet20average-poolingImageNet 100088%top-5</p>\n<p><a href=\"https://arxiv.org/abs/1504.06066\" target=\"_blank\" rel=\"external\">Ren</a>42$224\\times 224$$448 \\times 448$</p>\n<p>leaky ReLU</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\n\\begin{cases}\nx, &\\text{if}\\ x > 0 \\\\\\\\\n0.1x, &\\text{otherwise}\n\\end{cases}</script><p>loss function</p>\n<ul>\n<li>loss</li>\n<li>grid cellbounding boxbounding box<script type=\"math/tex; mode=display\">\\lambda_{\\text{coord}} = 5\\lambda_{\\text{noobj}} = 0.5</script></li>\n<li>$w$$h$boxlossbox$\\sqrt{w}$$\\sqrt{h}$</li>\n<li>grid cellbounding boxtrainingbounding boxobjectbounding boxground truthIoUbounding boxno obj</li>\n</ul>\n<p>loss$\\mathbb{1}_i$$i$grid cell</p>\n<p>$\\mathbb{1}_{i,j}$$i$grid cell$j$bounding box<br><img src=\"/img/yolo1_loss_fun.png\" alt=\"YOLO\"></p>\n<p>lossDarknet<a href=\"https://github.com/pjreddie/darknet/blob/master/src/detection_layer.c\" target=\"_blank\" rel=\"external\">detection_layer.c</a>costlossdelta</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span>(state.train)&#123;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_iou = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_cat = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_allcat = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_obj = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_anyobj = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</div><div class=\"line\">    *(l.cost) = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> size = l.inputs * l.batch;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(l.delta, <span class=\"number\">0</span>, size * <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</div><div class=\"line\">    <span class=\"keyword\">for</span> (b = <span class=\"number\">0</span>; b &lt; l.batch; ++b)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> index = b*l.inputs;</div><div class=\"line\">        <span class=\"comment\">// for each grid cell</span></div><div class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; locations; ++i) &#123;   <span class=\"comment\">// locations = S * S = 49</span></div><div class=\"line\">            <span class=\"keyword\">int</span> truth_index = (b*locations + i)*(<span class=\"number\">1</span>+l.coords+l.classes);</div><div class=\"line\">            <span class=\"keyword\">int</span> is_obj = state.truth[truth_index];</div><div class=\"line\">            <span class=\"comment\">// for each bbox</span></div><div class=\"line\">            <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; l.n; ++j) &#123;     <span class=\"comment\">// l.n = B = 2</span></div><div class=\"line\">                <span class=\"keyword\">int</span> p_index = index + locations*l.classes + i*l.n + j;</div><div class=\"line\">                l.delta[p_index] = l.noobject_scale*(<span class=\"number\">0</span> - l.output[p_index]);</div><div class=\"line\">                <span class=\"comment\">// no objbboxresponsible</span></div><div class=\"line\">                <span class=\"comment\">// bbox responsible for object</span></div><div class=\"line\">                *(l.cost) += l.noobject_scale*<span class=\"built_in\">pow</span>(l.output[p_index], <span class=\"number\">2</span>);  </div><div class=\"line\">                avg_anyobj += l.output[p_index];</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">int</span> best_index = <span class=\"number\">-1</span>;</div><div class=\"line\">            <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">float</span> best_rmse = <span class=\"number\">20</span>;</div><div class=\"line\">            <span class=\"comment\">// grid cell</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (!is_obj)&#123;</div><div class=\"line\">                <span class=\"keyword\">continue</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"comment\">// responsiblebounding boxloss</span></div><div class=\"line\">            <span class=\"keyword\">int</span> class_index = index + i*l.classes;</div><div class=\"line\">            <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; j &lt; l.classes; ++j) &#123;</div><div class=\"line\">                l.delta[class_index+j] = l.class_scale * (state.truth[truth_index+<span class=\"number\">1</span>+j] - l.output[class_index+j]);</div><div class=\"line\">                *(l.cost) += l.class_scale * <span class=\"built_in\">pow</span>(state.truth[truth_index+<span class=\"number\">1</span>+j] - l.output[class_index+j], <span class=\"number\">2</span>);</div><div class=\"line\">                <span class=\"keyword\">if</span>(state.truth[truth_index + <span class=\"number\">1</span> + j]) avg_cat += l.output[class_index+j];</div><div class=\"line\">                avg_allcat += l.output[class_index+j];</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            box truth = float_to_box(state.truth + truth_index + <span class=\"number\">1</span> + l.classes);</div><div class=\"line\">            truth.x /= l.side;</div><div class=\"line\">            truth.y /= l.side;</div><div class=\"line\">            <span class=\"comment\">// IoUbboxresponsibleindex</span></div><div class=\"line\">            <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; j &lt; l.n; ++j)&#123;</div><div class=\"line\">                <span class=\"keyword\">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + j) * l.coords;</div><div class=\"line\">                box out = float_to_box(l.output + box_index);</div><div class=\"line\">                out.x /= l.side;</div><div class=\"line\">                out.y /= l.side;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">if</span> (l.<span class=\"built_in\">sqrt</span>)&#123;</div><div class=\"line\">                    out.w = out.w*out.w;</div><div class=\"line\">                    out.h = out.h*out.h;</div><div class=\"line\">                &#125;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">float</span> iou  = box_iou(out, truth);</div><div class=\"line\">                <span class=\"comment\">//iou = 0;</span></div><div class=\"line\">                <span class=\"keyword\">float</span> rmse = box_rmse(out, truth);</div><div class=\"line\">                <span class=\"keyword\">if</span>(best_iou &gt; <span class=\"number\">0</span> || iou &gt; <span class=\"number\">0</span>)&#123;</div><div class=\"line\">                    <span class=\"keyword\">if</span>(iou &gt; best_iou)&#123;</div><div class=\"line\">                        best_iou = iou;</div><div class=\"line\">                        best_index = j;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">                    <span class=\"keyword\">if</span>(rmse &lt; best_rmse)&#123;</div><div class=\"line\">                        best_rmse = rmse;</div><div class=\"line\">                        best_index = j;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">if</span>(l.forced)&#123;</div><div class=\"line\">                <span class=\"keyword\">if</span>(truth.w*truth.h &lt; <span class=\"number\">.1</span>)&#123;</div><div class=\"line\">                    best_index = <span class=\"number\">1</span>;</div><div class=\"line\">                &#125;<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">                    best_index = <span class=\"number\">0</span>;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">if</span>(l.random &amp;&amp; *(state.net.seen) &lt; <span class=\"number\">64000</span>)&#123;</div><div class=\"line\">                best_index = rand()%l.n;</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + best_index) * l.coords;</div><div class=\"line\">            <span class=\"keyword\">int</span> tbox_index = truth_index + <span class=\"number\">1</span> + l.classes;</div><div class=\"line\"></div><div class=\"line\">            box out = float_to_box(l.output + box_index);</div><div class=\"line\">            out.x /= l.side;</div><div class=\"line\">            out.y /= l.side;</div><div class=\"line\">            <span class=\"keyword\">if</span> (l.<span class=\"built_in\">sqrt</span>) &#123;</div><div class=\"line\">                out.w = out.w*out.w;</div><div class=\"line\">                out.h = out.h*out.h;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">float</span> iou  = box_iou(out, truth);</div><div class=\"line\"></div><div class=\"line\">            <span class=\"comment\">//printf(\"%d,\", best_index);</span></div><div class=\"line\">            <span class=\"keyword\">int</span> p_index = index + locations*l.classes + i*l.n + best_index;</div><div class=\"line\">            *(l.cost) -= l.noobject_scale * <span class=\"built_in\">pow</span>(l.output[p_index], <span class=\"number\">2</span>);  <span class=\"comment\">// </span></div><div class=\"line\">            *(l.cost) += l.object_scale * <span class=\"built_in\">pow</span>(<span class=\"number\">1</span>-l.output[p_index], <span class=\"number\">2</span>);</div><div class=\"line\">            avg_obj += l.output[p_index];</div><div class=\"line\">            l.delta[p_index] = l.object_scale * (<span class=\"number\">1.</span>-l.output[p_index]);</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">if</span>(l.rescore)&#123;</div><div class=\"line\">                l.delta[p_index] = l.object_scale * (iou - l.output[p_index]);</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            l.delta[box_index+<span class=\"number\">0</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">0</span>] - l.output[box_index + <span class=\"number\">0</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">1</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">1</span>] - l.output[box_index + <span class=\"number\">1</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">2</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">2</span>] - l.output[box_index + <span class=\"number\">2</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">3</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">3</span>] - l.output[box_index + <span class=\"number\">3</span>]);</div><div class=\"line\">            <span class=\"keyword\">if</span>(l.<span class=\"built_in\">sqrt</span>)&#123;</div><div class=\"line\">                l.delta[box_index+<span class=\"number\">2</span>] = l.coord_scale*(<span class=\"built_in\">sqrt</span>(state.truth[tbox_index + <span class=\"number\">2</span>]) - l.output[box_index + <span class=\"number\">2</span>]);</div><div class=\"line\">                l.delta[box_index+<span class=\"number\">3</span>] = l.coord_scale*(<span class=\"built_in\">sqrt</span>(state.truth[tbox_index + <span class=\"number\">3</span>]) - l.output[box_index + <span class=\"number\">3</span>]);</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            *(l.cost) += <span class=\"built_in\">pow</span>(<span class=\"number\">1</span>-iou, <span class=\"number\">2</span>);</div><div class=\"line\">            avg_iou += iou;</div><div class=\"line\">            ++count;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"YOLO-V2\"><a href=\"#YOLO-V2\" class=\"headerlink\" title=\"YOLO V2\"></a>YOLO V2</h2><p>YOLO V2V1BetterFasterStronger</p>\n<ul>\n<li>Faster RCNNanchorK-Meansanchor</li>\n<li></li>\n<li>WordTreeImageNetCOCO</li>\n</ul>\n<p></p>\n<blockquote>\n<p>YOLO 9000State of the art9KYOLO V1PASCAL VOCCOCOState of the artmulti-scale training method YOLO V2imagetrade-off67fpsVOC200776.8mAP40fps78.6mAPFaster RCNN with ResNetSSDCOCO detection datasetImageNet classification datasetlabeldetection datadetectionImageNetdetectionYOLO 900020044detection dataImageNet datection19.7mAPCOCO156YOLO900016.0mAPYOLO90009K</p>\n</blockquote>\n<p>BetterFasterStronger</p>\n<h2 id=\"Better\"><a href=\"#Better\" class=\"headerlink\" title=\"Better\"></a>Better</h2><p>YOLO V1mAP1356Anchor Box34527</p>\n<h3 id=\"1BNBatch-Normalization\"><a href=\"#1BNBatch-Normalization\" class=\"headerlink\" title=\"1BNBatch Normalization\"></a>1BNBatch Normalization</h3><p>Batch NormalizationconvBNdrop out2%</p>\n<h3 id=\"2High-Resolution-Classifier\"><a href=\"#2High-Resolution-Classifier\" class=\"headerlink\" title=\"2High Resolution Classifier\"></a>2High Resolution Classifier</h3><p>YOLO V1ImageNet$224\\times 224$$448\\times 448$224$448\\times 448$ImageNetfine tuning10epochclsdetection4%</p>\n<h3 id=\"3Anchor-Box\"><a href=\"#3Anchor-Box\" class=\"headerlink\" title=\"3Anchor Box\"></a>3Anchor Box</h3><p>YOLO V1CNNbounding boxFaster RCNNanchor boxbounding boxanchor box</p>\n<p>fcmax poolingfeature mapshrink$416\\times 416$448imagefeature mapcenter cellYOLO conv-poolingimage downsamplig 32feature map$416/32 = 13$</p>\n<p>YOLO V1grid cellbounding box$C$bounding box$C$YOLO V1confidence</p>\n<p>anchoraccuracyrecallgrid cell2bounding boxrecallrecallaccuracy</p>\n<h3 id=\"4Dimension-Cluster\"><a href=\"#4Dimension-Cluster\" class=\"headerlink\" title=\"4Dimension Cluster\"></a>4Dimension Cluster</h3><p>anchor boxanchorFaster RCNNstrideanchor9anchor boxanchor box</p>\n<p></p>\n<ul>\n<li>K-Means</li>\n<li>IoU<script type=\"math/tex; mode=display\">d(\\text{box}, \\text{centroid}) = 1-\\text{IoU}(\\text{box}, \\text{centroid})</script></li>\n</ul>\n<p>$k$$k = 5$$k=9$Faster RCNNanchor boxCOCOVOC$k=5$boxanchor box<br><img src=\"/img/yolo2_cluster_result.png\" alt=\"\"></p>\n<h3 id=\"5Direct-Location-Prediction\"><a href=\"#5Direct-Location-Prediction\" class=\"headerlink\" title=\"5Direct Location Prediction\"></a>5Direct Location Prediction</h3><p>YOLO V1boxgrid cellsigmoid$[0, 1]$</p>\n<p>outputfeature mapcell$13\\times 13$bounding box$t_x$, $t_y$, $t_w$, $t_h$cell$k=5$bounding boxbounding box</p>\n<p><img src=\"/img/yolo2_bbox_location.png\" alt=\"bbox\"></p>\n<p>grid celloffset$(c_x, c_y)$bounding boxboxgrid cellanchor box<br><img src=\"/img/yolo2_bbox_param.png\" alt=\"bounding box\"></p>\n<p>Darknet</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// get bounding box</span></div><div class=\"line\"><span class=\"comment\">// x: data pointer of feature map</span></div><div class=\"line\"><span class=\"comment\">// biases: data pointer of anchor box data</span></div><div class=\"line\"><span class=\"comment\">// biases[2*n] = width of anchor box</span></div><div class=\"line\"><span class=\"comment\">// biases[2*n+1] = height of anchor box</span></div><div class=\"line\"><span class=\"comment\">// n: output bounding box for each cell in the feature map</span></div><div class=\"line\"><span class=\"comment\">// index: output bounding box index in the cell</span></div><div class=\"line\"><span class=\"comment\">// i: `cx` in the paper</span></div><div class=\"line\"><span class=\"comment\">// j: 'cy' in the paper</span></div><div class=\"line\"><span class=\"comment\">// (cx, cy) is the offset from the left top corner of the feature map</span></div><div class=\"line\"><span class=\"comment\">// (w, h) is the size of feature map (do normalization in the code)</span></div><div class=\"line\"><span class=\"function\">box <span class=\"title\">get_region_box</span><span class=\"params\">(<span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases, <span class=\"keyword\">int</span> n, <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    box b;</div><div class=\"line\">    <span class=\"comment\">// i &lt;- cx, j &lt;- cy</span></div><div class=\"line\">    <span class=\"comment\">// index + 0: tx</span></div><div class=\"line\">    <span class=\"comment\">// index + 1: ty</span></div><div class=\"line\">    <span class=\"comment\">// index + 2: tw</span></div><div class=\"line\">    <span class=\"comment\">// index + 3: th</span></div><div class=\"line\">    <span class=\"comment\">// index + 4: to   // not used here</span></div><div class=\"line\">    <span class=\"comment\">// index + 5, +6, ..., +(C+4)   // confidence of P(class c|Object), not used here</span></div><div class=\"line\">    b.x = (i + logistic_activate(x[index + <span class=\"number\">0</span>])) / w;    <span class=\"comment\">// bx = cx+sigmoid(tx)</span></div><div class=\"line\">    b.y = (j + logistic_activate(x[index + <span class=\"number\">1</span>])) / h;    <span class=\"comment\">// by = cy+sigmoid(ty)</span></div><div class=\"line\">    b.w = <span class=\"built_in\">exp</span>(x[index + <span class=\"number\">2</span>]) * biases[<span class=\"number\">2</span>*n]   / w;        <span class=\"comment\">// bw = exp(tw) * pw</span></div><div class=\"line\">    b.h = <span class=\"built_in\">exp</span>(x[index + <span class=\"number\">3</span>]) * biases[<span class=\"number\">2</span>*n+<span class=\"number\">1</span>] / h;        <span class=\"comment\">// bh = exp(th) * ph</span></div><div class=\"line\">    <span class=\"comment\">// Normalization[0, 1]</span></div><div class=\"line\">    <span class=\"comment\">// YOLO detectionbounding box</span></div><div class=\"line\">    <span class=\"keyword\">return</span> b;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>bounding boxbp</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// truth: ground truth</span></div><div class=\"line\"><span class=\"comment\">// x: data pointer of feature map</span></div><div class=\"line\"><span class=\"comment\">// biases: data pointer of anchor box data</span></div><div class=\"line\"><span class=\"comment\">// n, index, i, j, w, h: same meaning with `get_region_box`</span></div><div class=\"line\"><span class=\"comment\">// delta: data pointer of gradient</span></div><div class=\"line\"><span class=\"comment\">// scale: just a weight, given by user</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">delta_region_box</span><span class=\"params\">(box truth, <span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases,</span></span></div><div class=\"line\">                       <span class=\"keyword\">int</span> n, <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h,</div><div class=\"line\">                       <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">float</span> scale)</div><div class=\"line\">&#123;</div><div class=\"line\">    box pred = get_region_box(x, biases, n, index, i, j, w, h);</div><div class=\"line\">    <span class=\"comment\">// get iou of the bbox and truth</span></div><div class=\"line\">    <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">    <span class=\"comment\">// ground truth of the parameters (tx, ty, tw, th)</span></div><div class=\"line\">    <span class=\"keyword\">float</span> tx = (truth.x*w - i);</div><div class=\"line\">    <span class=\"keyword\">float</span> ty = (truth.y*h - j);</div><div class=\"line\">    <span class=\"keyword\">float</span> tw = <span class=\"built_in\">log</span>(truth.w*w / biases[<span class=\"number\">2</span>*n]);</div><div class=\"line\">    <span class=\"keyword\">float</span> th = <span class=\"built_in\">log</span>(truth.h*h / biases[<span class=\"number\">2</span>*n + <span class=\"number\">1</span>]);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"comment\">// tx</span></div><div class=\"line\">    <span class=\"comment\">// loss = 1/2*(bx^hat-bx)^2, bx = cx + sigmoid(tx)</span></div><div class=\"line\">    <span class=\"comment\">// d(loss)/d(tx) = -(bx^hat-bx) * d(bx)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// Darkentdeltadelta-d(loss)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// (bx^hat-bx) * d(bx)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// (bx^hat-bx)cxcell</span></div><div class=\"line\">    <span class=\"comment\">// sigmoid</span></div><div class=\"line\">    <span class=\"comment\">//  sigomid(tx) sigmoid(tx)</span></div><div class=\"line\">    delta[index + <span class=\"number\">0</span>] = scale * (tx - logistic_activate(x[index + <span class=\"number\">0</span>]))</div><div class=\"line\">                             * logistic_gradient(logistic_activate(x[index + <span class=\"number\">0</span>]));</div><div class=\"line\"></div><div class=\"line\">    delta[index + <span class=\"number\">1</span>] = scale * (ty - logistic_activate(x[index + <span class=\"number\">1</span>]))</div><div class=\"line\">                             * logistic_gradient(logistic_activate(x[index + <span class=\"number\">1</span>]));</div><div class=\"line\">    <span class=\"comment\">// tw  loss = 1/2(tw^hat-tw)^2bw^hat  bw</span></div><div class=\"line\">    delta[index + <span class=\"number\">2</span>] = scale * (tw - x[index + <span class=\"number\">2</span>]);</div><div class=\"line\">    delta[index + <span class=\"number\">3</span>] = scale * (th - x[index + <span class=\"number\">3</span>]);</div><div class=\"line\">    <span class=\"keyword\">return</span> iou;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>bpbounding box$t_o$$C$bounding box$t_o$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// groundtruthbounding box iou</span></div><div class=\"line\"><span class=\"comment\">// bounding boxresponsible for any groundtruth</span></div><div class=\"line\"><span class=\"comment\">// loss = 1/2*(0-sigmoid(to))^2</span></div><div class=\"line\"><span class=\"comment\">// =&gt; d(loss)/d(to) = -(0-sigmoid(to)) * d(sigmoid)/d(to)</span></div><div class=\"line\"><span class=\"comment\">// outputsigmoid</span></div><div class=\"line\"><span class=\"comment\">// logistic_gradient(y) dy/dx|(y=y0)logistic_gradient(y) = (1-y)*y</span></div><div class=\"line\">l.delta[index + <span class=\"number\">4</span>] = l.noobject_scale * ((<span class=\"number\">0</span> - l.output[index + <span class=\"number\">4</span>]) * logistic_gradient(l.output[index + <span class=\"number\">4</span>]));</div><div class=\"line\"><span class=\"comment\">// best iou &gt; thresh, bounding boxgroundtruth0</span></div><div class=\"line\"><span class=\"keyword\">if</span> (best_iou &gt; l.thresh) &#123;</div><div class=\"line\">    l.delta[index + <span class=\"number\">4</span>] = <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>lossV1MSELoss<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">// for each class</div><div class=\"line\">for(n = 0; n &lt; classes; ++n)&#123;</div><div class=\"line\">    // P_i = \\frac&#123;exp^out_i&#125;&#123;sum of exp^out_j&#125;</div><div class=\"line\">    // SoftmaxLoss = -logP(class)</div><div class=\"line\">    // SoftmaxLoss/output = -(1(n==class)-P)</div><div class=\"line\">    delta[index + n] = scale * (((n == class)?1 : 0) - output[index + n]);</div><div class=\"line\">    if(n == class) *avg_cat += output[index + n];</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"6Fine-Gained-Features\"><a href=\"#6Fine-Gained-Features\" class=\"headerlink\" title=\"6Fine-Gained Features\"></a>6Fine-Gained Features</h3><p>trickFaster RCNNSSDfeature mappass-through$26\\times 26$feature map</p>\n<p>higher resolution$26\\times 26$feature map stacking$26\\times 26 \\times 512$feature map$13\\times 13$channelDarknet<code>reorg_layer</code></p>\n<p>feature map1%</p>\n<h3 id=\"7Multi-Scale-Training\"><a href=\"#7Multi-Scale-Training\" class=\"headerlink\" title=\"7Multi-Scale Training\"></a>7Multi-Scale Training</h3><p>convpooling</p>\n<p>epoch10$32$$32$$\\lbrace 320, 352, \\dots, 608\\rbrace$</p>\n<p>YOLO V2GPUGPUYOLO V2state of the artFaster RCNNSSDYOLO30fpsFaster RCNNYOLO V2VOC 2007</p>\n<p><img src=\"/img/yolo2_different_methods_comparation.png\" alt=\"\"><br><img src=\"/img/yolo2_different_methods_comparation_in_table.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>BetterAnchor boxrecallmAP~33%<br><img src=\"/img/yolo2_different_methods_improvement.png\" alt=\"\"></p>\n<h2 id=\"Faster\"><a href=\"#Faster\" class=\"headerlink\" title=\"Faster\"></a>Faster</h2><p>Faster RCNNVGG-16base networkVGG-16$224\\times 224$30.69BYOLO V1VGG-16ImageNet88.0% vs 90.0%</p>\n<p>YOLO V2Darknet-19base network19VGG$3\\times 3$poolingchanneldoubleNINglobal average pooling$1\\times 1$feature mapchannelchannelBatch NormalizationDarknet-19VGG-16<br><img src=\"/img/yolo2_dartnet_19_structure.png\" alt=\"Darknet-19\"></p>\n<p>ImageNet 1K$224\\times 224$$448\\times 448$fine tuning</p>\n<p>1K$3$$3\\times 3$channel$1024$$1\\times 1$channelVOC$5$box$5$$20$$5\\times(5+20)=125$YOLO V2<code>yolo_voc.cfg</code><a href=\"https://github.com/pjreddie/darknet/blob/master/cfg/yolo.cfg\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">[convolutional]</div><div class=\"line\">batch_normalize=1</div><div class=\"line\">size=3</div><div class=\"line\">stride=1</div><div class=\"line\">pad=1</div><div class=\"line\">filters=1024</div><div class=\"line\">activation=leaky</div><div class=\"line\"></div><div class=\"line\">[convolutional]</div><div class=\"line\">size=1</div><div class=\"line\">stride=1</div><div class=\"line\">pad=1</div><div class=\"line\">filters=125</div><div class=\"line\">activation=linear</div></pre></td></tr></table></figure>\n<p>pass-through</p>\n<h2 id=\"Stronger\"><a href=\"#Stronger\" class=\"headerlink\" title=\"Stronger\"></a>Stronger</h2><p></p>\n","excerpt":"<p>YOLO(<strong>Y</strong>ou <strong>O</strong>nly <strong>L</strong>ook <strong>O</strong>nce)Faster RCNNstate of the art20172YOLO<a href=\"https://arxiv.org/abs/1506.02640\">YOLO V1</a><a href=\"https://arxiv.org/abs/1612.08242\">YOLO V2</a>YOLO V2<a href=\"http://pjreddie.com/darknet/yolo/\">Darknet</a><a href=\"\">GitHub</a>YOLOV2</p>\n<p>Update@2018/04: <a href=\"https://pjreddie.com/darknet/yolo/\">YOLO v3</a><a href=\"https://xmfbit.github.io/2018/04/01/paper-yolov3/\"> - YOLO v3</a></p>\n<p><img src=\"/img/yolo2_result.png\" alt=\"YOLO V2\"><br>","more":"</p>\n<h2 id=\"YOLO-V1\"><a href=\"#YOLO-V1\" class=\"headerlink\" title=\"YOLO V1\"></a>YOLO V1</h2><p>YOLO V1<a href=\"https://arxiv.org/abs/1506.02640\">You Only Look Once: Unitied, Real-Time Object Detection</a></p>\n<blockquote>\n<p>YOLObounding boxCNNbounding boxpipeline<br>YOLObase model45fpsmodelFast YOLO155fpsmAPState of the artYOLOlocalizationFalse PositivesYOLO</p>\n</blockquote>\n<p>HoG+SVMDPMRCNNYOLOimagebounding boxState of the artFaster RCNNFaster RCNNRPNFast RCNNproposalFast RCNNproposalYOLOYOLOtestCNN<br><img src=\"/img/yolo1_detection_system.png\" alt=\"YOLO V1\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/yolo1_basic_idea.png\" alt=\"\"></p>\n<ul>\n<li>image$S \\times S$grid cellimageobject boxgrid cellcellobjectresponsible for detection that objectgrid cell$B$bounding boxbounding boxbounding boxbounding boxIoUbounding box</li>\n</ul>\n<script type=\"math/tex; mode=display\">\\text{confidence} = P(\\text{Object})\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}</script><ul>\n<li><p>bounding box5$x,y,w,h$$x,y$bounding boxgrid cell$w,h$bounding box$x,y,w,h$bounded$[0,1]$grid cell$C$$P(\\text{Class}_i|\\text{Object})$$B$grid celltestbounding box</p>\n<script type=\"math/tex; mode=display\">\\text{confidence}\\times P(\\text{Class}_i|\\text{Object}) = P(\\text{Class}_i)\\times \\text{IoU}_{\\text{pred}}^{\\text{truth}}</script></li>\n<li><p>PASCAL VOC$S = 7$, $B=2$20$C=20$$7\\times 7 \\times 30$</p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Inspired by GoogLeNetinceptionsimply$1\\times 1$base model242<br><img src=\"/img/yolo1_network_arch.png\" alt=\"YOLO\"></p>\n<p>Fast YOLO9filter</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ImageNet20average-poolingImageNet 100088%top-5</p>\n<p><a href=\"https://arxiv.org/abs/1504.06066\">Ren</a>42$224\\times 224$$448 \\times 448$</p>\n<p>leaky ReLU</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\n\\begin{cases}\nx, &\\text{if}\\ x > 0 \\\\\\\\\n0.1x, &\\text{otherwise}\n\\end{cases}</script><p>loss function</p>\n<ul>\n<li>loss</li>\n<li>grid cellbounding boxbounding box<script type=\"math/tex; mode=display\">\\lambda_{\\text{coord}} = 5\\lambda_{\\text{noobj}} = 0.5</script></li>\n<li>$w$$h$boxlossbox$\\sqrt{w}$$\\sqrt{h}$</li>\n<li>grid cellbounding boxtrainingbounding boxobjectbounding boxground truthIoUbounding boxno obj</li>\n</ul>\n<p>loss$\\mathbb{1}_i$$i$grid cell</p>\n<p>$\\mathbb{1}_{i,j}$$i$grid cell$j$bounding box<br><img src=\"/img/yolo1_loss_fun.png\" alt=\"YOLO\"></p>\n<p>lossDarknet<a href=\"https://github.com/pjreddie/darknet/blob/master/src/detection_layer.c\">detection_layer.c</a>costlossdelta</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div><div class=\"line\">60</div><div class=\"line\">61</div><div class=\"line\">62</div><div class=\"line\">63</div><div class=\"line\">64</div><div class=\"line\">65</div><div class=\"line\">66</div><div class=\"line\">67</div><div class=\"line\">68</div><div class=\"line\">69</div><div class=\"line\">70</div><div class=\"line\">71</div><div class=\"line\">72</div><div class=\"line\">73</div><div class=\"line\">74</div><div class=\"line\">75</div><div class=\"line\">76</div><div class=\"line\">77</div><div class=\"line\">78</div><div class=\"line\">79</div><div class=\"line\">80</div><div class=\"line\">81</div><div class=\"line\">82</div><div class=\"line\">83</div><div class=\"line\">84</div><div class=\"line\">85</div><div class=\"line\">86</div><div class=\"line\">87</div><div class=\"line\">88</div><div class=\"line\">89</div><div class=\"line\">90</div><div class=\"line\">91</div><div class=\"line\">92</div><div class=\"line\">93</div><div class=\"line\">94</div><div class=\"line\">95</div><div class=\"line\">96</div><div class=\"line\">97</div><div class=\"line\">98</div><div class=\"line\">99</div><div class=\"line\">100</div><div class=\"line\">101</div><div class=\"line\">102</div><div class=\"line\">103</div><div class=\"line\">104</div><div class=\"line\">105</div><div class=\"line\">106</div><div class=\"line\">107</div><div class=\"line\">108</div><div class=\"line\">109</div><div class=\"line\">110</div><div class=\"line\">111</div><div class=\"line\">112</div><div class=\"line\">113</div><div class=\"line\">114</div><div class=\"line\">115</div><div class=\"line\">116</div><div class=\"line\">117</div><div class=\"line\">118</div><div class=\"line\">119</div><div class=\"line\">120</div><div class=\"line\">121</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">if</span>(state.train)&#123;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_iou = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_cat = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_allcat = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_obj = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">float</span> avg_anyobj = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> count = <span class=\"number\">0</span>;</div><div class=\"line\">    *(l.cost) = <span class=\"number\">0</span>;</div><div class=\"line\">    <span class=\"keyword\">int</span> size = l.inputs * l.batch;</div><div class=\"line\">    <span class=\"built_in\">memset</span>(l.delta, <span class=\"number\">0</span>, size * <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</div><div class=\"line\">    <span class=\"keyword\">for</span> (b = <span class=\"number\">0</span>; b &lt; l.batch; ++b)&#123;</div><div class=\"line\">        <span class=\"keyword\">int</span> index = b*l.inputs;</div><div class=\"line\">        <span class=\"comment\">// for each grid cell</span></div><div class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">0</span>; i &lt; locations; ++i) &#123;   <span class=\"comment\">// locations = S * S = 49</span></div><div class=\"line\">            <span class=\"keyword\">int</span> truth_index = (b*locations + i)*(<span class=\"number\">1</span>+l.coords+l.classes);</div><div class=\"line\">            <span class=\"keyword\">int</span> is_obj = state.truth[truth_index];</div><div class=\"line\">            <span class=\"comment\">// for each bbox</span></div><div class=\"line\">            <span class=\"keyword\">for</span> (j = <span class=\"number\">0</span>; j &lt; l.n; ++j) &#123;     <span class=\"comment\">// l.n = B = 2</span></div><div class=\"line\">                <span class=\"keyword\">int</span> p_index = index + locations*l.classes + i*l.n + j;</div><div class=\"line\">                l.delta[p_index] = l.noobject_scale*(<span class=\"number\">0</span> - l.output[p_index]);</div><div class=\"line\">                <span class=\"comment\">// no objbboxresponsible</span></div><div class=\"line\">                <span class=\"comment\">// bbox responsible for object</span></div><div class=\"line\">                *(l.cost) += l.noobject_scale*<span class=\"built_in\">pow</span>(l.output[p_index], <span class=\"number\">2</span>);  </div><div class=\"line\">                avg_anyobj += l.output[p_index];</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">int</span> best_index = <span class=\"number\">-1</span>;</div><div class=\"line\">            <span class=\"keyword\">float</span> best_iou = <span class=\"number\">0</span>;</div><div class=\"line\">            <span class=\"keyword\">float</span> best_rmse = <span class=\"number\">20</span>;</div><div class=\"line\">            <span class=\"comment\">// grid cell</span></div><div class=\"line\">            <span class=\"keyword\">if</span> (!is_obj)&#123;</div><div class=\"line\">                <span class=\"keyword\">continue</span>;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"comment\">// responsiblebounding boxloss</span></div><div class=\"line\">            <span class=\"keyword\">int</span> class_index = index + i*l.classes;</div><div class=\"line\">            <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; j &lt; l.classes; ++j) &#123;</div><div class=\"line\">                l.delta[class_index+j] = l.class_scale * (state.truth[truth_index+<span class=\"number\">1</span>+j] - l.output[class_index+j]);</div><div class=\"line\">                *(l.cost) += l.class_scale * <span class=\"built_in\">pow</span>(state.truth[truth_index+<span class=\"number\">1</span>+j] - l.output[class_index+j], <span class=\"number\">2</span>);</div><div class=\"line\">                <span class=\"keyword\">if</span>(state.truth[truth_index + <span class=\"number\">1</span> + j]) avg_cat += l.output[class_index+j];</div><div class=\"line\">                avg_allcat += l.output[class_index+j];</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            box truth = float_to_box(state.truth + truth_index + <span class=\"number\">1</span> + l.classes);</div><div class=\"line\">            truth.x /= l.side;</div><div class=\"line\">            truth.y /= l.side;</div><div class=\"line\">            <span class=\"comment\">// IoUbboxresponsibleindex</span></div><div class=\"line\">            <span class=\"keyword\">for</span>(j = <span class=\"number\">0</span>; j &lt; l.n; ++j)&#123;</div><div class=\"line\">                <span class=\"keyword\">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + j) * l.coords;</div><div class=\"line\">                box out = float_to_box(l.output + box_index);</div><div class=\"line\">                out.x /= l.side;</div><div class=\"line\">                out.y /= l.side;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">if</span> (l.<span class=\"built_in\">sqrt</span>)&#123;</div><div class=\"line\">                    out.w = out.w*out.w;</div><div class=\"line\">                    out.h = out.h*out.h;</div><div class=\"line\">                &#125;</div><div class=\"line\"></div><div class=\"line\">                <span class=\"keyword\">float</span> iou  = box_iou(out, truth);</div><div class=\"line\">                <span class=\"comment\">//iou = 0;</span></div><div class=\"line\">                <span class=\"keyword\">float</span> rmse = box_rmse(out, truth);</div><div class=\"line\">                <span class=\"keyword\">if</span>(best_iou &gt; <span class=\"number\">0</span> || iou &gt; <span class=\"number\">0</span>)&#123;</div><div class=\"line\">                    <span class=\"keyword\">if</span>(iou &gt; best_iou)&#123;</div><div class=\"line\">                        best_iou = iou;</div><div class=\"line\">                        best_index = j;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">                    <span class=\"keyword\">if</span>(rmse &lt; best_rmse)&#123;</div><div class=\"line\">                        best_rmse = rmse;</div><div class=\"line\">                        best_index = j;</div><div class=\"line\">                    &#125;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">if</span>(l.forced)&#123;</div><div class=\"line\">                <span class=\"keyword\">if</span>(truth.w*truth.h &lt; <span class=\"number\">.1</span>)&#123;</div><div class=\"line\">                    best_index = <span class=\"number\">1</span>;</div><div class=\"line\">                &#125;<span class=\"keyword\">else</span>&#123;</div><div class=\"line\">                    best_index = <span class=\"number\">0</span>;</div><div class=\"line\">                &#125;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">if</span>(l.random &amp;&amp; *(state.net.seen) &lt; <span class=\"number\">64000</span>)&#123;</div><div class=\"line\">                best_index = rand()%l.n;</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + best_index) * l.coords;</div><div class=\"line\">            <span class=\"keyword\">int</span> tbox_index = truth_index + <span class=\"number\">1</span> + l.classes;</div><div class=\"line\"></div><div class=\"line\">            box out = float_to_box(l.output + box_index);</div><div class=\"line\">            out.x /= l.side;</div><div class=\"line\">            out.y /= l.side;</div><div class=\"line\">            <span class=\"keyword\">if</span> (l.<span class=\"built_in\">sqrt</span>) &#123;</div><div class=\"line\">                out.w = out.w*out.w;</div><div class=\"line\">                out.h = out.h*out.h;</div><div class=\"line\">            &#125;</div><div class=\"line\">            <span class=\"keyword\">float</span> iou  = box_iou(out, truth);</div><div class=\"line\"></div><div class=\"line\">            <span class=\"comment\">//printf(\"%d,\", best_index);</span></div><div class=\"line\">            <span class=\"keyword\">int</span> p_index = index + locations*l.classes + i*l.n + best_index;</div><div class=\"line\">            *(l.cost) -= l.noobject_scale * <span class=\"built_in\">pow</span>(l.output[p_index], <span class=\"number\">2</span>);  <span class=\"comment\">// </span></div><div class=\"line\">            *(l.cost) += l.object_scale * <span class=\"built_in\">pow</span>(<span class=\"number\">1</span>-l.output[p_index], <span class=\"number\">2</span>);</div><div class=\"line\">            avg_obj += l.output[p_index];</div><div class=\"line\">            l.delta[p_index] = l.object_scale * (<span class=\"number\">1.</span>-l.output[p_index]);</div><div class=\"line\"></div><div class=\"line\">            <span class=\"keyword\">if</span>(l.rescore)&#123;</div><div class=\"line\">                l.delta[p_index] = l.object_scale * (iou - l.output[p_index]);</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            l.delta[box_index+<span class=\"number\">0</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">0</span>] - l.output[box_index + <span class=\"number\">0</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">1</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">1</span>] - l.output[box_index + <span class=\"number\">1</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">2</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">2</span>] - l.output[box_index + <span class=\"number\">2</span>]);</div><div class=\"line\">            l.delta[box_index+<span class=\"number\">3</span>] = l.coord_scale*(state.truth[tbox_index + <span class=\"number\">3</span>] - l.output[box_index + <span class=\"number\">3</span>]);</div><div class=\"line\">            <span class=\"keyword\">if</span>(l.<span class=\"built_in\">sqrt</span>)&#123;</div><div class=\"line\">                l.delta[box_index+<span class=\"number\">2</span>] = l.coord_scale*(<span class=\"built_in\">sqrt</span>(state.truth[tbox_index + <span class=\"number\">2</span>]) - l.output[box_index + <span class=\"number\">2</span>]);</div><div class=\"line\">                l.delta[box_index+<span class=\"number\">3</span>] = l.coord_scale*(<span class=\"built_in\">sqrt</span>(state.truth[tbox_index + <span class=\"number\">3</span>]) - l.output[box_index + <span class=\"number\">3</span>]);</div><div class=\"line\">            &#125;</div><div class=\"line\"></div><div class=\"line\">            *(l.cost) += <span class=\"built_in\">pow</span>(<span class=\"number\">1</span>-iou, <span class=\"number\">2</span>);</div><div class=\"line\">            avg_iou += iou;</div><div class=\"line\">            ++count;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div></pre></td></tr></table></figure>\n<h2 id=\"YOLO-V2\"><a href=\"#YOLO-V2\" class=\"headerlink\" title=\"YOLO V2\"></a>YOLO V2</h2><p>YOLO V2V1BetterFasterStronger</p>\n<ul>\n<li>Faster RCNNanchorK-Meansanchor</li>\n<li></li>\n<li>WordTreeImageNetCOCO</li>\n</ul>\n<p></p>\n<blockquote>\n<p>YOLO 9000State of the art9KYOLO V1PASCAL VOCCOCOState of the artmulti-scale training method YOLO V2imagetrade-off67fpsVOC200776.8mAP40fps78.6mAPFaster RCNN with ResNetSSDCOCO detection datasetImageNet classification datasetlabeldetection datadetectionImageNetdetectionYOLO 900020044detection dataImageNet datection19.7mAPCOCO156YOLO900016.0mAPYOLO90009K</p>\n</blockquote>\n<p>BetterFasterStronger</p>\n<h2 id=\"Better\"><a href=\"#Better\" class=\"headerlink\" title=\"Better\"></a>Better</h2><p>YOLO V1mAP1356Anchor Box34527</p>\n<h3 id=\"1BNBatch-Normalization\"><a href=\"#1BNBatch-Normalization\" class=\"headerlink\" title=\"1BNBatch Normalization\"></a>1BNBatch Normalization</h3><p>Batch NormalizationconvBNdrop out2%</p>\n<h3 id=\"2High-Resolution-Classifier\"><a href=\"#2High-Resolution-Classifier\" class=\"headerlink\" title=\"2High Resolution Classifier\"></a>2High Resolution Classifier</h3><p>YOLO V1ImageNet$224\\times 224$$448\\times 448$224$448\\times 448$ImageNetfine tuning10epochclsdetection4%</p>\n<h3 id=\"3Anchor-Box\"><a href=\"#3Anchor-Box\" class=\"headerlink\" title=\"3Anchor Box\"></a>3Anchor Box</h3><p>YOLO V1CNNbounding boxFaster RCNNanchor boxbounding boxanchor box</p>\n<p>fcmax poolingfeature mapshrink$416\\times 416$448imagefeature mapcenter cellYOLO conv-poolingimage downsamplig 32feature map$416/32 = 13$</p>\n<p>YOLO V1grid cellbounding box$C$bounding box$C$YOLO V1confidence</p>\n<p>anchoraccuracyrecallgrid cell2bounding boxrecallrecallaccuracy</p>\n<h3 id=\"4Dimension-Cluster\"><a href=\"#4Dimension-Cluster\" class=\"headerlink\" title=\"4Dimension Cluster\"></a>4Dimension Cluster</h3><p>anchor boxanchorFaster RCNNstrideanchor9anchor boxanchor box</p>\n<p></p>\n<ul>\n<li>K-Means</li>\n<li>IoU<script type=\"math/tex; mode=display\">d(\\text{box}, \\text{centroid}) = 1-\\text{IoU}(\\text{box}, \\text{centroid})</script></li>\n</ul>\n<p>$k$$k = 5$$k=9$Faster RCNNanchor boxCOCOVOC$k=5$boxanchor box<br><img src=\"/img/yolo2_cluster_result.png\" alt=\"\"></p>\n<h3 id=\"5Direct-Location-Prediction\"><a href=\"#5Direct-Location-Prediction\" class=\"headerlink\" title=\"5Direct Location Prediction\"></a>5Direct Location Prediction</h3><p>YOLO V1boxgrid cellsigmoid$[0, 1]$</p>\n<p>outputfeature mapcell$13\\times 13$bounding box$t_x$, $t_y$, $t_w$, $t_h$cell$k=5$bounding boxbounding box</p>\n<p><img src=\"/img/yolo2_bbox_location.png\" alt=\"bbox\"></p>\n<p>grid celloffset$(c_x, c_y)$bounding boxboxgrid cellanchor box<br><img src=\"/img/yolo2_bbox_param.png\" alt=\"bounding box\"></p>\n<p>Darknet</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// get bounding box</span></div><div class=\"line\"><span class=\"comment\">// x: data pointer of feature map</span></div><div class=\"line\"><span class=\"comment\">// biases: data pointer of anchor box data</span></div><div class=\"line\"><span class=\"comment\">// biases[2*n] = width of anchor box</span></div><div class=\"line\"><span class=\"comment\">// biases[2*n+1] = height of anchor box</span></div><div class=\"line\"><span class=\"comment\">// n: output bounding box for each cell in the feature map</span></div><div class=\"line\"><span class=\"comment\">// index: output bounding box index in the cell</span></div><div class=\"line\"><span class=\"comment\">// i: `cx` in the paper</span></div><div class=\"line\"><span class=\"comment\">// j: 'cy' in the paper</span></div><div class=\"line\"><span class=\"comment\">// (cx, cy) is the offset from the left top corner of the feature map</span></div><div class=\"line\"><span class=\"comment\">// (w, h) is the size of feature map (do normalization in the code)</span></div><div class=\"line\"><span class=\"function\">box <span class=\"title\">get_region_box</span><span class=\"params\">(<span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases, <span class=\"keyword\">int</span> n, <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    box b;</div><div class=\"line\">    <span class=\"comment\">// i &lt;- cx, j &lt;- cy</span></div><div class=\"line\">    <span class=\"comment\">// index + 0: tx</span></div><div class=\"line\">    <span class=\"comment\">// index + 1: ty</span></div><div class=\"line\">    <span class=\"comment\">// index + 2: tw</span></div><div class=\"line\">    <span class=\"comment\">// index + 3: th</span></div><div class=\"line\">    <span class=\"comment\">// index + 4: to   // not used here</span></div><div class=\"line\">    <span class=\"comment\">// index + 5, +6, ..., +(C+4)   // confidence of P(class c|Object), not used here</span></div><div class=\"line\">    b.x = (i + logistic_activate(x[index + <span class=\"number\">0</span>])) / w;    <span class=\"comment\">// bx = cx+sigmoid(tx)</span></div><div class=\"line\">    b.y = (j + logistic_activate(x[index + <span class=\"number\">1</span>])) / h;    <span class=\"comment\">// by = cy+sigmoid(ty)</span></div><div class=\"line\">    b.w = <span class=\"built_in\">exp</span>(x[index + <span class=\"number\">2</span>]) * biases[<span class=\"number\">2</span>*n]   / w;        <span class=\"comment\">// bw = exp(tw) * pw</span></div><div class=\"line\">    b.h = <span class=\"built_in\">exp</span>(x[index + <span class=\"number\">3</span>]) * biases[<span class=\"number\">2</span>*n+<span class=\"number\">1</span>] / h;        <span class=\"comment\">// bh = exp(th) * ph</span></div><div class=\"line\">    <span class=\"comment\">// Normalization[0, 1]</span></div><div class=\"line\">    <span class=\"comment\">// YOLO detectionbounding box</span></div><div class=\"line\">    <span class=\"keyword\">return</span> b;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>bounding boxbp</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// truth: ground truth</span></div><div class=\"line\"><span class=\"comment\">// x: data pointer of feature map</span></div><div class=\"line\"><span class=\"comment\">// biases: data pointer of anchor box data</span></div><div class=\"line\"><span class=\"comment\">// n, index, i, j, w, h: same meaning with `get_region_box`</span></div><div class=\"line\"><span class=\"comment\">// delta: data pointer of gradient</span></div><div class=\"line\"><span class=\"comment\">// scale: just a weight, given by user</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">float</span> <span class=\"title\">delta_region_box</span><span class=\"params\">(box truth, <span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *biases,</div><div class=\"line\">                       <span class=\"keyword\">int</span> n, <span class=\"keyword\">int</span> index, <span class=\"keyword\">int</span> i, <span class=\"keyword\">int</span> j, <span class=\"keyword\">int</span> w, <span class=\"keyword\">int</span> h,</div><div class=\"line\">                       <span class=\"keyword\">float</span> *delta, <span class=\"keyword\">float</span> scale)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    box pred = get_region_box(x, biases, n, index, i, j, w, h);</div><div class=\"line\">    <span class=\"comment\">// get iou of the bbox and truth</span></div><div class=\"line\">    <span class=\"keyword\">float</span> iou = box_iou(pred, truth);</div><div class=\"line\">    <span class=\"comment\">// ground truth of the parameters (tx, ty, tw, th)</span></div><div class=\"line\">    <span class=\"keyword\">float</span> tx = (truth.x*w - i);</div><div class=\"line\">    <span class=\"keyword\">float</span> ty = (truth.y*h - j);</div><div class=\"line\">    <span class=\"keyword\">float</span> tw = <span class=\"built_in\">log</span>(truth.w*w / biases[<span class=\"number\">2</span>*n]);</div><div class=\"line\">    <span class=\"keyword\">float</span> th = <span class=\"built_in\">log</span>(truth.h*h / biases[<span class=\"number\">2</span>*n + <span class=\"number\">1</span>]);</div><div class=\"line\">    <span class=\"comment\">// </span></div><div class=\"line\">    <span class=\"comment\">// tx</span></div><div class=\"line\">    <span class=\"comment\">// loss = 1/2*(bx^hat-bx)^2, bx = cx + sigmoid(tx)</span></div><div class=\"line\">    <span class=\"comment\">// d(loss)/d(tx) = -(bx^hat-bx) * d(bx)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// Darkentdeltadelta-d(loss)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// (bx^hat-bx) * d(bx)/d(tx)</span></div><div class=\"line\">    <span class=\"comment\">// (bx^hat-bx)cxcell</span></div><div class=\"line\">    <span class=\"comment\">// sigmoid</span></div><div class=\"line\">    <span class=\"comment\">//  sigomid(tx) sigmoid(tx)</span></div><div class=\"line\">    delta[index + <span class=\"number\">0</span>] = scale * (tx - logistic_activate(x[index + <span class=\"number\">0</span>]))</div><div class=\"line\">                             * logistic_gradient(logistic_activate(x[index + <span class=\"number\">0</span>]));</div><div class=\"line\"></div><div class=\"line\">    delta[index + <span class=\"number\">1</span>] = scale * (ty - logistic_activate(x[index + <span class=\"number\">1</span>]))</div><div class=\"line\">                             * logistic_gradient(logistic_activate(x[index + <span class=\"number\">1</span>]));</div><div class=\"line\">    <span class=\"comment\">// tw  loss = 1/2(tw^hat-tw)^2bw^hat  bw</span></div><div class=\"line\">    delta[index + <span class=\"number\">2</span>] = scale * (tw - x[index + <span class=\"number\">2</span>]);</div><div class=\"line\">    delta[index + <span class=\"number\">3</span>] = scale * (th - x[index + <span class=\"number\">3</span>]);</div><div class=\"line\">    <span class=\"keyword\">return</span> iou;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>bpbounding box$t_o$$C$bounding box$t_o$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// groundtruthbounding box iou</span></div><div class=\"line\"><span class=\"comment\">// bounding boxresponsible for any groundtruth</span></div><div class=\"line\"><span class=\"comment\">// loss = 1/2*(0-sigmoid(to))^2</span></div><div class=\"line\"><span class=\"comment\">// =&gt; d(loss)/d(to) = -(0-sigmoid(to)) * d(sigmoid)/d(to)</span></div><div class=\"line\"><span class=\"comment\">// outputsigmoid</span></div><div class=\"line\"><span class=\"comment\">// logistic_gradient(y) dy/dx|(y=y0)logistic_gradient(y) = (1-y)*y</span></div><div class=\"line\">l.delta[index + <span class=\"number\">4</span>] = l.noobject_scale * ((<span class=\"number\">0</span> - l.output[index + <span class=\"number\">4</span>]) * logistic_gradient(l.output[index + <span class=\"number\">4</span>]));</div><div class=\"line\"><span class=\"comment\">// best iou &gt; thresh, bounding boxgroundtruth0</span></div><div class=\"line\"><span class=\"keyword\">if</span> (best_iou &gt; l.thresh) &#123;</div><div class=\"line\">    l.delta[index + <span class=\"number\">4</span>] = <span class=\"number\">0</span>;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>lossV1MSELoss<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">// for each class</div><div class=\"line\">for(n = 0; n &lt; classes; ++n)&#123;</div><div class=\"line\">    // P_i = \\frac&#123;exp^out_i&#125;&#123;sum of exp^out_j&#125;</div><div class=\"line\">    // SoftmaxLoss = -logP(class)</div><div class=\"line\">    // SoftmaxLoss/output = -(1(n==class)-P)</div><div class=\"line\">    delta[index + n] = scale * (((n == class)?1 : 0) - output[index + n]);</div><div class=\"line\">    if(n == class) *avg_cat += output[index + n];</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h3 id=\"6Fine-Gained-Features\"><a href=\"#6Fine-Gained-Features\" class=\"headerlink\" title=\"6Fine-Gained Features\"></a>6Fine-Gained Features</h3><p>trickFaster RCNNSSDfeature mappass-through$26\\times 26$feature map</p>\n<p>higher resolution$26\\times 26$feature map stacking$26\\times 26 \\times 512$feature map$13\\times 13$channelDarknet<code>reorg_layer</code></p>\n<p>feature map1%</p>\n<h3 id=\"7Multi-Scale-Training\"><a href=\"#7Multi-Scale-Training\" class=\"headerlink\" title=\"7Multi-Scale Training\"></a>7Multi-Scale Training</h3><p>convpooling</p>\n<p>epoch10$32$$32$$\\lbrace 320, 352, \\dots, 608\\rbrace$</p>\n<p>YOLO V2GPUGPUYOLO V2state of the artFaster RCNNSSDYOLO30fpsFaster RCNNYOLO V2VOC 2007</p>\n<p><img src=\"/img/yolo2_different_methods_comparation.png\" alt=\"\"><br><img src=\"/img/yolo2_different_methods_comparation_in_table.png\" alt=\"\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>BetterAnchor boxrecallmAP~33%<br><img src=\"/img/yolo2_different_methods_improvement.png\" alt=\"\"></p>\n<h2 id=\"Faster\"><a href=\"#Faster\" class=\"headerlink\" title=\"Faster\"></a>Faster</h2><p>Faster RCNNVGG-16base networkVGG-16$224\\times 224$30.69BYOLO V1VGG-16ImageNet88.0% vs 90.0%</p>\n<p>YOLO V2Darknet-19base network19VGG$3\\times 3$poolingchanneldoubleNINglobal average pooling$1\\times 1$feature mapchannelchannelBatch NormalizationDarknet-19VGG-16<br><img src=\"/img/yolo2_dartnet_19_structure.png\" alt=\"Darknet-19\"></p>\n<p>ImageNet 1K$224\\times 224$$448\\times 448$fine tuning</p>\n<p>1K$3$$3\\times 3$channel$1024$$1\\times 1$channelVOC$5$box$5$$20$$5\\times(5+20)=125$YOLO V2<code>yolo_voc.cfg</code><a href=\"https://github.com/pjreddie/darknet/blob/master/cfg/yolo.cfg\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">[convolutional]</div><div class=\"line\">batch_normalize=1</div><div class=\"line\">size=3</div><div class=\"line\">stride=1</div><div class=\"line\">pad=1</div><div class=\"line\">filters=1024</div><div class=\"line\">activation=leaky</div><div class=\"line\"></div><div class=\"line\">[convolutional]</div><div class=\"line\">size=1</div><div class=\"line\">stride=1</div><div class=\"line\">pad=1</div><div class=\"line\">filters=125</div><div class=\"line\">activation=linear</div></pre></td></tr></table></figure>\n<p>pass-through</p>\n<h2 id=\"Stronger\"><a href=\"#Stronger\" class=\"headerlink\" title=\"Stronger\"></a>Stronger</h2><p></p>"},{"title":"YOLO CaffeBN","date":"2019-03-09T04:51:18.000Z","_content":"YOLODarknetInferenceCaffeDarknetYOLOCaffeYOLO V3 DarknetCaffe\n\n<!-- more -->\n\n# DarknetBN\n\nCPUDarknetBNnormalization[normalize_cpu](https://github.com/pjreddie/darknet/blob/master/src/blas.c#L147)\n\n``` cpp\nvoid normalize_cpu(float *x, float *mean, float *variance, int batch, int filters, int spatial)\n{\n    int b, f, i;\n    for(b = 0; b < batch; ++b){\n        for(f = 0; f < filters; ++f){\n            for(i = 0; i < spatial; ++i){\n                int index = b*filters*spatial + f*spatial + i;\n                x[index] = (x[index] - mean[f])/(sqrt(variance[f]) + .000001f);\n            }\n        }\n    }\n}\n```\n\nDarknetBN\n$$\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2} + \\epsilon}$$\n\n$\\epsilon$$1\\times 10^{-6}$\n\n# \n\nCaffe$\\epsilon$\n$$\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$$\n\n`caffe.proto`Caffe$\\epsilon$$1\\times 10^{-5}$\n\ncaffe prototxt`batch_norm_param`\n\n``` proto\nbatch_norm_param {\n  use_global_stats: true\n  eps: 1e-06\n}\n```\n\n$\\sigma^2$layer\n\n``` python\ndef convert_running_var(var, eps=DARKNET_EPS):\n    return np.square(np.sqrt(var) + eps) - eps\n```\n\nCaffeDarknet$1\\times 10^{-7}$\n","source":"_posts/darknet-caffe-converter.md","raw":"---\ntitle: YOLO CaffeBN\ndate: 2019-03-09 12:51:18\ntags:\n     - caffe\n     - deep learning\n---\nYOLODarknetInferenceCaffeDarknetYOLOCaffeYOLO V3 DarknetCaffe\n\n<!-- more -->\n\n# DarknetBN\n\nCPUDarknetBNnormalization[normalize_cpu](https://github.com/pjreddie/darknet/blob/master/src/blas.c#L147)\n\n``` cpp\nvoid normalize_cpu(float *x, float *mean, float *variance, int batch, int filters, int spatial)\n{\n    int b, f, i;\n    for(b = 0; b < batch; ++b){\n        for(f = 0; f < filters; ++f){\n            for(i = 0; i < spatial; ++i){\n                int index = b*filters*spatial + f*spatial + i;\n                x[index] = (x[index] - mean[f])/(sqrt(variance[f]) + .000001f);\n            }\n        }\n    }\n}\n```\n\nDarknetBN\n$$\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2} + \\epsilon}$$\n\n$\\epsilon$$1\\times 10^{-6}$\n\n# \n\nCaffe$\\epsilon$\n$$\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$$\n\n`caffe.proto`Caffe$\\epsilon$$1\\times 10^{-5}$\n\ncaffe prototxt`batch_norm_param`\n\n``` proto\nbatch_norm_param {\n  use_global_stats: true\n  eps: 1e-06\n}\n```\n\n$\\sigma^2$layer\n\n``` python\ndef convert_running_var(var, eps=DARKNET_EPS):\n    return np.square(np.sqrt(var) + eps) - eps\n```\n\nCaffeDarknet$1\\times 10^{-7}$\n","slug":"darknet-caffe-converter","published":1,"updated":"2019-03-09T04:58:35.441Z","_id":"cjt10habq00014t7bk73bk6cy","comments":1,"layout":"post","photos":[],"link":"","content":"<p>YOLODarknetInferenceCaffeDarknetYOLOCaffeYOLO V3 DarknetCaffe</p>\n<a id=\"more\"></a>\n<h1 id=\"DarknetBN\"><a href=\"#DarknetBN\" class=\"headerlink\" title=\"DarknetBN\"></a>DarknetBN</h1><p>CPUDarknetBNnormalization<a href=\"https://github.com/pjreddie/darknet/blob/master/src/blas.c#L147\" target=\"_blank\" rel=\"external\">normalize_cpu</a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">normalize_cpu</span><span class=\"params\">(<span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *mean, <span class=\"keyword\">float</span> *variance, <span class=\"keyword\">int</span> batch, <span class=\"keyword\">int</span> filters, <span class=\"keyword\">int</span> spatial)</span></span></div><div class=\"line\">&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> b, f, i;</div><div class=\"line\">    <span class=\"keyword\">for</span>(b = <span class=\"number\">0</span>; b &lt; batch; ++b)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(f = <span class=\"number\">0</span>; f &lt; filters; ++f)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(i = <span class=\"number\">0</span>; i &lt; spatial; ++i)&#123;</div><div class=\"line\">                <span class=\"keyword\">int</span> index = b*filters*spatial + f*spatial + i;</div><div class=\"line\">                x[index] = (x[index] - mean[f])/(<span class=\"built_in\">sqrt</span>(variance[f]) + <span class=\"number\">.000001</span>f);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>DarknetBN</p>\n<script type=\"math/tex; mode=display\">\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2} + \\epsilon}</script><p>$\\epsilon$$1\\times 10^{-6}$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>Caffe$\\epsilon$</p>\n<script type=\"math/tex; mode=display\">\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}</script><p><code>caffe.proto</code>Caffe$\\epsilon$$1\\times 10^{-5}$</p>\n<p>caffe prototxt<code>batch_norm_param</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">batch_norm_param &#123;</div><div class=\"line\">  use_global_stats: true</div><div class=\"line\">  eps: 1e-06</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>$\\sigma^2$layer</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">convert_running_var</span><span class=\"params\">(var, eps=DARKNET_EPS)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> np.square(np.sqrt(var) + eps) - eps</div></pre></td></tr></table></figure>\n<p>CaffeDarknet$1\\times 10^{-7}$</p>\n","excerpt":"<p>YOLODarknetInferenceCaffeDarknetYOLOCaffeYOLO V3 DarknetCaffe</p>","more":"<h1 id=\"DarknetBN\"><a href=\"#DarknetBN\" class=\"headerlink\" title=\"DarknetBN\"></a>DarknetBN</h1><p>CPUDarknetBNnormalization<a href=\"https://github.com/pjreddie/darknet/blob/master/src/blas.c#L147\">normalize_cpu</a></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">normalize_cpu</span><span class=\"params\">(<span class=\"keyword\">float</span> *x, <span class=\"keyword\">float</span> *mean, <span class=\"keyword\">float</span> *variance, <span class=\"keyword\">int</span> batch, <span class=\"keyword\">int</span> filters, <span class=\"keyword\">int</span> spatial)</span></div><div class=\"line\"></span>&#123;</div><div class=\"line\">    <span class=\"keyword\">int</span> b, f, i;</div><div class=\"line\">    <span class=\"keyword\">for</span>(b = <span class=\"number\">0</span>; b &lt; batch; ++b)&#123;</div><div class=\"line\">        <span class=\"keyword\">for</span>(f = <span class=\"number\">0</span>; f &lt; filters; ++f)&#123;</div><div class=\"line\">            <span class=\"keyword\">for</span>(i = <span class=\"number\">0</span>; i &lt; spatial; ++i)&#123;</div><div class=\"line\">                <span class=\"keyword\">int</span> index = b*filters*spatial + f*spatial + i;</div><div class=\"line\">                x[index] = (x[index] - mean[f])/(<span class=\"built_in\">sqrt</span>(variance[f]) + <span class=\"number\">.000001</span>f);</div><div class=\"line\">            &#125;</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>DarknetBN</p>\n<script type=\"math/tex; mode=display\">\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2} + \\epsilon}</script><p>$\\epsilon$$1\\times 10^{-6}$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>Caffe$\\epsilon$</p>\n<script type=\"math/tex; mode=display\">\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}</script><p><code>caffe.proto</code>Caffe$\\epsilon$$1\\times 10^{-5}$</p>\n<p>caffe prototxt<code>batch_norm_param</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">batch_norm_param &#123;</div><div class=\"line\">  use_global_stats: true</div><div class=\"line\">  eps: 1e-06</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>$\\sigma^2$layer</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">convert_running_var</span><span class=\"params\">(var, eps=DARKNET_EPS)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">return</span> np.square(np.sqrt(var) + eps) - eps</div></pre></td></tr></table></figure>\n<p>CaffeDarknet$1\\times 10^{-7}$</p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjolov8hx0006ae7bxvgoysqy","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8i70009ae7b1n7tdyda"},{"post_id":"cjolov8i8000aae7bjhbxnppg","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8ie000dae7b9n7ovww9"},{"post_id":"cjolov8ib000bae7btzewy29d","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8if000fae7bp57qhmam"},{"post_id":"cjolov8ie000eae7bxv14kzpz","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8ii000iae7b3qpfuqni"},{"post_id":"cjolov8h40000ae7b84r94vpo","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8im000kae7b1iwivsf5"},{"post_id":"cjolov8h40000ae7b84r94vpo","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8iq000nae7bby8sma0a"},{"post_id":"cjolov8h40000ae7b84r94vpo","tag_id":"cjolov8id000cae7bntfqfo9q","_id":"cjolov8iw000pae7b3getwicz"},{"post_id":"cjolov8hi0002ae7bx1uyik45","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8jb000wae7br1ez8kus"},{"post_id":"cjolov8hi0002ae7bx1uyik45","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8jg000yae7b2wjj76e4"},{"post_id":"cjolov8hi0002ae7bx1uyik45","tag_id":"cjolov8id000cae7bntfqfo9q","_id":"cjolov8jj0011ae7bkms1hdod"},{"post_id":"cjolov8hu0005ae7bwpovv1cx","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8jo0015ae7bloivd2s2"},{"post_id":"cjolov8hu0005ae7bwpovv1cx","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8js0017ae7b5wqkeeqw"},{"post_id":"cjolov8jl0014ae7b3byiaz48","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8jy001aae7bygssfgym"},{"post_id":"cjolov8jl0014ae7b3byiaz48","tag_id":"cjolov8id000cae7bntfqfo9q","_id":"cjolov8k3001cae7brerb4bf8"},{"post_id":"cjolov8i10007ae7bh0302s8i","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8k5001fae7b0tosvnmt"},{"post_id":"cjolov8i10007ae7bh0302s8i","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8k7001hae7bpk9x0s5k"},{"post_id":"cjolov8jp0016ae7bw9moem88","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8k9001kae7b6mxhkb0a"},{"post_id":"cjolov8jt0019ae7bw19ucwsv","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8kd001mae7btvni5sxa"},{"post_id":"cjolov8if000gae7b9ggg7go8","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8kg001pae7b6mh3p8oj"},{"post_id":"cjolov8if000gae7b9ggg7go8","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8kj001rae7bfx6tnfgc"},{"post_id":"cjolov8im000lae7bryi7n7l5","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8lc001zae7bylv1o91e"},{"post_id":"cjolov8im000lae7bryi7n7l5","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8ld0021ae7bcb5nx9mx"},{"post_id":"cjolov8lc0020ae7ble161rjq","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8ly0024ae7blt9z3xud"},{"post_id":"cjolov8ir000oae7bx4hbobzt","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8m90028ae7bmdrc66e0"},{"post_id":"cjolov8ir000oae7bx4hbobzt","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8me002aae7bzh0k3fvl"},{"post_id":"cjolov8ix000qae7b0i2kl844","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8mk002gae7bq8ajacli"},{"post_id":"cjolov8ix000qae7b0i2kl844","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8mm002iae7bo9lan1wa"},{"post_id":"cjolov8mj002fae7bawb3raya","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8mp002lae7b4suoxr30"},{"post_id":"cjolov8mo002kae7b0h0cl4xi","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8mv002oae7b95unkqjl"},{"post_id":"cjolov8j0000sae7bkcjecorl","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8mz002qae7b1n6zo9iy"},{"post_id":"cjolov8j0000sae7bkcjecorl","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8n0002tae7b8nx1ddb0"},{"post_id":"cjolov8mq002mae7b2l37opdy","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8n4002vae7bbsi595s7"},{"post_id":"cjolov8mz002rae7bmara1vu7","tag_id":"cjolov8k8001jae7b5duz6dv3","_id":"cjolov8n8002yae7bezwzo2z0"},{"post_id":"cjolov8j2000tae7bus1yv9a7","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8nb0030ae7b3s153zx0"},{"post_id":"cjolov8j2000tae7bus1yv9a7","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8nd0033ae7bs8vlpt4g"},{"post_id":"cjolov8j6000vae7bo9r36lss","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8nl0038ae7bugp7cciq"},{"post_id":"cjolov8j6000vae7bo9r36lss","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8no003aae7bgmtqm5l6"},{"post_id":"cjolov8je000xae7bjsmgudzv","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8nu003gae7ba2mrn5m4"},{"post_id":"cjolov8je000xae7bjsmgudzv","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8nw003iae7bu82q8zr7"},{"post_id":"cjolov8nv003hae7bi3wt3pm0","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8o0003lae7bkr7nt45p"},{"post_id":"cjolov8nx003kae7b80c4ps9h","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8o2003nae7bdufgj7j4"},{"post_id":"cjolov8jg0010ae7by4sfzrak","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8o5003qae7b7e1cdl4t"},{"post_id":"cjolov8jg0010ae7by4sfzrak","tag_id":"cjolov8nw003jae7bwdmgb1zt","_id":"cjolov8o9003sae7bnti0nlx6"},{"post_id":"cjolov8jj0012ae7bos0zf4ez","tag_id":"cjolov8js0018ae7b60iyko0n","_id":"cjolov8ou003yae7bv8985ic5"},{"post_id":"cjolov8jj0012ae7bos0zf4ez","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8ow0040ae7bmfh0msqh"},{"post_id":"cjolov8om003vae7bhe61as6j","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8oz0043ae7by0ihxx4t"},{"post_id":"cjolov8om003vae7bhe61as6j","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8p10045ae7b6z65v1v4"},{"post_id":"cjolov8k1001bae7bwfpk3s4z","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8p30048ae7bbukrv7a2"},{"post_id":"cjolov8k4001dae7bsu05nz7d","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8p5004aae7bjp6cuymm"},{"post_id":"cjolov8k6001gae7bd3ipqbws","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8pc004dae7bzc7bbtkf"},{"post_id":"cjolov8p6004bae7baoicr9jh","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8pe004fae7byacmt0se"},{"post_id":"cjolov8pc004eae7bogmqbnd3","tag_id":"cjolov8k8001jae7b5duz6dv3","_id":"cjolov8ph004iae7bnfaw1ye1"},{"post_id":"cjolov8k7001iae7b3rnetups","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8pj004kae7ba53fyqpw"},{"post_id":"cjolov8ka001lae7bk7j8zfo3","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8pm004nae7bj9lz101k"},{"post_id":"cjolov8ke001nae7by09pojvd","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8po004qae7bcil9mcvg"},{"post_id":"cjolov8kh001qae7bwsgprn9f","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8po004sae7bbfgesuz8"},{"post_id":"cjolov8km001sae7b6m37llp2","tag_id":"cjolov8or003wae7bw4gkklf6","_id":"cjolov8pp004uae7bdi114s38"},{"post_id":"cjolov8l4001vae7bcj5hxdco","tag_id":"cjolov8po004tae7b0feki4qj","_id":"cjolov8pq004wae7bxy9wguws"},{"post_id":"cjolov8l9001wae7bgag91bkt","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8ps004zae7bj7uwmemp"},{"post_id":"cjolov8l9001wae7bgag91bkt","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8pt0050ae7b0pq47l3j"},{"post_id":"cjolov8lb001yae7bvzheawrk","tag_id":"cjolov8po004tae7b0feki4qj","_id":"cjolov8px0052ae7bb1ytpm91"},{"post_id":"cjolov8ld0023ae7bre5rq59h","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8pz0054ae7btoj9gayo"},{"post_id":"cjolov8ld0023ae7bre5rq59h","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8pz0055ae7b59b8y4cf"},{"post_id":"cjolov8ly0025ae7bxo5xuz5p","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8q00057ae7bzin8mp8v"},{"post_id":"cjolov8ly0025ae7bxo5xuz5p","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8q10058ae7ba1nhfad9"},{"post_id":"cjolov8m00027ae7bav66cqr4","tag_id":"cjolov8k5001eae7bx3593i6c","_id":"cjolov8q2005bae7b5539afbz"},{"post_id":"cjolov8m00027ae7bav66cqr4","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8q2005cae7bljdsm5dx"},{"post_id":"cjolov8m00027ae7bav66cqr4","tag_id":"cjolov8q10059ae7bgx81ykmp","_id":"cjolov8q3005eae7by45zocqy"},{"post_id":"cjolov8mb0029ae7b14vfj77t","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8q5005hae7b89n71mpx"},{"post_id":"cjolov8mb0029ae7b14vfj77t","tag_id":"cjolov8q2005dae7buyaffhnb","_id":"cjolov8q5005iae7brwhr9axd"},{"post_id":"cjolov8mb0029ae7b14vfj77t","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8q6005kae7bha6her4z"},{"post_id":"cjolov8mf002cae7bum47b59i","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8q7005nae7bn4m8elx5"},{"post_id":"cjolov8mf002cae7bum47b59i","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8q7005oae7be4ikuey8"},{"post_id":"cjolov8mf002cae7bum47b59i","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8q8005qae7b4xxf1jjw"},{"post_id":"cjolov8mg002dae7b1y7wx9hn","tag_id":"cjolov8q7005mae7bikek1kc4","_id":"cjolov8q8005rae7b2ezie8mw"},{"post_id":"cjolov8mk002hae7b7lkun84d","tag_id":"cjolov8i40008ae7bw402vapg","_id":"cjolov8q9005tae7b8ek3akkb"},{"post_id":"cjolov8mk002hae7b7lkun84d","tag_id":"cjolov8q7005pae7bbv8iy7b8","_id":"cjolov8q9005uae7bpxrpg4is"},{"post_id":"cjolov8mw002pae7babfk8ifu","tag_id":"cjolov8q8005sae7b6k76eeou","_id":"cjolov8qa005wae7bsqw4wazp"},{"post_id":"cjolov8n1002uae7bgeqitutd","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qd0060ae7byxlmr8w8"},{"post_id":"cjolov8n1002uae7bgeqitutd","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qd0061ae7bxu0t19p7"},{"post_id":"cjolov8n1002uae7bgeqitutd","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8qe0063ae7b0jle6839"},{"post_id":"cjolov8n6002wae7bc4hh6bir","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qg0067ae7bp0hanuzs"},{"post_id":"cjolov8n6002wae7bc4hh6bir","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qg0068ae7b1a03cgyz"},{"post_id":"cjolov8n6002wae7bc4hh6bir","tag_id":"cjolov8qe0064ae7boewdl0ls","_id":"cjolov8qh006aae7b6gh09nw2"},{"post_id":"cjolov8n6002wae7bc4hh6bir","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8qh006bae7b4tq5zldm"},{"post_id":"cjolov8n9002zae7bqfhqzqqq","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qi006eae7b1aromrer"},{"post_id":"cjolov8n9002zae7bqfhqzqqq","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qi006fae7by3x42prc"},{"post_id":"cjolov8n9002zae7bqfhqzqqq","tag_id":"cjolov8qh006cae7bemc4pa97","_id":"cjolov8qj006hae7bczz6s91l"},{"post_id":"cjolov8nb0031ae7bhkjicr0v","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qm006kae7bo226x0yp"},{"post_id":"cjolov8nb0031ae7bhkjicr0v","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qm006lae7bzyobqjr9"},{"post_id":"cjolov8nb0031ae7bhkjicr0v","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8qn006nae7bdxn0e29t"},{"post_id":"cjolov8ne0034ae7by6q0ddm7","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qq006qae7bhne8kkm2"},{"post_id":"cjolov8ne0034ae7by6q0ddm7","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qq006rae7b4836ekeg"},{"post_id":"cjolov8ne0034ae7by6q0ddm7","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8qr006tae7bj9sdenqy"},{"post_id":"cjolov8nf0035ae7b7o3qxr04","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8qy006wae7bk5nkg96s"},{"post_id":"cjolov8nf0035ae7b7o3qxr04","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8qy006xae7b68409mw7"},{"post_id":"cjolov8nf0035ae7b7o3qxr04","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8qz006zae7b9naevex6"},{"post_id":"cjolov8ni0037ae7beh04md2o","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8r10072ae7bbiypui9p"},{"post_id":"cjolov8ni0037ae7beh04md2o","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8r10073ae7bynd7x7b8"},{"post_id":"cjolov8ni0037ae7beh04md2o","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8r20075ae7b9omuw748"},{"post_id":"cjolov8nm0039ae7bt3ify52z","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8r30078ae7bmsev54iw"},{"post_id":"cjolov8nm0039ae7bt3ify52z","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8r40079ae7b44d1ja96"},{"post_id":"cjolov8nm0039ae7bt3ify52z","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8r4007bae7b34f4o431"},{"post_id":"cjolov8np003cae7b7rgm79pn","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8r8007eae7b6n3mz8up"},{"post_id":"cjolov8np003cae7b7rgm79pn","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8ra007fae7b095mn1sf"},{"post_id":"cjolov8np003cae7b7rgm79pn","tag_id":"cjolov8q6005lae7b7j06czv5","_id":"cjolov8rc007hae7bmoidfld3"},{"post_id":"cjolov8nr003dae7bhjyys9z1","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8re007lae7bkybqx9pj"},{"post_id":"cjolov8nr003dae7bhjyys9z1","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8re007mae7b8uyes1rx"},{"post_id":"cjolov8nr003dae7bhjyys9z1","tag_id":"cjolov8qh006cae7bemc4pa97","_id":"cjolov8rf007oae7b3bdljk4g"},{"post_id":"cjolov8nr003dae7bhjyys9z1","tag_id":"cjolov8rd007jae7bxhkdmnqg","_id":"cjolov8rf007pae7brtfjz8gf"},{"post_id":"cjolov8nt003fae7b4i9vmrlx","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8rg007sae7bttjiln22"},{"post_id":"cjolov8nt003fae7b4i9vmrlx","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8rh007tae7b0297tkhy"},{"post_id":"cjolov8nt003fae7b4i9vmrlx","tag_id":"cjolov8rf007qae7bzlyfwbya","_id":"cjolov8rh007vae7bvfo6nbk0"},{"post_id":"cjolov8o0003mae7bp6yeh3em","tag_id":"cjolov8q10059ae7bgx81ykmp","_id":"cjolov8rh007wae7bc3bw1n1a"},{"post_id":"cjolov8o3003pae7bxei90rvh","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8rj007zae7bsq9e99b0"},{"post_id":"cjolov8o3003pae7bxei90rvh","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8rk0080ae7buvyobb0l"},{"post_id":"cjolov8o6003rae7b8ptocjcp","tag_id":"cjolov8q10059ae7bgx81ykmp","_id":"cjolov8rk0082ae7b520u7c3f"},{"post_id":"cjolov8oa003uae7bg5evygxs","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8rm0085ae7bss9bt4ds"},{"post_id":"cjolov8oa003uae7bg5evygxs","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8rm0086ae7blmkkbhe7"},{"post_id":"cjolov8os003xae7bmaehiowo","tag_id":"cjolov8q10059ae7bgx81ykmp","_id":"cjolov8rn0088ae7bolcu2zn7"},{"post_id":"cjolov8ou003zae7b3fivnp8w","tag_id":"cjolov8rm0087ae7blsakryij","_id":"cjolov8rp008bae7b6ncdi0op"},{"post_id":"cjolov8ou003zae7b3fivnp8w","tag_id":"cjolov8ro0089ae7bknzyqdxz","_id":"cjolov8rp008cae7b50ukzu17"},{"post_id":"cjolov8ow0041ae7bfr77xarj","tag_id":"cjolov8ro008aae7bu585hju3","_id":"cjolov8rp008eae7bpwykyq4n"},{"post_id":"cjolov8oz0044ae7b2tw23tyz","tag_id":"cjolov8ro008aae7bu585hju3","_id":"cjolov8rq008gae7b69f56r3t"},{"post_id":"cjolov8p10046ae7bmd4pfs4y","tag_id":"cjolov8j4000uae7bify69ikk","_id":"cjolov8rr008iae7bvr0bxi33"},{"post_id":"cjolov8p10046ae7bmd4pfs4y","tag_id":"cjolov8rq008fae7bg9ri4dvj","_id":"cjolov8rr008jae7bnznbn896"},{"post_id":"cjolov8pf004gae7bknk96n5x","tag_id":"cjolov8rr008hae7bt6klfp11","_id":"cjolov8rs008mae7bwwrs3ca6"},{"post_id":"cjolov8pf004gae7bknk96n5x","tag_id":"cjolov8rr008kae7bn2u2mqfe","_id":"cjolov8rs008nae7b45sv9n7r"},{"post_id":"cjolov8pi004jae7byslmsyv2","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjolov8rt008pae7bl7b2p1tb"},{"post_id":"cjolov8pi004jae7byslmsyv2","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8ru008qae7b74iocfq5"},{"post_id":"cjolov8pj004lae7b13xflkmn","tag_id":"cjolov8rd007jae7bxhkdmnqg","_id":"cjolov8rv008tae7b2bhyojc5"},{"post_id":"cjolov8pj004lae7b13xflkmn","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8rv008uae7bdtcgaj9c"},{"post_id":"cjolov8pm004oae7b9n42zyah","tag_id":"cjolov8pp004vae7bu60q89gm","_id":"cjolov8s3008yae7b60aooqg9"},{"post_id":"cjolov8pm004oae7b9n42zyah","tag_id":"cjolov8rd007jae7bxhkdmnqg","_id":"cjolov8s3008zae7bab88bj1u"},{"post_id":"cjolov8pm004oae7b9n42zyah","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjolov8s30090ae7bez24dh4w"},{"post_id":"cjolov8pm004oae7b9n42zyah","tag_id":"cjolov8qh006cae7bemc4pa97","_id":"cjolov8s40091ae7bnktzonbj"},{"post_id":"cjt10habq00014t7bk73bk6cy","tag_id":"cjolov8ho0004ae7bhh9o0nrr","_id":"cjt10nkvn00024t7bb5ullall"},{"post_id":"cjt10habq00014t7bk73bk6cy","tag_id":"cjolov8pr004xae7b7kuwlv5a","_id":"cjt10nkvo00034t7bfno1d6r5"}],"Tag":[{"name":"caffe","_id":"cjolov8ho0004ae7bhh9o0nrr"},{"name":"python","_id":"cjolov8i40008ae7bw402vapg"},{"name":"debug","_id":"cjolov8id000cae7bntfqfo9q"},{"name":"tool","_id":"cjolov8j4000uae7bify69ikk"},{"name":"cs131","_id":"cjolov8js0018ae7b60iyko0n"},{"name":"","_id":"cjolov8k5001eae7bx3593i6c"},{"name":"math","_id":"cjolov8k8001jae7b5duz6dv3"},{"name":"cs229","_id":"cjolov8nw003jae7bwdmgb1zt"},{"name":"cpp","_id":"cjolov8or003wae7bw4gkklf6"},{"name":"","_id":"cjolov8po004tae7b0feki4qj"},{"name":"paper","_id":"cjolov8pp004vae7bu60q89gm"},{"name":"deep learning","_id":"cjolov8pr004xae7b7kuwlv5a"},{"name":"pytorch","_id":"cjolov8q10059ae7bgx81ykmp"},{"name":"quantization","_id":"cjolov8q2005dae7buyaffhnb"},{"name":"model compression","_id":"cjolov8q6005lae7b7j06czv5"},{"name":"ubuntu","_id":"cjolov8q7005mae7bikek1kc4"},{"name":"qt","_id":"cjolov8q7005pae7bbv8iy7b8"},{"name":"mxnet","_id":"cjolov8q8005sae7b6k76eeou"},{"name":"model arch","_id":"cjolov8qe0064ae7boewdl0ls"},{"name":"detection","_id":"cjolov8qh006cae7bemc4pa97"},{"name":"yolo","_id":"cjolov8rd007jae7bxhkdmnqg"},{"name":"visulization","_id":"cjolov8rf007qae7bzlyfwbya"},{"name":"linux","_id":"cjolov8rm0087ae7blsakryij"},{"name":"shell","_id":"cjolov8ro0089ae7bknzyqdxz"},{"name":"reinforcement learning","_id":"cjolov8ro008aae7bu585hju3"},{"name":"doxygen","_id":"cjolov8rq008fae7bg9ri4dvj"},{"name":"vim","_id":"cjolov8rr008hae7bt6klfp11"},{"name":"tools","_id":"cjolov8rr008kae7bn2u2mqfe"}]}}